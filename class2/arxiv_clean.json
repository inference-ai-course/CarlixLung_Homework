[
  {
    "url": "https://arxiv.org/abs/2101.10848v1",
    "title": "Spark NLP: Natural Language Understanding at Scale",
    "abstract": "Spark NLP is a Natural Language Processing (NLP) library built on top of Apache Spark ML. It provides simple, performant and accurate NLP annotations for machine learning pipelines that can scale easily in a distributed environment. Spark NLP comes with 1100 pre trained pipelines and models in more than 192 languages. It supports nearly all the NLP tasks and modules that can be used seamlessly in a cluster. Downloaded more than 2.7 million times and experiencing nine times growth since January 2020, Spark NLP is used by 54% of healthcare organizations as the worlds most widely used NLP library in the enterprise.",
    "authors": [
      "Veysel Kocaman",
      "David Talby"
    ],
    "date": "[Submitted on 26 Jan 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2408.05664v1",
    "title": "Training an NLP Scholar at a Small Liberal Arts College: A Backwards Designed Course Proposal",
    "abstract": "The rapid growth in natural language processing (NLP) over the last couple years has generated student interest and excitement in learning more about the field. In this paper, we present two types of students that NLP courses might want to train. First, an \"NLP engineer\" who is able to flexibly design, build and apply new technologies in NLP for a wide range of tasks. Second, an \"NLP scholar\" who is able to pose, refine and answer questions in NLP and how it relates to the society, while also learning to effectively communicate these answers to a broader audience. While these two types of skills are not mutually exclusive -- NLP engineers should be able to think critically, and NLP scholars should be able to build systems -- we think that courses can differ in the balance of these skills. As educators at Small Liberal Arts Colleges, the strengths of our students and our institution favors an approach that is better suited to train NLP scholars. In this paper we articulate what kinds of skills an NLP scholar should have, and then adopt a backwards design to propose course components that can aid the acquisition of these skills.",
    "authors": [
      "Grusha Prasad",
      "Forrest Davis"
    ],
    "date": "[Submitted on 11 Aug 2024]"
  },
  {
    "url": "https://arxiv.org/abs/2304.02746v1",
    "title": "Sejarah dan Perkembangan Teknik Natural Language Processing (NLP) Bahasa Indonesia: Tinjauan tentang sejarah, perkembangan teknologi, dan aplikasi NLP dalam bahasa Indonesia",
    "abstract": "This study provides an overview of the history of the development of Natural Language Processing (NLP) in the context of the Indonesian language, with a focus on the basic technologies, methods, and practical applications that have been developed. This review covers developments in basic NLP technologies such as stemming, part-of-speech tagging, and related methods; practical applications in cross-language information retrieval systems, information extraction, and sentiment analysis; and methods and techniques used in Indonesian language NLP research, such as machine learning, statistics-based machine translation, and conflict-based approaches. This study also explores the application of NLP in Indonesian language industry and research and identifies challenges and opportunities in Indonesian language NLP research and development. Recommendations for future Indonesian language NLP research and development include developing more efficient methods and technologies, expanding NLP applications, increasing sustainability, further research into the potential of NLP, and promoting interdisciplinary collaboration. It is hoped that this review will help researchers, practitioners, and the government to understand the development of Indonesian language NLP and identify opportunities for further research and development.",
    "authors": [
      "Mukhlis Amien"
    ],
    "date": "[Submitted on 28 Mar 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2412.08520v1",
    "title": "GR-NLP-TOOLKIT: An Open-Source NLP Toolkit for Modern Greek",
    "abstract": "We present GR-NLP-TOOLKIT, an open-source natural language processing (NLP) toolkit developed specifically for modern Greek. The toolkit provides state-of-the-art performance in five core NLP tasks, namely part-of-speech tagging, morphological tagging, dependency parsing, named entity recognition, and Greeklishto-Greek transliteration. The toolkit is based on pre-trained Transformers, it is freely available, and can be easily installed in Python (pip install gr-nlp-toolkit). It is also accessible through a demonstration platform on HuggingFace, along with a publicly available API for non-commercial use. We discuss the functionality provided for each task, the underlying methods, experiments against comparable open-source toolkits, and future possible enhancements. The toolkit is available at: this https URL",
    "authors": [
      "Lefteris Loukas",
      "Nikolaos Smyrnioudis",
      "Chrysa Dikonomaki",
      "Spyros Barbakos",
      "Anastasios Toumazatos",
      "John Koutsikakis",
      "Manolis Kyriakakis",
      "Mary Georgiou",
      "Stavros Vassos",
      "John Pavlopoulos",
      "Ion Androutsopoulos"
    ],
    "date": "[Submitted on 11 Dec 2024]"
  },
  {
    "url": "https://arxiv.org/abs/2310.14346v1",
    "title": "The Law and NLP: Bridging Disciplinary Disconnects",
    "abstract": "Legal practice is intrinsically rooted in the fabric of language, yet legal practitioners and scholars have been slow to adopt tools from natural language processing (NLP). At the same time, the legal system is experiencing an access to justice crisis, which could be partially alleviated with NLP. In this position paper, we argue that the slow uptake of NLP in legal practice is exacerbated by a disconnect between the needs of the legal community and the focus of NLP researchers. In a review of recent trends in the legal NLP literature, we find limited overlap between the legal NLP community and legal academia. Our interpretation is that some of the most popular legal NLP tasks fail to address the needs of legal practitioners. We discuss examples of legal NLP tasks that promise to bridge disciplinary disconnects and highlight interesting areas for legal NLP research that remain underexplored.",
    "authors": [
      "Robert Mahari",
      "Dominik Stammbach",
      "Elliott Ash",
      "Alex 'Sandy' Pentland"
    ],
    "date": "[Submitted on 22 Oct 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2504.06669v1",
    "title": "NLP Security and Ethics, in the Wild",
    "abstract": "As NLP models are used by a growing number of end-users, an area of increasing importance is NLP Security (NLPSec): assessing the vulnerability of models to malicious attacks and developing comprehensive countermeasures against them. While work at the intersection of NLP and cybersecurity has the potential to create safer NLP for all, accidental oversights can result in tangible harm (e.g., breaches of privacy or proliferation of malicious models). In this emerging field, however, the research ethics of NLP have not yet faced many of the long-standing conundrums pertinent to cybersecurity, until now. We thus examine contemporary works across NLPSec, and explore their engagement with cybersecurity's ethical norms. We identify trends across the literature, ultimately finding alarming gaps on topics like harm minimization and responsible disclosure. To alleviate these concerns, we provide concrete recommendations to help NLP researchers navigate this space more ethically, bridging the gap between traditional cybersecurity and NLP ethics, which we frame as ``white hat NLP''. The goal of this work is to help cultivate an intentional culture of ethical research for those working in NLP Security.",
    "authors": [
      "Heather Lent",
      "Erick Galinkin",
      "Yiyi Chen",
      "Jens Myrup Pedersen",
      "Leon Derczynski",
      "Johannes Bjerva"
    ],
    "date": "[Submitted on 9 Apr 2025]"
  },
  {
    "url": "https://arxiv.org/abs/2010.03061v1",
    "title": "A Survey on Recognizing Textual Entailment as an NLP Evaluation",
    "abstract": "Recognizing Textual Entailment (RTE) was proposed as a unified evaluation framework to compare semantic understanding of different NLP systems. In this survey paper, we provide an overview of different approaches for evaluating and understanding the reasoning capabilities of NLP systems. We then focus our discussion on RTE by highlighting prominent RTE datasets as well as advances in RTE dataset that focus on specific linguistic phenomena that can be used to evaluate NLP systems on a fine-grained level. We conclude by arguing that when evaluating NLP systems, the community should utilize newly introduced RTE datasets that focus on specific linguistic phenomena.",
    "authors": [
      "Adam Poliak"
    ],
    "date": "[Submitted on 6 Oct 2020]"
  },
  {
    "url": "https://arxiv.org/abs/2106.11410v2",
    "title": "A Survey of Race, Racism, and Anti-Racism in NLP",
    "abstract": "Despite inextricable ties between race and language, little work has considered race in NLP research and development. In this work, we survey 79 papers from the ACL anthology that mention race. These papers reveal various types of race-related bias in all stages of NLP model development, highlighting the need for proactive consideration of how NLP systems can uphold racial hierarchies. However, persistent gaps in research on race and NLP remain: race has been siloed as a niche topic and remains ignored in many NLP tasks; most work operationalizes race as a fixed single-dimensional variable with a ground-truth label, which risks reinforcing differences produced by historical racism; and the voices of historically marginalized people are nearly absent in NLP literature. By identifying where and how NLP literature has and has not considered race, especially in comparison to related fields, our work calls for inclusion and racial justice in NLP research practices.",
    "authors": [
      "Anjalie Field",
      "Su Lin Blodgett",
      "Zeerak Waseem",
      "Yulia Tsvetkov"
    ],
    "date": "[Submitted on 21 Jun 2021 (v1), last revised 15 Jul 2021 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2410.14194v1",
    "title": "Speciesism in Natural Language Processing Research",
    "abstract": "Natural Language Processing (NLP) research on AI Safety and social bias in AI has focused on safety for humans and social bias against human minorities. However, some AI ethicists have argued that the moral significance of nonhuman animals has been ignored in AI research. Therefore, the purpose of this study is to investigate whether there is speciesism, i.e., discrimination against nonhuman animals, in NLP research. First, we explain why nonhuman animals are relevant in NLP research. Next, we survey the findings of existing research on speciesism in NLP researchers, data, and models and further investigate this problem in this study. The findings of this study suggest that speciesism exists within researchers, data, and models, respectively. Specifically, our survey and experiments show that (a) among NLP researchers, even those who study social bias in AI, do not recognize speciesism or speciesist bias; (b) among NLP data, speciesist bias is inherent in the data annotated in the datasets used to evaluate NLP models; (c) OpenAI GPTs, recent NLP models, exhibit speciesist bias by default. Finally, we discuss how we can reduce speciesism in NLP research.",
    "authors": [
      "Masashi Takeshita",
      "Rafal Rzepka"
    ],
    "date": "[Submitted on 18 Oct 2024]"
  },
  {
    "url": "https://arxiv.org/abs/2412.04784v2",
    "title": "NLP-ADBench: NLP Anomaly Detection Benchmark",
    "abstract": "Anomaly detection (AD) is an important machine learning task with applications in fraud detection, content moderation, and user behavior analysis. However, AD is relatively understudied in a natural language processing (NLP) context, limiting its effectiveness in detecting harmful content, phishing attempts, and spam reviews. We introduce NLP-ADBench, the most comprehensive NLP anomaly detection (NLP-AD) benchmark to date, which includes eight curated datasets and 19 state-of-the-art algorithms. These span 3 end-to-end methods and 16 two-step approaches that adapt classical, non-AD methods to language embeddings from BERT and OpenAI. Our empirical results show that no single model dominates across all datasets, indicating a need for automated model selection. Moreover, two-step methods with transformer-based embeddings consistently outperform specialized end-to-end approaches, with OpenAI embeddings outperforming those of BERT. We release NLP-ADBench at this https URL, providing a unified framework for NLP-AD and supporting future investigations.",
    "authors": [
      "Yuangang Li",
      "Jiaqi Li",
      "Zhuo Xiao",
      "Tiankai Yang",
      "Yi Nian",
      "Xiyang Hu",
      "Yue Zhao"
    ],
    "date": "[Submitted on 6 Dec 2024 (v1), last revised 9 Oct 2025 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2201.08066v2",
    "title": "NLP Methods in Host-based Intrusion Detection Systems: A Systematic Review and Future Directions",
    "abstract": "Host based Intrusion Detection System (HIDS) is an effective last line of defense for defending against cyber security attacks after perimeter defenses (e.g., Network based Intrusion Detection System and Firewall) have failed or been bypassed. HIDS is widely adopted in the industry as HIDS is ranked among the top two most used security tools by Security Operation Centers (SOC) of organizations. Although effective and efficient HIDS is highly desirable for industrial organizations, the evolution of increasingly complex attack patterns causes several challenges resulting in performance degradation of HIDS (e.g., high false alert rate creating alert fatigue for SOC staff). Since Natural Language Processing (NLP) methods are better suited for identifying complex attack patterns, an increasing number of HIDS are leveraging the advances in NLP that have shown effective and efficient performance in precisely detecting low footprint, zero day attacks and predicting the next steps of attackers. This active research trend of using NLP in HIDS demands a synthesized and comprehensive body of knowledge of NLP based HIDS. Thus, we conducted a systematic review of the literature on the end to end pipeline of the use of NLP in HIDS development. For the end to end NLP based HIDS development pipeline, we identify, taxonomically categorize and systematically compare the state of the art of NLP methods usage in HIDS, attacks detected by these NLP methods, datasets and evaluation metrics which are used to evaluate the NLP based HIDS. We highlight the relevant prevalent practices, considerations, advantages and limitations to support the HIDS developers. We also outline the future research directions for the NLP based HIDS development.",
    "authors": [
      "Zarrin Tasnim Sworna",
      "Zahra Mousavi",
      "Muhammad Ali Babar"
    ],
    "date": "[Submitted on 20 Jan 2022 (v1), last revised 19 Nov 2022 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2310.14870v3",
    "title": "We are Who We Cite: Bridges of Influence Between Natural Language Processing and Other Academic Fields",
    "abstract": "Natural Language Processing (NLP) is poised to substantially influence the world. However, significant progress comes hand-in-hand with substantial risks. Addressing them requires broad engagement with various fields of study. Yet, little empirical work examines the state of such engagement (past or current). In this paper, we quantify the degree of influence between 23 fields of study and NLP (on each other). We analyzed ~77k NLP papers, ~3.1m citations from NLP papers to other papers, and ~1.8m citations from other papers to NLP papers. We show that, unlike most fields, the cross-field engagement of NLP, measured by our proposed Citation Field Diversity Index (CFDI), has declined from 0.58 in 1980 to 0.31 in 2022 (an all-time low). In addition, we find that NLP has grown more insular -- citing increasingly more NLP papers and having fewer papers that act as bridges between fields. NLP citations are dominated by computer science; Less than 8% of NLP citations are to linguistics, and less than 3% are to math and psychology. These findings underscore NLP's urgent need to reflect on its engagement with various fields.",
    "authors": [
      "Jan Philip Wahle",
      "Terry Ruas",
      "Mohamed Abdalla",
      "Bela Gipp",
      "Saif M. Mohammad"
    ],
    "date": "[Submitted on 23 Oct 2023 (v1), last revised 16 Jul 2024 (this version, v3)]"
  },
  {
    "url": "https://arxiv.org/abs/2410.22937v1",
    "title": "Thoughtful Adoption of NLP for Civic Participation: Understanding Differences Among Policymakers",
    "abstract": "Natural language processing (NLP) tools have the potential to boost civic participation and enhance democratic processes because they can significantly increase governments' capacity to gather and analyze citizen opinions. However, their adoption in government remains limited, and harnessing their benefits while preventing unintended consequences remains a challenge. While prior work has focused on improving NLP performance, this work examines how different internal government stakeholders influence NLP tools' thoughtful adoption. We interviewed seven politicians (politically appointed officials as heads of government institutions) and thirteen public servants (career government employees who design and administrate policy interventions), inquiring how they choose whether and how to use NLP tools to support civic participation processes. The interviews suggest that policymakers across both groups focused on their needs for career advancement and the need to showcase the legitimacy and fairness of their work when considering NLP tool adoption and use. Because these needs vary between politicians and public servants, their preferred NLP features and tool designs also differ. Interestingly, despite their differing needs and opinions, neither group clearly identifies who should advocate for NLP adoption to enhance civic participation or address the unintended consequences of a poorly considered adoption. This lack of clarity in responsibility might have caused the governments' low adoption of NLP tools. We discuss how these findings reveal new insights for future HCI research. They inform the design of NLP tools for increasing civic participation efficiency and capacity, the design of other tools and methods that ensure thoughtful adoption of AI tools in government, and the design of NLP tools for collaborative use among users with different incentives and needs.",
    "authors": [
      "Jose A. Guridi",
      "Cristobal Cheyre",
      "Qian Yang"
    ],
    "date": "[Submitted on 30 Oct 2024]"
  },
  {
    "url": "https://arxiv.org/abs/2104.07874v1",
    "title": "Translational NLP: A New Paradigm and General Principles for Natural Language Processing Research",
    "abstract": "Natural language processing (NLP) research combines the study of universal principles, through basic science, with applied science targeting specific use cases and settings. However, the process of exchange between basic NLP and applications is often assumed to emerge naturally, resulting in many innovations going unapplied and many important questions left unstudied. We describe a new paradigm of Translational NLP, which aims to structure and facilitate the processes by which basic and applied NLP research inform one another. Translational NLP thus presents a third research paradigm, focused on understanding the challenges posed by application needs and how these challenges can drive innovation in basic science and technology design. We show that many significant advances in NLP research have emerged from the intersection of basic principles with application needs, and present a conceptual framework outlining the stakeholders and key questions in translational research. Our framework provides a roadmap for developing Translational NLP as a dedicated research area, and identifies general translational principles to facilitate exchange between basic and applied research.",
    "authors": [
      "Denis Newman-Griffis",
      "Jill Fain Lehman",
      "Carolyn Ros\u00e9",
      "Harry Hochheiser"
    ],
    "date": "[Submitted on 16 Apr 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2105.13704v1",
    "title": "Natural Language Processing 4 All (NLP4All): A New Online Platform for Teaching and Learning NLP Concepts",
    "abstract": "Natural Language Processing offers new insights into language data across almost all disciplines and domains, and allows us to corroborate and/or challenge existing knowledge. The primary hurdles to widening participation in and use of these new research tools are, first, a lack of coding skills in students across K-16, and in the population at large, and second, a lack of knowledge of how NLP-methods can be used to answer questions of disciplinary interest outside of linguistics and/or computer science. To broaden participation in NLP and improve NLP-literacy, we introduced a new tool web-based tool called Natural Language Processing 4 All (NLP4All). The intended purpose of NLP4All is to help teachers facilitate learning with and about NLP, by providing easy-to-use interfaces to NLP-methods, data, and analyses, making it possible for non- and novice-programmers to learn NLP concepts interactively.",
    "authors": [
      "Rebekah Baglini",
      "Arthur Hjorth"
    ],
    "date": "[Submitted on 28 May 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2204.04282v1",
    "title": "Classification of Natural Language Processing Techniques for Requirements Engineering",
    "abstract": "Research in applying natural language processing (NLP) techniques to requirements engineering (RE) tasks spans more than 40 years, from initial efforts carried out in the 1980s to more recent attempts with machine learning (ML) and deep learning (DL) techniques. However, in spite of the progress, our recent survey shows that there is still a lack of systematic understanding and organization of commonly used NLP techniques in RE. We believe one hurdle facing the industry is lack of shared knowledge of NLP techniques and their usage in RE tasks. In this paper, we present our effort to synthesize and organize 57 most frequently used NLP techniques in RE. We classify these NLP techniques in two ways: first, by their NLP tasks in typical pipelines and second, by their linguist analysis levels. We believe these two ways of classification are complementary, contributing to a better understanding of the NLP techniques in RE and such understanding is crucial to the development of better NLP tools for RE.",
    "authors": [
      "Liping Zhao",
      "Waad Alhoshan",
      "Alessio Ferrari",
      "Keletso J. Letsholo"
    ],
    "date": "[Submitted on 8 Apr 2022]"
  },
  {
    "url": "https://arxiv.org/abs/1808.09772v2",
    "title": "Notes on Deep Learning for NLP",
    "abstract": "My notes on Deep Learning for NLP.",
    "authors": [
      "Antoine J.-P. Tixier"
    ],
    "date": "[Submitted on 29 Aug 2018 (v1), last revised 30 Aug 2018 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2207.10524v2",
    "title": "NusaCrowd: A Call for Open and Reproducible NLP Research in Indonesian Languages",
    "abstract": "At the center of the underlying issues that halt Indonesian natural language processing (NLP) research advancement, we find data scarcity. Resources in Indonesian languages, especially the local ones, are extremely scarce and underrepresented. Many Indonesian researchers do not publish their dataset. Furthermore, the few public datasets that we have are scattered across different platforms, thus makes performing reproducible and data-centric research in Indonesian NLP even more arduous. Rising to this challenge, we initiate the first Indonesian NLP crowdsourcing effort, NusaCrowd. NusaCrowd strives to provide the largest datasheets aggregation with standardized data loading for NLP tasks in all Indonesian languages. By enabling open and centralized access to Indonesian NLP resources, we hope NusaCrowd can tackle the data scarcity problem hindering NLP progress in Indonesia and bring NLP practitioners to move towards collaboration.",
    "authors": [
      "Samuel Cahyawijaya",
      "Alham Fikri Aji",
      "Holy Lovenia",
      "Genta Indra Winata",
      "Bryan Wilie",
      "Rahmad Mahendra",
      "Fajri Koto",
      "David Moeljadi",
      "Karissa Vincentio",
      "Ade Romadhony",
      "Ayu Purwarianti"
    ],
    "date": "[Submitted on 21 Jul 2022 (v1), last revised 1 Aug 2022 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2304.01467v1",
    "title": "A Partial Exact Penalty Function Approach for Constrained Optimization",
    "abstract": "In this paper, we focus on a class of constrained nonlinear optimization problems (NLP), where some of its equality constraints define a closed embedded submanifold $\\mathcal{M}$ in $\\mathbb{R}^n$. Although NLP can be solved directly by various existing approaches for constrained optimization in Euclidean space, these approaches usually fail to recognize the manifold structure of $\\mathcal{M}$. To achieve better efficiency by utilizing the manifold structure of $\\mathcal{M}$ in directly applying these existing optimization approaches, we propose a partial penalty function approach for NLP. In our proposed penalty function approach, we transform NLP into the corresponding constraint dissolving problem (CDP) in the Euclidean space, where the constraints that define $\\mathcal{M}$ are eliminated through exact penalization. We establish the relationships on the constraint qualifications between NLP and CDP, and prove that NLP and CDP have the same stationary points and KKT points in a neighborhood of the feasible region under mild conditions. Therefore, various existing optimization approaches developed for constrained optimization in the Euclidean space can be directly applied to solve NLP through CDP. Preliminary numerical experiments demonstrate that by dissolving the constraints that define $\\mathcal{M}$, CDP gains superior computational efficiency when compared to directly applying existing optimization approaches to solve NLP, especially in high dimensional scenarios.",
    "authors": [
      "Nachuan Xiao",
      "Xin Liu",
      "Kim-Chuan Toh"
    ],
    "date": "[Submitted on 4 Apr 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2310.01603v1",
    "title": "A Review of Digital Learning Environments for Teaching Natural Language Processing in K-12 Education",
    "abstract": "Natural Language Processing (NLP) plays a significant role in our daily lives and has become an essential part of Artificial Intelligence (AI) education in K-12. As children grow up with NLP-powered applications, it is crucial to introduce NLP concepts to them, fostering their understanding of language processing, language generation, and ethical implications of AI and NLP. This paper presents a comprehensive review of digital learning environments for teaching NLP in K-12. Specifically, it explores existing digital learning tools, discusses how they support specific NLP tasks and procedures, and investigates their explainability and evaluation results in educational contexts. By examining the strengths and limitations of these tools, this literature review sheds light on the current state of NLP learning tools in K-12 education. It aims to guide future research efforts to refine existing tools, develop new ones, and explore more effective and inclusive strategies for integrating NLP into K-12 educational contexts.",
    "authors": [
      "Xiaoyi Tian",
      "Kristy Elizabeth Boyer"
    ],
    "date": "[Submitted on 2 Oct 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2206.14181v1",
    "title": "The NLP Sandbox: an efficient model-to-data system to enable federated and unbiased evaluation of clinical NLP models",
    "abstract": "Objective The evaluation of natural language processing (NLP) models for clinical text de-identification relies on the availability of clinical notes, which is often restricted due to privacy concerns. The NLP Sandbox is an approach for alleviating the lack of data and evaluation frameworks for NLP models by adopting a federated, model-to-data approach. This enables unbiased federated model evaluation without the need for sharing sensitive data from multiple institutions. Materials and Methods We leveraged the Synapse collaborative framework, containerization software, and OpenAPI generator to build the NLP Sandbox (this http URL). We evaluated two state-of-the-art NLP de-identification focused annotation models, Philter and NeuroNER, using data from three institutions. We further validated model performance using data from an external validation site. Results We demonstrated the usefulness of the NLP Sandbox through de-identification clinical model evaluation. The external developer was able to incorporate their model into the NLP Sandbox template and provide user experience feedback. Discussion We demonstrated the feasibility of using the NLP Sandbox to conduct a multi-site evaluation of clinical text de-identification models without the sharing of data. Standardized model and data schemas enable smooth model transfer and implementation. To generalize the NLP Sandbox, work is required on the part of data owners and model developers to develop suitable and standardized schemas and to adapt their data or model to fit the schemas. Conclusions The NLP Sandbox lowers the barrier to utilizing clinical data for NLP model evaluation and facilitates federated, multi-site, unbiased evaluation of NLP models.",
    "authors": [
      "Yao Yan",
      "Thomas Yu",
      "Kathleen Muenzen",
      "Sijia Liu",
      "Connor Boyle",
      "George Koslowski",
      "Jiaxin Zheng",
      "Nicholas Dobbins",
      "Clement Essien",
      "Hongfang Liu",
      "Larsson Omberg",
      "Meliha Yestigen",
      "Bradley Taylor",
      "James A Eddy",
      "Justin Guinney",
      "Sean Mooney",
      "Thomas Schaffter"
    ],
    "date": "[Submitted on 28 Jun 2022]"
  },
  {
    "url": "https://arxiv.org/abs/1409.2073v1",
    "title": "An NLP Assistant for Clide",
    "abstract": "This report describes an NLP assistant for the collaborative development environment Clide, that supports the development of NLP applications by providing easy access to some common NLP data structures. The assistant visualizes text fragments and their dependencies by displaying the semantic graph of a sentence, the coreference chain of a paragraph and mined triples that are extracted from a paragraph's semantic graphs and linked using its coreference chain. Using this information and a logic programming library, we create an NLP database which is used by a series of queries to mine the triples. The algorithm is tested by translating a natural language text describing a graph to an actual graph that is shown as an annotation in the text editor.",
    "authors": [
      "Tobias Kortkamp"
    ],
    "date": "[Submitted on 7 Sep 2014]"
  },
  {
    "url": "https://arxiv.org/abs/2109.11326v1",
    "title": "The Current State of Finnish NLP",
    "abstract": "There are a lot of tools and resources available for processing Finnish. In this paper, we survey recent papers focusing on Finnish NLP related to many different subcategories of NLP such as parsing, generation, semantics and speech. NLP research is conducted in many different research groups in Finland, and it is frequently the case that NLP tools and models resulting from academic research are made available for others to use on platforms such as Github.",
    "authors": [
      "Mika H\u00e4m\u00e4l\u00e4inen",
      "Khalid Alnajjar"
    ],
    "date": "[Submitted on 23 Sep 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2302.02016v1",
    "title": "Improving Interpretability via Explicit Word Interaction Graph Layer",
    "abstract": "Recent NLP literature has seen growing interest in improving model interpretability. Along this direction, we propose a trainable neural network layer that learns a global interaction graph between words and then selects more informative words using the learned word interactions. Our layer, we call WIGRAPH, can plug into any neural network-based NLP text classifiers right after its word embedding layer. Across multiple SOTA NLP models and various NLP datasets, we demonstrate that adding the WIGRAPH layer substantially improves NLP models' interpretability and enhances models' prediction performance at the same time.",
    "authors": [
      "Arshdeep Sekhon",
      "Hanjie Chen",
      "Aman Shrivastava",
      "Zhe Wang",
      "Yangfeng Ji",
      "Yanjun Qi"
    ],
    "date": "[Submitted on 3 Feb 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2308.13089v1",
    "title": "Towards a Holistic Approach: Understanding Sociodemographic Biases in NLP Models using an Interdisciplinary Lens",
    "abstract": "The rapid growth in the usage and applications of Natural Language Processing (NLP) in various sociotechnical solutions has highlighted the need for a comprehensive understanding of bias and its impact on society. While research on bias in NLP has expanded, several challenges persist that require attention. These include the limited focus on sociodemographic biases beyond race and gender, the narrow scope of analysis predominantly centered on models, and the technocentric implementation approaches. This paper addresses these challenges and advocates for a more interdisciplinary approach to understanding bias in NLP. The work is structured into three facets, each exploring a specific aspect of bias in NLP.",
    "authors": [
      "Pranav Narayanan Venkit"
    ],
    "date": "[Submitted on 24 Aug 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2310.20121v1",
    "title": "Ling-CL: Understanding NLP Models through Linguistic Curricula",
    "abstract": "We employ a characterization of linguistic complexity from psycholinguistic and language acquisition research to develop data-driven curricula to understand the underlying linguistic knowledge that models learn to address NLP tasks. The novelty of our approach is in the development of linguistic curricula derived from data, existing knowledge about linguistic complexity, and model behavior during training. By analyzing several benchmark NLP datasets, our curriculum learning approaches identify sets of linguistic metrics (indices) that inform the challenges and reasoning required to address each task. Our work will inform future research in all NLP areas, allowing linguistic complexity to be considered early in the research and development process. In addition, our work prompts an examination of gold standards and fair evaluation in NLP.",
    "authors": [
      "Mohamed Elgaar",
      "Hadi Amiri"
    ],
    "date": "[Submitted on 31 Oct 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2406.06021v1",
    "title": "Shoulders of Giants: A Look at the Degree and Utility of Openness in NLP Research",
    "abstract": "We analysed a sample of NLP research papers archived in ACL Anthology as an attempt to quantify the degree of openness and the benefit of such an open culture in the NLP community. We observe that papers published in different NLP venues show different patterns related to artefact reuse. We also note that more than 30% of the papers we analysed do not release their artefacts publicly, despite promising to do so. Further, we observe a wide language-wise disparity in publicly available NLP-related artefacts.",
    "authors": [
      "Surangika Ranathunga",
      "Nisansa de Silva",
      "Dilith Jayakody",
      "Aloka Fernando"
    ],
    "date": "[Submitted on 10 Jun 2024]"
  },
  {
    "url": "https://arxiv.org/abs/2107.06785v2",
    "title": "Large-Scale News Classification using BERT Language Model: Spark NLP Approach",
    "abstract": "The rise of big data analytics on top of NLP increases the computational burden for text processing at scale. The problems faced in NLP are very high dimensional text, so it takes a high computation resource. The MapReduce allows parallelization of large computations and can improve the efficiency of text processing. This research aims to study the effect of big data processing on NLP tasks based on a deep learning approach. We classify a big text of news topics with fine-tuning BERT used pre-trained models. Five pre-trained models with a different number of parameters were used in this study. To measure the efficiency of this method, we compared the performance of the BERT with the pipelines from Spark NLP. The result shows that BERT without Spark NLP gives higher accuracy compared to BERT with Spark NLP. The accuracy average and training time of all models using BERT is 0.9187 and 35 minutes while using BERT with Spark NLP pipeline is 0.8444 and 9 minutes. The bigger model will take more computation resources and need a longer time to complete the tasks. However, the accuracy of BERT with Spark NLP only decreased by an average of 5.7%, while the training time was reduced significantly by 62.9% compared to BERT without Spark NLP.",
    "authors": [
      "Kuncahyo Setyo Nugroho",
      "Anantha Yullian Sukmadewa",
      "Novanto Yudistira"
    ],
    "date": "[Submitted on 14 Jul 2021 (v1), last revised 15 Jul 2021 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2106.02359v3",
    "title": "How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social Impact",
    "abstract": "Recent years have seen many breakthroughs in natural language processing (NLP), transitioning it from a mostly theoretical field to one with many real-world applications. Noting the rising number of applications of other machine learning and AI techniques with pervasive societal impact, we anticipate the rising importance of developing NLP technologies for social good. Inspired by theories in moral philosophy and global priorities research, we aim to promote a guideline for social good in the context of NLP. We lay the foundations via the moral philosophy definition of social good, propose a framework to evaluate the direct and indirect real-world impact of NLP tasks, and adopt the methodology of global priorities research to identify priority causes for NLP research. Finally, we use our theoretical framework to provide some practical guidelines for future NLP research for social good. Our data and code are available at this http URL. In addition, we curate a list of papers and resources on NLP for social good at this https URL.",
    "authors": [
      "Zhijing Jin",
      "Geeticka Chauhan",
      "Brian Tse",
      "Mrinmaya Sachan",
      "Rada Mihalcea"
    ],
    "date": "[Submitted on 4 Jun 2021 (v1), last revised 18 Jan 2023 (this version, v3)]"
  },
  {
    "url": "https://arxiv.org/abs/2409.19505v2",
    "title": "The Nature of NLP: Analyzing Contributions in NLP Papers",
    "abstract": "Natural Language Processing (NLP) is an established and dynamic field. Despite this, what constitutes NLP research remains debated. In this work, we address the question by quantitatively examining NLP research papers. We propose a taxonomy of research contributions and introduce NLPContributions, a dataset of nearly $2k$ NLP research paper abstracts, carefully annotated to identify scientific contributions and classify their types according to this taxonomy. We also introduce a novel task of automatically identifying contribution statements and classifying their types from research papers. We present experimental results for this task and apply our model to $\\sim$$29k$ NLP research papers to analyze their contributions, aiding in the understanding of the nature of NLP research. We show that NLP research has taken a winding path -- with the focus on language and human-centric studies being prominent in the 1970s and 80s, tapering off in the 1990s and 2000s, and starting to rise again since the late 2010s. Alongside this revival, we observe a steady rise in dataset and methodological contributions since the 1990s, such that today, on average, individual NLP papers contribute in more ways than ever before. Our dataset and analyses offer a powerful lens for tracing research trends and offer potential for generating informed, data-driven literature surveys.",
    "authors": [
      "Aniket Pramanick",
      "Yufang Hou",
      "Saif M. Mohammad",
      "Iryna Gurevych"
    ],
    "date": "[Submitted on 29 Sep 2024 (v1), last revised 1 Jun 2025 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2411.14463v1",
    "title": "Leveraging AI and NLP for Bank Marketing: A Systematic Review and Gap Analysis",
    "abstract": "This paper explores the growing impact of AI and NLP in bank marketing, highlighting their evolving roles in enhancing marketing strategies, improving customer engagement, and creating value within this sector. While AI and NLP have been widely studied in general marketing, there is a notable gap in understanding their specific applications and potential within the banking sector. This research addresses this specific gap by providing a systematic review and strategic analysis of AI and NLP applications in bank marketing, focusing on their integration across the customer journey and operational excellence. Employing the PRISMA methodology, this study systematically reviews existing literature to assess the current landscape of AI and NLP in bank marketing. Additionally, it incorporates semantic mapping using Sentence Transformers and UMAP for strategic gap analysis to identify underexplored areas and opportunities for future research.\nThe systematic review reveals limited research specifically focused on NLP applications in bank marketing. The strategic gap analysis identifies key areas where NLP can further enhance marketing strategies, including customer-centric applications like acquisition, retention, and personalized engagement, offering valuable insights for both academic research and practical implementation. This research contributes to the field of bank marketing by mapping the current state of AI and NLP applications and identifying strategic gaps. The findings provide actionable insights for developing NLP-driven growth and innovation frameworks and highlight the role of NLP in improving operational efficiency and regulatory compliance. This work has broader implications for enhancing customer experience, profitability, and innovation in the banking industry.",
    "authors": [
      "Christopher Gerling",
      "Stefan Lessmann"
    ],
    "date": "[Submitted on 17 Nov 2024]"
  },
  {
    "url": "https://arxiv.org/abs/2105.00895v1",
    "title": "Teaching NLP outside Linguistics and Computer Science classrooms: Some challenges and some opportunities",
    "abstract": "NLP's sphere of influence went much beyond computer science research and the development of software applications in the past decade. We see people using NLP methods in a range of academic disciplines from Asian Studies to Clinical Oncology. We also notice the presence of NLP as a module in most of the data science curricula within and outside of regular university setups. These courses are taken by students from very diverse backgrounds. This paper takes a closer look at some issues related to teaching NLP to these diverse audiences based on my classroom experiences, and identifies some challenges the instructors face, particularly when there is no ecosystem of related courses for the students. In this process, it also identifies a few challenge areas for both NLP researchers and tool developers.",
    "authors": [
      "Sowmya Vajjala"
    ],
    "date": "[Submitted on 3 May 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2007.09134v1",
    "title": "A Systematic Review of Natural Language Processing for Knowledge Management in Healthcare",
    "abstract": "Driven by the visions of Data Science, recent years have seen a paradigm shift in Natural Language Processing (NLP). NLP has set the milestone in text processing and proved to be the preferred choice for researchers in the healthcare domain. The objective of this paper is to identify the potential of NLP, especially, how NLP is used to support the knowledge management process in the healthcare domain, making data a critical and trusted component in improving the health outcomes. This paper provides a comprehensive survey of the state-of-the-art NLP research with a particular focus on how knowledge is created, captured, shared, and applied in the healthcare domain. Our findings suggest, first, the techniques of NLP those supporting knowledge management extraction and knowledge capture processes in healthcare. Second, we propose a conceptual model for the knowledge extraction process through NLP. Finally, we discuss a set of issues, challenges, and proposed future research areas.",
    "authors": [
      "Ganga Prasad Basyal",
      "Bhaskar P. Rimal",
      "David Zeng"
    ],
    "date": "[Submitted on 17 Jul 2020]"
  },
  {
    "url": "https://arxiv.org/abs/2106.07410v1",
    "title": "Model Explainability in Deep Learning Based Natural Language Processing",
    "abstract": "Machine learning (ML) model explainability has received growing attention, especially in the area related to model risk and regulations. In this paper, we reviewed and compared some popular ML model explainability methodologies, especially those related to Natural Language Processing (NLP) models. We then applied one of the NLP explainability methods Layer-wise Relevance Propagation (LRP) to a NLP classification model. We used the LRP method to derive a relevance score for each word in an instance, which is a local explainability. The relevance scores are then aggregated together to achieve global variable importance of the model. Through the case study, we also demonstrated how to apply the local explainability method to false positive and false negative instances to discover the weakness of a NLP model. These analysis can help us to understand NLP models better and reduce the risk due to the black-box nature of NLP models. We also identified some common issues due to the special natures of NLP models and discussed how explainability analysis can act as a control to detect these issues after the model has been trained.",
    "authors": [
      "Shafie Gholizadeh",
      "Nengfeng Zhou"
    ],
    "date": "[Submitted on 14 Jun 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2106.07499v1",
    "title": "An Empirical Survey of Data Augmentation for Limited Data Learning in NLP",
    "abstract": "NLP has achieved great progress in the past decade through the use of neural models and large labeled datasets. The dependence on abundant data prevents NLP models from being applied to low-resource settings or novel tasks where significant time, money, or expertise is required to label massive amounts of textual data. Recently, data augmentation methods have been explored as a means of improving data efficiency in NLP. To date, there has been no systematic empirical overview of data augmentation for NLP in the limited labeled data setting, making it difficult to understand which methods work in which settings. In this paper, we provide an empirical survey of recent progress on data augmentation for NLP in the limited labeled data setting, summarizing the landscape of methods (including token-level augmentations, sentence-level augmentations, adversarial augmentations, and hidden-space augmentations) and carrying out experiments on 11 datasets covering topics/news classification, inference tasks, paraphrasing tasks, and single-sentence tasks. Based on the results, we draw several conclusions to help practitioners choose appropriate augmentations in different settings and discuss the current challenges and future directions for limited data learning in NLP.",
    "authors": [
      "Jiaao Chen",
      "Derek Tam",
      "Colin Raffel",
      "Mohit Bansal",
      "Diyi Yang"
    ],
    "date": "[Submitted on 14 Jun 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2109.00544v2",
    "title": "Towards Improving Adversarial Training of NLP Models",
    "abstract": "Adversarial training, a method for learning robust deep neural networks, constructs adversarial examples during training. However, recent methods for generating NLP adversarial examples involve combinatorial search and expensive sentence encoders for constraining the generated instances. As a result, it remains challenging to use vanilla adversarial training to improve NLP models' performance, and the benefits are mainly uninvestigated. This paper proposes a simple and improved vanilla adversarial training process for NLP models, which we name Attacking to Training (A2T). The core part of A2T is a new and cheaper word substitution attack optimized for vanilla adversarial training. We use A2T to train BERT and RoBERTa models on IMDB, Rotten Tomatoes, Yelp, and SNLI datasets. Our results empirically show that it is possible to train robust NLP models using a much cheaper adversary. We demonstrate that vanilla adversarial training with A2T can improve an NLP model's robustness to the attack it was originally trained with and also defend the model against other types of word substitution attacks. Furthermore, we show that A2T can improve NLP models' standard accuracy, cross-domain generalization, and interpretability. Code is available at this https URL .",
    "authors": [
      "Jin Yong Yoo",
      "Yanjun Qi"
    ],
    "date": "[Submitted on 1 Sep 2021 (v1), last revised 11 Sep 2021 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2110.02467v1",
    "title": "BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models",
    "abstract": "Pre-trained Natural Language Processing (NLP) models can be easily adapted to a variety of downstream language tasks. This significantly accelerates the development of language models. However, NLP models have been shown to be vulnerable to backdoor attacks, where a pre-defined trigger word in the input text causes model misprediction. Previous NLP backdoor attacks mainly focus on some specific tasks. This makes those attacks less general and applicable to other kinds of NLP models and tasks. In this work, we propose \\Name, the first task-agnostic backdoor attack against the pre-trained NLP models. The key feature of our attack is that the adversary does not need prior information about the downstream tasks when implanting the backdoor to the pre-trained model. When this malicious model is released, any downstream models transferred from it will also inherit the backdoor, even after the extensive transfer learning process. We further design a simple yet effective strategy to bypass a state-of-the-art defense. Experimental results indicate that our approach can compromise a wide range of downstream NLP tasks in an effective and stealthy way.",
    "authors": [
      "Kangjie Chen",
      "Yuxian Meng",
      "Xiaofei Sun",
      "Shangwei Guo",
      "Tianwei Zhang",
      "Jiwei Li",
      "Chun Fan"
    ],
    "date": "[Submitted on 6 Oct 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2205.01500v2",
    "title": "Meta Learning for Natural Language Processing: A Survey",
    "abstract": "Deep learning has been the mainstream technique in natural language processing (NLP) area. However, the techniques require many labeled data and are less generalizable across domains. Meta-learning is an arising field in machine learning studying approaches to learn better learning algorithms. Approaches aim at improving algorithms in various aspects, including data efficiency and generalizability. Efficacy of approaches has been shown in many NLP tasks, but there is no systematic survey of these approaches in NLP, which hinders more researchers from joining the field. Our goal with this survey paper is to offer researchers pointers to relevant meta-learning works in NLP and attract more attention from the NLP community to drive future innovation. This paper first introduces the general concepts of meta-learning and the common approaches. Then we summarize task construction settings and application of meta-learning for various NLP problems and review the development of meta-learning in NLP community.",
    "authors": [
      "Hung-yi Lee",
      "Shang-Wen Li",
      "Ngoc Thang Vu"
    ],
    "date": "[Submitted on 3 May 2022 (v1), last revised 2 Jul 2022 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2301.09112v2",
    "title": "Differentially Private Natural Language Models: Recent Advances and Future Directions",
    "abstract": "Recent developments in deep learning have led to great success in various natural language processing (NLP) tasks. However, these applications may involve data that contain sensitive information. Therefore, how to achieve good performance while also protecting the privacy of sensitive data is a crucial challenge in NLP. To preserve privacy, Differential Privacy (DP), which can prevent reconstruction attacks and protect against potential side knowledge, is becoming a de facto technique for private data analysis. In recent years, NLP in DP models (DP-NLP) has been studied from different perspectives, which deserves a comprehensive review. In this paper, we provide the first systematic review of recent advances in DP deep learning models in NLP. In particular, we first discuss some differences and additional challenges of DP-NLP compared with the standard DP deep learning. Then, we investigate some existing work on DP-NLP and present its recent developments from three aspects: gradient perturbation based methods, embedding vector perturbation based methods, and ensemble model based methods. We also discuss some challenges and future directions.",
    "authors": [
      "Lijie Hu",
      "Ivan Habernal",
      "Lei Shen",
      "Di Wang"
    ],
    "date": "[Submitted on 22 Jan 2023 (v1), last revised 23 Oct 2023 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2302.05721v1",
    "title": "Synthesizing Human Gaze Feedback for Improved NLP Performance",
    "abstract": "Integrating human feedback in models can improve the performance of natural language processing (NLP) models. Feedback can be either explicit (e.g. ranking used in training language models) or implicit (e.g. using human cognitive signals in the form of eyetracking). Prior eye tracking and NLP research reveal that cognitive processes, such as human scanpaths, gleaned from human gaze patterns aid in the understanding and performance of NLP models. However, the collection of real eyetracking data for NLP tasks is challenging due to the requirement of expensive and precise equipment coupled with privacy invasion issues. To address this challenge, we propose ScanTextGAN, a novel model for generating human scanpaths over text. We show that ScanTextGAN-generated scanpaths can approximate meaningful cognitive signals in human gaze patterns. We include synthetically generated scanpaths in four popular NLP tasks spanning six different datasets as proof of concept and show that the models augmented with generated scanpaths improve the performance of all downstream NLP tasks.",
    "authors": [
      "Varun Khurana",
      "Yaman Kumar Singla",
      "Nora Hollenstein",
      "Rajesh Kumar",
      "Balaji Krishnamurthy"
    ],
    "date": "[Submitted on 11 Feb 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2305.09281v1",
    "title": "On the Origins of Bias in NLP through the Lens of the Jim Code",
    "abstract": "In this paper, we trace the biases in current natural language processing (NLP) models back to their origins in racism, sexism, and homophobia over the last 500 years. We review literature from critical race theory, gender studies, data ethics, and digital humanities studies, and summarize the origins of bias in NLP models from these social science perspective. We show how the causes of the biases in the NLP pipeline are rooted in social issues. Finally, we argue that the only way to fix the bias and unfairness in NLP is by addressing the social problems that caused them in the first place and by incorporating social sciences and social scientists in efforts to mitigate bias in NLP models. We provide actionable recommendations for the NLP research community to do so.",
    "authors": [
      "Fatma Elsafoury",
      "Gavin Abercrombie"
    ],
    "date": "[Submitted on 16 May 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2401.01262v2",
    "title": "Fairness Certification for Natural Language Processing and Large Language Models",
    "abstract": "Natural Language Processing (NLP) plays an important role in our daily lives, particularly due to the enormous progress of Large Language Models (LLM). However, NLP has many fairness-critical use cases, e.g., as an expert system in recruitment or as an LLM-based tutor in education. Since NLP is based on human language, potentially harmful biases can diffuse into NLP systems and produce unfair results, discriminate against minorities or generate legal issues. Hence, it is important to develop a fairness certification for NLP approaches. We follow a qualitative research approach towards a fairness certification for NLP. In particular, we have reviewed a large body of literature on algorithmic fairness, and we have conducted semi-structured expert interviews with a wide range of experts from that area. We have systematically devised six fairness criteria for NLP, which can be further refined into 18 sub-categories. Our criteria offer a foundation for operationalizing and testing processes to certify fairness, both from the perspective of the auditor and the audited organization.",
    "authors": [
      "Vincent Freiberger",
      "Erik Buchmann"
    ],
    "date": "[Submitted on 2 Jan 2024 (v1), last revised 3 Jan 2024 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2402.06964v1",
    "title": "NLP for Knowledge Discovery and Information Extraction from Energetics Corpora",
    "abstract": "We present a demonstration of the utility of NLP for aiding research into energetic materials and associated systems. The NLP method enables machine understanding of textual data, offering an automated route to knowledge discovery and information extraction from energetics text. We apply three established unsupervised NLP models: Latent Dirichlet Allocation, Word2Vec, and the Transformer to a large curated dataset of energetics-related scientific articles. We demonstrate that each NLP algorithm is capable of identifying energetic topics and concepts, generating a language model which aligns with Subject Matter Expert knowledge. Furthermore, we present a document classification pipeline for energetics text. Our classification pipeline achieves 59-76\\% accuracy depending on the NLP model used, with the highest performing Transformer model rivaling inter-annotator agreement metrics. The NLP approaches studied in this work can identify concepts germane to energetics and therefore hold promise as a tool for accelerating energetics research efforts and energetics material development.",
    "authors": [
      "Francis G. VanGessel",
      "Efrem Perry",
      "Salil Mohan",
      "Oliver M. Barham",
      "Mark Cavolowsky"
    ],
    "date": "[Submitted on 10 Feb 2024]"
  },
  {
    "url": "https://arxiv.org/abs/2406.15294v2",
    "title": "NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing",
    "abstract": "Scientific literature searches are often exploratory, whereby users are not yet familiar with a particular field or concept but are interested in learning more about it. However, existing systems for scientific literature search are typically tailored to keyword-based lookup searches, limiting the possibilities for exploration. We propose NLP-KG, a feature-rich system designed to support the exploration of research literature in unfamiliar natural language processing (NLP) fields. In addition to a semantic search, NLP-KG allows users to easily find survey papers that provide a quick introduction to a field of interest. Further, a Fields of Study hierarchy graph enables users to familiarize themselves with a field and its related areas. Finally, a chat interface allows users to ask questions about unfamiliar concepts or specific articles in NLP and obtain answers grounded in knowledge retrieved from scientific publications. Our system provides users with comprehensive exploration possibilities, supporting them in investigating the relationships between different fields, understanding unfamiliar concepts in NLP, and finding relevant research literature. Demo, video, and code are available at: this https URL.",
    "authors": [
      "Tim Schopf",
      "Florian Matthes"
    ],
    "date": "[Submitted on 21 Jun 2024 (v1), last revised 4 Jul 2024 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2407.05538v1",
    "title": "On the Equivalence between Logic Programming and SETAF",
    "abstract": "A framework with sets of attacking arguments (SETAF) is an extension of the well-known Dung's Abstract Argumentation Frameworks (AAFs) that allows joint attacks on arguments. In this paper, we provide a translation from Normal Logic Programs (NLPs) to SETAFs and vice versa, from SETAFs to NLPs. We show that there is pairwise equivalence between their semantics, including the equivalence between L-stable and semi-stable semantics. Furthermore, for a class of NLPs called Redundancy-Free Atomic Logic Programs (RFALPs), there is also a structural equivalence as these back-and-forth translations are each other's inverse. Then, we show that RFALPs are as expressive as NLPs by transforming any NLP into an equivalent RFALP through a series of program transformations already known in the literature. We also show that these program transformations are confluent, meaning that every NLP will be transformed into a unique RFALP. The results presented in this paper enhance our understanding that NLPs and SETAFs are essentially the same formalism. Under consideration in Theory and Practice of Logic Programming (TPLP).",
    "authors": [
      "Jo\u00e3o Alc\u00e2ntara",
      "Renan Cordeiro",
      "Samy S\u00e1"
    ],
    "date": "[Submitted on 8 Jul 2024]"
  },
  {
    "url": "https://arxiv.org/abs/2407.09861v4",
    "title": "A Systematic Survey of Natural Language Processing for the Greek Language",
    "abstract": "Comprehensive monolingual Natural Language Processing (NLP) surveys are essential for assessing language-specific challenges, resource availability, and research gaps. However, existing surveys often lack standardized methodologies, leading to selection bias and fragmented coverage of NLP tasks and resources. This study introduces a generalizable framework for systematic monolingual NLP surveys. Our approach integrates a structured search protocol to minimize bias, an NLP task taxonomy for classification, and language resource taxonomies to identify potential benchmarks and highlight opportunities for improving resource availability. We apply this framework to Greek NLP (2012-2023), providing an in-depth analysis of its current state, task-specific progress, and resource gaps. The survey results are publicly available (this https URL) and are regularly updated to provide an evergreen resource. This systematic survey of Greek NLP serves as a case study, demonstrating the effectiveness of our framework and its potential for broader application to other not so well-resourced languages as regards NLP.",
    "authors": [
      "Juli Bakagianni",
      "Kanella Pouli",
      "Maria Gavriilidou",
      "John Pavlopoulos"
    ],
    "date": "[Submitted on 13 Jul 2024 (v1), last revised 18 Jun 2025 (this version, v4)]"
  },
  {
    "url": "https://arxiv.org/abs/2110.03353v1",
    "title": "Noisy Text Data: Achilles' Heel of popular transformer based NLP models",
    "abstract": "In the last few years, the ML community has created a number of new NLP models based on transformer architecture. These models have shown great performance for various NLP tasks on benchmark datasets, often surpassing SOTA results. Buoyed with this success, one often finds industry practitioners actively experimenting with fine-tuning these models to build NLP applications for industry use cases. However, for most datasets that are used by practitioners to build industrial NLP applications, it is hard to guarantee the presence of any noise in the data. While most transformer based NLP models have performed exceedingly well in transferring the learnings from one dataset to another, it remains unclear how these models perform when fine-tuned on noisy text. We address the open question by Kumar et al. (2020) to explore the sensitivity of popular transformer based NLP models to noise in the text data. We continue working with the noise as defined by them -- spelling mistakes & typos (which are the most commonly occurring noise). We show (via experimental results) that these models perform badly on most common NLP tasks namely text classification, textual similarity, NER, question answering, text summarization on benchmark datasets. We further show that as the noise in data increases, the performance degrades. Our findings suggest that one must be vary of the presence of noise in their datasets while fine-tuning popular transformer based NLP models.",
    "authors": [
      "Kartikay Bagla",
      "Ankit Kumar",
      "Shivam Gupta",
      "Anuj Gupta"
    ],
    "date": "[Submitted on 7 Oct 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2111.08408v1",
    "title": "STAMP 4 NLP -- An Agile Framework for Rapid Quality-Driven NLP Applications Development",
    "abstract": "The progress in natural language processing (NLP) research over the last years, offers novel business opportunities for companies, as automated user interaction or improved data analysis. Building sophisticated NLP applications requires dealing with modern machine learning (ML) technologies, which impedes enterprises from establishing successful NLP projects. Our experience in applied NLP research projects shows that the continuous integration of research prototypes in production-like environments with quality assurance builds trust in the software and shows convenience and usefulness regarding the business goal. We introduce STAMP 4 NLP as an iterative and incremental process model for developing NLP applications. With STAMP 4 NLP, we merge software engineering principles with best practices from data science. Instantiating our process model allows efficiently creating prototypes by utilizing templates, conventions, and implementations, enabling developers and data scientists to focus on the business goals. Due to our iterative-incremental approach, businesses can deploy an enhanced version of the prototype to their software environment after every iteration, maximizing potential business value and trust early and avoiding the cost of successful yet never deployed experiments.",
    "authors": [
      "Philipp Kohl",
      "Oliver Schmidts",
      "Lars Kl\u00f6ser",
      "Henri Werth",
      "Bodo Kraft",
      "Albert Z\u00fcndorf"
    ],
    "date": "[Submitted on 16 Nov 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2406.12618v2",
    "title": "From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP",
    "abstract": "Interpretability and analysis (IA) research is a growing subfield within NLP with the goal of developing a deeper understanding of the behavior or inner workings of NLP systems and methods. Despite growing interest in the subfield, a criticism of this work is that it lacks actionable insights and therefore has little impact on NLP. In this paper, we seek to quantify the impact of IA research on the broader field of NLP. We approach this with a mixed-methods analysis of: (1) a citation graph of 185K+ papers built from all papers published at ACL and EMNLP conferences from 2018 to 2023, and their references and citations, and (2) a survey of 138 members of the NLP community. Our quantitative results show that IA work is well-cited outside of IA, and central in the NLP citation graph. Through qualitative analysis of survey responses and manual annotation of 556 papers, we find that NLP researchers build on findings from IA work and perceive it as important for progress in NLP, multiple subfields, and rely on its findings and terminology for their own work. Many novel methods are proposed based on IA findings and highly influenced by them, but highly influential non-IA work cites IA findings without being driven by them. We end by summarizing what is missing in IA work today and provide a call to action, to pave the way for a more impactful future of IA research.",
    "authors": [
      "Marius Mosbach",
      "Vagrant Gautam",
      "Tom\u00e1s Vergara-Browne",
      "Dietrich Klakow",
      "Mor Geva"
    ],
    "date": "[Submitted on 18 Jun 2024 (v1), last revised 5 Oct 2024 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2104.02756v1",
    "title": "Efficient transfer learning for NLP with ELECTRA",
    "abstract": "Clark et al. [2020] claims that the ELECTRA approach is highly efficient in NLP performances relative to computation budget. As such, this reproducibility study focus on this claim, summarized by the following question: Can we use ELECTRA to achieve close to SOTA performances for NLP in low-resource settings, in term of compute cost?",
    "authors": [
      "Fran\u00e7ois Mercier"
    ],
    "date": "[Submitted on 6 Apr 2021]"
  },
  {
    "url": "https://arxiv.org/abs/1809.01448v1",
    "title": "Appendix - Recommended Statistical Significance Tests for NLP Tasks",
    "abstract": "Statistical significance testing plays an important role when drawing conclusions from experimental results in NLP papers. Particularly, it is a valuable tool when one would like to establish the superiority of one algorithm over another. This appendix complements the guide for testing statistical significance in NLP presented in \\cite{dror2018hitchhiker} by proposing valid statistical tests for the common tasks and evaluation measures in the field.",
    "authors": [
      "Rotem Dror",
      "Roi Reichart"
    ],
    "date": "[Submitted on 5 Sep 2018]"
  },
  {
    "url": "https://arxiv.org/abs/2105.01052v1",
    "title": "Applied Language Technology: NLP for the Humanities",
    "abstract": "This contribution describes a two-course module that seeks to provide humanities majors with a basic understanding of language technology and its applications using Python. The learning materials consist of interactive Jupyter Notebooks and accompanying YouTube videos, which are openly available with a Creative Commons licence.",
    "authors": [
      "Tuomo Hiippala"
    ],
    "date": "[Submitted on 3 May 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2102.03732v1",
    "title": "Representation Learning for Natural Language Processing",
    "abstract": "This book aims to review and present the recent advances of distributed representation learning for NLP, including why representation learning can improve NLP, how representation learning takes part in various important topics of NLP, and what challenges are still not well addressed by distributed representation.",
    "authors": [
      "Zhiyuan Liu",
      "Yankai Lin",
      "Maosong Sun"
    ],
    "date": "[Submitted on 7 Feb 2021]"
  },
  {
    "url": "https://arxiv.org/abs/1702.01923v1",
    "title": "Comparative Study of CNN and RNN for Natural Language Processing",
    "abstract": "Deep neural networks (DNN) have revolutionized the field of natural language processing (NLP). Convolutional neural network (CNN) and recurrent neural network (RNN), the two main types of DNN architectures, are widely explored to handle various NLP tasks. CNN is supposed to be good at extracting position-invariant features and RNN at modeling units in sequence. The state of the art on many NLP tasks often switches due to the battle between CNNs and RNNs. This work is the first systematic comparison of CNN and RNN on a wide range of representative NLP tasks, aiming to give basic guidance for DNN selection.",
    "authors": [
      "Wenpeng Yin",
      "Katharina Kann",
      "Mo Yu",
      "Hinrich Sch\u00fctze"
    ],
    "date": "[Submitted on 7 Feb 2017]"
  },
  {
    "url": "https://arxiv.org/abs/1708.05148v1",
    "title": "Natural Language Processing: State of The Art, Current Trends and Challenges",
    "abstract": "Natural language processing (NLP) has recently gained much attention for representing and analysing human language computationally. It has spread its applications in various fields such as machine translation, email spam detection, information extraction, summarization, medical, and question answering etc. The paper distinguishes four phases by discussing different levels of NLP and components of Natural Language Generation (NLG) followed by presenting the history and evolution of NLP, state of the art presenting the various applications of NLP and current trends and challenges.",
    "authors": [
      "Diksha Khurana",
      "Aditya Koli",
      "Kiran Khatter",
      "Sukhdev Singh"
    ],
    "date": "[Submitted on 17 Aug 2017]"
  },
  {
    "url": "https://arxiv.org/abs/2005.14299v1",
    "title": "What is SemEval evaluating? A Systematic Analysis of Evaluation Campaigns in NLP",
    "abstract": "SemEval is the primary venue in the NLP community for the proposal of new challenges and for the systematic empirical evaluation of NLP systems. This paper provides a systematic quantitative analysis of SemEval aiming to evidence the patterns of the contributions behind SemEval. By understanding the distribution of task types, metrics, architectures, participation and citations over time we aim to answer the question on what is being evaluated by SemEval.",
    "authors": [
      "Oskar Wysocki",
      "Malina Florea",
      "Andre Freitas"
    ],
    "date": "[Submitted on 28 May 2020]"
  },
  {
    "url": "https://arxiv.org/abs/2104.12405v2",
    "title": "A dissemination workshop for introducing young Italian students to NLP",
    "abstract": "We describe and make available the game-based material developed for a laboratory run at several Italian science festivals to popularize NLP among young students.",
    "authors": [
      "Lucio Messina",
      "Lucia Busso",
      "Claudia Roberta Combei",
      "Ludovica Pannitto",
      "Alessio Miaschi",
      "Gabriele Sarti",
      "Malvina Nissim"
    ],
    "date": "[Submitted on 26 Apr 2021 (v1), last revised 14 May 2021 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2002.03056v1",
    "title": "autoNLP: NLP Feature Recommendations for Text Analytics Applications",
    "abstract": "While designing machine learning based text analytics applications, often, NLP data scientists manually determine which NLP features to use based upon their knowledge and experience with related problems. This results in increased efforts during feature engineering process and renders automated reuse of features across semantically related applications inherently difficult. In this paper, we argue for standardization in feature specification by outlining structure of a language for specifying NLP features and present an approach for their reuse across applications to increase likelihood of identifying optimal features.",
    "authors": [
      "Janardan Misra"
    ],
    "date": "[Submitted on 8 Feb 2020]"
  },
  {
    "url": "https://arxiv.org/abs/2105.02746v1",
    "title": "Introducing Information Retrieval for Biomedical Informatics Students",
    "abstract": "Introducing biomedical informatics (BMI) students to natural language processing (NLP) requires balancing technical depth with practical know-how to address application-focused needs. We developed a set of three activities introducing introductory BMI students to information retrieval with NLP, covering document representation strategies and language models from TF-IDF to BERT. These activities provide students with hands-on experience targeted towards common use cases, and introduce fundamental components of NLP workflows for a wide variety of applications.",
    "authors": [
      "Sanya B. Taneja",
      "Richard D. Boyce",
      "William T. Reynolds",
      "Denis Newman-Griffis"
    ],
    "date": "[Submitted on 6 May 2021]"
  },
  {
    "url": "https://arxiv.org/abs/1801.06422v3",
    "title": "Evaluating neural network explanation methods using hybrid documents and morphological agreement",
    "abstract": "The behavior of deep neural networks (DNNs) is hard to understand. This makes it necessary to explore post hoc explanation methods. We conduct the first comprehensive evaluation of explanation methods for NLP. To this end, we design two novel evaluation paradigms that cover two important classes of NLP problems: small context and large context problems. Both paradigms require no manual annotation and are therefore broadly applicable. We also introduce LIMSSE, an explanation method inspired by LIME that is designed for NLP. We show empirically that LIMSSE, LRP and DeepLIFT are the most effective explanation methods and recommend them for explaining DNNs in NLP.",
    "authors": [
      "Nina Poerner",
      "Benjamin Roth",
      "Hinrich Sch\u00fctze"
    ],
    "date": "[Submitted on 19 Jan 2018 (v1), last revised 6 May 2019 (this version, v3)]"
  },
  {
    "url": "https://arxiv.org/abs/2102.13461v1",
    "title": "Methods for the Design and Evaluation of HCI+NLP Systems",
    "abstract": "HCI and NLP traditionally focus on different evaluation methods. While HCI involves a small number of people directly and deeply, NLP traditionally relies on standardized benchmark evaluations that involve a larger number of people indirectly. We present five methodological proposals at the intersection of HCI and NLP and situate them in the context of ML-based NLP models. Our goal is to foster interdisciplinary collaboration and progress in both fields by emphasizing what the fields can learn from each other.",
    "authors": [
      "Hendrik Heuer",
      "Daniel Buschek"
    ],
    "date": "[Submitted on 26 Feb 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2209.06169v1",
    "title": "The Role of Explanatory Value in Natural Language Processing",
    "abstract": "A key aim of science is explanation, yet the idea of explaining language phenomena has taken a backseat in mainstream Natural Language Processing (NLP) and many other areas of Artificial Intelligence. I argue that explanation of linguistic behaviour should be a main goal of NLP, and that this is not the same as making NLP models explainable. To illustrate these ideas, some recent models of human language production are compared with each other. I conclude by asking what it would mean for NLP research and institutional policies if our community took explanatory value seriously, while heeding some possible pitfalls.",
    "authors": [
      "Kees van Deemter"
    ],
    "date": "[Submitted on 13 Sep 2022]"
  },
  {
    "url": "https://arxiv.org/abs/1711.01505v1",
    "title": "Towards Linguistically Generalizable NLP Systems: A Workshop and Shared Task",
    "abstract": "This paper presents a summary of the first Workshop on Building Linguistically Generalizable Natural Language Processing Systems, and the associated Build It Break It, The Language Edition shared task. The goal of this workshop was to bring together researchers in NLP and linguistics with a shared task aimed at testing the generalizability of NLP systems beyond the distributions of their training data. We describe the motivation, setup, and participation of the shared task, provide discussion of some highlighted results, and discuss lessons learned.",
    "authors": [
      "Allyson Ettinger",
      "Sudha Rao",
      "Hal Daum\u00e9 III",
      "Emily M. Bender"
    ],
    "date": "[Submitted on 4 Nov 2017]"
  },
  {
    "url": "https://arxiv.org/abs/2106.01167v1",
    "title": "End-to-End NLP Knowledge Graph Construction",
    "abstract": "This paper studies the end-to-end construction of an NLP Knowledge Graph (KG) from scientific papers. We focus on extracting four types of relations: evaluatedOn between tasks and datasets, evaluatedBy between tasks and evaluation metrics, as well as coreferent and related relations between the same type of entities. For instance, F1-score is coreferent with F-measure. We introduce novel methods for each of these relation types and apply our final framework (SciNLP-KG) to 30,000 NLP papers from ACL Anthology to build a large-scale KG, which can facilitate automatically constructing scientific leaderboards for the NLP community. The results of our experiments indicate that the resulting KG contains high-quality information.",
    "authors": [
      "Ishani Mondal",
      "Yufang Hou",
      "Charles Jochim"
    ],
    "date": "[Submitted on 2 Jun 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2109.01211v1",
    "title": "Quantifying Reproducibility in NLP and ML",
    "abstract": "Reproducibility has become an intensely debated topic in NLP and ML over recent years, but no commonly accepted way of assessing reproducibility, let alone quantifying it, has so far emerged. The assumption has been that wider scientific reproducibility terminology and definitions are not applicable to NLP/ML, with the result that many different terms and definitions have been proposed, some diametrically opposed. In this paper, we test this assumption, by taking the standard terminology and definitions from metrology and applying them directly to NLP/ML. We find that we are able to straightforwardly derive a practical framework for assessing reproducibility which has the desirable property of yielding a quantified degree of reproducibility that is comparable across different reproduction studies.",
    "authors": [
      "Anya Belz"
    ],
    "date": "[Submitted on 2 Sep 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2311.07171v1",
    "title": "calamanCy: A Tagalog Natural Language Processing Toolkit",
    "abstract": "We introduce calamanCy, an open-source toolkit for constructing natural language processing (NLP) pipelines for Tagalog. It is built on top of spaCy, enabling easy experimentation and integration with other frameworks. calamanCy addresses the development gap by providing a consistent API for building NLP applications and offering general-purpose multitask models with out-of-the-box support for dependency parsing, parts-of-speech (POS) tagging, and named entity recognition (NER). calamanCy aims to accelerate the progress of Tagalog NLP by consolidating disjointed resources in a unified framework. The calamanCy toolkit is available on GitHub: this https URL.",
    "authors": [
      "Lester James V. Miranda"
    ],
    "date": "[Submitted on 13 Nov 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2406.03930v2",
    "title": "Culturally Aware and Adapted NLP: A Taxonomy and a Survey of the State of the Art",
    "abstract": "The surge of interest in \"culture\" in NLP has inspired much recent research, but a shared understanding of \"culture\" remains unclear, making it difficult to evaluate progress in this emerging area. Drawing on prior research in NLP and related fields, we propose a fine-grained taxonomy of elements in culture that can provide a systematic framework for analyzing and understanding research progress. Using the taxonomy, we survey existing resources and methods for culturally aware and adapted NLP, providing an overview of the state of the art and the research gaps that still need to be filled.",
    "authors": [
      "Chen Cecilia Liu",
      "Iryna Gurevych",
      "Anna Korhonen"
    ],
    "date": "[Submitted on 6 Jun 2024 (v1), last revised 14 Mar 2025 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2408.10962v1",
    "title": "NLP for The Greek Language: A Longer Survey",
    "abstract": "English language is in the spotlight of the Natural Language Processing (NLP) community with other languages, like Greek, lagging behind in terms of offered methods, tools and resources. Due to the increasing interest in NLP, in this paper we try to condense research efforts for the automatic processing of Greek language covering the last three decades. In particular, we list and briefly discuss related works, resources and tools, categorized according to various processing layers and contexts. We are not restricted to the modern form of Greek language but also cover Ancient Greek and various Greek dialects. This survey can be useful for researchers and students interested in NLP tasks, Information Retrieval and Knowledge Management for the Greek language.",
    "authors": [
      "Katerina Papantoniou",
      "Yannis Tzitzikas"
    ],
    "date": "[Submitted on 20 Aug 2024]"
  },
  {
    "url": "https://arxiv.org/abs/2111.08529v1",
    "title": "Improving the robustness and accuracy of biomedical language models through adversarial training",
    "abstract": "Deep transformer neural network models have improved the predictive accuracy of intelligent text processing systems in the biomedical domain. They have obtained state-of-the-art performance scores on a wide variety of biomedical and clinical Natural Language Processing (NLP) benchmarks. However, the robustness and reliability of these models has been less explored so far. Neural NLP models can be easily fooled by adversarial samples, i.e. minor changes to input that preserve the meaning and understandability of the text but force the NLP system to make erroneous decisions. This raises serious concerns about the security and trust-worthiness of biomedical NLP systems, especially when they are intended to be deployed in real-world use cases. We investigated the robustness of several transformer neural language models, i.e. BioBERT, SciBERT, BioMed-RoBERTa, and Bio-ClinicalBERT, on a wide range of biomedical and clinical text processing tasks. We implemented various adversarial attack methods to test the NLP systems in different attack scenarios. Experimental results showed that the biomedical NLP models are sensitive to adversarial samples; their performance dropped in average by 21 and 18.9 absolute percent on character-level and word-level adversarial noise, respectively. Conducting extensive adversarial training experiments, we fine-tuned the NLP models on a mixture of clean samples and adversarial inputs. Results showed that adversarial training is an effective defense mechanism against adversarial noise; the models robustness improved in average by 11.3 absolute percent. In addition, the models performance on clean data increased in average by 2.4 absolute present, demonstrating that adversarial training can boost generalization abilities of biomedical NLP systems.",
    "authors": [
      "Milad Moradi",
      "Matthias Samwald"
    ],
    "date": "[Submitted on 16 Nov 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2304.14803v1",
    "title": "SemEval-2023 Task 11: Learning With Disagreements (LeWiDi)",
    "abstract": "NLP datasets annotated with human judgments are rife with disagreements between the judges. This is especially true for tasks depending on subjective judgments such as sentiment analysis or offensive language detection. Particularly in these latter cases, the NLP community has come to realize that the approach of 'reconciling' these different subjective interpretations is inappropriate. Many NLP researchers have therefore concluded that rather than eliminating disagreements from annotated corpora, we should preserve them-indeed, some argue that corpora should aim to preserve all annotator judgments. But this approach to corpus creation for NLP has not yet been widely accepted. The objective of the LeWiDi series of shared tasks is to promote this approach to developing NLP models by providing a unified framework for training and evaluating with such datasets. We report on the second LeWiDi shared task, which differs from the first edition in three crucial respects: (i) it focuses entirely on NLP, instead of both NLP and computer vision tasks in its first edition; (ii) it focuses on subjective tasks, instead of covering different types of disagreements-as training with aggregated labels for subjective NLP tasks is a particularly obvious misrepresentation of the data; and (iii) for the evaluation, we concentrate on soft approaches to evaluation. This second edition of LeWiDi attracted a wide array of participants resulting in 13 shared task submission papers.",
    "authors": [
      "Elisa Leonardelli",
      "Alexandra Uma",
      "Gavin Abercrombie",
      "Dina Almanea",
      "Valerio Basile",
      "Tommaso Fornaciari",
      "Barbara Plank",
      "Verena Rieser",
      "Massimo Poesio"
    ],
    "date": "[Submitted on 28 Apr 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2305.04003v3",
    "title": "ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for Verification",
    "abstract": "Verification of machine learning models used in Natural Language Processing (NLP) is known to be a hard problem. In particular, many known neural network verification methods that work for computer vision and other numeric datasets do not work for NLP. Here, we study technical reasons that underlie this problem. Based on this analysis, we propose practical methods and heuristics for preparing NLP datasets and models in a way that renders them amenable to known verification methods based on abstract interpretation. We implement these methods as a Python library called ANTONIO that links to the neural network verifiers ERAN and Marabou. We perform evaluation of the tool using an NLP dataset R-U-A-Robot suggested as a benchmark for verifying legally critical NLP applications. We hope that, thanks to its general applicability, this work will open novel possibilities for including NLP verification problems into neural network verification competitions, and will popularise NLP problems within this community.",
    "authors": [
      "Marco Casadio",
      "Luca Arnaboldi",
      "Matthew L. Daggitt",
      "Omri Isac",
      "Tanvi Dinkar",
      "Daniel Kienitz",
      "Verena Rieser",
      "Ekaterina Komendantskaya"
    ],
    "date": "[Submitted on 6 May 2023 (v1), last revised 15 Aug 2023 (this version, v3)]"
  },
  {
    "url": "https://arxiv.org/abs/2305.08264v1",
    "title": "MatSci-NLP: Evaluating Scientific Language Models on Materials Science Language Tasks Using Text-to-Schema Modeling",
    "abstract": "We present MatSci-NLP, a natural language benchmark for evaluating the performance of natural language processing (NLP) models on materials science text. We construct the benchmark from publicly available materials science text data to encompass seven different NLP tasks, including conventional NLP tasks like named entity recognition and relation classification, as well as NLP tasks specific to materials science, such as synthesis action retrieval which relates to creating synthesis procedures for materials. We study various BERT-based models pretrained on different scientific text corpora on MatSci-NLP to understand the impact of pretraining strategies on understanding materials science text. Given the scarcity of high-quality annotated data in the materials science domain, we perform our fine-tuning experiments with limited training data to encourage the generalize across MatSci-NLP tasks. Our experiments in this low-resource training setting show that language models pretrained on scientific text outperform BERT trained on general text. MatBERT, a model pretrained specifically on materials science journals, generally performs best for most tasks. Moreover, we propose a unified text-to-schema for multitask learning on \\benchmark and compare its performance with traditional fine-tuning methods. In our analysis of different training methods, we find that our proposed text-to-schema methods inspired by question-answering consistently outperform single and multitask NLP fine-tuning methods. The code and datasets are publicly available at \\url{this https URL}.",
    "authors": [
      "Yu Song",
      "Santiago Miret",
      "Bang Liu"
    ],
    "date": "[Submitted on 14 May 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2401.07518v4",
    "title": "Survey of Natural Language Processing for Education: Taxonomy, Systematic Review, and Future Trends",
    "abstract": "Natural Language Processing (NLP) aims to analyze text or speech via techniques in the computer science field. It serves applications in the domains of healthcare, commerce, education, and so on. Particularly, NLP has been widely applied to the education domain and its applications have enormous potential to help teaching and learning. In this survey, we review recent advances in NLP with a focus on solving problems relevant to the education domain. In detail, we begin with introducing the related background and the real-world scenarios in education to which NLP techniques could contribute. Then, we present a taxonomy of NLP in the education domain and highlight typical NLP applications including question answering, question construction, automated assessment, and error correction. Next, we illustrate the task definition, challenges, and corresponding cutting-edge techniques based on the above taxonomy. In particular, LLM-involved methods are included for discussion due to the wide usage of LLMs in diverse NLP applications. After that, we showcase some off-the-shelf demonstrations in this domain, which are designed for educators or researchers. At last, we conclude with five promising directions for future research, including generalization over subjects and languages, deployed LLM-based systems for education, adaptive learning for teaching and learning, interpretability for education, and ethical consideration of NLP techniques. We organize all relevant datasets and papers in the open-available Github Link for better review this https URL.",
    "authors": [
      "Yunshi Lan",
      "Xinyuan Li",
      "Hanyue Du",
      "Xuesong Lu",
      "Ming Gao",
      "Weining Qian",
      "Aoying Zhou"
    ],
    "date": "[Submitted on 15 Jan 2024 (v1), last revised 11 Oct 2025 (this version, v4)]"
  },
  {
    "url": "https://arxiv.org/abs/2401.10995v1",
    "title": "The Radiation Oncology NLP Database",
    "abstract": "We present the Radiation Oncology NLP Database (ROND), the first dedicated Natural Language Processing (NLP) dataset for radiation oncology, an important medical specialty that has received limited attention from the NLP community in the past. With the advent of Artificial General Intelligence (AGI), there is an increasing need for specialized datasets and benchmarks to facilitate research and development. ROND is specifically designed to address this gap in the domain of radiation oncology, a field that offers many opportunities for NLP exploration. It encompasses various NLP tasks including Logic Reasoning, Text Classification, Named Entity Recognition (NER), Question Answering (QA), Text Summarization, and Patient-Clinician Conversations, each with a distinct focus on radiation oncology concepts and application cases. In addition, we have developed an instruction-tuning dataset consisting of over 20k instruction pairs (based on ROND) and trained a large language model, CancerChat. This serves to demonstrate the potential of instruction-tuning large language models within a highly-specialized medical domain. The evaluation results in this study could serve as baseline results for future research. ROND aims to stimulate advancements in radiation oncology and clinical NLP by offering a platform for testing and improving algorithms and models in a domain-specific context. The ROND dataset is a joint effort of multiple U.S. health institutions. The data is available at this https URL.",
    "authors": [
      "Zhengliang Liu",
      "Jason Holmes",
      "Wenxiong Liao",
      "Chenbin Liu",
      "Lian Zhang",
      "Hongying Feng",
      "Peilong Wang",
      "Muhammad Ali Elahi",
      "Hongmin Cai",
      "Lichao Sun",
      "Quanzheng Li",
      "Xiang Li",
      "Tianming Liu",
      "Jiajian Shen",
      "Wei Liu"
    ],
    "date": "[Submitted on 19 Jan 2024]"
  },
  {
    "url": "https://arxiv.org/abs/2405.12819v2",
    "title": "Large Language Models Meet NLP: A Survey",
    "abstract": "While large language models (LLMs) like ChatGPT have shown impressive capabilities in Natural Language Processing (NLP) tasks, a systematic investigation of their potential in this field remains largely unexplored. This study aims to address this gap by exploring the following questions: (1) How are LLMs currently applied to NLP tasks in the literature? (2) Have traditional NLP tasks already been solved with LLMs? (3) What is the future of the LLMs for NLP? To answer these questions, we take the first step to provide a comprehensive overview of LLMs in NLP. Specifically, we first introduce a unified taxonomy including (1) parameter-frozen paradigm and (2) parameter-tuning paradigm to offer a unified perspective for understanding the current progress of LLMs in NLP. Furthermore, we summarize the new frontiers and the corresponding challenges, aiming to inspire further groundbreaking advancements. We hope this work offers valuable insights into the potential and limitations of LLMs, while also serving as a practical guide for building effective LLMs in NLP.",
    "authors": [
      "Libo Qin",
      "Qiguang Chen",
      "Xiachong Feng",
      "Yang Wu",
      "Yongheng Zhang",
      "Yinghui Li",
      "Min Li",
      "Wanxiang Che",
      "Philip S. Yu"
    ],
    "date": "[Submitted on 21 May 2024 (v1), last revised 25 Aug 2025 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2407.12026v1",
    "title": "The Pitfalls of Publishing in the Age of LLMs: Strange and Surprising Adventures with a High-Impact NLP Journal",
    "abstract": "We show the fraught side of the academic publishing realm and illustrate it through a recent case study with an NLP journal.",
    "authors": [
      "Rakesh M. Verma",
      "Nachum Dershowitz"
    ],
    "date": "[Submitted on 28 Jun 2024]"
  },
  {
    "url": "https://arxiv.org/abs/2410.09948v1",
    "title": "State of NLP in Kenya: A Survey",
    "abstract": "Kenya, known for its linguistic diversity, faces unique challenges and promising opportunities in advancing Natural Language Processing (NLP) technologies, particularly for its underrepresented indigenous languages. This survey provides a detailed assessment of the current state of NLP in Kenya, emphasizing ongoing efforts in dataset creation, machine translation, sentiment analysis, and speech recognition for local dialects such as Kiswahili, Dholuo, Kikuyu, and Luhya. Despite these advancements, the development of NLP in Kenya remains constrained by limited resources and tools, resulting in the underrepresentation of most indigenous languages in digital spaces. This paper uncovers significant gaps by critically evaluating the available datasets and existing NLP models, most notably the need for large-scale language models and the insufficient digital representation of Indigenous languages. We also analyze key NLP applications: machine translation, information retrieval, and sentiment analysis-examining how they are tailored to address local linguistic needs. Furthermore, the paper explores the governance, policies, and regulations shaping the future of AI and NLP in Kenya and proposes a strategic roadmap to guide future research and development efforts. Our goal is to provide a foundation for accelerating the growth of NLP technologies that meet Kenya's diverse linguistic demands.",
    "authors": [
      "Cynthia Jayne Amol",
      "Everlyn Asiko Chimoto",
      "Rose Delilah Gesicho",
      "Antony M. Gitau",
      "Naome A. Etori",
      "Caringtone Kinyanjui",
      "Steven Ndung'u",
      "Lawrence Moruye",
      "Samson Otieno Ooko",
      "Kavengi Kitonga",
      "Brian Muhia",
      "Catherine Gitau",
      "Antony Ndolo",
      "Lilian D. A. Wanzare",
      "Albert Njoroge Kahira",
      "Ronald Tombe"
    ],
    "date": "[Submitted on 13 Oct 2024]"
  },
  {
    "url": "https://arxiv.org/abs/2410.22180v1",
    "title": "Natural Language Processing for Analyzing Electronic Health Records and Clinical Notes in Cancer Research: A Review",
    "abstract": "Objective: This review aims to analyze the application of natural language processing (NLP) techniques in cancer research using electronic health records (EHRs) and clinical notes. This review addresses gaps in the existing literature by providing a broader perspective than previous studies focused on specific cancer types or applications. Methods: A comprehensive literature search was conducted using the Scopus database, identifying 94 relevant studies published between 2019 and 2024. Data extraction included study characteristics, cancer types, NLP methodologies, dataset information, performance metrics, challenges, and future directions. Studies were categorized based on cancer types and NLP applications. Results: The results showed a growing trend in NLP applications for cancer research, with breast, lung, and colorectal cancers being the most studied. Information extraction and text classification emerged as predominant NLP tasks. A shift from rule-based to advanced machine learning techniques, particularly transformer-based models, was observed. The Dataset sizes used in existing studies varied widely. Key challenges included the limited generalizability of proposed solutions and the need for improved integration into clinical workflows. Conclusion: NLP techniques show significant potential in analyzing EHRs and clinical notes for cancer research. However, future work should focus on improving model generalizability, enhancing robustness in handling complex clinical language, and expanding applications to understudied cancer types. Integration of NLP tools into clinical practice and addressing ethical considerations remain crucial for utilizing the full potential of NLP in enhancing cancer diagnosis, treatment, and patient outcomes.",
    "authors": [
      "Muhammad Bilal",
      "Ameer Hamza",
      "Nadia Malik"
    ],
    "date": "[Submitted on 29 Oct 2024]"
  },
  {
    "url": "https://arxiv.org/abs/2505.23030v1",
    "title": "Can Modern NLP Systems Reliably Annotate Chest Radiography Exams? A Pre-Purchase Evaluation and Comparative Study of Solutions from AWS, Google, Azure, John Snow Labs, and Open-Source Models on an Independent Pediatric Dataset",
    "abstract": "General-purpose clinical natural language processing (NLP) tools are increasingly used for the automatic labeling of clinical reports. However, independent evaluations for specific tasks, such as pediatric chest radiograph (CXR) report labeling, are limited. This study compares four commercial clinical NLP systems - Amazon Comprehend Medical (AWS), Google Healthcare NLP (GC), Azure Clinical NLP (AZ), and SparkNLP (SP) - for entity extraction and assertion detection in pediatric CXR reports. Additionally, CheXpert and CheXbert, two dedicated chest radiograph report labelers, were evaluated on the same task using CheXpert-defined labels. We analyzed 95,008 pediatric CXR reports from a large academic pediatric hospital. Entities and assertion statuses (positive, negative, uncertain) from the findings and impression sections were extracted by the NLP systems, with impression section entities mapped to 12 disease categories and a No Findings category. CheXpert and CheXbert extracted the same 13 categories. Outputs were compared using Fleiss Kappa and accuracy against a consensus pseudo-ground truth. Significant differences were found in the number of extracted entities and assertion distributions across NLP systems. SP extracted 49,688 unique entities, GC 16,477, AZ 31,543, and AWS 27,216. Assertion accuracy across models averaged around 62%, with SP highest (76%) and AWS lowest (50%). CheXpert and CheXbert achieved 56% accuracy. Considerable variability in performance highlights the need for careful validation and review before deploying NLP tools for clinical report labeling.",
    "authors": [
      "Shruti Hegde",
      "Mabon Manoj Ninan",
      "Jonathan R. Dillman",
      "Shireen Hayatghaibi",
      "Lynn Babcock",
      "Elanchezhian Somasundaram"
    ],
    "date": "[Submitted on 29 May 2025]"
  },
  {
    "url": "https://arxiv.org/abs/1401.0569v2",
    "title": "Natural Language Processing in Biomedicine: A Unified System Architecture Overview",
    "abstract": "In modern electronic medical records (EMR) much of the clinically important data - signs and symptoms, symptom severity, disease status, etc. - are not provided in structured data fields, but rather are encoded in clinician generated narrative text. Natural language processing (NLP) provides a means of \"unlocking\" this important data source for applications in clinical decision support, quality assurance, and public health. This chapter provides an overview of representative NLP systems in biomedicine based on a unified architectural view. A general architecture in an NLP system consists of two main components: background knowledge that includes biomedical knowledge resources and a framework that integrates NLP tools to process text. Systems differ in both components, which we will review briefly. Additionally, challenges facing current research efforts in biomedical NLP include the paucity of large, publicly available annotated corpora, although initiatives that facilitate data sharing, system evaluation, and collaborative work between researchers in clinical NLP are starting to emerge.",
    "authors": [
      "Son Doan",
      "Mike Conway",
      "Tu Minh Phuong",
      "Lucila Ohno-Machado"
    ],
    "date": "[Submitted on 3 Jan 2014 (v1), last revised 8 Jan 2014 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/1503.00168v1",
    "title": "The NLP Engine: A Universal Turing Machine for NLP",
    "abstract": "It is commonly accepted that machine translation is a more complex task than part of speech tagging. But how much more complex? In this paper we make an attempt to develop a general framework and methodology for computing the informational and/or processing complexity of NLP applications and tasks. We define a universal framework akin to a Turning Machine that attempts to fit (most) NLP tasks into one paradigm. We calculate the complexities of various NLP tasks using measures of Shannon Entropy, and compare `simple' ones such as part of speech tagging to `complex' ones such as machine translation. This paper provides a first, though far from perfect, attempt to quantify NLP tasks under a uniform paradigm. We point out current deficiencies and suggest some avenues for fruitful research.",
    "authors": [
      "Jiwei Li",
      "Eduard Hovy"
    ],
    "date": "[Submitted on 28 Feb 2015]"
  },
  {
    "url": "https://arxiv.org/abs/1707.04244v1",
    "title": "Lithium NLP: A System for Rich Information Extraction from Noisy User Generated Text on Social Media",
    "abstract": "In this paper, we describe the Lithium Natural Language Processing (NLP) system - a resource-constrained, high- throughput and language-agnostic system for information extraction from noisy user generated text on social media. Lithium NLP extracts a rich set of information including entities, topics, hashtags and sentiment from text. We discuss several real world applications of the system currently incorporated in Lithium products. We also compare our system with existing commercial and academic NLP systems in terms of performance, information extracted and languages supported. We show that Lithium NLP is at par with and in some cases, outperforms state- of-the-art commercial NLP systems.",
    "authors": [
      "Preeti Bhargava",
      "Nemanja Spasojevic",
      "Guoning Hu"
    ],
    "date": "[Submitted on 13 Jul 2017]"
  },
  {
    "url": "https://arxiv.org/abs/1905.08741v1",
    "title": "Next-to-leading power threshold effects for inclusive and exclusive processes with final state jets",
    "abstract": "It is well known that cross-sections in perturbative QCD receive large corrections from soft and collinear radiation, whose properties must be resummed to all orders in the coupling. Whether or not the universal properties of this radiation can be extended to next-to-leading power (NLP) in the threshold expansion has been the subject of much recent study. In this paper, we consider two types of NLP effects: the interplay of next-to-soft and collinear radiation in processes with final state jets and the NLP contributions stemming from soft quarks. We derive an NLP amplitude for soft gluons and quarks, valid for an arbitrary number of coloured or colourless massless final state particles. We show explicitly that this framework can be used to correctly obtain the dominant NLP effects in three different types of processes at next-to-leading order: deep-inelastic scattering, hadroproduction via electron-positron annihilation and prompt photon production. Our results provide an important ingredient for developing a universal resummation formalism for NLP effects.",
    "authors": [
      "Melissa van Beekveld",
      "Wim Beenakker",
      "Eric Laenen",
      "Chris D. White"
    ],
    "date": "[Submitted on 21 May 2019]"
  },
  {
    "url": "https://arxiv.org/abs/1807.00571v1",
    "title": "The Interplay between Lexical Resources and Natural Language Processing",
    "abstract": "Incorporating linguistic, world and common sense knowledge into AI/NLP systems is currently an important research area, with several open problems and challenges. At the same time, processing and storing this knowledge in lexical resources is not a straightforward task. This tutorial proposes to address these complementary goals from two methodological perspectives: the use of NLP methods to help the process of constructing and enriching lexical resources and the use of lexical resources for improving NLP applications. Two main types of audience can benefit from this tutorial: those working on language resources who are interested in becoming acquainted with automatic NLP techniques, with the end goal of speeding and/or easing up the process of resource curation; and on the other hand, researchers in NLP who would like to benefit from the knowledge of lexical resources to improve their systems and models. The slides of the tutorial are available at this https URL",
    "authors": [
      "Jose Camacho-Collados",
      "Luis Espinosa-Anke",
      "Mohammad Taher Pilehvar"
    ],
    "date": "[Submitted on 2 Jul 2018]"
  },
  {
    "url": "https://arxiv.org/abs/2007.05872v1",
    "title": "Is Machine Learning Speaking my Language? A Critical Look at the NLP-Pipeline Across 8 Human Languages",
    "abstract": "Natural Language Processing (NLP) is increasingly used as a key ingredient in critical decision-making systems such as resume parsers used in sorting a list of job candidates. NLP systems often ingest large corpora of human text, attempting to learn from past human behavior and decisions in order to produce systems that will make recommendations about our future world. Over 7000 human languages are being spoken today and the typical NLP pipeline underrepresents speakers of most of them while amplifying the voices of speakers of other languages. In this paper, a team including speakers of 8 languages - English, Chinese, Urdu, Farsi, Arabic, French, Spanish, and Wolof - takes a critical look at the typical NLP pipeline and how even when a language is technically supported, substantial caveats remain to prevent full participation. Despite huge and admirable investments in multilingual support in many tools and resources, we are still making NLP-guided decisions that systematically and dramatically underrepresent the voices of much of the world.",
    "authors": [
      "Esma Wali",
      "Yan Chen",
      "Christopher Mahoney",
      "Thomas Middleton",
      "Marzieh Babaeianjelodar",
      "Mariama Njie",
      "Jeanna Neefe Matthews"
    ],
    "date": "[Submitted on 11 Jul 2020]"
  },
  {
    "url": "https://arxiv.org/abs/2011.04372v1",
    "title": "Low-Resource Adaptation of Neural NLP Models",
    "abstract": "Real-world applications of natural language processing (NLP) are challenging. NLP models rely heavily on supervised machine learning and require large amounts of annotated data. These resources are often based on language data available in large quantities, such as English newswire. However, in real-world applications of NLP, the textual resources vary across several dimensions, such as language, dialect, topic, and genre. It is challenging to find annotated data of sufficient amount and quality. The objective of this thesis is to investigate methods for dealing with such low-resource scenarios in information extraction and natural language understanding. To this end, we study distant supervision and sequential transfer learning in various low-resource settings. We develop and adapt neural NLP models to explore a number of research questions concerning NLP tasks with minimal or no training data.",
    "authors": [
      "Farhad Nooralahzadeh"
    ],
    "date": "[Submitted on 9 Nov 2020]"
  },
  {
    "url": "https://arxiv.org/abs/2101.07270v1",
    "title": "Next-to-leading power threshold corrections for finite order and resummed colour-singlet cross sections",
    "abstract": "We study next-to-leading-power (NLP) threshold corrections in colour-singlet production processes, with particular emphasis on Drell-Yan (DY) and single-Higgs production. We assess the quality of the partonic and hadronic threshold expansions for each process up to NNLO. We determine numerically the NLP leading-logarithmic (LL) resummed contribution in addition to the leading-power next-to-next-to-leading logarithmic (LP NNLL) resummed DY and Higgs cross sections, matched to NNLO. We find that the inclusion of NLP logarithms is numerically more relevant than increasing the precision to N$^3$LL at LP for these processes. We also perform an analytical and numerical comparison of LP NNLL + NLP LL resummation in soft-collinear effective theory and direct QCD, where we achieve excellent analytical and numerical agreement once the NLP LL terms are included in both formalisms. Our results underline the phenomenological importance of understanding the NLP structure of QCD cross sections.",
    "authors": [
      "Melissa van Beekveld",
      "Eric Laenen",
      "Jort Sinninghe Damst\u00e9",
      "Leonardo Vernazza"
    ],
    "date": "[Submitted on 18 Jan 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2103.04044v1",
    "title": "Putting Humans in the Natural Language Processing Loop: A Survey",
    "abstract": "How can we design Natural Language Processing (NLP) systems that learn from human feedback? There is a growing research body of Human-in-the-loop (HITL) NLP frameworks that continuously integrate human feedback to improve the model itself. HITL NLP research is nascent but multifarious -- solving various NLP problems, collecting diverse feedback from different people, and applying different methods to learn from collected feedback. We present a survey of HITL NLP work from both Machine Learning (ML) and Human-Computer Interaction (HCI) communities that highlights its short yet inspiring history, and thoroughly summarize recent frameworks focusing on their tasks, goals, human interactions, and feedback learning methods. Finally, we discuss future directions for integrating human feedback in the NLP development loop.",
    "authors": [
      "Zijie J. Wang",
      "Dongjin Choi",
      "Shenyu Xu",
      "Diyi Yang"
    ],
    "date": "[Submitted on 6 Mar 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2103.06944v2",
    "title": "Preregistering NLP Research",
    "abstract": "Preregistration refers to the practice of specifying what you are going to do, and what you expect to find in your study, before carrying out the study. This practice is increasingly common in medicine and psychology, but is rarely discussed in NLP. This paper discusses preregistration in more detail, explores how NLP researchers could preregister their work, and presents several preregistration questions for different kinds of studies. Finally, we argue in favour of registered reports, which could provide firmer grounds for slow science in NLP research. The goal of this paper is to elicit a discussion in the NLP community, which we hope to synthesise into a general NLP preregistration form in future research.",
    "authors": [
      "Emiel van Miltenburg",
      "Chris van der Lee",
      "Emiel Krahmer"
    ],
    "date": "[Submitted on 11 Mar 2021 (v1), last revised 23 Mar 2021 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2203.13357v1",
    "title": "One Country, 700+ Languages: NLP Challenges for Underrepresented Languages and Dialects in Indonesia",
    "abstract": "NLP research is impeded by a lack of resources and awareness of the challenges presented by underrepresented languages and dialects. Focusing on the languages spoken in Indonesia, the second most linguistically diverse and the fourth most populous nation of the world, we provide an overview of the current state of NLP research for Indonesia's 700+ languages. We highlight challenges in Indonesian NLP and how these affect the performance of current NLP systems. Finally, we provide general recommendations to help develop NLP technology not only for languages of Indonesia but also other underrepresented languages.",
    "authors": [
      "Alham Fikri Aji",
      "Genta Indra Winata",
      "Fajri Koto",
      "Samuel Cahyawijaya",
      "Ade Romadhony",
      "Rahmad Mahendra",
      "Kemal Kurniawan",
      "David Moeljadi",
      "Radityo Eko Prasojo",
      "Timothy Baldwin",
      "Jey Han Lau",
      "Sebastian Ruder"
    ],
    "date": "[Submitted on 24 Mar 2022]"
  },
  {
    "url": "https://arxiv.org/abs/2210.04675v2",
    "title": "A Survey of Methods for Addressing Class Imbalance in Deep-Learning Based Natural Language Processing",
    "abstract": "Many natural language processing (NLP) tasks are naturally imbalanced, as some target categories occur much more frequently than others in the real world. In such scenarios, current NLP models still tend to perform poorly on less frequent classes. Addressing class imbalance in NLP is an active research topic, yet, finding a good approach for a particular task and imbalance scenario is difficult.\nWith this survey, the first overview on class imbalance in deep-learning based NLP, we provide guidance for NLP researchers and practitioners dealing with imbalanced data. We first discuss various types of controlled and real-world class imbalance. Our survey then covers approaches that have been explicitly proposed for class-imbalanced NLP tasks or, originating in the computer vision community, have been evaluated on them. We organize the methods by whether they are based on sampling, data augmentation, choice of loss function, staged learning, or model design. Finally, we discuss open problems such as dealing with multi-label scenarios, and propose systematic benchmarking and reporting in order to move forward on this problem as a community.",
    "authors": [
      "Sophie Henning",
      "William Beluch",
      "Alexander Fraser",
      "Annemarie Friedrich"
    ],
    "date": "[Submitted on 10 Oct 2022 (v1), last revised 22 Feb 2023 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2010.01724v1",
    "title": "TextAttack: Lessons learned in designing Python frameworks for NLP",
    "abstract": "TextAttack is an open-source Python toolkit for adversarial attacks, adversarial training, and data augmentation in NLP. TextAttack unites 15+ papers from the NLP adversarial attack literature into a single framework, with many components reused across attacks. This framework allows both researchers and developers to test and study the weaknesses of their NLP models. To build such an open-source NLP toolkit requires solving some common problems: How do we enable users to supply models from different deep learning frameworks? How can we build tools to support as many different datasets as possible? We share our insights into developing a well-written, well-documented NLP Python framework in hope that they can aid future development of similar packages.",
    "authors": [
      "John X. Morris",
      "Jin Yong Yoo",
      "Yanjun Qi"
    ],
    "date": "[Submitted on 5 Oct 2020]"
  },
  {
    "url": "https://arxiv.org/abs/2110.15803v3",
    "title": "Natural Language Processing for Smart Healthcare",
    "abstract": "Smart healthcare has achieved significant progress in recent years. Emerging artificial intelligence (AI) technologies enable various smart applications across various healthcare scenarios. As an essential technology powered by AI, natural language processing (NLP) plays a key role in smart healthcare due to its capability of analysing and understanding human language. In this work, we review existing studies that concern NLP for smart healthcare from the perspectives of technique and application. We first elaborate on different NLP approaches and the NLP pipeline for smart healthcare from the technical point of view. Then, in the context of smart healthcare applications employing NLP techniques, we introduce representative smart healthcare scenarios, including clinical practice, hospital management, personal care, public health, and drug development. We further discuss two specific medical issues, i.e., the coronavirus disease 2019 (COVID-19) pandemic and mental health, in which NLP-driven smart healthcare plays an important role. Finally, we discuss the limitations of current works and identify the directions for future works.",
    "authors": [
      "Binggui Zhou",
      "Guanghua Yang",
      "Zheng Shi",
      "Shaodan Ma"
    ],
    "date": "[Submitted on 19 Oct 2021 (v1), last revised 26 Sep 2022 (this version, v3)]"
  },
  {
    "url": "https://arxiv.org/abs/2205.05071v4",
    "title": "Towards Climate Awareness in NLP Research",
    "abstract": "The climate impact of AI, and NLP research in particular, has become a serious issue given the enormous amount of energy that is increasingly being used for training and running computational models. Consequently, increasing focus is placed on efficient NLP. However, this important initiative lacks simple guidelines that would allow for systematic climate reporting of NLP research. We argue that this deficiency is one of the reasons why very few publications in NLP report key figures that would allow a more thorough examination of environmental impact. As a remedy, we propose a climate performance model card with the primary purpose of being practically usable with only limited information about experiments and the underlying computer hardware. We describe why this step is essential to increase awareness about the environmental impact of NLP research and, thereby, paving the way for more thorough discussions.",
    "authors": [
      "Daniel Hershcovich",
      "Nicolas Webersinke",
      "Mathias Kraus",
      "Julia Anna Bingler",
      "Markus Leippold"
    ],
    "date": "[Submitted on 10 May 2022 (v1), last revised 18 Oct 2022 (this version, v4)]"
  },
  {
    "url": "https://arxiv.org/abs/2302.06801v1",
    "title": "Backdoor Learning for NLP: Recent Advances, Challenges, and Future Research Directions",
    "abstract": "Although backdoor learning is an active research topic in the NLP domain, the literature lacks studies that systematically categorize and summarize backdoor attacks and defenses. To bridge the gap, we present a comprehensive and unifying study of backdoor learning for NLP by summarizing the literature in a systematic manner. We first present and motivate the importance of backdoor learning for building robust NLP systems. Next, we provide a thorough account of backdoor attack techniques, their applications, defenses against backdoor attacks, and various mitigation techniques to remove backdoor attacks. We then provide a detailed review and analysis of evaluation metrics, benchmark datasets, threat models, and challenges related to backdoor learning in NLP. Ultimately, our work aims to crystallize and contextualize the landscape of existing literature in backdoor learning for the text domain and motivate further research in the field. To this end, we identify troubling gaps in the literature and offer insights and ideas into open challenges and future research directions. Finally, we provide a GitHub repository with a list of backdoor learning papers that will be continuously updated at this https URL.",
    "authors": [
      "Marwan Omar"
    ],
    "date": "[Submitted on 14 Feb 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2306.15766v1",
    "title": "Large Language Models as Annotators: Enhancing Generalization of NLP Models at Minimal Cost",
    "abstract": "State-of-the-art supervised NLP models achieve high accuracy but are also susceptible to failures on inputs from low-data regimes, such as domains that are not represented in training data. As an approximation to collecting ground-truth labels for the specific domain, we study the use of large language models (LLMs) for annotating inputs and improving the generalization of NLP models. Specifically, given a budget for LLM annotations, we present an algorithm for sampling the most informative inputs to annotate and retrain the NLP model. We find that popular active learning strategies such as uncertainty-based sampling do not work well. Instead, we propose a sampling strategy based on the difference in prediction scores between the base model and the finetuned NLP model, utilizing the fact that most NLP models are finetuned from a base model. Experiments with classification (semantic similarity) and ranking (semantic search) tasks show that our sampling strategy leads to significant gains in accuracy for both the training and target domains.",
    "authors": [
      "Parikshit Bansal",
      "Amit Sharma"
    ],
    "date": "[Submitted on 27 Jun 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2308.16549v2",
    "title": "Thesis Distillation: Investigating The Impact of Bias in NLP Models on Hate Speech Detection",
    "abstract": "This paper is a summary of the work done in my PhD thesis. Where I investigate the impact of bias in NLP models on the task of hate speech detection from three perspectives: explainability, offensive stereotyping bias, and fairness. Then, I discuss the main takeaways from my thesis and how they can benefit the broader NLP community. Finally, I discuss important future research directions. The findings of my thesis suggest that the bias in NLP models impacts the task of hate speech detection from all three perspectives. And that unless we start incorporating social sciences in studying bias in NLP models, we will not effectively overcome the current limitations of measuring and mitigating bias in NLP models.",
    "authors": [
      "Fatma Elsafoury"
    ],
    "date": "[Submitted on 31 Aug 2023 (v1), last revised 5 Dec 2023 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2310.12418v1",
    "title": "The Shifted and The Overlooked: A Task-oriented Investigation of User-GPT Interactions",
    "abstract": "Recent progress in Large Language Models (LLMs) has produced models that exhibit remarkable performance across a variety of NLP tasks. However, it remains unclear whether the existing focus of NLP research accurately captures the genuine requirements of human users. This paper provides a comprehensive analysis of the divergence between current NLP research and the needs of real-world NLP applications via a large-scale collection of user-GPT conversations. We analyze a large-scale collection of real user queries to GPT. We compare these queries against existing NLP benchmark tasks and identify a significant gap between the tasks that users frequently request from LLMs and the tasks that are commonly studied in academic research. For example, we find that tasks such as ``design'' and ``planning'' are prevalent in user interactions but are largely neglected or different from traditional NLP benchmarks. We investigate these overlooked tasks, dissect the practical challenges they pose, and provide insights toward a roadmap to make LLMs better aligned with user needs.",
    "authors": [
      "Siru Ouyang",
      "Shuohang Wang",
      "Yang Liu",
      "Ming Zhong",
      "Yizhu Jiao",
      "Dan Iter",
      "Reid Pryzant",
      "Chenguang Zhu",
      "Heng Ji",
      "Jiawei Han"
    ],
    "date": "[Submitted on 19 Oct 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2311.08391v1",
    "title": "A Material Lens on Coloniality in NLP",
    "abstract": "Coloniality, the continuation of colonial harms beyond \"official\" colonization, has pervasive effects across society and scientific fields. Natural Language Processing (NLP) is no exception to this broad phenomenon. In this work, we argue that coloniality is implicitly embedded in and amplified by NLP data, algorithms, and software. We formalize this analysis using Actor-Network Theory (ANT): an approach to understanding social phenomena through the network of relationships between human stakeholders and technology. We use our Actor-Network to guide a quantitative survey of the geography of different phases of NLP research, providing evidence that inequality along colonial boundaries increases as NLP builds on itself. Based on this, we argue that combating coloniality in NLP requires not only changing current values but also active work to remove the accumulation of colonial ideals in our foundational data and algorithms.",
    "authors": [
      "William Held",
      "Camille Harris",
      "Michael Best",
      "Diyi Yang"
    ],
    "date": "[Submitted on 14 Nov 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2401.11972v2",
    "title": "Synergizing Machine Learning & Symbolic Methods: A Survey on Hybrid Approaches to Natural Language Processing",
    "abstract": "The advancement of machine learning and symbolic approaches have underscored their strengths and weaknesses in Natural Language Processing (NLP). While machine learning approaches are powerful in identifying patterns in data, they often fall short in learning commonsense and the factual knowledge required for the NLP tasks. Meanwhile, the symbolic methods excel in representing knowledge-rich data. However, they struggle to adapt dynamic data and generalize the knowledge. Bridging these two paradigms through hybrid approaches enables the alleviation of weaknesses in both while preserving their strengths. Recent studies extol the virtues of this union, showcasing promising results in a wide range of NLP tasks. In this paper, we present an overview of hybrid approaches used for NLP. Specifically, we delve into the state-of-the-art hybrid approaches used for a broad spectrum of NLP tasks requiring natural language understanding, generation, and reasoning. Furthermore, we discuss the existing resources available for hybrid approaches for NLP along with the challenges and future directions, offering a roadmap for future research avenues.",
    "authors": [
      "Rrubaa Panchendrarajan",
      "Arkaitz Zubiaga"
    ],
    "date": "[Submitted on 22 Jan 2024 (v1), last revised 18 Mar 2024 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2402.18849v1",
    "title": "Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP Models on Accuracy and Semantic Coherence",
    "abstract": "This study discusses a new method combining image steganography technology with Natural Language Processing (NLP) large models, aimed at improving the accuracy and robustness of extracting steganographic text. Traditional Least Significant Bit (LSB) steganography techniques face challenges in accuracy and robustness of information extraction when dealing with complex character encoding, such as Chinese characters. To address this issue, this study proposes an innovative LSB-NLP hybrid framework. This framework integrates the advanced capabilities of NLP large models, such as error detection, correction, and semantic consistency analysis, as well as information reconstruction techniques, thereby significantly enhancing the robustness of steganographic text extraction. Experimental results show that the LSB-NLP hybrid framework excels in improving the extraction accuracy of steganographic text, especially in handling Chinese characters. The findings of this study not only confirm the effectiveness of combining image steganography technology and NLP large models but also propose new ideas for research and application in the field of information hiding. The successful implementation of this interdisciplinary approach demonstrates the great potential of integrating image steganography technology with natural language processing technology in solving complex information processing problems.",
    "authors": [
      "Mingyang Li",
      "Maoqin Yuan",
      "Luyao Li",
      "Han Pengsihua"
    ],
    "date": "[Submitted on 29 Feb 2024]"
  },
  {
    "url": "https://arxiv.org/abs/2403.11009v2",
    "title": "DIALECTBENCH: A NLP Benchmark for Dialects, Varieties, and Closely-Related Languages",
    "abstract": "Language technologies should be judged on their usefulness in real-world use cases. An often overlooked aspect in natural language processing (NLP) research and evaluation is language variation in the form of non-standard dialects or language varieties (hereafter, varieties). Most NLP benchmarks are limited to standard language varieties. To fill this gap, we propose DIALECTBENCH, the first-ever large-scale benchmark for NLP on varieties, which aggregates an extensive set of task-varied variety datasets (10 text-level tasks covering 281 varieties). This allows for a comprehensive evaluation of NLP system performance on different language varieties. We provide substantial evidence of performance disparities between standard and non-standard language varieties, and we also identify language clusters with large performance divergence across tasks. We believe DIALECTBENCH provides a comprehensive view of the current state of NLP for language varieties and one step towards advancing it further. Code/data: this https URL",
    "authors": [
      "Fahim Faisal",
      "Orevaoghene Ahia",
      "Aarohi Srivastava",
      "Kabir Ahuja",
      "David Chiang",
      "Yulia Tsvetkov",
      "Antonios Anastasopoulos"
    ],
    "date": "[Submitted on 16 Mar 2024 (v1), last revised 7 Jul 2024 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2405.09854v2",
    "title": "Striking a Balance between Classical and Deep Learning Approaches in Natural Language Processing Pedagogy",
    "abstract": "While deep learning approaches represent the state-of-the-art of natural language processing (NLP) today, classical algorithms and approaches still find a place in NLP textbooks and courses of recent years. This paper discusses the perspectives of conveners of two introductory NLP courses taught in Australia and India, and examines how classical and deep learning approaches can be balanced within the lecture plan and assessments of the courses. We also draw parallels with the objects-first and objects-later debate in CS1 education. We observe that teaching classical approaches adds value to student learning by building an intuitive understanding of NLP problems, potential solutions, and even deep learning models themselves. Despite classical approaches not being state-of-the-art, the paper makes a case for their inclusion in NLP courses today.",
    "authors": [
      "Aditya Joshi",
      "Jake Renzella",
      "Pushpak Bhattacharyya",
      "Saurav Jha",
      "Xiangyu Zhang"
    ],
    "date": "[Submitted on 16 May 2024 (v1), last revised 9 Jul 2024 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2406.09765v2",
    "title": "Application of Natural Language Processing in Financial Risk Detection",
    "abstract": "This paper explores the application of Natural Language Processing (NLP) in financial risk detection. By constructing an NLP-based financial risk detection model, this study aims to identify and predict potential risks in financial documents and communications. First, the fundamental concepts of NLP and its theoretical foundation, including text mining methods, NLP model design principles, and machine learning algorithms, are introduced. Second, the process of text data preprocessing and feature extraction is described. Finally, the effectiveness and predictive performance of the model are validated through empirical research. The results show that the NLP-based financial risk detection model performs excellently in risk identification and prediction, providing effective risk management tools for financial institutions. This study offers valuable references for the field of financial risk management, utilizing advanced NLP techniques to improve the accuracy and efficiency of financial risk detection.",
    "authors": [
      "Liyang Wang",
      "Yu Cheng",
      "Ao Xiang",
      "Jingyu Zhang",
      "Haowei Yang"
    ],
    "date": "[Submitted on 14 Jun 2024 (v1), last revised 20 Jun 2024 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2407.01697v1",
    "title": "NLPGuard: A Framework for Mitigating the Use of Protected Attributes by NLP Classifiers",
    "abstract": "AI regulations are expected to prohibit machine learning models from using sensitive attributes during training. However, the latest Natural Language Processing (NLP) classifiers, which rely on deep learning, operate as black-box systems, complicating the detection and remediation of such misuse. Traditional bias mitigation methods in NLP aim for comparable performance across different groups based on attributes like gender or race but fail to address the underlying issue of reliance on protected attributes. To partly fix that, we introduce NLPGuard, a framework for mitigating the reliance on protected attributes in NLP classifiers. NLPGuard takes an unlabeled dataset, an existing NLP classifier, and its training data as input, producing a modified training dataset that significantly reduces dependence on protected attributes without compromising accuracy. NLPGuard is applied to three classification tasks: identifying toxic language, sentiment analysis, and occupation classification. Our evaluation shows that current NLP classifiers heavily depend on protected attributes, with up to $23\\%$ of the most predictive words associated with these attributes. However, NLPGuard effectively reduces this reliance by up to $79\\%$, while slightly improving accuracy.",
    "authors": [
      "Salvatore Greco",
      "Ke Zhou",
      "Licia Capra",
      "Tania Cerquitelli",
      "Daniele Quercia"
    ],
    "date": "[Submitted on 1 Jul 2024]"
  },
  {
    "url": "https://arxiv.org/abs/2412.15471v2",
    "title": "A Review of the Marathi Natural Language Processing",
    "abstract": "Marathi is one of the most widely used languages in the world. One might expect that the latest advances in NLP research in languages like English reach such a large community. However, NLP advancements in English didn't immediately reach Indian languages like Marathi. There were several reasons for this. They included diversity of scripts used, lack of (publicly available) resources like tokenization strategies, high quality datasets \\& benchmarks, and evaluation metrics. In addition to this, the morphologically rich nature of Marathi, made NLP tasks challenging. Advances in Neural Network (NN) based models and tools since the early 2000s helped improve this situation and make NLP research more accessible. In the past 10 years, significant efforts were made to improve language resources for all 22 scheduled languages of India. This paper presents a broad overview of evolution of NLP research in Indic languages with a focus on Marathi and state-of-the-art resources and tools available to the research community. It also provides an overview of tools \\& techniques associated with Marathi NLP tasks.",
    "authors": [
      "Asang Dani",
      "Shailesh R Sathe"
    ],
    "date": "[Submitted on 20 Dec 2024 (v1), last revised 24 Dec 2024 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2501.12826v1",
    "title": "Open or Closed LLM for Lesser-Resourced Languages? Lessons from Greek",
    "abstract": "Natural Language Processing (NLP) for lesser-resourced languages faces persistent challenges, including limited datasets, inherited biases from high-resource languages, and the need for domain-specific solutions. This study addresses these gaps for Modern Greek through three key contributions. First, we evaluate the performance of open-source (Llama-70b) and closed-source (GPT-4o mini) large language models (LLMs) on seven core NLP tasks with dataset availability, revealing task-specific strengths, weaknesses, and parity in their performance. Second, we expand the scope of Greek NLP by reframing Authorship Attribution as a tool to assess potential data usage by LLMs in pre-training, with high 0-shot accuracy suggesting ethical implications for data provenance. Third, we showcase a legal NLP case study, where a Summarize, Translate, and Embed (STE) methodology outperforms the traditional TF-IDF approach for clustering \\emph{long} legal texts. Together, these contributions provide a roadmap to advance NLP in lesser-resourced languages, bridging gaps in model evaluation, task innovation, and real-world impact.",
    "authors": [
      "John Pavlopoulos",
      "Juli Bakagianni",
      "Kanella Pouli",
      "Maria Gavriilidou"
    ],
    "date": "[Submitted on 22 Jan 2025]"
  },
  {
    "url": "https://arxiv.org/abs/2505.21315v3",
    "title": "Charting the Landscape of African NLP: Mapping Progress and Shaping the Road Ahead",
    "abstract": "With over 2,000 languages and potentially millions of speakers, Africa represents one of the richest linguistic regions in the world. Yet, this diversity is scarcely reflected in state-of-the-art natural language processing (NLP) systems and large language models (LLMs), which predominantly support a narrow set of high-resource languages. This exclusion not only limits the reach and utility of modern NLP technologies but also risks widening the digital divide across linguistic communities. Nevertheless, NLP research on African languages is active and growing. In recent years, there has been a surge of interest in this area, driven by several factors-including the creation of multilingual language resources, the rise of community-led initiatives, and increased support through funding programs. In this survey, we analyze 884 research papers on NLP for African languages published over the past five years, offering a comprehensive overview of recent progress across core tasks. We identify key trends shaping the field and conclude by outlining promising directions to foster more inclusive and sustainable NLP research for African languages.",
    "authors": [
      "Jesujoba O. Alabi",
      "Michael A. Hedderich",
      "David Ifeoluwa Adelani",
      "Dietrich Klakow"
    ],
    "date": "[Submitted on 27 May 2025 (v1), last revised 2 Oct 2025 (this version, v3)]"
  },
  {
    "url": "https://arxiv.org/abs/2505.23801v1",
    "title": "SEMFED: Semantic-Aware Resource-Efficient Federated Learning for Heterogeneous NLP Tasks",
    "abstract": "Background: Federated Learning (FL) has emerged as a promising paradigm for training machine learning models while preserving data privacy. However, applying FL to Natural Language Processing (NLP) tasks presents unique challenges due to semantic heterogeneity across clients, vocabulary mismatches, and varying resource constraints on edge devices. Objectives: This paper introduces SEMFED, a novel semantic-aware resource-efficient federated learning framework specifically designed for heterogeneous NLP tasks. Methods: SEMFED incorporates three key innovations: (1) a semantic-aware client selection mechanism that balances semantic diversity with resource constraints, (2) adaptive NLP-specific model architectures tailored to device capabilities while preserving semantic information, and (3) a communication-efficient semantic feature compression technique that significantly reduces bandwidth requirements. Results: Experimental results on various NLP classification tasks demonstrate that SEMFED achieves an 80.5% reduction in communication costs while maintaining model accuracy above 98%, outperforming state-of-the-art FL approaches. Conclusion: SEMFED effectively manages heterogeneous client environments with varying computational resources, network reliability, and semantic data distributions, making it particularly suitable for real-world federated NLP deployments.",
    "authors": [
      "Sajid Hussain",
      "Muhammad Sohail",
      "Nauman Ali Khan"
    ],
    "date": "[Submitted on 26 May 2025]"
  },
  {
    "url": "https://arxiv.org/abs/2506.22481v1",
    "title": "Theories of \"Sexuality\" in Natural Language Processing Bias Research",
    "abstract": "In recent years, significant advancements in the field of Natural Language Processing (NLP) have positioned commercialized language models as wide-reaching, highly useful tools. In tandem, there has been an explosion of multidisciplinary research examining how NLP tasks reflect, perpetuate, and amplify social biases such as gender and racial bias. A significant gap in this scholarship is a detailed analysis of how queer sexualities are encoded and (mis)represented by both NLP systems and practitioners. Following previous work in the field of AI fairness, we document how sexuality is defined and operationalized via a survey and analysis of 55 articles that quantify sexuality-based NLP bias. We find that sexuality is not clearly defined in a majority of the literature surveyed, indicating a reliance on assumed or normative conceptions of sexual/romantic practices and identities. Further, we find that methods for extracting biased outputs from NLP technologies often conflate gender and sexual identities, leading to monolithic conceptions of queerness and thus improper quantifications of bias. With the goal of improving sexuality-based NLP bias analyses, we conclude with recommendations that encourage more thorough engagement with both queer communities and interdisciplinary literature.",
    "authors": [
      "Jacob Hobbs"
    ],
    "date": "[Submitted on 22 Jun 2025]"
  },
  {
    "url": "https://arxiv.org/abs/2507.10559v2",
    "title": "NLP Meets the World: Toward Improving Conversations With the Public About Natural Language Processing Research",
    "abstract": "Recent developments in large language models (LLMs) have been accompanied by rapidly growing public interest in natural language processing (NLP). This attention is reflected by major news venues, which sometimes invite NLP researchers to share their knowledge and views with a wide audience. Recognizing the opportunities of the present, for both the research field and for individual researchers, this paper shares recommendations for communicating with a general audience about the capabilities and limitations of NLP. These recommendations cover three themes: vague terminology as an obstacle to public understanding, unreasonable expectations as obstacles to sustainable growth, and ethical failures as obstacles to continued support. Published NLP research and popular news coverage are cited to illustrate these themes with examples. The recommendations promote effective, transparent communication with the general public about NLP, in order to strengthen public understanding and encourage support for research.",
    "authors": [
      "Shomir Wilson"
    ],
    "date": "[Submitted on 2 Jul 2025 (v1), last revised 16 Jul 2025 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2509.17335v1",
    "title": "BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing",
    "abstract": "Fuzzing has shown great success in evaluating the robustness of intelligent natural language processing (NLP) software. As large language model (LLM)-based NLP software is widely deployed in critical industries, existing methods still face two main challenges: 1 testing methods are insufficiently coupled with the behavioral patterns of LLM-based NLP software; 2 fuzzing capability for the testing scenario of natural language generation (NLG) generally degrades. To address these issues, we propose BASFuzz, an efficient Fuzz testing method tailored for LLM-based NLP software. BASFuzz targets complete test inputs composed of prompts and examples, and uses a text consistency metric to guide mutations of the fuzzing loop, aligning with the behavioral patterns of LLM-based NLP software. A Beam-Annealing Search algorithm, which integrates beam search and simulated annealing, is employed to design an efficient fuzzing loop. In addition, information entropy-based adaptive adjustment and an elitism strategy further enhance fuzzing capability. We evaluate BASFuzz on six datasets in representative scenarios of NLG and natural language understanding (NLU). Experimental results demonstrate that BASFuzz achieves a testing effectiveness of 90.335% while reducing the average time overhead by 2,163.852 seconds compared to the current best baseline, enabling more effective robustness evaluation prior to software deployment.",
    "authors": [
      "Mingxuan Xiao",
      "Yan Xiao",
      "Shunhui Ji",
      "Jiahe Tu",
      "Pengcheng Zhang"
    ],
    "date": "[Submitted on 22 Sep 2025]"
  },
  {
    "url": "https://arxiv.org/abs/2104.10640v3",
    "title": "The NLP Cookbook: Modern Recipes for Transformer based Deep Learning Architectures",
    "abstract": "In recent years, Natural Language Processing (NLP) models have achieved phenomenal success in linguistic and semantic tasks like text classification, machine translation, cognitive dialogue systems, information retrieval via Natural Language Understanding (NLU), and Natural Language Generation (NLG). This feat is primarily attributed due to the seminal Transformer architecture, leading to designs such as BERT, GPT (I, II, III), etc. Although these large-size models have achieved unprecedented performances, they come at high computational costs. Consequently, some of the recent NLP architectures have utilized concepts of transfer learning, pruning, quantization, and knowledge distillation to achieve moderate model sizes while keeping nearly similar performances as achieved by their predecessors. Additionally, to mitigate the data size challenge raised by language models from a knowledge extraction perspective, Knowledge Retrievers have been built to extricate explicit data documents from a large corpus of databases with greater efficiency and accuracy. Recent research has also focused on superior inference by providing efficient attention to longer input sequences. In this paper, we summarize and examine the current state-of-the-art (SOTA) NLP models that have been employed for numerous NLP tasks for optimal performance and efficiency. We provide a detailed understanding and functioning of the different architectures, a taxonomy of NLP designs, comparative evaluations, and future directions in NLP.",
    "authors": [
      "Sushant Singh",
      "Ausif Mahmood"
    ],
    "date": "[Submitted on 23 Mar 2021 (v1), last revised 24 Apr 2021 (this version, v3)]"
  },
  {
    "url": "https://arxiv.org/abs/2204.11909v1",
    "title": "How can NLP Help Revitalize Endangered Languages? A Case Study and Roadmap for the Cherokee Language",
    "abstract": "More than 43% of the languages spoken in the world are endangered, and language loss currently occurs at an accelerated rate because of globalization and neocolonialism. Saving and revitalizing endangered languages has become very important for maintaining the cultural diversity on our planet. In this work, we focus on discussing how NLP can help revitalize endangered languages. We first suggest three principles that may help NLP practitioners to foster mutual understanding and collaboration with language communities, and we discuss three ways in which NLP can potentially assist in language education. We then take Cherokee, a severely-endangered Native American language, as a case study. After reviewing the language's history, linguistic features, and existing resources, we (in collaboration with Cherokee community members) arrive at a few meaningful ways NLP practitioners can collaborate with community partners. We suggest two approaches to enrich the Cherokee language's resources with machine-in-the-loop processing, and discuss several NLP tools that people from the Cherokee community have shown interest in. We hope that our work serves not only to inform the NLP community about Cherokee, but also to provide inspiration for future work on endangered languages in general. Our code and data will be open-sourced at this https URL",
    "authors": [
      "Shiyue Zhang",
      "Ben Frey",
      "Mohit Bansal"
    ],
    "date": "[Submitted on 25 Apr 2022]"
  },
  {
    "url": "https://arxiv.org/abs/2012.00633v1",
    "title": "Meta-Embeddings for Natural Language Inference and Semantic Similarity tasks",
    "abstract": "Word Representations form the core component for almost all advanced Natural Language Processing (NLP) applications such as text mining, question-answering, and text summarization, etc. Over the last two decades, immense research is conducted to come up with one single model to solve all major NLP tasks. The major problem currently is that there are a plethora of choices for different NLP tasks. Thus for NLP practitioners, the task of choosing the right model to be used itself becomes a challenge. Thus combining multiple pre-trained word embeddings and forming meta embeddings has become a viable approach to improve tackle NLP tasks. Meta embedding learning is a process of producing a single word embedding from a given set of pre-trained input word embeddings. In this paper, we propose to use Meta Embedding derived from few State-of-the-Art (SOTA) models to efficiently tackle mainstream NLP tasks like classification, semantic relatedness, and text similarity. We have compared both ensemble and dynamic variants to identify an efficient approach. The results obtained show that even the best State-of-the-Art models can be bettered. Thus showing us that meta-embeddings can be used for several NLP tasks by harnessing the power of several individual representations.",
    "authors": [
      "Shree Charran R",
      "Rahul Kumar Dubey"
    ],
    "date": "[Submitted on 1 Dec 2020]"
  },
  {
    "url": "https://arxiv.org/abs/2102.12982v1",
    "title": "A Primer on Contrastive Pretraining in Language Processing: Methods, Lessons Learned and Perspectives",
    "abstract": "Modern natural language processing (NLP) methods employ self-supervised pretraining objectives such as masked language modeling to boost the performance of various application tasks. These pretraining methods are frequently extended with recurrence, adversarial or linguistic property masking, and more recently with contrastive learning objectives. Contrastive self-supervised training objectives enabled recent successes in image representation pretraining by learning to contrast input-input pairs of augmented images as either similar or dissimilar. However, in NLP, automated creation of text input augmentations is still very challenging because a single token can invert the meaning of a sentence. For this reason, some contrastive NLP pretraining methods contrast over input-label pairs, rather than over input-input pairs, using methods from Metric Learning and Energy Based Models. In this survey, we summarize recent self-supervised and supervised contrastive NLP pretraining methods and describe where they are used to improve language modeling, few or zero-shot learning, pretraining data-efficiency and specific NLP end-tasks. We introduce key contrastive learning concepts with lessons learned from prior research and structure works by applications and cross-field relations. Finally, we point to open challenges and future directions for contrastive NLP to encourage bringing contrastive NLP pretraining closer to recent successes in image representation pretraining.",
    "authors": [
      "Nils Rethmeier",
      "Isabelle Augenstein"
    ],
    "date": "[Submitted on 25 Feb 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2103.01834v4",
    "title": "A Data-Centric Framework for Composable NLP Workflows",
    "abstract": "Empirical natural language processing (NLP) systems in application domains (e.g., healthcare, finance, education) involve interoperation among multiple components, ranging from data ingestion, human annotation, to text retrieval, analysis, generation, and visualization. We establish a unified open-source framework to support fast development of such sophisticated NLP workflows in a composable manner. The framework introduces a uniform data representation to encode heterogeneous results by a wide range of NLP tasks. It offers a large repository of processors for NLP tasks, visualization, and annotation, which can be easily assembled with full interoperability under the unified representation. The highly extensible framework allows plugging in custom processors from external off-the-shelf NLP and deep learning libraries. The whole framework is delivered through two modularized yet integratable open-source projects, namely Forte (for workflow infrastructure and NLP function processors) and Stave (for user interaction, visualization, and annotation).",
    "authors": [
      "Zhengzhong Liu",
      "Guanxiong Ding",
      "Avinash Bukkittu",
      "Mansi Gupta",
      "Pengzhi Gao",
      "Atif Ahmed",
      "Shikun Zhang",
      "Xin Gao",
      "Swapnil Singhavi",
      "Linwei Li",
      "Wei Wei",
      "Zecong Hu",
      "Haoran Shi",
      "Haoying Zhang",
      "Xiaodan Liang",
      "Teruko Mitamura",
      "Eric P. Xing",
      "Zhiting Hu"
    ],
    "date": "[Submitted on 2 Mar 2021 (v1), last revised 2 Sep 2021 (this version, v4)]"
  },
  {
    "url": "https://arxiv.org/abs/2201.07281v2",
    "title": "Annotating the Tweebank Corpus on Named Entity Recognition and Building NLP Models for Social Media Analysis",
    "abstract": "Social media data such as Twitter messages (\"tweets\") pose a particular challenge to NLP systems because of their short, noisy, and colloquial nature. Tasks such as Named Entity Recognition (NER) and syntactic parsing require highly domain-matched training data for good performance. To date, there is no complete training corpus for both NER and syntactic analysis (e.g., part of speech tagging, dependency parsing) of tweets. While there are some publicly available annotated NLP datasets of tweets, they are only designed for individual tasks. In this study, we aim to create Tweebank-NER, an English NER corpus based on Tweebank V2 (TB2), train state-of-the-art (SOTA) Tweet NLP models on TB2, and release an NLP pipeline called Twitter-Stanza. We annotate named entities in TB2 using Amazon Mechanical Turk and measure the quality of our annotations. We train the Stanza pipeline on TB2 and compare with alternative NLP frameworks (e.g., FLAIR, spaCy) and transformer-based models. The Stanza tokenizer and lemmatizer achieve SOTA performance on TB2, while the Stanza NER tagger, part-of-speech (POS) tagger, and dependency parser achieve competitive performance against non-transformer models. The transformer-based models establish a strong baseline in Tweebank-NER and achieve the new SOTA performance in POS tagging and dependency parsing on TB2. We release the dataset and make both the Stanza pipeline and BERTweet-based models available \"off-the-shelf\" for use in future Tweet NLP research. Our source code, data, and pre-trained models are available at: \\url{this https URL}.",
    "authors": [
      "Hang Jiang",
      "Yining Hua",
      "Doug Beeferman",
      "Deb Roy"
    ],
    "date": "[Submitted on 18 Jan 2022 (v1), last revised 10 May 2022 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2208.04676v3",
    "title": "DeepHider: A Covert NLP Watermarking Framework Based on Multi-task Learning",
    "abstract": "Natural language processing (NLP) technology has shown great commercial value in applications such as sentiment analysis. But NLP models are vulnerable to the threat of pirated redistribution, damaging the economic interests of model owners. Digital watermarking technology is an effective means to protect the intellectual property rights of NLP model. The existing NLP model protection mainly designs watermarking schemes by improving both security and robustness purposes, however, the security and robustness of these schemes have the following problems, respectively: (1) Watermarks are difficult to defend against fraudulent declaration by adversary and are easily detected and blocked from verification by human or anomaly detector during the verification process. (2) The watermarking model cannot meet multiple robustness requirements at the same time. To solve the above problems, this paper proposes a novel watermarking framework for NLP model based on the over-parameterization of depth model and the multi-task learning theory. Specifically, a covert trigger set is established to realize the perception-free verification of the watermarking model, and a novel auxiliary network is designed to improve the robustness and security of the watermarking model. The proposed framework was evaluated on two benchmark datasets and three mainstream NLP models, and the results show that the framework can successfully validate model ownership with 100% validation accuracy and advanced robustness and security without compromising the host model performance.",
    "authors": [
      "Long Dai",
      "Jiarong Mao",
      "Xuefeng Fan",
      "Xiaoyi Zhou"
    ],
    "date": "[Submitted on 9 Aug 2022 (v1), last revised 18 Nov 2022 (this version, v3)]"
  },
  {
    "url": "https://arxiv.org/abs/2208.11701v1",
    "title": "Ontology-Driven Self-Supervision for Adverse Childhood Experiences Identification Using Social Media Datasets",
    "abstract": "Adverse Childhood Experiences (ACEs) are defined as a collection of highly stressful, and potentially traumatic, events or circumstances that occur throughout childhood and/or adolescence. They have been shown to be associated with increased risks of mental health diseases or other abnormal behaviours in later lives. However, the identification of ACEs from textual data with Natural Language Processing (NLP) is challenging because (a) there are no NLP ready ACE ontologies; (b) there are few resources available for machine learning, necessitating the data annotation from clinical experts; (c) costly annotations by domain experts and large number of documents for supporting large machine learning models. In this paper, we present an ontology-driven self-supervised approach (derive concept embeddings using an auto-encoder from baseline NLP results) for producing a publicly available resource that would support large-scale machine learning (e.g., training transformer based large language models) on social media corpus. This resource as well as the proposed approach are aimed to facilitate the community in training transferable NLP models for effectively surfacing ACEs in low-resource scenarios like NLP on clinical notes within Electronic Health Records. The resource including a list of ACE ontology terms, ACE concept embeddings and the NLP annotated corpus is available at this https URL.",
    "authors": [
      "Jinge Wu",
      "Rowena Smith",
      "Honghan Wu"
    ],
    "date": "[Submitted on 24 Aug 2022]"
  },
  {
    "url": "https://arxiv.org/abs/2208.14923v2",
    "title": "Few-Shot Learning for Clinical Natural Language Processing Using Siamese Neural Networks",
    "abstract": "Clinical Natural Language Processing (NLP) has become an emerging technology in healthcare that leverages a large amount of free-text data in electronic health records (EHRs) to improve patient care, support clinical decisions, and facilitate clinical and translational science research. Recently, deep learning has achieved state-of-the-art performance in many clinical NLP tasks. However, training deep learning models usually requires large annotated datasets, which are normally not publicly available and can be time-consuming to build in clinical domains. Working with smaller annotated datasets is typical in clinical NLP and therefore, ensuring that deep learning models perform well is crucial for the models to be used in real-world applications. A widely adopted approach is fine-tuning existing Pre-trained Language Models (PLMs), but these attempts fall short when the training dataset contains only a few annotated samples. Few-Shot Learning (FSL) has recently been investigated to tackle this problem. Siamese Neural Network (SNN) has been widely utilized as an FSL approach in computer vision, but has not been studied well in NLP. Furthermore, the literature on its applications in clinical domains is scarce. In this paper, we propose two SNN-based FSL approaches for clinical NLP, including Pre-Trained SNN (PT-SNN) and SNN with Second-Order Embeddings (SOE-SNN). We evaluated the proposed approaches on two clinical tasks, namely clinical text classification and clinical named entity recognition. We tested three few-shot settings including 4-shot, 8-shot, and 16-shot learning. Both clinical NLP tasks were benchmarked using three PLMs, including BERT,BioBERT, and BioClinicalBERT. The experimental results verified the effectiveness of the proposed SNN-based FSL approaches in both NLP tasks.",
    "authors": [
      "David Oniani",
      "Sonish Sivarajkumar",
      "Yanshan Wang"
    ],
    "date": "[Submitted on 31 Aug 2022 (v1), last revised 26 Oct 2022 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2210.06929v1",
    "title": "On the Explainability of Natural Language Processing Deep Models",
    "abstract": "While there has been a recent explosion of work on ExplainableAI ExAI on deep models that operate on imagery and tabular data, textual datasets present new challenges to the ExAI community. Such challenges can be attributed to the lack of input structure in textual data, the use of word embeddings that add to the opacity of the models and the difficulty of the visualization of the inner workings of deep models when they are trained on textual data.\nLately, methods have been developed to address the aforementioned challenges and present satisfactory explanations on Natural Language Processing (NLP) models. However, such methods are yet to be studied in a comprehensive framework where common challenges are properly stated and rigorous evaluation practices and metrics are proposed. Motivated to democratize ExAI methods in the NLP field, we present in this work a survey that studies model-agnostic as well as model-specific explainability methods on NLP models. Such methods can either develop inherently interpretable NLP models or operate on pre-trained models in a post-hoc manner. We make this distinction and we further decompose the methods into three categories according to what they explain: (1) word embeddings (input-level), (2) inner workings of NLP models (processing-level) and (3) models' decisions (output-level). We also detail the different evaluation approaches interpretability methods in the NLP field. Finally, we present a case-study on the well-known neural machine translation in an appendix and we propose promising future research directions for ExAI in the NLP field.",
    "authors": [
      "Julia El Zini",
      "Mariette Awad"
    ],
    "date": "[Submitted on 13 Oct 2022]"
  },
  {
    "url": "https://arxiv.org/abs/2210.09389v1",
    "title": "Potrika: Raw and Balanced Newspaper Datasets in the Bangla Language with Eight Topics and Five Attributes",
    "abstract": "Knowledge is central to human and scientific developments. Natural Language Processing (NLP) allows automated analysis and creation of knowledge. Data is a crucial NLP and machine learning ingredient. The scarcity of open datasets is a well-known problem in machine and deep learning research. This is very much the case for textual NLP datasets in English and other major world languages. For the Bangla language, the situation is even more challenging and the number of large datasets for NLP research is practically nil. We hereby present Potrika, a large single-label Bangla news article textual dataset curated for NLP research from six popular online news portals in Bangladesh (Jugantor, Jaijaidin, Ittefaq, Kaler Kontho, Inqilab, and Somoyer Alo) for the period 2014-2020. The articles are classified into eight distinct categories (National, Sports, International, Entertainment, Economy, Education, Politics, and Science \\& Technology) providing five attributes (News Article, Category, Headline, Publication Date, and Newspaper Source). The raw dataset contains 185.51 million words and 12.57 million sentences contained in 664,880 news articles. Moreover, using NLP augmentation techniques, we create from the raw (unbalanced) dataset another (balanced) dataset comprising 320,000 news articles with 40,000 articles in each of the eight news categories. Potrika contains both the datasets (raw and balanced) to suit a wide range of NLP research. By far, to the best of our knowledge, Potrika is the largest and the most extensive dataset for news classification.",
    "authors": [
      "Istiak Ahmad",
      "Fahad AlQurashi",
      "Rashid Mehmood"
    ],
    "date": "[Submitted on 17 Oct 2022]"
  },
  {
    "url": "https://arxiv.org/abs/1810.01048v1",
    "title": "Privacy-Preserving Outsourcing of Large-Scale Nonlinear Programming to the Cloud",
    "abstract": "The increasing massive data generated by various sources has given birth to big data analytics. Solving large-scale nonlinear programming problems (NLPs) is one important big data analytics task that has applications in many domains such as transport and logistics. However, NLPs are usually too computationally expensive for resource-constrained users. Fortunately, cloud computing provides an alternative and economical service for resource-constrained users to outsource their computation tasks to the cloud. However, one major concern with outsourcing NLPs is the leakage of user's private information contained in NLP formulations and results. Although much work has been done on privacy-preserving outsourcing of computation tasks, little attention has been paid to NLPs. In this paper, we for the first time investigate secure outsourcing of general large-scale NLPs with nonlinear constraints. A secure and efficient transformation scheme at the user side is proposed to protect user's private information; at the cloud side, generalized reduced gradient method is applied to effectively solve the transformed large-scale NLPs. The proposed protocol is implemented on a cloud computing testbed. Experimental evaluations demonstrate that significant time can be saved for users and the proposed mechanism has the potential for practical use.",
    "authors": [
      "Ang Li",
      "Wei Du",
      "Qinghua Li"
    ],
    "date": "[Submitted on 2 Oct 2018]"
  },
  {
    "url": "https://arxiv.org/abs/2004.08333v2",
    "title": "Natural Language Processing with Deep Learning for Medical Adverse Event Detection from Free-Text Medical Narratives: A Case Study of Detecting Total Hip Replacement Dislocation",
    "abstract": "Accurate and timely detection of medical adverse events (AEs) from free-text medical narratives is challenging. Natural language processing (NLP) with deep learning has already shown great potential for analyzing free-text data, but its application for medical AE detection has been limited. In this study we proposed deep learning based NLP (DL-NLP) models for efficient and accurate hip dislocation AE detection following total hip replacement from standard (radiology notes) and non-standard (follow-up telephone notes) free-text medical narratives. We benchmarked these proposed models with a wide variety of traditional machine learning based NLP (ML-NLP) models, and also assessed the accuracy of International Classification of Diseases (ICD) and Current Procedural Terminology (CPT) codes in capturing these hip dislocation AEs in a multi-center orthopaedic registry. All DL-NLP models out-performed all of the ML-NLP models, with a convolutional neural network (CNN) model achieving the best overall performance (Kappa = 0.97 for radiology notes, and Kappa = 1.00 for follow-up telephone notes). On the other hand, the ICD/CPT codes of the patients who sustained a hip dislocation AE were only 75.24% accurate, showing the potential of the proposed model to be used in largescale orthopaedic registries for accurate and efficient hip dislocation AE detection to improve the quality of care and patient outcome.",
    "authors": [
      "Alireza Borjali",
      "Martin Magneli",
      "David Shin",
      "Henrik Malchau",
      "Orhun K. Muratoglu",
      "Kartik M. Varadarajan"
    ],
    "date": "[Submitted on 17 Apr 2020 (v1), last revised 26 Apr 2020 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2106.06090v2",
    "title": "Graph Neural Networks for Natural Language Processing: A Survey",
    "abstract": "Deep learning has become the dominant approach in coping with various tasks in Natural LanguageProcessing (NLP). Although text inputs are typically represented as a sequence of tokens, there isa rich variety of NLP problems that can be best expressed with a graph structure. As a result, thereis a surge of interests in developing new deep learning techniques on graphs for a large numberof NLP tasks. In this survey, we present a comprehensive overview onGraph Neural Networks(GNNs) for Natural Language Processing. We propose a new taxonomy of GNNs for NLP, whichsystematically organizes existing research of GNNs for NLP along three axes: graph construction,graph representation learning, and graph based encoder-decoder models. We further introducea large number of NLP applications that are exploiting the power of GNNs and summarize thecorresponding benchmark datasets, evaluation metrics, and open-source codes. Finally, we discussvarious outstanding challenges for making the full use of GNNs for NLP as well as future researchdirections. To the best of our knowledge, this is the first comprehensive overview of Graph NeuralNetworks for Natural Language Processing.",
    "authors": [
      "Lingfei Wu",
      "Yu Chen",
      "Kai Shen",
      "Xiaojie Guo",
      "Hanning Gao",
      "Shucheng Li",
      "Jian Pei",
      "Bo Long"
    ],
    "date": "[Submitted on 10 Jun 2021 (v1), last revised 20 Oct 2022 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2112.07869v1",
    "title": "Fine-Tuning Large Neural Language Models for Biomedical Natural Language Processing",
    "abstract": "Motivation: A perennial challenge for biomedical researchers and clinical practitioners is to stay abreast with the rapid growth of publications and medical notes. Natural language processing (NLP) has emerged as a promising direction for taming information overload. In particular, large neural language models facilitate transfer learning by pretraining on unlabeled text, as exemplified by the successes of BERT models in various NLP applications. However, fine-tuning such models for an end task remains challenging, especially with small labeled datasets, which are common in biomedical NLP.\nResults: We conduct a systematic study on fine-tuning stability in biomedical NLP. We show that finetuning performance may be sensitive to pretraining settings, especially in low-resource domains. Large models have potential to attain better performance, but increasing model size also exacerbates finetuning instability. We thus conduct a comprehensive exploration of techniques for addressing fine-tuning instability. We show that these techniques can substantially improve fine-tuning performance for lowresource biomedical NLP applications. Specifically, freezing lower layers is helpful for standard BERT-BASE models, while layerwise decay is more effective for BERT-LARGE and ELECTRA models. For low-resource text similarity tasks such as BIOSSES, reinitializing the top layer is the optimal strategy. Overall, domainspecific vocabulary and pretraining facilitate more robust models for fine-tuning. Based on these findings, we establish new state of the art on a wide range of biomedical NLP applications.\nAvailability and implementation: To facilitate progress in biomedical NLP, we release our state-of-the-art pretrained and fine-tuned models: this https URL.",
    "authors": [
      "Robert Tinn",
      "Hao Cheng",
      "Yu Gu",
      "Naoto Usuyama",
      "Xiaodong Liu",
      "Tristan Naumann",
      "Jianfeng Gao",
      "Hoifung Poon"
    ],
    "date": "[Submitted on 15 Dec 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2206.09755v1",
    "title": "Square One Bias in NLP: Towards a Multi-Dimensional Exploration of the Research Manifold",
    "abstract": "The prototypical NLP experiment trains a standard architecture on labeled English data and optimizes for accuracy, without accounting for other dimensions such as fairness, interpretability, or computational efficiency. We show through a manual classification of recent NLP research papers that this is indeed the case and refer to it as the square one experimental setup. We observe that NLP research often goes beyond the square one setup, e.g, focusing not only on accuracy, but also on fairness or interpretability, but typically only along a single dimension. Most work targeting multilinguality, for example, considers only accuracy; most work on fairness or interpretability considers only English; and so on. We show this through manual classification of recent NLP research papers and ACL Test-of-Time award recipients. Such one-dimensionality of most research means we are only exploring a fraction of the NLP research search space. We provide historical and recent examples of how the square one bias has led researchers to draw false conclusions or make unwise choices, point to promising yet unexplored directions on the research manifold, and make practical recommendations to enable more multi-dimensional research. We open-source the results of our annotations to enable further analysis at this https URL",
    "authors": [
      "Sebastian Ruder",
      "Ivan Vuli\u0107",
      "Anders S\u00f8gaard"
    ],
    "date": "[Submitted on 20 Jun 2022]"
  },
  {
    "url": "https://arxiv.org/abs/2305.02797v4",
    "title": "The Elephant in the Room: Analyzing the Presence of Big Tech in Natural Language Processing Research",
    "abstract": "Recent advances in deep learning methods for natural language processing (NLP) have created new business opportunities and made NLP research critical for industry development. As one of the big players in the field of NLP, together with governments and universities, it is important to track the influence of industry on research. In this study, we seek to quantify and characterize industry presence in the NLP community over time. Using a corpus with comprehensive metadata of 78,187 NLP publications and 701 resumes of NLP publication authors, we explore the industry presence in the field since the early 90s. We find that industry presence among NLP authors has been steady before a steep increase over the past five years (180% growth from 2017 to 2022). A few companies account for most of the publications and provide funding to academic researchers through grants and internships. Our study shows that the presence and impact of the industry on natural language processing research are significant and fast-growing. This work calls for increased transparency of industry influence in the field.",
    "authors": [
      "Mohamed Abdalla",
      "Jan Philip Wahle",
      "Terry Ruas",
      "Aur\u00e9lie N\u00e9v\u00e9ol",
      "Fanny Ducel",
      "Saif M. Mohammad",
      "Kar\u00ebn Fort"
    ],
    "date": "[Submitted on 4 May 2023 (v1), last revised 16 Jul 2024 (this version, v4)]"
  },
  {
    "url": "https://arxiv.org/abs/2305.19409v1",
    "title": "Examining risks of racial biases in NLP tools for child protective services",
    "abstract": "Although much literature has established the presence of demographic bias in natural language processing (NLP) models, most work relies on curated bias metrics that may not be reflective of real-world applications. At the same time, practitioners are increasingly using algorithmic tools in high-stakes settings, with particular recent interest in NLP. In this work, we focus on one such setting: child protective services (CPS). CPS workers often write copious free-form text notes about families they are working with, and CPS agencies are actively seeking to deploy NLP models to leverage these data. Given well-established racial bias in this setting, we investigate possible ways deployed NLP is liable to increase racial disparities. We specifically examine word statistics within notes and algorithmic fairness in risk prediction, coreference resolution, and named entity recognition (NER). We document consistent algorithmic unfairness in NER models, possible algorithmic unfairness in coreference resolution models, and little evidence of exacerbated racial bias in risk prediction. While there is existing pronounced criticism of risk prediction, our results expose previously undocumented risks of racial bias in realistic information extraction systems, highlighting potential concerns in deploying them, even though they may appear more benign. Our work serves as a rare realistic examination of NLP algorithmic fairness in a potential deployed setting and a timely investigation of a specific risk associated with deploying NLP in CPS settings.",
    "authors": [
      "Anjalie Field",
      "Amanda Coston",
      "Nupoor Gandhi",
      "Alexandra Chouldechova",
      "Emily Putnam-Hornstein",
      "David Steier",
      "Yulia Tsvetkov"
    ],
    "date": "[Submitted on 30 May 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2308.12420v4",
    "title": "Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature",
    "abstract": "Distributed Ledger Technology (DLT) faces increasing environmental scrutiny, particularly concerning the energy consumption of the Proof of Work (PoW) consensus mechanism and broader Environmental, Social, and Governance (ESG) issues. However, existing systematic literature reviews of DLT rely on limited analyses of citations, abstracts, and keywords, failing to fully capture the field's complexity and ESG concerns. We address these challenges by analyzing the full text of 24,539 publications using Natural Language Processing (NLP) with our manually labeled Named Entity Recognition (NER) dataset of 39,427 entities for DLT. This methodology identified 505 key publications at the DLT/ESG intersection, enabling comprehensive domain analysis. Our combined NLP and temporal graph analysis reveals critical trends in DLT evolution and ESG impacts, including cryptography and peer-to-peer networks research's foundational influence, Bitcoin's persistent impact on research and environmental concerns (a \"Lindy effect\"), Ethereum's catalytic role on Proof of Stake (PoS) and smart contract adoption, and the industry's progressive shift toward energy-efficient consensus mechanisms. Our contributions include the first DLT-specific NER dataset addressing the scarcity of high-quality labeled NLP data in blockchain research, a methodology integrating NLP and temporal graph analysis for large-scale interdisciplinary literature reviews, and the first NLP-driven literature review focusing on DLT's ESG aspects.",
    "authors": [
      "Walter Hernandez Cruz",
      "Kamil Tylinski",
      "Alastair Moore",
      "Niall Roche",
      "Nikhil Vadgama",
      "Horst Treiblmaier",
      "Jiangbo Shangguan",
      "Paolo Tasca",
      "Jiahua Xu"
    ],
    "date": "[Submitted on 23 Aug 2023 (v1), last revised 17 Jun 2025 (this version, v4)]"
  },
  {
    "url": "https://arxiv.org/abs/2310.05553v1",
    "title": "Regulation and NLP (RegNLP): Taming Large Language Models",
    "abstract": "The scientific innovation in Natural Language Processing (NLP) and more broadly in artificial intelligence (AI) is at its fastest pace to date. As large language models (LLMs) unleash a new era of automation, important debates emerge regarding the benefits and risks of their development, deployment and use. Currently, these debates have been dominated by often polarized narratives mainly led by the AI Safety and AI Ethics movements. This polarization, often amplified by social media, is swaying political agendas on AI regulation and governance and posing issues of regulatory capture. Capture occurs when the regulator advances the interests of the industry it is supposed to regulate, or of special interest groups rather than pursuing the general public interest. Meanwhile in NLP research, attention has been increasingly paid to the discussion of regulating risks and harms. This often happens without systematic methodologies or sufficient rooting in the disciplines that inspire an extended scope of NLP research, jeopardizing the scientific integrity of these endeavors. Regulation studies are a rich source of knowledge on how to systematically deal with risk and uncertainty, as well as with scientific evidence, to evaluate and compare regulatory options. This resource has largely remained untapped so far. In this paper, we argue how NLP research on these topics can benefit from proximity to regulatory studies and adjacent fields. We do so by discussing basic tenets of regulation, and risk and uncertainty, and by highlighting the shortcomings of current NLP discussions dealing with risk assessment. Finally, we advocate for the development of a new multidisciplinary research space on regulation and NLP (RegNLP), focused on connecting scientific knowledge to regulatory processes based on systematic methodologies.",
    "authors": [
      "Catalina Goanta",
      "Nikolaos Aletras",
      "Ilias Chalkidis",
      "Sofia Ranchordas",
      "Gerasimos Spanakis"
    ],
    "date": "[Submitted on 9 Oct 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2310.09411v1",
    "title": "Surveying the Landscape of Text Summarization with Deep Learning: A Comprehensive Review",
    "abstract": "In recent years, deep learning has revolutionized natural language processing (NLP) by enabling the development of models that can learn complex representations of language data, leading to significant improvements in performance across a wide range of NLP tasks. Deep learning models for NLP typically use large amounts of data to train deep neural networks, allowing them to learn the patterns and relationships in language data. This is in contrast to traditional NLP approaches, which rely on hand-engineered features and rules to perform NLP tasks. The ability of deep neural networks to learn hierarchical representations of language data, handle variable-length input sequences, and perform well on large datasets makes them well-suited for NLP applications. Driven by the exponential growth of textual data and the increasing demand for condensed, coherent, and informative summaries, text summarization has been a critical research area in the field of NLP. Applying deep learning to text summarization refers to the use of deep neural networks to perform text summarization tasks. In this survey, we begin with a review of fashionable text summarization tasks in recent years, including extractive, abstractive, multi-document, and so on. Next, we discuss most deep learning-based models and their experimental results on these tasks. The paper also covers datasets and data representation for summarization tasks. Finally, we delve into the opportunities and challenges associated with summarization tasks and their corresponding methodologies, aiming to inspire future research efforts to advance the field further. A goal of our survey is to explain how these methods differ in their requirements as understanding them is essential for choosing a technique suited for a specific setting.",
    "authors": [
      "Guanghua Wang",
      "Weili Wu"
    ],
    "date": "[Submitted on 13 Oct 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2311.02205v2",
    "title": "An Introduction to Natural Language Processing Techniques and Framework for Clinical Implementation in Radiation Oncology",
    "abstract": "Natural Language Processing (NLP) is a key technique for developing Medical Artificial Intelligence (AI) systems that leverage Electronic Health Record (EHR) data to build diagnostic and prognostic models. NLP enables the conversion of unstructured clinical text into structured data that can be fed into AI algorithms. The emergence of the transformer architecture and large language models (LLMs) has led to remarkable advances in NLP for various healthcare tasks, such as entity recognition, relation extraction, sentence similarity, text summarization, and question answering. In this article, we review the major technical innovations that underpin modern NLP models and present state-of-the-art NLP applications that employ LLMs in radiation oncology research. However, these LLMs are prone to many errors such as hallucinations, biases, and ethical violations, which necessitate rigorous evaluation and validation before clinical deployment. As such, we propose a comprehensive framework for assessing the NLP models based on their purpose and clinical fit, technical performance, bias and trust, legal and ethical implications, and quality assurance, prior to implementation in clinical radiation oncology. Our article aims to provide guidance and insights for researchers and clinicians who are interested in developing and using NLP models in clinical radiation oncology.",
    "authors": [
      "Reza Khanmohammadi",
      "Mohammad M. Ghassemi",
      "Kyle Verdecchia",
      "Ahmed I. Ghanem",
      "Luo Bing",
      "Indrin J. Chetty",
      "Hassan Bagher-Ebadian",
      "Farzan Siddiqui",
      "Mohamed Elshaikh",
      "Benjamin Movsas",
      "Kundan Thind"
    ],
    "date": "[Submitted on 3 Nov 2023 (v1), last revised 8 Nov 2023 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2401.01508v3",
    "title": "Practical Guidelines for the Selection and Evaluation of Natural Language Processing Techniques in Requirements Engineering",
    "abstract": "Natural Language Processing (NLP) is now a cornerstone of requirements automation. One compelling factor behind the growing adoption of NLP in Requirements Engineering (RE) is the prevalent use of natural language (NL) for specifying requirements in industry. NLP techniques are commonly used for automatically classifying requirements, extracting important information, e.g., domain models and glossary terms, and performing quality assurance tasks, such as ambiguity handling and completeness checking. With so many different NLP solution strategies available and the possibility of applying machine learning alongside, it can be challenging to choose the right strategy for a specific RE task and to evaluate the resulting solution in an empirically rigorous manner. In this chapter, we present guidelines for the selection of NLP techniques as well as for their evaluation in the context of RE. In particular, we discuss how to choose among different strategies such as traditional NLP, feature-based machine learning, and language-model-based methods. Our ultimate hope for this chapter is to serve as a stepping stone, assisting newcomers to NLP4RE in quickly initiating themselves into the NLP technologies most pertinent to the RE field.",
    "authors": [
      "Mehrdad Sabetzadeh",
      "Chetan Arora"
    ],
    "date": "[Submitted on 3 Jan 2024 (v1), last revised 16 Jul 2024 (this version, v3)]"
  },
  {
    "url": "https://arxiv.org/abs/2402.17467v1",
    "title": "Natural Language Processing Methods for Symbolic Music Generation and Information Retrieval: a Survey",
    "abstract": "Several adaptations of Transformers models have been developed in various domains since its breakthrough in Natural Language Processing (NLP). This trend has spread into the field of Music Information Retrieval (MIR), including studies processing music data. However, the practice of leveraging NLP tools for symbolic music data is not novel in MIR. Music has been frequently compared to language, as they share several similarities, including sequential representations of text and music. These analogies are also reflected through similar tasks in MIR and NLP. This survey reviews NLP methods applied to symbolic music generation and information retrieval studies following two axes. We first propose an overview of representations of symbolic music adapted from natural language sequential representations. Such representations are designed by considering the specificities of symbolic music. These representations are then processed by models. Such models, possibly originally developed for text and adapted for symbolic music, are trained on various tasks. We describe these models, in particular deep learning models, through different prisms, highlighting music-specialized mechanisms. We finally present a discussion surrounding the effective use of NLP tools for symbolic music data. This includes technical issues regarding NLP methods and fundamental differences between text and music, which may open several doors for further research into more effectively adapting NLP tools to symbolic MIR.",
    "authors": [
      "Dinh-Viet-Toan Le",
      "Louis Bigo",
      "Mikaela Keller",
      "Dorien Herremans"
    ],
    "date": "[Submitted on 27 Feb 2024]"
  },
  {
    "url": "https://arxiv.org/abs/2407.12994v2",
    "title": "A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks",
    "abstract": "Large language models (LLMs) have shown remarkable performance on many different Natural Language Processing (NLP) tasks. Prompt engineering plays a key role in adding more to the already existing abilities of LLMs to achieve significant performance gains on various NLP tasks. Prompt engineering requires composing natural language instructions called prompts to elicit knowledge from LLMs in a structured way. Unlike previous state-of-the-art (SoTA) models, prompt engineering does not require extensive parameter re-training or fine-tuning based on the given NLP task and thus solely operates on the embedded knowledge of LLMs. Additionally, LLM enthusiasts can intelligently extract LLMs' knowledge through a basic natural language conversational exchange or prompt engineering, allowing more and more people even without deep mathematical machine learning background to experiment with LLMs. With prompt engineering gaining popularity in the last two years, researchers have come up with numerous engineering techniques around designing prompts to improve accuracy of information extraction from the LLMs. In this paper, we summarize different prompting techniques and club them together based on different NLP tasks that they have been used for. We further granularly highlight the performance of these prompting strategies on various datasets belonging to that NLP task, talk about the corresponding LLMs used, present a taxonomy diagram and discuss the possible SoTA for specific datasets. In total, we read and present a survey of 44 research papers which talk about 39 different prompting methods on 29 different NLP tasks of which most of them have been published in the last two years.",
    "authors": [
      "Shubham Vatsal",
      "Harsh Dubey"
    ],
    "date": "[Submitted on 17 Jul 2024 (v1), last revised 24 Jul 2024 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2504.01342v1",
    "title": "Foundations and Evaluations in NLP",
    "abstract": "This memoir explores two fundamental aspects of Natural Language Processing (NLP): the creation of linguistic resources and the evaluation of NLP system performance. Over the past decade, my work has focused on developing a morpheme-based annotation scheme for the Korean language that captures linguistic properties from morphology to semantics. This approach has achieved state-of-the-art results in various NLP tasks, including part-of-speech tagging, dependency parsing, and named entity recognition. Additionally, this work provides a comprehensive analysis of segmentation granularity and its critical impact on NLP system performance. In parallel with linguistic resource development, I have proposed a novel evaluation framework, the jp-algorithm, which introduces an alignment-based method to address challenges in preprocessing tasks like tokenization and sentence boundary detection (SBD). Traditional evaluation methods assume identical tokenization and sentence lengths between gold standards and system outputs, limiting their applicability to real-world data. The jp-algorithm overcomes these limitations, enabling robust end-to-end evaluations across a variety of NLP tasks. It enhances accuracy and flexibility by incorporating linear-time alignment while preserving the complexity of traditional evaluation metrics. This memoir provides key insights into the processing of morphologically rich languages, such as Korean, while offering a generalizable framework for evaluating diverse end-to-end NLP systems. My contributions lay the foundation for future developments, with broader implications for multilingual resource development and system evaluation.",
    "authors": [
      "Jungyeul Park"
    ],
    "date": "[Submitted on 2 Apr 2025]"
  },
  {
    "url": "https://arxiv.org/abs/2505.14311v3",
    "title": "HausaNLP: Current Status, Challenges and Future Directions for Hausa Natural Language Processing",
    "abstract": "Hausa Natural Language Processing (NLP) has gained increasing attention in recent years, yet remains understudied as a low-resource language despite having over 120 million first-language (L1) and 80 million second-language (L2) speakers worldwide. While significant advances have been made in high-resource languages, Hausa NLP faces persistent challenges, including limited open-source datasets and inadequate model representation. This paper presents an overview of the current state of Hausa NLP, systematically examining existing resources, research contributions, and gaps across fundamental NLP tasks: text classification, machine translation, named entity recognition, speech recognition, and question answering. We introduce HausaNLP (this https URL), a curated catalog that aggregates datasets, tools, and research works to enhance accessibility and drive further development. Furthermore, we discuss challenges in integrating Hausa into large language models (LLMs), addressing issues of suboptimal tokenization and dialectal variation. Finally, we propose strategic research directions emphasizing dataset expansion, improved language modeling approaches, and strengthened community collaboration to advance Hausa NLP. Our work provides both a foundation for accelerating Hausa NLP progress and valuable insights for broader multilingual NLP research.",
    "authors": [
      "Shamsuddeen Hassan Muhammad",
      "Ibrahim Said Ahmad",
      "Idris Abdulmumin",
      "Falalu Ibrahim Lawan",
      "Babangida Sani",
      "Sukairaj Hafiz Imam",
      "Yusuf Aliyu",
      "Sani Abdullahi Sani",
      "Ali Usman Umar",
      "Tajuddeen Gwadabe",
      "Kenneth Church",
      "Vukosi Marivate"
    ],
    "date": "[Submitted on 20 May 2025 (v1), last revised 22 Jul 2025 (this version, v3)]"
  },
  {
    "url": "https://arxiv.org/abs/2112.05780v1",
    "title": "A Scoping Review of Publicly Available Language Tasks in Clinical Natural Language Processing",
    "abstract": "Objective: to provide a scoping review of papers on clinical natural language processing (NLP) tasks that use publicly available electronic health record data from a cohort of patients. Materials and Methods: We searched six databases, including biomedical research and computer science literature database. A round of title/abstract screening and full-text screening were conducted by two reviewers. Our method followed the Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) guidelines. Results: A total of 35 papers with 47 clinical NLP tasks met inclusion criteria between 2007 and 2021. We categorized the tasks by the type of NLP problems, including name entity recognition, summarization, and other NLP tasks. Some tasks were introduced with a topic of clinical decision support applications, such as substance abuse, phenotyping, cohort selection for clinical trial. We summarized the tasks by publication and dataset information. Discussion: The breadth of clinical NLP tasks keeps growing as the field of NLP evolves with advancements in language systems. However, gaps exist in divergent interests between general domain NLP community and clinical informatics community, and in generalizability of the data sources. We also identified issues in data selection and preparation including the lack of time-sensitive data, and invalidity of problem size and evaluation. Conclusions: The existing clinical NLP tasks cover a wide range of topics and the field will continue to grow and attract more attention from both general domain NLP and clinical informatics community. We encourage future work to incorporate multi-disciplinary collaboration, reporting transparency, and standardization in data preparation.",
    "authors": [
      "Yanjun Gao",
      "Dmitriy Dligach",
      "Leslie Christensen",
      "Samuel Tesch",
      "Ryan Laffin",
      "Dongfang Xu",
      "Timothy Miller",
      "Ozlem Uzuner",
      "Matthew M Churpek",
      "Majid Afshar"
    ],
    "date": "[Submitted on 7 Dec 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2302.10406v1",
    "title": "Time to Embrace Natural Language Processing (NLP)-based Digital Pathology: Benchmarking NLP- and Convolutional Neural Network-based Deep Learning Pipelines",
    "abstract": "NLP-based computer vision models, particularly vision transformers, have been shown to outperform CNN models in many imaging tasks. However, most digital pathology artificial-intelligence models are based on CNN architectures, probably owing to a lack of data regarding NLP models for pathology images. In this study, we developed digital pathology pipelines to benchmark the five most recently proposed NLP models (vision transformer (ViT), Swin Transformer, MobileViT, CMT, and Sequencer2D) and four popular CNN models (ResNet18, ResNet50, MobileNetV2, and EfficientNet) to predict biomarkers in colorectal cancer (microsatellite instability, CpG island methylator phenotype, and BRAF mutation). Hematoxylin and eosin-stained whole-slide images from Molecular and Cellular Oncology and The Cancer Genome Atlas were used as training and external validation datasets, respectively. Cross-study external validations revealed that the NLP-based models significantly outperformed the CNN-based models in biomarker prediction tasks, improving the overall prediction and precision up to approximately 10% and 26%, respectively. Notably, compared with existing models in the current literature using large training datasets, our NLP models achieved state-of-the-art predictions for all three biomarkers using a relatively small training dataset, suggesting that large training datasets are not a prerequisite for NLP models or transformers, and NLP may be more suitable for clinical studies in which small training datasets are commonly collected. The superior performance of Sequencer2D suggests that further research and innovation on both transformer and bidirectional long short-term memory architectures are warranted in the field of digital pathology. NLP models can replace classic CNN architectures and become the new workhorse backbone in the field of digital pathology.",
    "authors": [
      "Min Cen",
      "Xingyu Li",
      "Bangwei Guo",
      "Jitendra Jonnagaddala",
      "Hong Zhang",
      "Xu Steven Xu"
    ],
    "date": "[Submitted on 21 Feb 2023]"
  },
  {
    "url": "https://arxiv.org/abs/1401.0923v2",
    "title": "Heavy Quarkonium Production at Collider Energies: Factorization and Evolution",
    "abstract": "We present a factorization formalism for inclusive production of heavy quarkonia of large transverse momentum, $p_T$ at collider energies, including both leading power (LP) and next-to-leading power (NLP) behavior in $p_T$. We demonstrate that both LP and NLP contributions can be factorized in terms of perturbatively calculable short-distance partonic coefficient functions and universal non-perturbative fragmentation functions, and derive the evolution equations that are implied by the factorization. We identify projection operators for all channels of the factorized LP and NLP infrared safe short-distance partonic hard parts, and corresponding operator definitions of fragmentation functions. For the NLP, we focus on the contributions involving the production of a heavy quark pair, a necessary condition for producing a heavy quarkonium. We evaluate the first non-trivial order of evolution kernels for all relevant fragmentation functions, and discuss the role of NLP contributions.",
    "authors": [
      "Zhong-Bo Kang",
      "Yan-Qing Ma",
      "Jian-Wei Qiu",
      "George Sterman"
    ],
    "date": "[Submitted on 5 Jan 2014 (v1), last revised 10 Nov 2014 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/1508.06044v1",
    "title": "Visualizing NLP annotations for Crowdsourcing",
    "abstract": "Visualizing NLP annotation is useful for the collection of training data for the statistical NLP approaches. Existing toolkits either provide limited visual aid, or introduce comprehensive operators to realize sophisticated linguistic rules. Workers must be well trained to use them. Their audience thus can hardly be scaled to large amounts of non-expert crowdsourced workers. In this paper, we present CROWDANNO, a visualization toolkit to allow crowd-sourced workers to annotate two general categories of NLP problems: clustering and parsing. Workers can finish the tasks with simplified operators in an interactive interface, and fix errors conveniently. User studies show our toolkit is very friendly to NLP non-experts, and allow them to produce high quality labels for several sophisticated problems. We release our source code and toolkit to spur future research.",
    "authors": [
      "Hanchuan Li",
      "Haichen Shen",
      "Shengliang Xu",
      "Congle Zhang"
    ],
    "date": "[Submitted on 25 Aug 2015]"
  },
  {
    "url": "https://arxiv.org/abs/1610.06842v2",
    "title": "Non-abelian factorisation for next-to-leading-power threshold logarithms",
    "abstract": "Soft and collinear radiation is responsible for large corrections to many hadronic cross sections, near thresholds for the production of heavy final states. There is much interest in extending our understanding of this radiation to next-to-leading power (NLP) in the threshold expansion. In this paper, we generalise a previously proposed all-order NLP factorisation formula to include non-abelian corrections. We define a non-abelian radiative jet function, organising collinear enhancements at NLP, and compute it for quark jets at one loop. We discuss in detail the issue of double counting between soft and collinear regions. Finally, we verify our prescription by reproducing all NLP logarithms in Drell-Yan production up to NNLO, including those associated with double real emission. Our results constitute an important step in the development of a fully general resummation formalism for NLP threshold effects.",
    "authors": [
      "D. Bonocore",
      "E. Laenen",
      "L. Magnea",
      "L. Vernazza",
      "C. D. White"
    ],
    "date": "[Submitted on 21 Oct 2016 (v1), last revised 11 Jan 2018 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/1710.06632v1",
    "title": "Towards a Seamless Integration of Word Senses into Downstream NLP Applications",
    "abstract": "Lexical ambiguity can impede NLP systems from accurate understanding of semantics. Despite its potential benefits, the integration of sense-level information into NLP systems has remained understudied. By incorporating a novel disambiguation algorithm into a state-of-the-art classification model, we create a pipeline to integrate sense-level information into downstream NLP applications. We show that a simple disambiguation of the input text can lead to consistent performance improvement on multiple topic categorization and polarity detection datasets, particularly when the fine granularity of the underlying sense inventory is reduced and the document is sufficiently large. Our results also point to the need for sense representation research to focus more on in vivo evaluations which target the performance in downstream NLP applications rather than artificial benchmarks.",
    "authors": [
      "Mohammad Taher Pilehvar",
      "Jose Camacho-Collados",
      "Roberto Navigli",
      "Nigel Collier"
    ],
    "date": "[Submitted on 18 Oct 2017]"
  },
  {
    "url": "https://arxiv.org/abs/1906.02243v1",
    "title": "Energy and Policy Considerations for Deep Learning in NLP",
    "abstract": "Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.",
    "authors": [
      "Emma Strubell",
      "Ananya Ganesh",
      "Andrew McCallum"
    ],
    "date": "[Submitted on 5 Jun 2019]"
  },
  {
    "url": "https://arxiv.org/abs/1906.08976v1",
    "title": "Mitigating Gender Bias in Natural Language Processing: Literature Review",
    "abstract": "As Natural Language Processing (NLP) and Machine Learning (ML) tools rise in popularity, it becomes increasingly vital to recognize the role they play in shaping societal biases and stereotypes. Although NLP models have shown success in modeling various applications, they propagate and may even amplify gender bias found in text corpora. While the study of bias in artificial intelligence is not new, methods to mitigate gender bias in NLP are relatively nascent. In this paper, we review contemporary studies on recognizing and mitigating gender bias in NLP. We discuss gender bias based on four forms of representation bias and analyze methods recognizing gender bias. Furthermore, we discuss the advantages and drawbacks of existing gender debiasing methods. Finally, we discuss future studies for recognizing and mitigating gender bias in NLP.",
    "authors": [
      "Tony Sun",
      "Andrew Gaut",
      "Shirlyn Tang",
      "Yuxin Huang",
      "Mai ElSherief",
      "Jieyu Zhao",
      "Diba Mirza",
      "Elizabeth Belding",
      "Kai-Wei Chang",
      "William Yang Wang"
    ],
    "date": "[Submitted on 21 Jun 2019]"
  },
  {
    "url": "https://arxiv.org/abs/1912.11078v2",
    "title": "Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview",
    "abstract": "An increasing number of works in natural language processing have addressed the effect of bias on the predicted outcomes, introducing mitigation techniques that act on different parts of the standard NLP pipeline (data and models). However, these works have been conducted in isolation, without a unifying framework to organize efforts within the field. This leads to repetitive approaches, and puts an undue focus on the effects of bias, rather than on their origins. Research focused on bias symptoms rather than the underlying origins could limit the development of effective countermeasures. In this paper, we propose a unifying conceptualization: the predictive bias framework for NLP. We summarize the NLP literature and propose a general mathematical definition of predictive bias in NLP along with a conceptual framework, differentiating four main origins of biases: label bias, selection bias, model overamplification, and semantic bias. We discuss how past work has countered each bias origin. Our framework serves to guide an introductory overview of predictive bias in NLP, integrating existing work into a single structure and opening avenues for future research.",
    "authors": [
      "Deven Shah",
      "H. Andrew Schwartz",
      "Dirk Hovy"
    ],
    "date": "[Submitted on 9 Nov 2019 (v1), last revised 12 Sep 2020 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2005.13012v2",
    "title": "Comparing BERT against traditional machine learning text classification",
    "abstract": "The BERT model has arisen as a popular state-of-the-art machine learning model in the recent years that is able to cope with multiple NLP tasks such as supervised text classification without human supervision. Its flexibility to cope with any type of corpus delivering great results has make this approach very popular not only in academia but also in the industry. Although, there are lots of different approaches that have been used throughout the years with success. In this work, we first present BERT and include a little review on classical NLP approaches. Then, we empirically test with a suite of experiments dealing different scenarios the behaviour of BERT against the traditional TF-IDF vocabulary fed to machine learning algorithms. Our purpose of this work is to add empirical evidence to support or refuse the use of BERT as a default on NLP tasks. Experiments show the superiority of BERT and its independence of features of the NLP problem such as the language of the text adding empirical evidence to use BERT as a default technique to be used in NLP problems.",
    "authors": [
      "Santiago Gonz\u00e1lez-Carvajal",
      "Eduardo C. Garrido-Merch\u00e1n"
    ],
    "date": "[Submitted on 26 May 2020 (v1), last revised 12 Jan 2021 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2005.14050v2",
    "title": "Language (Technology) is Power: A Critical Survey of \"Bias\" in NLP",
    "abstract": "We survey 146 papers analyzing \"bias\" in NLP systems, finding that their motivations are often vague, inconsistent, and lacking in normative reasoning, despite the fact that analyzing \"bias\" is an inherently normative process. We further find that these papers' proposed quantitative techniques for measuring or mitigating \"bias\" are poorly matched to their motivations and do not engage with the relevant literature outside of NLP. Based on these findings, we describe the beginnings of a path forward by proposing three recommendations that should guide work analyzing \"bias\" in NLP systems. These recommendations rest on a greater recognition of the relationships between language and social hierarchies, encouraging researchers and practitioners to articulate their conceptualizations of \"bias\"---i.e., what kinds of system behaviors are harmful, in what ways, to whom, and why, as well as the normative reasoning underlying these statements---and to center work around the lived experiences of members of communities affected by NLP systems, while interrogating and reimagining the power relations between technologists and such communities.",
    "authors": [
      "Su Lin Blodgett",
      "Solon Barocas",
      "Hal Daum\u00e9 III",
      "Hanna Wallach"
    ],
    "date": "[Submitted on 28 May 2020 (v1), last revised 29 May 2020 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2104.08835v2",
    "title": "CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in NLP",
    "abstract": "Humans can learn a new language task efficiently with only few examples, by leveraging their knowledge obtained when learning prior tasks. In this paper, we explore whether and how such cross-task generalization ability can be acquired, and further applied to build better few-shot learners across diverse NLP tasks. We introduce CrossFit, a problem setup for studying cross-task generalization ability, which standardizes seen/unseen task partitions, data access during different learning stages, and the evaluation protocols. To instantiate different seen/unseen task partitions in CrossFit and facilitate in-depth analysis, we present the NLP Few-shot Gym, a repository of 160 diverse few-shot NLP tasks created from open-access NLP datasets and converted to a unified text-to-text format. Our analysis reveals that the few-shot learning ability on unseen tasks can be improved via an upstream learning stage using a set of seen tasks. We also observe that the selection of upstream learning tasks can significantly influence few-shot performance on unseen tasks, asking further analysis on task similarity and transferability.",
    "authors": [
      "Qinyuan Ye",
      "Bill Yuchen Lin",
      "Xiang Ren"
    ],
    "date": "[Submitted on 18 Apr 2021 (v1), last revised 30 Sep 2021 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/1904.09535v3",
    "title": "NeuronBlocks: Building Your NLP DNN Models Like Playing Lego",
    "abstract": "Deep Neural Networks (DNN) have been widely employed in industry to address various Natural Language Processing (NLP) tasks. However, many engineers find it a big overhead when they have to choose from multiple frameworks, compare different types of models, and understand various optimization mechanisms. An NLP toolkit for DNN models with both generality and flexibility can greatly improve the productivity of engineers by saving their learning cost and guiding them to find optimal solutions to their tasks. In this paper, we introduce NeuronBlocks\\footnote{Code: \\url{this https URL}} \\footnote{Demo: \\url{this https URL}}, a toolkit encapsulating a suite of neural network modules as building blocks to construct various DNN models with complex architecture. This toolkit empowers engineers to build, train, and test various NLP models through simple configuration of JSON files. The experiments on several NLP datasets such as GLUE, WikiQA and CoNLL-2003 demonstrate the effectiveness of NeuronBlocks.",
    "authors": [
      "Ming Gong",
      "Linjun Shou",
      "Wutao Lin",
      "Zhijie Sang",
      "Quanjia Yan",
      "Ze Yang",
      "Feixiang Cheng",
      "Daxin Jiang"
    ],
    "date": "[Submitted on 21 Apr 2019 (v1), last revised 18 Oct 2019 (this version, v3)]"
  },
  {
    "url": "https://arxiv.org/abs/1302.4814v1",
    "title": "NLP and CALL: integration is working",
    "abstract": "In the first part of this article, we explore the background of computer-assisted learning from its beginnings in the early XIXth century and the first teaching machines, founded on theories of learning, at the start of the XXth century. With the arrival of the computer, it became possible to offer language learners different types of language activities such as comprehension tasks, simulations, etc. However, these have limits that cannot be overcome without some contribution from the field of natural language processing (NLP). In what follows, we examine the challenges faced and the issues raised by integrating NLP into CALL. We hope to demonstrate that the key to success in integrating NLP into CALL is to be found in multidisciplinary work between computer experts, linguists, language teachers, didacticians and NLP specialists.",
    "authors": [
      "Georges Antoniadis",
      "Sylviane Granger",
      "Olivier Kraif",
      "Claude Ponton",
      "Virginie Zampa"
    ],
    "date": "[Submitted on 20 Feb 2013]"
  },
  {
    "url": "https://arxiv.org/abs/2105.00823v1",
    "title": "Switching Contexts: Transportability Measures for NLP",
    "abstract": "This paper explores the topic of transportability, as a sub-area of generalisability. By proposing the utilisation of metrics based on well-established statistics, we are able to estimate the change in performance of NLP models in new contexts. Defining a new measure for transportability may allow for better estimation of NLP system performance in new domains, and is crucial when assessing the performance of NLP systems in new tasks and domains. Through several instances of increasing complexity, we demonstrate how lightweight domain similarity measures can be used as estimators for the transportability in NLP applications. The proposed transportability measures are evaluated in the context of Named Entity Recognition and Natural Language Inference tasks.",
    "authors": [
      "Guy Marshall",
      "Mokanarangan Thayaparan",
      "Philip Osborne",
      "Andre Freitas"
    ],
    "date": "[Submitted on 3 May 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2108.04674v2",
    "title": "Natural Language Processing with Commonsense Knowledge: A Survey",
    "abstract": "Commonsense knowledge is essential for advancing natural language processing (NLP) by enabling models to engage in human-like reasoning, which requires a deeper understanding of context and often involves making inferences based on implicit external knowledge. This paper explores the integration of commonsense knowledge into various NLP tasks. We begin by reviewing prominent commonsense knowledge bases and then discuss the benchmarks used to evaluate the commonsense reasoning capabilities of NLP models, particularly language models. Furthermore, we highlight key methodologies for incorporating commonsense knowledge and their applications across different NLP tasks. The paper also examines the challenges and emerging trends in enhancing NLP systems with commonsense reasoning. All literature referenced in this survey can be accessed via our GitHub repository: this https URL.",
    "authors": [
      "Yubo Xie",
      "Zonghui Liu",
      "Zongyang Ma",
      "Fanyuan Meng",
      "Yan Xiao",
      "Fahui Miao",
      "Pearl Pu"
    ],
    "date": "[Submitted on 10 Aug 2021 (v1), last revised 13 Sep 2024 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2202.04824v2",
    "title": "AdaPrompt: Adaptive Model Training for Prompt-based NLP",
    "abstract": "Prompt-based learning, with its capability to tackle zero-shot and few-shot NLP tasks, has gained much attention in community. The main idea is to bridge the gap between NLP downstream tasks and language modeling (LM), by mapping these tasks into natural language prompts, which are then filled by pre-trained language models (PLMs). However, for prompt learning, there are still two salient gaps between NLP tasks and pretraining. First, prompt information is not necessarily sufficiently present during LM pretraining. Second, task-specific data are not necessarily well represented during pretraining. We address these two issues by proposing AdaPrompt, adaptively retrieving external data for continual pretraining of PLMs by making use of both task and prompt characteristics. In addition, we make use of knowledge in Natural Language Inference models for deriving adaptive verbalizers. Experimental results on five NLP benchmarks show that AdaPrompt can improve over standard PLMs in few-shot settings. In addition, in zero-shot settings, our method outperforms standard prompt-based methods by up to 26.35\\% relative error reduction.",
    "authors": [
      "Yulong Chen",
      "Yang Liu",
      "Li Dong",
      "Shuohang Wang",
      "Chenguang Zhu",
      "Michael Zeng",
      "Yue Zhang"
    ],
    "date": "[Submitted on 10 Feb 2022 (v1), last revised 18 Nov 2022 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2202.08772v1",
    "title": "A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models",
    "abstract": "With the increasing of model capacity brought by pre-trained language models, there emerges boosting needs for more knowledgeable natural language processing (NLP) models with advanced functionalities including providing and making flexible use of encyclopedic and commonsense knowledge. The mere pre-trained language models, however, lack the capacity of handling such knowledge-intensive NLP tasks alone. To address this challenge, large numbers of pre-trained language models augmented with external knowledge sources are proposed and in rapid development. In this paper, we aim to summarize the current progress of pre-trained language model-based knowledge-enhanced models (PLMKEs) by dissecting their three vital elements: knowledge sources, knowledge-intensive NLP tasks, and knowledge fusion methods. Finally, we present the challenges of PLMKEs based on the discussion regarding the three elements and attempt to provide NLP practitioners with potential directions for further research.",
    "authors": [
      "Da Yin",
      "Li Dong",
      "Hao Cheng",
      "Xiaodong Liu",
      "Kai-Wei Chang",
      "Furu Wei",
      "Jianfeng Gao"
    ],
    "date": "[Submitted on 17 Feb 2022]"
  },
  {
    "url": "https://arxiv.org/abs/2204.10192v2",
    "title": "Residue-Based Natural Language Adversarial Attack Detection",
    "abstract": "Deep learning based systems are susceptible to adversarial attacks, where a small, imperceptible change at the input alters the model prediction. However, to date the majority of the approaches to detect these attacks have been designed for image processing systems. Many popular image adversarial detection approaches are able to identify adversarial examples from embedding feature spaces, whilst in the NLP domain existing state of the art detection approaches solely focus on input text features, without consideration of model embedding spaces. This work examines what differences result when porting these image designed strategies to Natural Language Processing (NLP) tasks - these detectors are found to not port over well. This is expected as NLP systems have a very different form of input: discrete and sequential in nature, rather than the continuous and fixed size inputs for images. As an equivalent model-focused NLP detection approach, this work proposes a simple sentence-embedding \"residue\" based detector to identify adversarial examples. On many tasks, it out-performs ported image domain detectors and recent state of the art NLP specific detectors.",
    "authors": [
      "Vyas Raina",
      "Mark Gales"
    ],
    "date": "[Submitted on 17 Apr 2022 (v1), last revised 25 Sep 2022 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/1805.11824v1",
    "title": "Anaphora and Coreference Resolution: A Review",
    "abstract": "Entity resolution aims at resolving repeated references to an entity in a document and forms a core component of natural language processing (NLP) research. This field possesses immense potential to improve the performance of other NLP fields like machine translation, sentiment analysis, paraphrase detection, summarization, etc. The area of entity resolution in NLP has seen proliferation of research in two separate sub-areas namely: anaphora resolution and coreference resolution. Through this review article, we aim at clarifying the scope of these two tasks in entity resolution. We also carry out a detailed analysis of the datasets, evaluation metrics and research methods that have been adopted to tackle this NLP problem. This survey is motivated with the aim of providing the reader with a clear understanding of what constitutes this NLP problem and the issues that require attention.",
    "authors": [
      "Rhea Sukthanker",
      "Soujanya Poria",
      "Erik Cambria",
      "Ramkumar Thirunavukarasu"
    ],
    "date": "[Submitted on 30 May 2018]"
  },
  {
    "url": "https://arxiv.org/abs/1811.06179v1",
    "title": "Implementing a Portable Clinical NLP System with a Common Data Model - a Lisp Perspective",
    "abstract": "This paper presents a Lisp architecture for a portable NLP system, termed LAPNLP, for processing clinical notes. LAPNLP integrates multiple standard, customized and in-house developed NLP tools. Our system facilitates portability across different institutions and data systems by incorporating an enriched Common Data Model (CDM) to standardize necessary data elements. It utilizes UMLS to perform domain adaptation when integrating generic domain NLP tools. It also features stand-off annotations that are specified by positional reference to the original document. We built an interval tree based search engine to efficiently query and retrieve the stand-off annotations by specifying positional requirements. We also developed a utility to convert an inline annotation format to stand-off annotations to enable the reuse of clinical text datasets with inline annotations. We experimented with our system on several NLP facilitated tasks including computational phenotyping for lymphoma patients and semantic relation extraction for clinical notes. These experiments showcased the broader applicability and utility of LAPNLP.",
    "authors": [
      "Yuan Luo",
      "Peter Szolovits"
    ],
    "date": "[Submitted on 15 Nov 2018]"
  },
  {
    "url": "https://arxiv.org/abs/1902.00679v1",
    "title": "Natural Language Processing, Sentiment Analysis and Clinical Analytics",
    "abstract": "Recent advances in Big Data has prompted health care practitioners to utilize the data available on social media to discern sentiment and emotions expression. Health Informatics and Clinical Analytics depend heavily on information gathered from diverse sources. Traditionally, a healthcare practitioner will ask a patient to fill out a questionnaire that will form the basis of diagnosing the medical condition. However, medical practitioners have access to many sources of data including the patients writings on various media. Natural Language Processing (NLP) allows researchers to gather such data and analyze it to glean the underlying meaning of such writings. The field of sentiment analysis (applied to many other domains) depend heavily on techniques utilized by NLP. This work will look into various prevalent theories underlying the NLP field and how they can be leveraged to gather users sentiments on social media. Such sentiments can be culled over a period of time thus minimizing the errors introduced by data input and other stressors. Furthermore, we look at some applications of sentiment analysis and application of NLP to mental health. The reader will also learn about the NLTK toolkit that implements various NLP theories and how they can make the data scavenging process a lot easier.",
    "authors": [
      "Adil Rajput"
    ],
    "date": "[Submitted on 2 Feb 2019]"
  },
  {
    "url": "https://arxiv.org/abs/2011.05911v1",
    "title": "Situated Data, Situated Systems: A Methodology to Engage with Power Relations in Natural Language Processing Research",
    "abstract": "We propose a bias-aware methodology to engage with power relations in natural language processing (NLP) research. NLP research rarely engages with bias in social contexts, limiting its ability to mitigate bias. While researchers have recommended actions, technical methods, and documentation practices, no methodology exists to integrate critical reflections on bias with technical NLP methods. In this paper, after an extensive and interdisciplinary literature review, we contribute a bias-aware methodology for NLP research. We also contribute a definition of biased text, a discussion of the implications of biased NLP systems, and a case study demonstrating how we are executing the bias-aware methodology in research on archival metadata descriptions.",
    "authors": [
      "Lucy Havens",
      "Melissa Terras",
      "Benjamin Bach",
      "Beatrice Alex"
    ],
    "date": "[Submitted on 11 Nov 2020]"
  },
  {
    "url": "https://arxiv.org/abs/2011.13231v1",
    "title": "NLPStatTest: A Toolkit for Comparing NLP System Performance",
    "abstract": "Statistical significance testing centered on p-values is commonly used to compare NLP system performance, but p-values alone are insufficient because statistical significance differs from practical significance. The latter can be measured by estimating effect size. In this paper, we propose a three-stage procedure for comparing NLP system performance and provide a toolkit, NLPStatTest, that automates the process. Users can upload NLP system evaluation scores and the toolkit will analyze these scores, run appropriate significance tests, estimate effect size, and conduct power analysis to estimate Type II error. The toolkit provides a convenient and systematic way to compare NLP system performance that goes beyond statistical significance testing",
    "authors": [
      "Haotian Zhu",
      "Denise Mak",
      "Jesse Gioannini",
      "Fei Xia"
    ],
    "date": "[Submitted on 26 Nov 2020]"
  },
  {
    "url": "https://arxiv.org/abs/2102.00214v1",
    "title": "Taxonomic survey of Hindi Language NLP systems",
    "abstract": "Natural Language processing (NLP) represents the task of automatic handling of natural human language by this http URL is large spectrum of possible applications of NLP which help in automating tasks like translating text from one language to other, retrieving and summarizing data from very huge repositories, spam email filtering, identifying fake news in digital media, find sentiment and feedback of people, find political opinions and views of people on various government policies, provide effective medical assistance based on past history records of patient etc. Hindi is the official language of India with nearly 691 million users in India and 366 million in rest of world. At present, a number of government and private sector projects and researchers in India and abroad, are working towards developing NLP applications and resources for Indian languages. This survey gives a report of the resources and applications available for Hindi language NLP.",
    "authors": [
      "Nikita P. Desai",
      "Prof.",
      "Vipul K. Dabhi"
    ],
    "date": "[Submitted on 30 Jan 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2102.13136v1",
    "title": "Automated essay scoring using efficient transformer-based language models",
    "abstract": "Automated Essay Scoring (AES) is a cross-disciplinary effort involving Education, Linguistics, and Natural Language Processing (NLP). The efficacy of an NLP model in AES tests it ability to evaluate long-term dependencies and extrapolate meaning even when text is poorly written. Large pretrained transformer-based language models have dominated the current state-of-the-art in many NLP tasks, however, the computational requirements of these models make them expensive to deploy in practice. The goal of this paper is to challenge the paradigm in NLP that bigger is better when it comes to AES. To do this, we evaluate the performance of several fine-tuned pretrained NLP models with a modest number of parameters on an AES dataset. By ensembling our models, we achieve excellent results with fewer parameters than most pretrained transformer-based models.",
    "authors": [
      "Christopher M Ormerod",
      "Akanksha Malhotra",
      "Amir Jafari"
    ],
    "date": "[Submitted on 25 Feb 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2107.03072v1",
    "title": "Android Security using NLP Techniques: A Review",
    "abstract": "Android is among the most targeted platform by attackers. While attackers are improving their techniques, traditional solutions based on static and dynamic analysis have been also evolving. In addition to the application code, Android applications have some metadata that could be useful for security analysis of applications. Unlike traditional application distribution mechanisms, Android applications are distributed centrally in mobile markets. Therefore, beside application packages, such markets contain app information provided by app developers and app users. The availability of such useful textual data together with the advancement in Natural Language Processing (NLP) that is used to process and understand textual data has encouraged researchers to investigate the use of NLP techniques in Android security. Especially, security solutions based on NLP have accelerated in the last 5 years and proven to be useful. This study reviews these proposals and aim to explore possible research directions for future studies by presenting state-of-the-art in this domain. We mainly focus on NLP-based solutions under four categories: description-to-behaviour fidelity, description generation, privacy and malware detection.",
    "authors": [
      "Sevil Sen",
      "Burcu Can"
    ],
    "date": "[Submitted on 7 Jul 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2107.04374v1",
    "title": "Benchmarking for Biomedical Natural Language Processing Tasks with a Domain Specific ALBERT",
    "abstract": "The availability of biomedical text data and advances in natural language processing (NLP) have made new applications in biomedical NLP possible. Language models trained or fine tuned using domain specific corpora can outperform general models, but work to date in biomedical NLP has been limited in terms of corpora and tasks. We present BioALBERT, a domain-specific adaptation of A Lite Bidirectional Encoder Representations from Transformers (ALBERT), trained on biomedical (PubMed and PubMed Central) and clinical (MIMIC-III) corpora and fine tuned for 6 different tasks across 20 benchmark datasets. Experiments show that BioALBERT outperforms the state of the art on named entity recognition (+11.09% BLURB score improvement), relation extraction (+0.80% BLURB score), sentence similarity (+1.05% BLURB score), document classification (+0.62% F1-score), and question answering (+2.83% BLURB score). It represents a new state of the art in 17 out of 20 benchmark datasets. By making BioALBERT models and data available, our aim is to help the biomedical NLP community avoid computational costs of training and establish a new set of baselines for future efforts across a broad range of biomedical NLP tasks.",
    "authors": [
      "Usman Naseem",
      "Adam G. Dunn",
      "Matloob Khushi",
      "Jinman Kim"
    ],
    "date": "[Submitted on 9 Jul 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2107.08262v1",
    "title": "Tea: Program Repair Using Neural Network Based on Program Information Attention Matrix",
    "abstract": "The advance in machine learning (ML)-driven natural language process (NLP) points a promising direction for automatic bug fixing for software programs, as fixing a buggy program can be transformed to a translation task. While software programs contain much richer information than one-dimensional natural language documents, pioneering work on using ML-driven NLP techniques for automatic program repair only considered a limited set of such information. We hypothesize that more comprehensive information of software programs, if appropriately utilized, can improve the effectiveness of ML-driven NLP approaches in repairing software programs. As the first step towards proving this hypothesis, we propose a unified representation to capture the syntax, data flow, and control flow aspects of software programs, and devise a method to use such a representation to guide the transformer model from NLP in better understanding and fixing buggy programs. Our preliminary experiment confirms that the more comprehensive information of software programs used, the better ML-driven NLP techniques can perform in fixing bugs in these programs.",
    "authors": [
      "Wenshuo Wang",
      "Chen Wu",
      "Liang Cheng",
      "Yang Zhang"
    ],
    "date": "[Submitted on 17 Jul 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2201.00768v1",
    "title": "Robust Natural Language Processing: Recent Advances, Challenges, and Future Directions",
    "abstract": "Recent natural language processing (NLP) techniques have accomplished high performance on benchmark datasets, primarily due to the significant improvement in the performance of deep learning. The advances in the research community have led to great enhancements in state-of-the-art production systems for NLP tasks, such as virtual assistants, speech recognition, and sentiment analysis. However, such NLP systems still often fail when tested with adversarial attacks. The initial lack of robustness exposed troubling gaps in current models' language understanding capabilities, creating problems when NLP systems are deployed in real life. In this paper, we present a structured overview of NLP robustness research by summarizing the literature in a systemic way across various dimensions. We then take a deep-dive into the various dimensions of robustness, across techniques, metrics, embeddings, and benchmarks. Finally, we argue that robustness should be multi-dimensional, provide insights into current research, identify gaps in the literature to suggest directions worth pursuing to address these gaps.",
    "authors": [
      "Marwan Omar",
      "Soohyeon Choi",
      "DaeHun Nyang",
      "David Mohaisen"
    ],
    "date": "[Submitted on 3 Jan 2022]"
  },
  {
    "url": "https://arxiv.org/abs/2203.10020v1",
    "title": "Challenges and Strategies in Cross-Cultural NLP",
    "abstract": "Various efforts in the Natural Language Processing (NLP) community have been made to accommodate linguistic diversity and serve speakers of many different languages. However, it is important to acknowledge that speakers and the content they produce and require, vary not just by language, but also by culture. Although language and culture are tightly linked, there are important differences. Analogous to cross-lingual and multilingual NLP, cross-cultural and multicultural NLP considers these differences in order to better serve users of NLP systems. We propose a principled framework to frame these efforts, and survey existing and potential strategies.",
    "authors": [
      "Daniel Hershcovich",
      "Stella Frank",
      "Heather Lent",
      "Miryam de Lhoneux",
      "Mostafa Abdou",
      "Stephanie Brandl",
      "Emanuele Bugliarello",
      "Laura Cabello Piqueras",
      "Ilias Chalkidis",
      "Ruixiang Cui",
      "Constanza Fierro",
      "Katerina Margatina",
      "Phillip Rust",
      "Anders S\u00f8gaard"
    ],
    "date": "[Submitted on 18 Mar 2022]"
  },
  {
    "url": "https://arxiv.org/abs/2208.08140v1",
    "title": "Differential Privacy in Natural Language Processing: The Story So Far",
    "abstract": "As the tide of Big Data continues to influence the landscape of Natural Language Processing (NLP), the utilization of modern NLP methods has grounded itself in this data, in order to tackle a variety of text-based tasks. These methods without a doubt can include private or otherwise personally identifiable information. As such, the question of privacy in NLP has gained fervor in recent years, coinciding with the development of new Privacy-Enhancing Technologies (PETs). Among these PETs, Differential Privacy boasts several desirable qualities in the conversation surrounding data privacy. Naturally, the question becomes whether Differential Privacy is applicable in the largely unstructured realm of NLP. This topic has sparked novel research, which is unified in one basic goal: how can one adapt Differential Privacy to NLP methods? This paper aims to summarize the vulnerabilities addressed by Differential Privacy, the current thinking, and above all, the crucial next steps that must be considered.",
    "authors": [
      "Oleksandra Klymenko",
      "Stephen Meisenbacher",
      "Florian Matthes"
    ],
    "date": "[Submitted on 17 Aug 2022]"
  },
  {
    "url": "https://arxiv.org/abs/2209.12226v5",
    "title": "Re-contextualizing Fairness in NLP: The Case of India",
    "abstract": "Recent research has revealed undesirable biases in NLP data and models. However, these efforts focus on social disparities in West, and are not directly portable to other geo-cultural contexts. In this paper, we focus on NLP fair-ness in the context of India. We start with a brief account of the prominent axes of social disparities in India. We build resources for fairness evaluation in the Indian context and use them to demonstrate prediction biases along some of the axes. We then delve deeper into social stereotypes for Region andReligion, demonstrating its prevalence in corpora and models. Finally, we outline a holistic research agenda to re-contextualize NLP fairness research for the Indian context, ac-counting for Indian societal context, bridging technological gaps in NLP capabilities and re-sources, and adapting to Indian cultural values. While we focus on India, this framework can be generalized to other geo-cultural contexts.",
    "authors": [
      "Shaily Bhatt",
      "Sunipa Dev",
      "Partha Talukdar",
      "Shachi Dave",
      "Vinodkumar Prabhakaran"
    ],
    "date": "[Submitted on 25 Sep 2022 (v1), last revised 21 Nov 2022 (this version, v5)]"
  },
  {
    "url": "https://arxiv.org/abs/2210.03312v2",
    "title": "Distillation-Resistant Watermarking for Model Protection in NLP",
    "abstract": "How can we protect the intellectual property of trained NLP models? Modern NLP models are prone to stealing by querying and distilling from their publicly exposed APIs. However, existing protection methods such as watermarking only work for images but are not applicable to text. We propose Distillation-Resistant Watermarking (DRW), a novel technique to protect NLP models from being stolen via distillation. DRW protects a model by injecting watermarks into the victim's prediction probability corresponding to a secret key and is able to detect such a key by probing a suspect model. We prove that a protected model still retains the original accuracy within a certain bound. We evaluate DRW on a diverse set of NLP tasks including text classification, part-of-speech tagging, and named entity recognition. Experiments show that DRW protects the original model and detects stealing suspects at 100% mean average precision for all four tasks while the prior method fails on two.",
    "authors": [
      "Xuandong Zhao",
      "Lei Li",
      "Yu-Xiang Wang"
    ],
    "date": "[Submitted on 7 Oct 2022 (v1), last revised 23 Oct 2022 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2210.06894v1",
    "title": "Dim-Krum: Backdoor-Resistant Federated Learning for NLP with Dimension-wise Krum-Based Aggregation",
    "abstract": "Despite the potential of federated learning, it is known to be vulnerable to backdoor attacks. Many robust federated aggregation methods are proposed to reduce the potential backdoor risk. However, they are mainly validated in the CV field. In this paper, we find that NLP backdoors are hard to defend against than CV, and we provide a theoretical analysis that the malicious update detection error probabilities are determined by the relative backdoor strengths. NLP attacks tend to have small relative backdoor strengths, which may result in the failure of robust federated aggregation methods for NLP attacks. Inspired by the theoretical results, we can choose some dimensions with higher backdoor strengths to settle this issue. We propose a novel federated aggregation algorithm, Dim-Krum, for NLP tasks, and experimental results validate its effectiveness.",
    "authors": [
      "Zhiyuan Zhang",
      "Qi Su",
      "Xu Sun"
    ],
    "date": "[Submitted on 13 Oct 2022]"
  },
  {
    "url": "https://arxiv.org/abs/2210.13865v1",
    "title": "Missing Counter-Evidence Renders NLP Fact-Checking Unrealistic for Misinformation",
    "abstract": "Misinformation emerges in times of uncertainty when credible information is limited. This is challenging for NLP-based fact-checking as it relies on counter-evidence, which may not yet be available. Despite increasing interest in automatic fact-checking, it is still unclear if automated approaches can realistically refute harmful real-world misinformation. Here, we contrast and compare NLP fact-checking with how professional fact-checkers combat misinformation in the absence of counter-evidence. In our analysis, we show that, by design, existing NLP task definitions for fact-checking cannot refute misinformation as professional fact-checkers do for the majority of claims. We then define two requirements that the evidence in datasets must fulfill for realistic fact-checking: It must be (1) sufficient to refute the claim and (2) not leaked from existing fact-checking articles. We survey existing fact-checking datasets and find that all of them fail to satisfy both criteria. Finally, we perform experiments to demonstrate that models trained on a large-scale fact-checking dataset rely on leaked evidence, which makes them unsuitable in real-world scenarios. Taken together, we show that current NLP fact-checking cannot realistically combat real-world misinformation because it depends on unrealistic assumptions about counter-evidence in the data.",
    "authors": [
      "Max Glockner",
      "Yufang Hou",
      "Iryna Gurevych"
    ],
    "date": "[Submitted on 25 Oct 2022]"
  },
  {
    "url": "https://arxiv.org/abs/2212.09682v1",
    "title": "Multilingual Sequence-to-Sequence Models for Hebrew NLP",
    "abstract": "Recent work attributes progress in NLP to large language models (LMs) with increased model size and large quantities of pretraining data. Despite this, current state-of-the-art LMs for Hebrew are both under-parameterized and under-trained compared to LMs in other languages. Additionally, previous work on pretrained Hebrew LMs focused on encoder-only models. While the encoder-only architecture is beneficial for classification tasks, it does not cater well for sub-word prediction tasks, such as Named Entity Recognition, when considering the morphologically rich nature of Hebrew. In this paper we argue that sequence-to-sequence generative architectures are more suitable for LLMs in the case of morphologically rich languages (MRLs) such as Hebrew. We demonstrate that by casting tasks in the Hebrew NLP pipeline as text-to-text tasks, we can leverage powerful multilingual, pretrained sequence-to-sequence models as mT5, eliminating the need for a specialized, morpheme-based, separately fine-tuned decoder. Using this approach, our experiments show substantial improvements over previously published results on existing Hebrew NLP benchmarks. These results suggest that multilingual sequence-to-sequence models present a promising building block for NLP for MRLs.",
    "authors": [
      "Matan Eyal",
      "Hila Noga",
      "Roee Aharoni",
      "Idan Szpektor",
      "Reut Tsarfaty"
    ],
    "date": "[Submitted on 19 Dec 2022]"
  },
  {
    "url": "https://arxiv.org/abs/1907.09548v1",
    "title": "On the Equivalence Between Abstract Dialectical Frameworks and Logic Programs",
    "abstract": "Abstract Dialectical Frameworks (ADFs) are argumentation frameworks where each node is associated with an acceptance condition. This allows us to model different types of dependencies as supports and attacks. Previous studies provided a translation from Normal Logic Programs (NLPs) to ADFs and proved the stable models semantics for a normal logic program has an equivalent semantics to that of the corresponding ADF. However, these studies failed in identifying a semantics for ADFs equivalent to a three-valued semantics (as partial stable models and well-founded models) for NLPs. In this work, we focus on a fragment of ADFs, called Attacking Dialectical Frameworks (ADF$^+$s), and provide a translation from NLPs to ADF$^+$s robust enough to guarantee the equivalence between partial stable models, well-founded models, regular models, stable models semantics for NLPs and respectively complete models, grounded models, preferred models, stable models for ADFs. In addition, we define a new semantics for ADF$^+$s, called L-stable, and show it is equivalent to the L-stable semantics for NLPs. This paper is under consideration for acceptance in TPLP.",
    "authors": [
      "Jo\u00e3o Alc\u00e2ntara",
      "Samy S\u00e1",
      "Juan Acosta-Guadarrama"
    ],
    "date": "[Submitted on 22 Jul 2019]"
  },
  {
    "url": "https://arxiv.org/abs/2004.09890v1",
    "title": "Considering Likelihood in NLP Classification Explanations with Occlusion and Language Modeling",
    "abstract": "Recently, state-of-the-art NLP models gained an increasing syntactic and semantic understanding of language, and explanation methods are crucial to understand their decisions. Occlusion is a well established method that provides explanations on discrete language data, e.g. by removing a language unit from an input and measuring the impact on a model's decision. We argue that current occlusion-based methods often produce invalid or syntactically incorrect language data, neglecting the improved abilities of recent NLP models. Furthermore, gradient-based explanation methods disregard the discrete distribution of data in NLP. Thus, we propose OLM: a novel explanation method that combines occlusion and language models to sample valid and syntactically correct replacements with high likelihood, given the context of the original input. We lay out a theoretical foundation that alleviates these weaknesses of other explanation methods in NLP and provide results that underline the importance of considering data likelihood in occlusion-based explanation.",
    "authors": [
      "David Harbecke",
      "Christoph Alt"
    ],
    "date": "[Submitted on 21 Apr 2020]"
  },
  {
    "url": "https://arxiv.org/abs/2010.01526v1",
    "title": "NLP Service APIs and Models for Efficient Registration of New Clients",
    "abstract": "State-of-the-art NLP inference uses enormous neural architectures and models trained for GPU-months, well beyond the reach of most consumers of NLP. This has led to one-size-fits-all public API-based NLP service models by major AI companies, serving large numbers of clients. Neither (hardware deficient) clients nor (heavily subscribed) servers can afford traditional fine tuning. Many clients own little or no labeled data. We initiate a study of adaptation of centralized NLP services to clients, and present one practical and lightweight approach. Each client uses an unsupervised, corpus-based sketch to register to the service. The server uses an auxiliary network to map the sketch to an abstract vector representation, which then informs the main labeling network. When a new client registers with its sketch, it gets immediate accuracy benefits. We demonstrate the success of the proposed architecture using sentiment labeling, NER, and predictive language modeling",
    "authors": [
      "Sahil Shah",
      "Vihari Piratla",
      "Soumen Chakrabarti",
      "Sunita Sarawagi"
    ],
    "date": "[Submitted on 4 Oct 2020]"
  },
  {
    "url": "https://arxiv.org/abs/2106.02192v1",
    "title": "Grounding 'Grounding' in NLP",
    "abstract": "The NLP community has seen substantial recent interest in grounding to facilitate interaction between language technologies and the world. However, as a community, we use the term broadly to reference any linking of text to data or non-textual modality. In contrast, Cognitive Science more formally defines \"grounding\" as the process of establishing what mutual information is required for successful communication between two interlocutors -- a definition which might implicitly capture the NLP usage but differs in intent and scope. We investigate the gap between these definitions and seek answers to the following questions: (1) What aspects of grounding are missing from NLP tasks? Here we present the dimensions of coordination, purviews and constraints. (2) How is the term \"grounding\" used in the current research? We study the trends in datasets, domains, and tasks introduced in recent NLP conferences. And finally, (3) How to advance our current definition to bridge the gap with Cognitive Science? We present ways to both create new tasks or repurpose existing ones to make advancements towards achieving a more complete sense of grounding.",
    "authors": [
      "Khyathi Raghavi Chandu",
      "Yonatan Bisk",
      "Alan W Black"
    ],
    "date": "[Submitted on 4 Jun 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2109.02941v1",
    "title": "Countering Online Hate Speech: An NLP Perspective",
    "abstract": "Online hate speech has caught everyone's attention from the news related to the COVID-19 pandemic, US elections, and worldwide protests. Online toxicity - an umbrella term for online hateful behavior, manifests itself in forms such as online hate speech. Hate speech is a deliberate attack directed towards an individual or a group motivated by the targeted entity's identity or opinions. The rising mass communication through social media further exacerbates the harmful consequences of online hate speech. While there has been significant research on hate-speech identification using Natural Language Processing (NLP), the work on utilizing NLP for prevention and intervention of online hate speech lacks relatively. This paper presents a holistic conceptual framework on hate-speech NLP countering methods along with a thorough survey on the current progress of NLP for countering online hate speech. It classifies the countering techniques based on their time of action, and identifies potential future research areas on this topic.",
    "authors": [
      "Mudit Chaudhary",
      "Chandni Saxena",
      "Helen Meng"
    ],
    "date": "[Submitted on 7 Sep 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2109.09138v2",
    "title": "Multi-Task Learning in Natural Language Processing: An Overview",
    "abstract": "Deep learning approaches have achieved great success in the field of Natural Language Processing (NLP). However, directly training deep neural models often suffer from overfitting and data scarcity problems that are pervasive in NLP tasks. In recent years, Multi-Task Learning (MTL), which can leverage useful information of related tasks to achieve simultaneous performance improvement on these tasks, has been used to handle these problems. In this paper, we give an overview of the use of MTL in NLP tasks. We first review MTL architectures used in NLP tasks and categorize them into four classes, including parallel architecture, hierarchical architecture, modular architecture, and generative adversarial architecture. Then we present optimization techniques on loss construction, gradient regularization, data sampling, and task scheduling to properly train a multi-task model. After presenting applications of MTL in a variety of NLP tasks, we introduce some benchmark datasets. Finally, we make a conclusion and discuss several possible research directions in this field.",
    "authors": [
      "Shijie Chen",
      "Yu Zhang",
      "Qiang Yang"
    ],
    "date": "[Submitted on 19 Sep 2021 (v1), last revised 28 Apr 2024 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2109.12575v2",
    "title": "Paradigm Shift in Natural Language Processing",
    "abstract": "In the era of deep learning, modeling for most NLP tasks has converged to several mainstream paradigms. For example, we usually adopt the sequence labeling paradigm to solve a bundle of tasks such as POS-tagging, NER, Chunking, and adopt the classification paradigm to solve tasks like sentiment analysis. With the rapid progress of pre-trained language models, recent years have observed a rising trend of Paradigm Shift, which is solving one NLP task by reformulating it as another one. Paradigm shift has achieved great success on many tasks, becoming a promising way to improve model performance. Moreover, some of these paradigms have shown great potential to unify a large number of NLP tasks, making it possible to build a single model to handle diverse tasks. In this paper, we review such phenomenon of paradigm shifts in recent years, highlighting several paradigms that have the potential to solve different NLP tasks.",
    "authors": [
      "Tianxiang Sun",
      "Xiangyang Liu",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ],
    "date": "[Submitted on 26 Sep 2021 (v1), last revised 29 May 2022 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2110.06733v1",
    "title": "Systematic Inequalities in Language Technology Performance across the World's Languages",
    "abstract": "Natural language processing (NLP) systems have become a central technology in communication, education, medicine, artificial intelligence, and many other domains of research and development. While the performance of NLP methods has grown enormously over the last decade, this progress has been restricted to a minuscule subset of the world's 6,500 languages. We introduce a framework for estimating the global utility of language technologies as revealed in a comprehensive snapshot of recent publications in NLP. Our analyses involve the field at large, but also more in-depth studies on both user-facing technologies (machine translation, language understanding, question answering, text-to-speech synthesis) as well as more linguistic NLP tasks (dependency parsing, morphological inflection). In the process, we (1) quantify disparities in the current state of NLP research, (2) explore some of its associated societal and academic factors, and (3) produce tailored recommendations for evidence-based policy making aimed at promoting more global and equitable language technologies.",
    "authors": [
      "Dami\u00e1n Blasi",
      "Antonios Anastasopoulos",
      "Graham Neubig"
    ],
    "date": "[Submitted on 13 Oct 2021]"
  },
  {
    "url": "https://arxiv.org/abs/2110.10470v2",
    "title": "Interpreting Deep Learning Models in Natural Language Processing: A Review",
    "abstract": "Neural network models have achieved state-of-the-art performances in a wide range of natural language processing (NLP) tasks. However, a long-standing criticism against neural network models is the lack of interpretability, which not only reduces the reliability of neural NLP systems but also limits the scope of their applications in areas where interpretability is essential (e.g., health care applications). In response, the increasing interest in interpreting neural NLP models has spurred a diverse array of interpretation methods over recent years. In this survey, we provide a comprehensive review of various interpretation methods for neural models in NLP. We first stretch out a high-level taxonomy for interpretation methods in NLP, i.e., training-based approaches, test-based approaches, and hybrid approaches. Next, we describe sub-categories in each category in detail, e.g., influence-function based methods, KNN-based methods, attention-based models, saliency-based methods, perturbation-based methods, etc. We point out deficiencies of current methods and suggest some avenues for future research.",
    "authors": [
      "Xiaofei Sun",
      "Diyi Yang",
      "Xiaoya Li",
      "Tianwei Zhang",
      "Yuxian Meng",
      "Han Qiu",
      "Guoyin Wang",
      "Eduard Hovy",
      "Jiwei Li"
    ],
    "date": "[Submitted on 20 Oct 2021 (v1), last revised 25 Oct 2021 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2112.08159v3",
    "title": "One size does not fit all: Investigating strategies for differentially-private learning across NLP tasks",
    "abstract": "Preserving privacy in contemporary NLP models allows us to work with sensitive data, but unfortunately comes at a price. We know that stricter privacy guarantees in differentially-private stochastic gradient descent (DP-SGD) generally degrade model performance. However, previous research on the efficiency of DP-SGD in NLP is inconclusive or even counter-intuitive. In this short paper, we provide an extensive analysis of different privacy preserving strategies on seven downstream datasets in five different `typical' NLP tasks with varying complexity using modern neural models based on BERT and XtremeDistil architectures. We show that unlike standard non-private approaches to solving NLP tasks, where bigger is usually better, privacy-preserving strategies do not exhibit a winning pattern, and each task and privacy regime requires a special treatment to achieve adequate performance.",
    "authors": [
      "Manuel Senge",
      "Timour Igamberdiev",
      "Ivan Habernal"
    ],
    "date": "[Submitted on 15 Dec 2021 (v1), last revised 31 Jan 2023 (this version, v3)]"
  },
  {
    "url": "https://arxiv.org/abs/2112.08313v2",
    "title": "Measure and Improve Robustness in NLP Models: A Survey",
    "abstract": "As NLP models achieved state-of-the-art performances over benchmarks and gained wide applications, it has been increasingly important to ensure the safe deployment of these models in the real world, e.g., making sure the models are robust against unseen or challenging scenarios. Despite robustness being an increasingly studied topic, it has been separately explored in applications like vision and NLP, with various definitions, evaluation and mitigation strategies in multiple lines of research. In this paper, we aim to provide a unifying survey of how to define, measure and improve robustness in NLP. We first connect multiple definitions of robustness, then unify various lines of work on identifying robustness failures and evaluating models' robustness. Correspondingly, we present mitigation strategies that are data-driven, model-driven, and inductive-prior-based, with a more systematic view of how to effectively improve robustness in NLP models. Finally, we conclude by outlining open challenges and future directions to motivate further research in this area.",
    "authors": [
      "Xuezhi Wang",
      "Haohan Wang",
      "Diyi Yang"
    ],
    "date": "[Submitted on 15 Dec 2021 (v1), last revised 9 May 2022 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2205.01393v2",
    "title": "Noise-like Pulses from an All-Normal-Dispersion Fiber Laser with Weakened Spectrum Filtering",
    "abstract": "Noise-like pulses (NLP) are extremely sought after in many fields. Here, we experimentally and numerically investigated the generation of noise-like pulses in an all-normal-dispersion fiber laser with weak spectrum filtering. With the insertion of the grating as a tunable spectrum filter, the laser operates at a stable dissipative soliton state with a 3.84 ps duration. Replacing the grating with a mirror, NLPs with double-scale intensity autocorrelation trace is ultimately attained. Numerical simulations are performed in detail and demonstrated that with the absence of a spectrum filter, the stable state cannot be established but form the random pulse cluster. The random pulse cluster achieves dynamic stability with suitable feedback, and the NLP is ultimately generated. The NLP here is directly evolved by the initial noise, and no other states occur during its evolution. These explorations could deepen the understanding of NLP and enrich the complex dynamics of the ANDi ultrafast fiber laser.",
    "authors": [
      "Zhicheng Zhang",
      "Sha Wang",
      "Jun Wang"
    ],
    "date": "[Submitted on 3 May 2022 (v1), last revised 30 May 2022 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2205.02182v2",
    "title": "Reproducibility Beyond the Research Community: Experience from NLP Beginners",
    "abstract": "As NLP research attracts public attention and excitement, it becomes increasingly important for it to be accessible to a broad audience. As the research community works to democratize NLP, it remains unclear whether beginners to the field can easily apply the latest developments. To understand their needs, we conducted a study with 93 students in an introductory NLP course, where students reproduced results of recent NLP papers. Surprisingly, our results suggest that their technical skill (i.e., programming experience) has limited impact on their effort spent completing the exercise. Instead, we find accessibility efforts by research authors to be key to a successful experience, including thorough documentation and easy access to required models and datasets.",
    "authors": [
      "Shane Storks",
      "Keunwoo Peter Yu",
      "Joyce Chai"
    ],
    "date": "[Submitted on 4 May 2022 (v1), last revised 5 May 2022 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2205.03559v2",
    "title": "Improving Downstream Task Performance by Treating Numbers as Entities",
    "abstract": "Numbers are essential components of text, like any other word tokens, from which natural language processing (NLP) models are built and deployed. Though numbers are typically not accounted for distinctly in most NLP tasks, there is still an underlying amount of numeracy already exhibited by NLP models. In this work, we attempt to tap this potential of state-of-the-art NLP models and transfer their ability to boost performance in related tasks. Our proposed classification of numbers into entities helps NLP models perform well on several tasks, including a handcrafted Fill-In-The-Blank (FITB) task and on question answering using joint embeddings, outperforming the BERT and RoBERTa baseline classification.",
    "authors": [
      "Dhanasekar Sundararaman",
      "Vivek Subramanian",
      "Guoyin Wang",
      "Liyan Xu",
      "Lawrence Carin"
    ],
    "date": "[Submitted on 7 May 2022 (v1), last revised 18 Sep 2022 (this version, v2)]"
  },
  {
    "url": "https://arxiv.org/abs/2205.04504v1",
    "title": "TinyGenius: Intertwining Natural Language Processing with Microtask Crowdsourcing for Scholarly Knowledge Graph Creation",
    "abstract": "As the number of published scholarly articles grows steadily each year, new methods are needed to organize scholarly knowledge so that it can be more efficiently discovered and used. Natural Language Processing (NLP) techniques are able to autonomously process scholarly articles at scale and to create machine readable representations of the article content. However, autonomous NLP methods are by far not sufficiently accurate to create a high-quality knowledge graph. Yet quality is crucial for the graph to be useful in practice. We present TinyGenius, a methodology to validate NLP-extracted scholarly knowledge statements using microtasks performed with crowdsourcing. The scholarly context in which the crowd workers operate has multiple challenges. The explainability of the employed NLP methods is crucial to provide context in order to support the decision process of crowd workers. We employed TinyGenius to populate a paper-centric knowledge graph, using five distinct NLP methods. In the end, the resulting knowledge graph serves as a digital library for scholarly articles.",
    "authors": [
      "Allard Oelen",
      "Markus Stocker",
      "S\u00f6ren Auer"
    ],
    "date": "[Submitted on 9 May 2022]"
  },
  {
    "url": "https://arxiv.org/abs/2205.05050v1",
    "title": "White-box Testing of NLP models with Mask Neuron Coverage",
    "abstract": "Recent literature has seen growing interest in using black-box strategies like CheckList for testing the behavior of NLP models. Research on white-box testing has developed a number of methods for evaluating how thoroughly the internal behavior of deep models is tested, but they are not applicable to NLP models. We propose a set of white-box testing methods that are customized for transformer-based NLP models. These include Mask Neuron Coverage (MNCOVER) that measures how thoroughly the attention layers in models are exercised during testing. We show that MNCOVER can refine testing suites generated by CheckList by substantially reduce them in size, for more than 60\\% on average, while retaining failing tests -- thereby concentrating the fault detection power of the test suite. Further we show how MNCOVER can be used to guide CheckList input generation, evaluate alternative NLP testing methods, and drive data augmentation to improve accuracy.",
    "authors": [
      "Arshdeep Sekhon",
      "Yangfeng Ji",
      "Matthew B. Dwyer",
      "Yanjun Qi"
    ],
    "date": "[Submitted on 10 May 2022]"
  },
  {
    "url": "https://arxiv.org/abs/2211.06431v1",
    "title": "FinTech for Social Good: A Research Agenda from NLP Perspective",
    "abstract": "Making our research results positively impact on society and environment is one of the goals our community has been pursuing recently. Although financial technology (FinTech) is one of the popular application fields, we notice that there is no discussion on how NLP can help in FinTech for the social good. When mentioning FinTech for social good, people are talking about financial inclusion and green finance. However, the role of NLP in these directions only gets limited discussions. To fill this gap, this paper shares our idea of how we can use NLP in FinTech for social good. We hope readers can rethink the relationship between finance and NLP based on our sharing, and further join us in improving the financial literacy of individual investors and improving the supports for impact investment.",
    "authors": [
      "Chung-Chi Chen",
      "Hiroya Takamura",
      "Hsin-Hsi Chen"
    ],
    "date": "[Submitted on 13 Nov 2022]"
  },
  {
    "url": "https://arxiv.org/abs/2303.13365v1",
    "title": "Requirement Formalisation using Natural Language Processing and Machine Learning: A Systematic Review",
    "abstract": "Improvement of software development methodologies attracts developers to automatic Requirement Formalisation (RF) in the Requirement Engineering (RE) field. The potential advantages by applying Natural Language Processing (NLP) and Machine Learning (ML) in reducing the ambiguity and incompleteness of requirement written in natural languages is reported in different studies. The goal of this paper is to survey and classify existing work on NLP and ML for RF, identifying challenges in this domain and providing promising future research directions. To achieve this, we conducted a systematic literature review to outline the current state-of-the-art of NLP and ML techniques in RF by selecting 257 papers from common used libraries. The search result is filtered by defining inclusion and exclusion criteria and 47 relevant studies between 2012 and 2022 are selected. We found that heuristic NLP approaches are the most common NLP techniques used for automatic RF, primary operating on structured and semi-structured data. This study also revealed that Deep Learning (DL) technique are not widely used, instead classical ML techniques are predominant in the surveyed studies. More importantly, we identified the difficulty of comparing the performance of different approaches due to the lack of standard benchmark cases for RF.",
    "authors": [
      "Shekoufeh Kolahdouz-Rahimi",
      "Kevin Lano",
      "Chenghua Lin"
    ],
    "date": "[Submitted on 18 Mar 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2304.08315v3",
    "title": "Thorny Roses: Investigating the Dual Use Dilemma in Natural Language Processing",
    "abstract": "Dual use, the intentional, harmful reuse of technology and scientific artefacts, is a problem yet to be well-defined within the context of Natural Language Processing (NLP). However, as NLP technologies continue to advance and become increasingly widespread in society, their inner workings have become increasingly opaque. Therefore, understanding dual use concerns and potential ways of limiting them is critical to minimising the potential harms of research and development. In this paper, we conduct a survey of NLP researchers and practitioners to understand the depth and their perspective of the problem as well as to assess existing available support. Based on the results of our survey, we offer a definition of dual use that is tailored to the needs of the NLP community. The survey revealed that a majority of researchers are concerned about the potential dual use of their research but only take limited action toward it. In light of the survey results, we discuss the current state and potential means for mitigating dual use in NLP and propose a checklist that can be integrated into existing conference ethics-frameworks, e.g., the ACL ethics checklist.",
    "authors": [
      "Lucie-Aim\u00e9e Kaffee",
      "Arnav Arora",
      "Zeerak Talat",
      "Isabelle Augenstein"
    ],
    "date": "[Submitted on 17 Apr 2023 (v1), last revised 30 Oct 2023 (this version, v3)]"
  },
  {
    "url": "https://arxiv.org/abs/2305.16579v3",
    "title": "NLP Reproducibility For All: Understanding Experiences of Beginners",
    "abstract": "As natural language processing (NLP) has recently seen an unprecedented level of excitement, and more people are eager to enter the field, it is unclear whether current research reproducibility efforts are sufficient for this group of beginners to apply the latest developments. To understand their needs, we conducted a study with 93 students in an introductory NLP course, where students reproduced the results of recent NLP papers. Surprisingly, we find that their programming skill and comprehension of research papers have a limited impact on their effort spent completing the exercise. Instead, we find accessibility efforts by research authors to be the key to success, including complete documentation, better coding practice, and easier access to data files. Going forward, we recommend that NLP researchers pay close attention to these simple aspects of open-sourcing their work, and use insights from beginners' feedback to provide actionable ideas on how to better support them.",
    "authors": [
      "Shane Storks",
      "Keunwoo Peter Yu",
      "Ziqiao Ma",
      "Joyce Chai"
    ],
    "date": "[Submitted on 26 May 2023 (v1), last revised 3 Jun 2023 (this version, v3)]"
  },
  {
    "url": "https://arxiv.org/abs/2306.04459v1",
    "title": "Uncertainty in Natural Language Processing: Sources, Quantification, and Applications",
    "abstract": "As a main field of artificial intelligence, natural language processing (NLP) has achieved remarkable success via deep neural networks. Plenty of NLP tasks have been addressed in a unified manner, with various tasks being associated with each other through sharing the same paradigm. However, neural networks are black boxes and rely on probability computation. Making mistakes is inevitable. Therefore, estimating the reliability and trustworthiness (in other words, uncertainty) of neural networks becomes a key research direction, which plays a crucial role in reducing models' risks and making better decisions. Therefore, in this survey, we provide a comprehensive review of uncertainty-relevant works in the NLP field. Considering the data and paradigms characteristics, we first categorize the sources of uncertainty in natural language into three types, including input, system, and output. Then, we systemically review uncertainty quantification approaches and the main applications. Finally, we discuss the challenges of uncertainty estimation in NLP and discuss potential future directions, taking into account recent trends in the field. Though there have been a few surveys about uncertainty estimation, our work is the first to review uncertainty from the NLP perspective.",
    "authors": [
      "Mengting Hu",
      "Zhen Zhang",
      "Shiwan Zhao",
      "Minlie Huang",
      "Bingzhe Wu"
    ],
    "date": "[Submitted on 5 Jun 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2306.04874v1",
    "title": "Expanding Scope: Adapting English Adversarial Attacks to Chinese",
    "abstract": "Recent studies have revealed that NLP predictive models are vulnerable to adversarial attacks. Most existing studies focused on designing attacks to evaluate the robustness of NLP models in the English language alone. Literature has seen an increasing need for NLP solutions for other languages. We, therefore, ask one natural question: whether state-of-the-art (SOTA) attack methods generalize to other languages. This paper investigates how to adapt SOTA adversarial attack algorithms in English to the Chinese language. Our experiments show that attack methods previously applied to English NLP can generate high-quality adversarial examples in Chinese when combined with proper text segmentation and linguistic constraints. In addition, we demonstrate that the generated adversarial examples can achieve high fluency and semantic consistency by focusing on the Chinese language's morphology and phonology, which in turn can be used to improve the adversarial robustness of Chinese NLP models.",
    "authors": [
      "Hanyu Liu",
      "Chengyuan Cai",
      "Yanjun Qi"
    ],
    "date": "[Submitted on 8 Jun 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2306.12043v1",
    "title": "Sample Attackability in Natural Language Adversarial Attacks",
    "abstract": "Adversarial attack research in natural language processing (NLP) has made significant progress in designing powerful attack methods and defence approaches. However, few efforts have sought to identify which source samples are the most attackable or robust, i.e. can we determine for an unseen target model, which samples are the most vulnerable to an adversarial attack. This work formally extends the definition of sample attackability/robustness for NLP attacks. Experiments on two popular NLP datasets, four state of the art models and four different NLP adversarial attack methods, demonstrate that sample uncertainty is insufficient for describing characteristics of attackable/robust samples and hence a deep learning based detector can perform much better at identifying the most attackable and robust samples for an unseen target model. Nevertheless, further analysis finds that there is little agreement in which samples are considered the most attackable/robust across different NLP attack methods, explaining a lack of portability of attackability detection methods across attack methods.",
    "authors": [
      "Vyas Raina",
      "Mark Gales"
    ],
    "date": "[Submitted on 21 Jun 2023]"
  },
  {
    "url": "https://arxiv.org/abs/2306.16367v1",
    "title": "Multi-Site Clinical Federated Learning using Recursive and Attentive Models and NVFlare",
    "abstract": "The prodigious growth of digital health data has precipitated a mounting interest in harnessing machine learning methodologies, such as natural language processing (NLP), to scrutinize medical records, clinical notes, and other text-based health information. Although NLP techniques have exhibited substantial potential in augmenting patient care and informing clinical decision-making, data privacy and adherence to regulations persist as critical concerns. Federated learning (FL) emerges as a viable solution, empowering multiple organizations to train machine learning models collaboratively without disseminating raw data. This paper proffers a pragmatic approach to medical NLP by amalgamating FL, NLP models, and the NVFlare framework, developed by NVIDIA. We introduce two exemplary NLP models, the Long-Short Term Memory (LSTM)-based model and Bidirectional Encoder Representations from Transformers (BERT), which have demonstrated exceptional performance in comprehending context and semantics within medical data. This paper encompasses the development of an integrated framework that addresses data privacy and regulatory compliance challenges while maintaining elevated accuracy and performance, incorporating BERT pretraining, and comprehensively substantiating the efficacy of the proposed approach.",
    "authors": [
      "Won Joon Yun",
      "Samuel Kim",
      "Joongheon Kim"
    ],
    "date": "[Submitted on 28 Jun 2023]"
  }
]