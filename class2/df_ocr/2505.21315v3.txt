arXiv:2505.21315v3 [cs.CL] 2 Oct 2025

Charting the Landscape of African NLP: Mapping Progress and Shaping
the Road Ahead

Jesujoba O. Alabi! Michael A. Hedderich? David Ifeoluwa Adelani*? Dietrich Klakow!
‘Saarland University, Saarland Informatics Campus
2LMU Munich and Munich Center for Machine Learning
3Mila - Quebec AI Institute, McGill University & Canada CIFAR AI Chair

{jalabi,dietrich.klakow}@lsv.uni-saarland.de,

Abstract

With over 2,000 languages and potentially mil-
lions of speakers, Africa represents one of the
richest linguistic regions in the world. Yet, this
diversity is scarcely reflected in state-of-the-art
natural language processing (NLP) systems and
large language models (LLMs), which predom-
inantly support a narrow set of high-resource
languages. This exclusion not only limits the
reach and utility of modern NLP technologies
but also risks widening the digital divide across
linguistic communities. Nevertheless, NLP re-
search on African languages is active and grow-
ing. In recent years, there has been a surge
of interest in this area, driven by several fac-
tors—including the creation of multilingual lan-
guage resources, the rise of community-led ini-
tiatives, and increased support through funding
programs. In this survey, we analyze 884 re-
search papers on NLP for African languages
published over the past five years, offering
a comprehensive overview of recent progress
across core tasks. We identify key trends shap-
ing the field and conclude by outlining promis-
ing directions to foster more inclusive and sus-
tainable NLP research for African languages.!

1 Introduction

The field of Natural Language Processing (NLP)
has undergone significant advancements in recent
years. However, languages primarily spoken on the
African continent have often been left behind in
these developments. Many major large language
models—such as Llama3 (Dubey et al., 2024),
Gemma2 (Gemma Team et al., 2024), and An-
thropic’s Claude Sonnet-3.5 (Anthropic, 2024), do
not list any African languages among their offi-
cially supported languages, thereby excluding the
native tongues of potentially millions of speakers.

Despite this exclusion, NLP research on African
languages is far from dormant. In recent years,

'We release our data and code publicly at https: //
github.com/uds-lsv/africanlp-survey

mhedderich@cis.lmu.de, david.adelani@mila. quebec

Figure 1: NLP research distribution across Africa by
language coverage. Darker green indicate more papers
on languages spoken in each country.

there has been a surge of interest in both spo-
ken and written form with the number of publi-
cations quadrupling in just five years and spanning
a wide range of topics—from natural language un-
derstanding and text-to-speech systems to research
on ethics, bias, and fairness. This momentum is
fueled, in part, by community-driven initiatives,
the creation of large corpora, shared tasks, and the
emergence of dedicated venues.

While the broader NLP field has acknowledged
the importance of supporting low-resource lan-
guages in general (Bender, 2019; Joshi et al., 2020;
Hedderich et al., 2021; Nigatu et al., 2024), this
survey narrows its focus specifically to African lan-
guages. Many African countries share common
historical, socio-economic, and infrastructural chal-
lenges, as well as pan-African research and pol-
icy initiatives. At the same time, Africa is char-
acterized by its rich cultural and linguistic diver-
sity (Tchindjang et al., 2008; Ouane and Glanz,
2010). A continent-wide survey is therefore essen-
tial to capture both shared challenges and distinct
differences in the development of language tech-
nologies for Africa.


27,593 papers
(All papers, except expert recommendations, were collected using keyword
matching via the Semantic Scholar API.)

Al Conferences (aaai, cal, ..):. 2,222

ARXIV: 11,680

HCI Conferences (africui, cul): 1,290

IR Conferences (www, sicir, ..): 1,507

ML Conferences (neurips, ICLR, ..): 4,804

NLP Conferences (act, EMNLP, COLING, ..): 2,654
NLP Journals (tact, TALLIP, LREA, ..): 124

Speech Conferences (icassp, INTERSPEECH, ..): 2,412
Speech Journals (Speech Communication, TASLP, ..): 279
Summits (ut summit, amt): 52

Workshops (africaNtp, MRL, WMT ..): 360

Expert Recommendations: 209

GPT-40

10,584 papers excluded:
ARXIV: 9,481
HCl Conferences: 1,102

16,126 papers excluded:
not-nlp, not-africa
position papers

survey papers

theses

Filtering of high false positive
sources (HCI and ARXIV) with

17,010 papers manually
reviewed

884 articles manually analyzed

Figure 2: Inclusion flow of the systematic review.

This survey has three primary goals:

1. Comprehensive overview: By systematically
collecting and annotating literature from over
twenty-five venues—spanning core NLP and
speech, as well as adjacent fields like human-
computer-interaction and machine learning—
from the past five years, we provide an in-
depth overview of contemporary research on
African languages.

2. Accessible Entry Point: By organizing this
literature by language, task, technology, and
theme, we offer a useful resource for both new-
comers and experienced researchers newly en-
gaging with African languages, thereby low-
ering the barrier to entry and encouraging fur-
ther work in this crucial area.

3. Identification of Open Issues: Through an
extensive discussion of the current body of
work, we highlight critical open issues—such
as the imbalance in resources across African
languages and the need for non-translated,
native-language datasets—which can guide
the strategic development of language tech-
nologies tailored to Africa.

2 Related Surveys

African languages are usually classified as low-
resource languages. In their six-class classification
scheme, Joshi et al. (2020) placed most African
languages into the classes "left-behinds", scraping-
bys", and "hopefuls" due to limited or non-existent
labeled data. Surveys exist for low-resource lan-
guages in general, covering common NLP ap-
proaches to boost performance in settings with little
data (Hedderich et al., 2021; Haddow et al., 2022;
Chen et al., 2023). However, as Nigatu et al. (2024)

point out, the definition of "low-resource" is more
complex than just a measurement of data availabil-
ity, including also the availability of other resources
and socio-political factors. This paper therefore
focuses specifically on languages on the African
continent, which could have substantially differ-
ent settings compared to low-resource languages in
other parts of the world.

Several studies have focused on languages
within specific countries, such as South
Africa (Grover et al., 2010), Ethiopia (Tonja
et al., 2023), Kenya (Amol et al., 2024), Nige-
ria (Nwafor and Andy, 2022; Inuwa-Dutse, 2025),
and Ghana (Azunre et al., 2021a; Issaka et al.,
2024). These surveys provide insights into the
linguistic landscape, document available language
resources, and explore computational method-
ologies tailored to the languages spoken in these
countries. By offering a country-level perspective,
they contribute to a broader understanding of
language preservation and technological advance-
ments within specific national contexts. Beyond
country-specific studies, language-specific surveys
have been conducted for individual African
languages such as Southern Sotho (Sibeko and
Setaka, 2022) and Yoruba (Jimoh et al., 2025).
However, a survey looking at the broader African
continent is necessary to uncover both unique
and shared challenges of its languages, and chart
a cohesive future for building technologies for
African languages.

Similar to our effort, the survey by Mussandi and
Wichert (2024) provides a tool-centric overview
of NLP resources available for African languages.
Keet (2022) instead reviews how bootstrapping
has been applied in practice to the Niger-Congo
(‘Bantu’) subset of African languages, showing that
rule- and grammar-based approaches transfer more


successfully across distant languages, whereas data-
driven methods work reliably only for closely re-
lated languages. In contrast, Ikae and Kurpicz-
Briki (2024) concentrates on bias detection in ma-
chine translation for African and European lan-
guages. Our work differs by offering a broader
landscape analysis of African NLP research, high-
lighting trends in language coverage, tasks, and
research output.

3 Survey Methodology

Literature Collection To conduct a comprehen-
sive systematic survey of the relevant literature,
we employ a multi-source approach that integrates
automated and expert-driven methods. First, we
use the Semantic Scholar API, which retrieves
papers by matching query terms against titles and
abstracts in its database. The inclusion criteria
are “Africa”, the names of the 54 African coun-
tries, and 2,290 African languages from the Glot-
tolog database? These searches are conducted
across leading conferences, journals, and work-
shops in NLP, speech, HCI, and AI, as well as the
preprint repository arXiv. The full list of venues
is provided in Section A. We then augment this
dataset with additional relevant papers to ensure
the inclusion of influential and high-impact works
that the Semantic Scholar API does not cap-
ture, adding 209 publications. In total, this process
yields 27,593 relevant publications spanning five
years, from 2019 to 2024. By combining these
sources, our approach ensures a well-rounded lit-
erature survey that balances algorithmic discovery
with human expertise, leading to a more compre-
hensive and accurate understanding of the topic.

Filtering The automatically retrieved articles
contained irrelevant articles not focused on AI or
more specifically, NLP research, especially from
HCI venues and pre-prints. To address this, we
filtered the papers by prompting GPT-40 to clas-
sify whether they were NLP-related based on their
title and abstract. Details for reproducibility are
provided in Section B.

Manual Annotation We manually coded all the
extracted papers with a codebook inspired by the
ACL 2025 tracks and iteratively refined during the
coding process. We identify the languages cov-
ered, the NLP tasks addressed, the low-resource

*Glottolog documents over 3,000 African languages and

dialects, but we used only those with an official ISO 639-3
code.

techniques employed, and other relevant themes.
In addition, our annotation process included deter-
mining whether the paper introduced a dataset and,
if so, whether it was released and whether it was
cross-cultural or translated from one language to
another. We also assessed whether the paper pro-
posed a model and, if so, whether the model was
released. We excluded papers on African American
Vernacular English (AAVE) and those on spoken
English that is not African-accent. We include
African-accented variants of European languages
because they are part of the linguistic reality of
the continent, and handling them well is crucial
for making NLP inclusive for Africans. Figure 2
shows an overview of the data filtering process.
The resulting publication set contains a total of 884
papers.

4 Analysis Result

In this section we analyze the annotated pool of
publications along different dimensions.

4.1. How much do researchers publish?

Figure 3 illustrates the distribution of the papers
over the five-year period under review. The number
of publications grew significantly—from approx-
imately 57 papers in 2019 to 117 in 2020—con-
tinuing to rise and peaking at 232 papers in
2024. We hypothesize that this overall growth
is driven by three key factors: (1) increased ef-
forts to develop multilingual language resources,
including embeddings and language models; (2)
the emergence of community-led initiatives such
as MasakhaneNLP,? EthioNLP,* HausaNLP, and,
GhanaNLP;° and (3) the support of targeted fund-
ing programs such as Lacuna Fund’ and AI4D8,
which have provided crucial resources for African
language research. Furthermore, shared tasks have
contributed to this momentum, with one paper each
in 2019 and 2020, 11 in 2021, 15 in 2022, 41 in
2023, and 24 in 2024. This upward trend highlights
the growing and sustained interest in African NLP
research.

3https ://www.masakhane. io/
“https: //ethionlp. github. io/
Shttps://hausanlp. github. io/
https ://ghananlp.org/
Thttps://lacunafund. org/
Shttps://www.ai4d.ai/


250 Swahilit

N
3
3

ied
3
Language
=
Q
ey

B
=)
S

Nigerian Pidgin
s

Paper Count

Tigrinyat

Tsonga

Moroccan Arabict
Southern Sotho
West Central Oromo

Atlantic-Congo
Afro-Asiatic

Artificial Language

Language Family
ES
3
3
xz
=
5
a

Top-20 Languages \joid Top-20 Language families

2019 2020 2021 2022 2023 2024
Year

Figure 3: Distribution of papers by
publication year.

4.2 What languages do researchers work on?

Given the annotated data, we evaluate all
the African languages covered by the publi-
cations, using the African languages listed in
Glottolog’? (Hammarstrém et al., 2024) as a ref-
erence. Our analysis shows that a total of 2,275
African languages and dialects—including dialects
of Arabic, creoles, and sign languages from vari-
ous African countries—have been covered by the
papers. However, only about 25% of these lan-
guages appear in at least 10 papers, while over
67% were featured in less than 5 papers, high-
lighting the skewed distribution of language cov-
erage. Figure 4 presents the top 20 languages by
frequency, which closely align with the rankings
of the most spoken languages in Africa accord-
ing to LinguaMeta (Ritchie et al., 2024). In par-
ticular, 11 of the top 20 languages according to
publication counts appear among the most widely
spoken languages. However, Afrikaans (7.3M
speakers) and other South African languages such
as Tswana (6M), and Tsonga (2.5M) appeared
among the top 20 languages covered in the pa-
pers—demonstrating the significant research ef-
forts dedicated to South African languages de-
spite their relatively lower positions in the Lin-
guaMeta ranking. In terms of language fami-
lies, Figure 5 shows that Atlantic-Congo lan-
guages dominate the papers, followed closely by
Afro-Asiatic, with other families receiving much
less coverage.

In addition to indigenous African languages,
some papers, particularly those focusing on speech
also included African accents of widely spoken
non-indigenous languages such as French, En-
glish, and Portuguese. While some studies clearly

https ://github.com/glottolog/glottolog-cldf/
blob/master/cldf/languages.csv

1) 50

Figure 4: Top 20 languages by paper
count;} indicates languages among
the top 20 spoken in Africa.

100 150 200 250 300 0 100 200 300 400 500 600

Paper Count Paper Count

Figure 5: Top 20 language families
by number of unique African lan-
guages studied.

Efficient/Low-Resource Methods for NLP
Natural Language Understanding
Machine Translation

Speech: SR, TTS, and SLU
Language Modeling

Information Extraction

Question Answering

Syntax: Tagging, Chunking and Parsing
Representation Learning

Phonology, Morphology, & Segmentation
Dialect & Language Identification

Information Retrieval and Text Mining

Reasoning

Interpreting and Analyzing NLP Models

Ethics, Bias, and Fairness

Semantics: Lexical and Sentence-Level

NLP Applications

Text Generation

Multimodality and Language Grounding

Text Summarization

Human-Centered NLP

Computational Social Science and Cultural Analytics
Dialogue and Interactive Systems

Error Correction

Sign Language

Category

Discourse and Pragmatics lm Methods
Linguistics, Cognition, and Psycholinguistics Mill Tasks
Ml Themes
0 100 200 300 400 500

Paper Count
Figure 6: Bar plot of annotated paper categories (papers
may appear in multiple categories).

specified the country-specific accents they ad-
dressed (Aryal et al., 2023; Afonja et al., 2021;
Olatunji et al., 2023b; Hagemeijer et al., 2022a),
others were more generic (Shan et al., 2023). There
are also research efforts on texts in non-indigenous
languages tailored to African contexts, such as
AfriSenti (Muhammad et al., 2023) and AfriMed-
QA (Nimo et al., 2025).

Furthermore, African languages are often code-
mixed (Bandia, 1996), typically with English or
other languages spoken within the same region.
Our analysis shows that 5.1% of the reviewed
articles focused on code mixing, with empha-
sis on the dialects of the North African Arabic
dialects (Hamed et al., 2023, 2024), and South


African languages (Wilkinson et al., 2020), but also
several other cases (Diallo et al., 2021; Muhammad
et al., 2022; Ilevbare et al., 2024).

Overall, in terms of continent coverage, Figure 1
shows that every country has at least one language
covered, with Mozambique and Uganda leading at
445 and 383 papers respectively. Tanzania, Nigeria,
Rwanda, Burundi, Kenya and Somalia also have
strong representation, each with over 350 papers.
This shows a notable skew in the geographic dis-
tribution of NLP research, with certain countries
receiving more attention.

4.3. What tasks do researchers work on?

The papers cover a skewed distribution of NLP
tasks, with many addressing multiple tasks rather
than just one. For instance, a paper that introduces
a language model and evaluates it on a named entity
recognition task contributes to both language mod-
eling and named entity recognition. Figure 6 shows
the distribution of these tasks, and we highlight the
10 major tasks by publications below:

Natural Language Understanding (NLU) is
the most common task category. Within this cate-
gory, multiple subcategories of sequence classifi-
cation tasks exist, such as text or topic classifica-
tion (Adelani et al., 2023; Ma et al., 2023), hateful
or offensive or abusive speech detection (Thirion
et al., 2020), emotion detection (Moudjari et al.,
2020; Martin et al., 2022), natural language infer-
ence (Lin et al., 2022; Ahuja et al., 2023; Adelani
et al., 2025), intent detection (Moghe et al., 2023;
Skiredj et al., 2024), slot filling (FitzGerald et al.,
2023; Mastel et al., 2023), semantic parsing (Ruder
et al., 2023), and sentiment analysis (Diallo et al.,
2021; Muhammad et al., 2022; Shode et al., 2023).
Notably, around 40% of the NLU papers focus on
sentiment analysis. Sequence classification tasks
appear to be more common, likely due to the rela-
tive ease of creating datasets for them. This is espe-
cially true with techniques like annotation projec-
tion (Adelani et al., 2023; Ma et al., 2023), which
facilitate multilingual data creation when parallel
corpora are available. While some works focus on
building datasets, others concentrate on develop-
ing methods to address these tasks, often through
shared task contributions.

Machine Translation (MT), the second most
common task category, includes work on bitext
mining and alignment (Heffernan et al., 2022; Feng
et al., 2022)—especially from web sources—which
has enabled the creation of widely used datasets

Task Datasets

Datasets

NLU Taxi-1500, SIB-200, MasakhaNEWS, AfriSenti,
AfriXNLI

MT FLORES-200, AfroLingu-MT, NTREX-128, TICO-19,
MAFAND-MT

Reasoning AfriMGSM, LINGOLY, MGSM

TE MasakhaNER, MasakhaNER 2.0

Speech FLEURS, BibleTTS, African Voices

LM mC4, ROOTS, WURA, GlotCC, MADLAD

Models

MT NLLB-200, Toucan, M2M-100, MADLAD

Encoder LM Serengeti, AfroXLMR{-76L}, AfroLM, AfriBERTaV2

Decoder LM BLOOM, XGLM, mGPT, AfroLLaMa, InkubaLM

Enc-Dec LM Cheetah, AfriTeVa V2, AfriMBART, Afri{M,By}T5S

Table 1: Examples of 5 representative datasets and mod-
els with task categories, sorted by languages covered.

like JW300 (Agié and Vulié, 2019), CCAligned (El-
Kishky et al., 2020), and WikiMatrix (Schwenk
et al., 2021), despite some concerns about content
quality (Kreutzer et al., 2022). Multilingual bench-
marks like NTREX-128 (Federmann et al., 2022),
Flores (Goyal et al., 2022; NLLB Team et al.,
2024), MAFAND-MT (Adelani et al., 2022a), and
AfroLingu-MT (Elmadany et al., 2024) have also
incorporated African languages. Furthermore, sev-
eral efforts target specific language pairs (Sanchez-
Martinez et al., 2020; Nguer et al., 2020; Ade-
lani et al., 2021b; Azunre et al., 2021b). Much
of the work focuses on training and evaluating
MT systems, including LLMs, for translation be-
tween African and high-resource languages (Ade-
lani et al., 2022a; Elmadany et al., 2024). Further-
more, standard MT metrics like BLEU are inad-
equate for these morphologically rich languages,
leading to the development of embedding-based
metrics like AfriCOMET (Wang et al., 2024a,b),
though its coverage remains limited.

Speech Processing: Aside from text-based re-
search, there is a substantial amount of work fo-
cused on speech modality, including automatic
phoneme or speech recognition (ASR) (Dossou
and Emezue, 2021; Mohamud et al., 2021; Con-
neau et al., 2022; Sikasote et al., 2023a; Ogunremi
et al., 2024), text-to-speech (TTS) (Ogayo et al.,
2022; Meyer et al., 2022; Maet al., 2024; Lux et al.,
2024), speaker recognition (Villalba et al., 2019),
tone recognition (Obiang et al., 2024), emotion
recognition, speech translation (Zanon Boito et al.,
2022; Sikasote et al., 2023a; Ahia et al., 2024), and
acoustic modeling (Vyas et al., 2020; Tachbelie
et al., 2020). Recently, there has been growing in-
terest in speech representation learning, particularly
with transformer-based models. A few models in-
clude African languages, both African-centric (Ki-
manuka et al., 2024; Caubriére and Gauthier, 2024;
Alabi et al., 2025) and massively multilingual mod-


els (Conneau et al., 2020a; Zanon Boito et al., 2024;
Chen et al., 2024c). These advances are driven by
efforts in the massive curation of speech resources.
However, despite the broad coverage of these mod-
els, the most commonly used evaluation benchmark
for ASR, FLEURS (Conneat et al., 2022), covers
only 21 African languages, creating an imbalance
in evaluation.

Language Models (LMs): During the survey
period, there was a notable increase in the devel-
opment of large transformer-based language mod-
els. Many studies introduced such models for
African languages, including monolingual mod-
els for individual languages (Nzeyimana and Niy-
ongabo Rubungo, 2022; Martin et al., 2022), and
massively multilingual models that include African
languages alongside others (Conneau and Lample,
2019; Imani et al., 2023). These models were de-
veloped by training them from scratch (Jude Ogun-
depo et al., 2022; Ogueji et al., 2021) or extend-
ing existing language models (Alabi et al., 2022;
Adelani et al., 2024; Meyer et al., 2024). These
advances, like those in speech, rely on large-scale
language data from the web. In this line are also
works on representation learning, which includes
learning embedding representation for text (Yuan
et al., 2020; Liu et al., 2023) or speech (Jacobs,
2024), and analyzing them (Alabi et al., 2020). In
Section E.2, we provide an overview of several
models for African languages, including LMs.

Information Extraction (IE) is another com-
mon category of NLP tasks and includes work on
named entity recognition (NER) (Adelani et al.,
2021a, 2022b; Rahimi et al., 2019; Oyewusi et al.,
2021; Mbuvha et al., 2023), entity linking and typ-
ing (Lin et al., 2019; Zhu et al., 2019), event ex-
traction (Jenkins et al., 2023), relation classifica-
tion (Lent et al., 2024), and keyword spotting and
localization (Yusuf and Saraglar, 2019; Olaleye
et al., 2022; Nortje et al., 2024). Among these,
NER is particularly common due to the availability
of resources such as MasakhaNER (Adelani et al.,
2021a, 2022b) and Wikiann NER (Pan et al., 2017).

Language and Dialect Identification, for both
text and speech, is another common task ex-
plored across many languages—including African
languages—and has led to the development of
tools such as AfroLID (Adebara et al., 2022b),
GlotLID (Kargaran et al., 2023), and Open-
LID (Burchell et al., 2023). While some studies
treat this as a benchmark task for evaluating rep-
resentation learning models (Zanon Boito et al.,

2024; Chen et al., 2024b), others focus on devel-
oping practical tools (Burchell et al., 2023; Kar-
garan et al., 2024b) that support downstream appli-
cations—such as multilingual data curation, where
they are used to filter and organize resources by
language (Abadji et al., 2022).

Question Answering (QA)—which involves ex-
tracting, retrieving, or generating answers to in-
put queries—remains an emerging research area
for African languages. Recent efforts have fo-
cused on creating benchmarks from sources such
as Wikipedia, for both QA and machine reading
comprehension across multiple languages. For ex-
ample, multilingual datasets like TyDi QA (Clark
et al., 2020), which includes only Swahili from
Africa, AfriQA (Ogundepo et al., 2023), Nai-
jaRC (Aremu et al., 2024), and AfriMed-QA (Nimo
et al., 2025). There have also been language-
specific initiatives (Wanjawa et al., 2023; Taffa
et al., 2024; Costa-jussa et al., 2025). Another rel-
evant work is Belebele (Bandarkar et al., 2024), a
machine reading comprehension dataset translated
into over 200 languages, including 50+ African
languages.

Reasoning: Closely related to QA is the grow-
ing focus on evaluating the reasoning abilities of
large language models. Recent work explores var-
ious types of reasoning—linguistic (Bean et al.,
2024), cultural knowledge (Myung et al., 2024a),
commonsense (Ponti et al., 2020), mathemati-
cal (Adelani et al., 2025), comparative (Agrawal
et al., 2024), ethical (Agarwal et al., 2024), and
moral (Khandelwal et al., 2024). Notably, many of
the datasets used for such evaluations in African
languages are translated from English, which may
limit cultural relevance and linguistic nuance. Eval-
uation results show that LLMs generally perform
better on these tasks in high-resource languages
compared to low-resource ones, including African
languages (Adelani et al., 2025).

Information Retrieval (IR)-the task of find-
ing relevant documents or information in response
to a query—is a less common but growing area
of research for African languages. Recent efforts
include the development of multilingual and cross-
lingual IR resources, such as Mr. TyDi (Zhang
et al., 2021), MIRACL (Zhang et al., 2023) and
CIRAL (Adeyemi et al., 2024), which include
one, two and four African languages respectively.
Additional work in this field involves the cre-
ation of annotated resources for individual lan-
guages (Yeshambel et al., 2021). Furthermore,


there are works on developing multilingual bi-
text and sentence retrieval models (Artetxe and
Schwenk, 2019; Feng et al., 2022; Winata et al.,
2024b) including several African languages.

Syntax, Tagging, and Parsing: A total of 68
papers have explored various syntax-related tasks,
including dependency parsing (Seddah et al., 2020;
Dione, 2021; Steimel and Kiibler, 2023; Ralethe,
2020), syntactic parsing (Momoh, 2024), part-of-
speech (POS) tagging (Dione et al., 2023; Faisal
et al., 2024), and computational grammar (Hellan,
2020). These efforts span both resource creation
and evaluation; however, they cover only a limited
number of African languages.

Others: Other tasks categorization with less
publications including semantics, multimodality
(text + image or video), text generation (excluding
machine translation) are described in Section C.

4.4 What resources are available?

Given that African languages are low-resource, ef-
forts over the past five years have focused on de-
veloping resources—both for individual languages
and at a large-scale multilingual level, particularly
in the form of datasets. Our analysis shows that 401
papers (about 45%) involve dataset creation, with
126 papers creating datasets via translation. Many
large multilingual datasets—such as NLU’s SIB-
200 and Taxi-1500—are based on English transla-
tions. Similarly, speech datasets like FLEURS,
FLEURS-R, and SpeechTaxi rely on translated
data, which often lacks cultural relevance and may
exhibit translationese (Koppel and Ordan, 2011;
Bizzoni et al., 2020), limiting their real-world ap-
plicability. Table 1 lists examples of datasets and
models, with a more comprehensive list in Sec-
tion E.

4.5 What are the efficient or low-resource
techniques used?

Given the low-resource status of African languages,
researchers often rely on specialized techniques.
Figure 7 (Section D) summarizes those used in the
analyzed papers; we highlight six below.
Transfer Learning Our analysis shows that
about 49% of the papers used transfer learning, pri-
marily through word embeddings, or by fine-tuning
pretrained models or using them as feature extrac-
tors. This approach has been effective across many
languages, including low-resource ones, largely
due to the availability of multilingually pretrained
models that support cross-lingual transfer (Pfeiffer

et al., 2021). However, a major challenge arises
when the target African language is not well rep-
resented in the pretrained model or its tokenizer.
Common strategies to address this include adap-
tive pretraining (Pfeiffer et al., 2021; Alabi et al.,
2022; Adelani et al., 2024; Meyer et al., 2024), and
embedding initialization (Liu et al., 2024; Quinjica
and Adelani, 2024; Dobler and de Melo, 2023).

Zero-Shot Cross-Lingual Transfer Learning
is another commonly used technique in the papers.
In this approach, a model is trained—often using
transfer learning—on a source language and then
evaluated directly on the target language. While
English is a commonly used source language, some
of the analyzed papers explore how to select the
most effective source language (Dione et al., 2023;
Adelani et al., 2023) and how to improve perfor-
mance from the model side such as checkpoint and
run averaging (Schmidt et al., 2023a,b).

Data Augmentation Data augmentation is an-
other popular low-resource technique, used in 8%
of the analyzed papers, and it has been success-
fully used for various tasks such as language model-
ing (Adelani et al., 2024; Singh et al., 2024; Azime
et al., 2024), machine translation via back transla-
tion (Reid et al., 2021; Adelani et al., 2021b), and
other tasks (Zhang et al., 2024b).

Audit and Data Filtering Due to the pres-
ence of language resources on the web that of-
ten contain irrelevant or low-quality content, au-
diting and filtering have become common and ef-
fective approaches—especially for low-resource
languages. For instance, these methods have been
shown to improve performance in language mod-
eling tasks (Oladipo et al., 2023; Kudugunta et al.,
2023)

Weak and Distant Supervision was also em-
ployed in the reviewed works, with the aim to im-
prove model performance by generating noisy la-
bels for unlabeled data via heuristics or external
sources. When paired with noisy-label handling
approaches, it proves beneficial for African lan-
guages. (Zhu et al., 2022; Hedderich et al., 2020;
Adelani et al., 2020).

Other methods Other techniques including an-
notation projection (AP), meta learning, and multi-
task learning (MTL) are described in Section D.

4.6 What are the other themes?

Interpretability and Analysis (IA): Methods on
interpretability and model analysis have gained in-
creasing attention in NLP in recent years (Mos-


bach et al., 2024). Although few studies focus
exclusively on African languages (Chimoto et al.,
2024), there are several multilingual [A works on
MT (Ahia et al., 2021; Adebara et al., 2022a; Mo-
hammadshahi et al., 2022b), speech models (Os-
akuade and King, 2024), and LLM (Ahia et al.,
2023; Alabi et al., 2024a; Zebaze et al., 2025;
Zhang et al., 2024a; Shafayat et al., 2024) which in-
clude African languages. We identified 38 relevant
papers in total, showing progress but highlighting
the need for further work, especially in applying
these insights to improve models’ performance.

Ethics, Bias, and Fairness: There are also a
few works that focus on analyzing biases in NLP
models and proposing mitigation strategies to pro-
mote fairness. Among the 29 relevant papers identi-
fied, gender bias (Costa-jussa et al., 2022) and cul-
tural bias (Shan et al., 2023; Olatunji et al., 2023a;
Magomere et al., 2025) were the most commonly
addressed. However, much remains to be done
to address bias and ensure equity across diverse
linguistic and cultural contexts.

Human-Centered NLP: Human-centric re-
search in NLP has gained prominence in both the
NLP community (Soni et al., 2024) and the field
of human-computer interaction (HCI), which has
seen a massive uptake on work about LLMs (Pang
et al., 2025). However, such work remains scarce
in African NLP—for example, only 11 relevant
papers have been presented at CHI, a leading HCI
conference, and its African counterpart, AfriCHI.

NLP Applications: Our analysis identified 25
relevant papers that focus on the development of
NLP technologies aimed at application areas such
as education (Corallo and Varde, 2023), health (Ab-
dulhamid et al., 2023), agriculture (Akera et al.,
2019), banking (Skiredj et al., 2024), and humani-
tarian response (Oktem et al., 2021).

5 Discussion and Future Directions

In this survey, we presented an overview of re-
search on African languages over the past five
years, covering key tasks such as machine trans-
lation, sentiment analysis, language identification,
question answering, and reasoning with large lan-
guage models. While notable progress has been
made—particularly in dataset creation, benchmark-
ing, and adaptation of multilingual models—our
analysis reveals several limitations and points to
important future directions.

Scaling beyond the top-10 resourced lan-

guages: It is important to invest efforts in support-
ing African languages beyond Swahili and other
widely spoken ones, ensuring that lower-resourced
and endangered languages also receive attention in
preservation, research, and technological integra-
tion. Unlike other regions, Africa has more than
100 languages with more than 1M speakers, so
scaling beyond the top-10 is urgently needed.

Towards more multi-cultural dataset creation:
Our analysis shows that many benchmark datasets
created for these languages, especially large-scale
datasets such as Flores, are based on translated
texts. Some of these lack cultural contexts of
the users of this technology, and can amplify
bias towards Western concepts especially for QA
tasks (Romero et al., 2024) or reduce performance
due to lack of cultural understanding (Akinade
et al., 2023; Yao et al., 2024). There is a need to go
beyond scaling by translation to building realistic
multicultural datasets for African languages.

Towards more multimodal models for African
languages: At the moment, there is significantly
less research on developing Visual LMs (VLMs) for
African languages. Existing VLMs perform poorly
on African languages and cultural understanding of
artifacts from African countries (Nayak et al., 2024;
Winata et al., 2024a). This makes it difficult to an-
swer culture-specific questions over images, and
also amplifies cultural bias related to Africans iden-
tity, lifestyles, occupations, food, clothing, among
others (Chiu et al., 2024).

More investment in speech processing tasks:
Many languages in Africa are often spoken rather
than written. However, only few languages have
large-scale datasets covering over 100 hours for
ASR. While platforms such as Mozilla Common-
Voice have democratized the data collection, only
few languages used the platforms due to lack of at-
tribution by the contributors of the datasets (Rajab
et al., 2025) and the difficulty of finding volunteers.
Aside from popular tasks like ASR, other tasks
such as text-to-speech, audio classification, speech
translation, and many others lack datasets. To de-
velop NLP models that would be used by many
African communities, it must be accompained with
a speech component.

More exploration of other generation tasks:
Most benchmarks for African languages have pri-
marily focused on NLU and MT, partly due to the
relative ease of creating datasets for these tasks.
However, more attention should be given to lan-
guage generation tasks—such as text summariza-


tion, grammar correction, dialog and table-to-text
generation—which are typically more challenging
to build datasets for but are equally important for
the development of robust language technologies.

More development of African-centric LLMs:
Current LLMs, especially the open-weight ver-
sions, often do not officially include African lan-
guages in their pre-training (Aryabumi et al., 2024),
and when they do, only few high-resource ones
such as Afrikaans and Swahili with more than 1B
tokens are covered (Yang et al., 2024). There is
need to develop or adapt LLMs to more African lan-
guages. This should be accompanied by evaluation
datasets that are culturally relevant, sector-specific,
knowledge-intensive, and require reasoning to as-
sess LLMs in truly low-resource languages.

Towards human-centered, application-driven
NLP: Understanding human-centric factors and de-
veloping methods in the context of applications
is essential to ensure that NLP technologies gen-
uinely benefit users. More research is needed to ex-
plore the shared and distinct human-centric needs
of African language-speaking communities, both
within the continent and in comparison to other
global contexts.

Finally, the successful implementation of all the
aforementioned directions ultimately depends on
activities such as support for community initiatives,
the organization of shared tasks, and adequate fund-
ing—all of which serve as the foundational pillars
for initiating, sustaining, and scaling these efforts.

6 Conclusion

In this survey, we provide a structured overview of
recent developments in natural language processing
for African languages over the past five years. Our
study reveals steady and significant progress in re-
search on African languages, driven by several fac-
tors such as the creation of multilingual language
resources, increased community engagement, and
various funding initiatives. We highlight common
tasks, methods, and recurring themes that character-
ize current research efforts. However, these efforts
have been disproportionately focused on a limited
set of languages, tasks, and countries. As a result,
we outline several potential directions for future
research to ensure more balanced and inclusive
development across the continent.

Limitations

Coverage Limitations: Although we used a sys-
tematic survey approach that combines automated
and expert-driven methods, one of the limitations
of this survey is that it primarily focused on pa-
pers published in top-tier conferences and jour-
nals, which may exclude relevant works published
within African venues and other venues. While
we included papers from AfricaNLP, and AfriCHI,
which are both African-centric venues, local re-
search published in other venues may offer addi-
tional insights that are not captured in this study.
Future work should broaden the scope to incorpo-
rate Africa-specific studies to provide more com-
prehensive understanding of the field and ensure
that insights from the different parts of Africa are
adequately represented. Similarly, our automated
method, which relied on the Semantic Scholar API,
may not have correctly indexed all relevant papers
from the selected venues.

Potential False Negatives in Data Selection:
Our manual annotation of 100 examples revealed
that our filtering process using GPT-40 on HCI and
arXiv papers resulted in a false negative. It is pos-
sible that a few relevant NLP papers on African
languages were also omitted, particularly since
large language models like GPT-40 are sensitive to
prompts, and we only tested a single prompt.

Lack of dataset sheet for some papers: Some
papers such as (Li et al., 2022), (Nguyen et al.,
2024a) and toolkit papers such as (Emezue and
Dossou, 2020a) and (Muite and Kizito, 2022) did
not provide the list of languages covered despite
covering hundred and thousands of languages. Al-
though we included them in our analysis, we could
not provide the studied languages.

Lack of social and ethical dimensions: of
African NLP development. This survey focuses
primarily on the technical landscape of African
NLP, including datasets, tasks, languages, and mod-
eling approaches, and does not systematically ad-
dress social, cultural, or ethical dimensions such as
community involvement, consent, bias, or potential
harms of NLP systems. Human-centered evalua-
tions and assessments of societal impact are beyond
the scope of this survey. Future research should
incorporate ethical, cultural, and social considera-
tions to ensure that African NLP technologies are
developed responsibly and equitably.


Acknowledgments

Jesujoba Alabi was funded by the Deutsche
Forschungsgemeinschaft (DFG, German Research
Foundation) — Project-ID 232722074 — SFB 1102.
David Adelani acknowledges the funding of
IVADO and the Canada First Research Excellence
Fund. We are grateful to Aravind Krishnan and
Max Rausch-Dupont for their feedback on the
manuscript. Finally, we would like to thank Ope-
nAI for providing API credits through their Re-
searcher Access API Program.

References

Julien Abadji, Pedro Ortiz Suarez, Laurent Romary, and
Benoit Sagot. 2022. Towards a cleaner document-
oriented multilingual crawled corpus. In Proceedings
of the Thirteenth Language Resources and Evalua-
tion Conference, pages 4344-4355, Marseille, France.
European Language Resources Association.

Amine Abdaoui, Mohamed Berrimi, Mourad Oussalah,
and Abdelouahab Moussaoui. 2021. Dziribert: a
pre-trained language model for the algerian dialect.
ArXiv, abs/2109.12346.

Lamiaa Abdel-Hamid. 2020. Egyptian arabic speech
emotion recognition using prosodic, spectral and
wavelet features. Speech Commun., 122:19-30.

Najeeb Gambo Abdulhamid, Millicent Ochieng, Kalika
Bali, Elizabeth A. Ankrah, Naveena Karusala, Keshet
Ronen, and Jacki O’ Neill. 2023. Can large language
models support medical facilitation work? a specula-
tive analysis. Proceedings of the 4th African Human
Computer Interaction Conference.

Idris Abdulmumin, Satya Ranjan Dash, Musa Ab-
dullahi Dawud, Shantipriya Parida, Shamsuddeen
Muhammad, Ibrahim Sa’id Ahmad, Subhadarshi
Panda, Ondrej Bojar, Bashir Shehu Galadanci, and
Bello Shehu Bello. 2022. Hausa visual genome: A
dataset for multi-modal English to Hausa machine
translation. In Proceedings of the Thirteenth Lan-
guage Resources and Evaluation Conference, pages
6471-6479, Marseille, France. European Language
Resources Association.

Ife Adebara, Muhammad Abdul-Mageed, and Miikka
Silfverberg. 2022a. Linguistically-motivated Yoruba-
English machine translation. In Proceedings of the
29th International Conference on Computational Lin-
guistics, pages 5066-5075, Gyeongju, Republic of
Korea. International Committee on Computational
Linguistics.

Ife Adebara, AbdelRahim Elmadany, and Muhammad
Abdul-Mageed. 2023a. Improving african language
identification with multi-task learning. In AfricaNLP.

10

Ife Adebara, AbdelRahim Elmadany, and Muhammad
Abdul-Mageed. 2024. Cheetah: Natural language
generation for 517 African languages. In Proceed-
ings of the 62nd Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 12798-12823, Bangkok, Thailand. As-
sociation for Computational Linguistics.

Ife Adebara, AbdelRahim Elmadany, Muhammad
Abdul-Mageed, and Alcides Alcoba Inciarte. 2023b.
SERENGETI: Massively multilingual language mod-
els for Africa. In Findings of the Association for
Computational Linguistics: ACL 2023, pages 1498-
1537, Toronto, Canada. Association for Computa-
tional Linguistics.

Ife Adebara, AbdelRahim Elmadany, Muhammad
Abdul-Mageed, and Alcides Inciarte. 2022b.
AfroLID: A neural language identification tool for
African languages. In Proceedings of the 2022
Conference on Empirical Methods in Natural
Language Processing, pages 1958-1981, Abu
Dhabi, United Arab Emirates. Association for
Computational Linguistics.

David Ifeoluwa Adelani, Jade Abbott, Graham Neu-
big, Daniel D’souza, Julia Kreutzer, Constantine
Lignos, Chester Palen-Michel, Happy Buzaaba,
Shruti Rijhwani, Sebastian Ruder, Stephen May-
hew, Israel Abebe Azime, Shamsuddeen H. Muham-
mad, Chris Chinenye Emezue, Joyce Nakatumba-
Nabende, Perez Ogayo, Aremu Anuoluwapo, Cather-
ine Gitau, Derguene Mbaye, and 42 others. 2021a.
MasakhaNER: Named entity recognition for African
languages. Transactions of the Association for Com-
putational Linguistics, 9:1116-1131.

David Ifeoluwa Adelani, Jesujoba Oluwadara Alabi,
Angela Fan, Julia Kreutzer, Xiaoyu Shen, Machel
Reid, Dana Ruiter, Dietrich Klakow, Peter Nabende,
Ernie Chang, Tajuddeen Gwadabe, Freshia Sackey,
Bonaventure F. P. Dossou, Chris Emezue, Colin
Leong, Michael Beukman, Shamsuddeen H. Muham-
mad, Guyo D. Jarso, Oreen Yousuf, and 26 others.
2022a. A few thousand translations go a long way!
leveraging pre-trained models for African news trans-
lation. In Proceedings of the 2022 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 3053-3070, Seattle, United States.
Association for Computational Linguistics.

David Ifeoluwa Adelani, Michael A. Hedderich, D. Zhu,
Esther van den Berg, and Dietrich Klakow. 2020.
Distant supervision and noisy label learning for low
resource named entity recognition: A study on hausa
and yoruba. arXiv: Computation and Language.

David Ifeoluwa Adelani, Hannah Liu, Xiaoyu Shen,
Nikita Vassilyev, Jesujoba O. Alabi, Yanke Mao, Hao-
nan Gao, and En-Shiun Annie Lee. 2024. SIB-200:
A simple, inclusive, and big evaluation dataset for
topic classification in 200+ languages and dialects.
In Proceedings of the 18th Conference of the Euro-
pean Chapter of the Association for Computational


Linguistics (Volume 1: Long Papers), pages 226-245,
St. Julian’s, Malta. Association for Computational
Linguistics.

David Ifeoluwa Adelani, Marek Masiak, Israel Abebe
Azime, Jesujoba Alabi, Atnafu Lambebo Tonja,
Christine Mwase, Odunayo Ogundepo, Bonaventure
F. P. Dossou, Akintunde Oladipo, Doreen Nixdorf,
Chris Chinenye Emezue, Sana Al-azzawi, Blessing
Sibanda, Davis David, Lolwethu Ndolela, Jonathan
Mukiibi, Tunde Ajayi, Tatiana Moteu, Brian Odhi-
ambo, and 46 others. 2023. MasakhaNEWS: News
topic classification for African languages. In Pro-
ceedings of the 13th International Joint Conference
on Natural Language Processing and the 3rd Confer-
ence of the Asia-Pacific Chapter of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 144-159, Nusa Dua, Bali. Association
for Computational Linguistics.

David Ifeoluwa Adelani, Graham Neubig, Sebastian
Ruder, Shruti Rijhwani, Michael Beukman, Chester
Palen-Michel, Constantine Lignos, Jesujoba O. Al-
abi, Shamsuddeen H. Muhammad, Peter Nabende,
Cheikh M. Bamba Dione, Andiswa Bukula, Roowei-
ther Mabuya, Bonaventure F. P. Dossou, Blessing
Sibanda, Happy Buzaaba, Jonathan Mukiibi, God-
son Kalipe, Derguene Mbaye, and 26 others. 2022b.
MasakhaNER 2.0: Africa-centric transfer learning
for named entity recognition. In Proceedings of
the 2022 Conference on Empirical Methods in Nat-
ural Language Processing, pages 4488-4508, Abu
Dhabi, United Arab Emirates. Association for Com-
putational Linguistics.

David Ifeoluwa Adelani, Jessica Ojo, Israel Abebe Az-
ime, Jian Yun Zhuang, Jesujoba O. Alabi, Xuanli He,
Millicent Ochieng, Sara Hooker, Andiswa Bukula,
En-Shiun Annie Lee, Chiamaka Chukwuneke, Happy
Buzaaba, Blessing Sibanda, Godson Kalipe, Jonathan
Mukiibi, Salomon Kabongo, Foutse Yuehgoh, Mma-
sibidi Setaka, Lolwethu Ndolela, and 8 others. 2025.
Irokobench: A new benchmark for african languages
in the age of large language models. Preprint,
arXiv:2406.03368.

David Ifeoluwa Adelani, Dana Ruiter, Jesujoba O. Alabi,

Damilola Adebonojo, Adesina Ayeni, Mofe Adeyemi,
Ayodele Esther Awokoya, and Cristina Espafia-Bonet.
2021b. The effect of domain and diacritics in Yoruba—
English neural machine translation. In Proceed-
ings of Machine Translation Summit XVIII: Research

Track, pages 61-75, Virtual. Association for Machine

Translation in the Americas.

Henok Biadglign Ademtew and Mikiyas Birbo. 2024.

Age: Amharic, ge’ez and english parallel dataset.
Proceedings of the Seventh Workshop on Technolo-
gies for Machine Translation of Low-Resource Lan-
guages (LoResMT 2024).

Tosin P. Adewumi, Mofetoluwa Adeyemi, Aremu An-

uoluwapo, Bukola Peters, Happy Buzaaba, Oy-
erinde Samuel, Amina Mardiyyah Rufai, Ben-
jamin Ayoade Ajibade, Tajudeen Gwadabe, Mory

11

Moussou Koulibaly Traore, Tunde Oluwaseyi Ajayi,
Shamsuddeen Hassan Muhammad, Ahmed Baruwa,
Paul Owoicho, Toltilopé Oginrémi, Phylis Ngigi,
Orevaoghene Ahia, Ruqayya Nasir, Foteini Simistira
Liwicki, and Marcus Liwicki. 2023. Afriwoz: Cor-
pus for exploiting cross-lingual transfer for dialogue
generation in low-resource, african languages. 2023
International Joint Conference on Neural Networks
(IJCNN), pages 1-8.

Mofetoluwa Adeyemi, Akintunde Oladipo, Xinyu

Zhang, David Alfonso-Hermelo, Mehdi Reza-
gholizadeh, Boxing Chen, Abdul-Hakeem Omo-
tayo, Idris Abdulmumin, Naome A. Etori, Toyib Ba-
batunde Musa, Samuel Fanijo, Oluwabusayo Olu-
funke Awoyomi, Saheed Abdullahi Salahudeen,
Labaran Adamu Mohammed, Daud Olamide Abo-
lade, Falalu Ibrahim Lawan, Maryam Sabo Abubakar,
Rugqayya Nasir Iro, Amina Imam Abubakar, and 4
others. 2024. Ciral: A test collection for clir evalua-
tions in african languages. In Proceedings of the 47th
International ACM SIGIR Conference on Research
and Development in Information Retrieval, SIGIR
°24, page 293-302, New York, NY, USA. Association
for Computing Machinery.

Wafia Adouane, Jean-Philippe Bernardy, and Simon

Dobnik. 2019. Normalising non-standardised orthog-
raphy in Algerian code-switched user-generated data.
In Proceedings of the 5th Workshop on Noisy User-
generated Text (W-NUT 2019), pages 131-140, Hong
Kong, China. Association for Computational Linguis-
tics.

Olanrewaju Tahir Aduragba, Jialin Yu, Alexandra Ioana

Cristea, and Yang Long. 2023. Improving health
mention classification through emphasising literal
meanings: A study towards diversity and generalisa-
tion for public health surveillance. Proceedings of
the ACM Web Conference 2023.

Tejumade Afonja, Oladimeji Mudele, Iroro Orife,

Kenechi Dukor, Lawrence Francis, Duru Goodness,
Oluwafemi Azeez, Ademola Malomo, and Clinton
Mbataku. 2021. Learning nigerian accent embed-
dings from speech: preliminary results based on
sautidb-naija corpus. ArXiv, abs/2112.06199.

Utkarsh Agarwal, Kumar Tanmay, Aditi Khandelwal,

and Monojit Choudhury. 2024. Ethical reasoning
and moral value alignment of LLMs depend on the
language we prompt them in. In Proceedings of the
2024 Joint International Conference on Computa-
tional Linguistics, Language Resources and Eval-
uation (LREC-COLING 2024), pages 6330-6340,
Torino, Italia. ELRA and ICCL.

Zeljko Agié and Ivan Vuli¢. 2019. JW300: A wide-

coverage parallel corpus for low-resource languages.
In Proceedings of the 57th Annual Meeting of the As-
sociation for Computational Linguistics, pages 3204—
3210, Florence, Italy. Association for Computational
Linguistics.

Ameeta Agrawal, Andy Dang, Sina Bagheri Nezhad,

Rhitabrat Pokharel, and Russell Scheinberg. 2024.


Evaluating multilingual long-context models for re-
trieval and reasoning. In Proceedings of the Fourth
Workshop on Multilingual Representation Learning
(MRL 2024), pages 216-231, Miami, Florida, USA.
Association for Computational Linguistics.

Orevaoghene Ahia, Anuoluwapo Aremu, Diana
Abagyan, Hila Gonen, David Ifeoluwa Adelani, Daud
Abolade, Noah A. Smith, and Yulia Tsvetkov. 2024.
Voices unheard: NLP resources and models for
Yoruba regional dialects. In Proceedings of the 2024
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 4392-4409, Miami, Florida,
USA. Association for Computational Linguistics.

Orevaoghene Ahia, Julia Kreutzer, and Sara Hooker.
2021. The low-resource double bind: An empirical
study of pruning for low-resource machine transla-
tion. In Findings of the Association for Computa-
tional Linguistics: EMNLP 2021, pages 3316-3333,
Punta Cana, Dominican Republic. Association for
Computational Linguistics.

Orevaoghene Ahia, Sachin Kumar, Hila Gonen, Jungo
Kasai, David Mortensen, Noah Smith, and Yulia
Tsvetkov. 2023. Do all languages cost the same?
tokenization in the era of commercial language mod-
els. In Proceedings of the 2023 Conference on Em-
pirical Methods in Natural Language Processing,
pages 9904—9923, Singapore. Association for Com-
putational Linguistics.

Emily P. Ahn, Gina-Anne Levow, Richard A. Wright,
and Eleanor Chodroff. 2023. An outlier analysis of
vowel formants from a corpus phonetics pipeline. In
Interspeech 2023, pages 2573-2577.

Kabir Ahuja, Harshita Diddee, Rishav Hada, Milli-
cent Ochieng, Krithika Ramesh, Prachi Jain, Ak-
shay Nambi, Tanuja Ganu, Sameer Segal, Mohamed
Ahmed, Kalika Bali, and Sunayana Sitaram. 2023.
MEGA: Multilingual evaluation of generative AI.
In Proceedings of the 2023 Conference on Empir-
ical Methods in Natural Language Processing, pages
4232-4267, Singapore. Association for Computa-
tional Linguistics.

Sanchit Ahuja, Divyanshu Aggarwal, Varun Gumma,
Ishaan Watts, Ashutosh Sathe, Millicent Ochieng,
Rishav Hada, Prachi Jain, Mohamed Ahmed, Kalika
Bali, and Sunayana Sitaram. 2024. MEGAVERSE:
Benchmarking large language models across lan-
guages, modalities, models and tasks. In Proceed-
ings of the 2024 Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies (Volume
1: Long Papers), pages 2598-2637, Mexico City,
Mexico. Association for Computational Linguistics.

Daniel Ajisafe, Oluwabukola Grace Adegboro, Esther
Oduntan, and Tayo Oladiran Arulogun. 2020. To-
wards end-to-end training of automatic speech recog-
nition for nigerian pidgin. ArXiv, abs/2010.11123.

12

Benjamin Akera, Joyce Nakatumba-Nabende, Jonathan
Mukiibi, Ali Hussein, Nathan Baleeta, Daniel Ssendi-
wala, and Samiiha Nalwooga. 2019. Keyword spot-
ter model for crop pest and disease monitoring from
community radio data. ArXiv, abs/1910.02292.

Idris Akinade, Jesujoba O. Alabi, David Ifeoluwa Ade-
lani, Clement Odoje, and Dietrich Klakow. 2023.
Varepsilon ki mask: Integrating Yoruba cultural
greetings into machine translation. In Proceedings of
the First Workshop on Cross-Cultural Considerations
in NLP (C3NLP), pages 1-7, Dubrovnik, Croatia. As-
sociation for Computational Linguistics.

Jesujoba Alabi, Marius Mosbach, Matan Eyal, Dietrich
Klakow, and Mor Geva. 2024a. The hidden space
of transformer language adapters. In Proceedings
of the 62nd Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers),
pages 6588-6607, Bangkok, Thailand. Association
for Computational Linguistics.

Jesujoba O. Alabi, David Ifeoluwa Adelani, Marius
Mosbach, and Dietrich Klakow. 2022. Adapting pre-
trained language models to African languages via
multilingual adaptive fine-tuning. In Proceedings of
the 29th International Conference on Computational
Linguistics, pages 4336-4349, Gyeongju, Republic
of Korea. International Committee on Computational
Linguistics.

Jesujoba O. Alabi, Kwabena Amponsah-Kaakyire,
David I. Adelani, and Cristina Espafia-Bonet. 2020.
Massive vs. curated embeddings for low-resourced
languages: the case of Yoruba and Twi. In Proceed-
ings of the Twelfth Language Resources and Evalua-
tion Conference, pages 2754-2762, Marseille, France.
European Language Resources Association.

Jesujoba O. Alabi, Xuechen Liu, Dietrich Klakow, and
Junichi Yamagishi. 2025. AfriduBERT: A self-
supervised speech representation model for African
languages. In Interspeech 2025, pages 4023-4027.

Jesujoba Oluwadara Alabi, Xuechen Liu, Dietrich
Klakow, and Junichi Yamagishi. 2024b. Afrihubert:
A self-supervised speech representation model for
african languages. ArXiv, abs/2409.20201.

Sadeen Alharbi, Areeb Alowishegq, Zoltan Tiiske, Ka-
reem Darwish, Abdullah Alrajeh, Abdulmajeed Al-
rowithi, Aljawharah Bin Tamran, Asma Ibrahim,
Raghad Aloraini, Raneem Alnajim, Ranya Alkah-
tani, Renad Almuasaad, Sara Alrasheed, Shaykhah Z.
Alsubaie, and Yaser Alonaizan. 2024. Sada: Saudi
audio dataset for arabic. ICASSP 2024 - 2024 IEEE
International Conference on Acoustics, Speech and
Signal Processing (ICASSP), pages 10286-10290.

Felermino D. M. A. Ali, Henrique Lopes Cardoso,
and Rui Sousa-Silva. 2024a. Building resources for
emakhuwa: Machine translation and news classifica-
tion benchmarks. In Proceedings of the 2024 Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 14842-14857, Miami, Florida, USA.
Association for Computational Linguistics.


Felermino Dario Mario Ali, Henrique Lopes Cardoso,
and Rui Sousa-Silva. 2024b. Expanding FLO-
RES+ benchmark for more low-resource settings:
Portuguese-emakhuwa machine translation evalua-
tion. In Proceedings of the Ninth Conference on Ma-
chine Translation, pages 579-592, Miami, Florida,
USA. Association for Computational Linguistics.

Tanel Alumde, Kunnar Kukk, Viet Bac Le, Claude Bar-
ras, Abdelkhalek Messaoudi, and Waad Ben Kheder.
2023. Exploring the impact of pretrained models and
web-scraped data for the 2022 nist language recogni-
tion evaluation. In Interspeech.

Cynthia Jayne Amol, Everlyn Asiko Chimoto,
Rose Delilah Gesicho, Antony M. Gitau, Naome A.
Etori, Caringtone Kinyanjui, Steven Ndung’u,
Lawrence Moruye, Samson Otieno Ooko, Kavengi
Kitonga, Brian Muhia, Catherine Gitau, Antony
Ndolo, Lilian D. A. Wanzare, Albert Njoroge Kahira,
and Ronald Tombe. 2024. State of nlp in kenya: A
survey. Preprint, arXiv:2410.09948.

Antonios Anastasopoulos, Alessandro Cattelan, Zi-
Yi Dou, Marcello Federico, Christian Federmann,
Dmitriy Genzel, Franscisco Guzman, Junjie Hu, Mac-
duff Hughes, Philipp Koehn, Rosie Lazar, Will Lewis,
Graham Neubig, Mengmeng Niu, Alp Oktem, Eric
Paquin, Grace Tang, and Sylwia Tur. 2020. TICO-19:
the translation initiative for COvid-19. In Proceed-
ings of the Ist Workshop on NLP for COVID-19 (Part
2) at EMNLP 2020, Online. Association for Compu-
tational Linguistics.

Michael Andersland. 2024. Amharic llama and Ilava:
Multimodal Ilms for low resource languages. ArXiv,
abs/2403.06354.

Anthropic. 2024. Claude 3.5 sonnet. https://www.
anthropic.com/news/claude-3-5-sonnet. Ac-
cessed October 14, 2024.

Rosana Ardila, Megan Branson, Kelly Davis, Michael
Kohler, Josh Meyer, Michael Henretty, Reuben
Morais, Lindsay Saunders, Francis Tyers, and Gre-
gor Weber. 2020. Common voice: A massively-
multilingual speech corpus. In Proceedings of the
Twelfth Language Resources and Evaluation Confer-
ence, pages 4218-4222, Marseille, France. European
Language Resources Association.

Anuoluwapo Aremu, Jesujoba Oluwadara Alabi, Daud
Abolade, Nkechinyere Faith Aguobi, Shamsud-
deen Hassan Muhammad, and David Ifeoluwa Ade-
lani. 2024. NaijaRC: A multi-choice reading com-
prehension dataset for nigerian languages. In 5th
Workshop on African Natural Language Processing.

Mikel Artetxe and Holger Schwenk. 2019. Mas-
sively multilingual sentence embeddings for zero-
shot cross-lingual transfer and beyond. Transactions
of the Association for Computational Linguistics,
7:597-610.

Viraat Aryabumi, John Dang, Dwarak Talupuru,
Saurabh Dash, David Cairuz, Hangyu Lin, Bharat

13

Venkitesh, Madeline Smith, Kelly Marchisio, Sebas-
tian Ruder, Acyr F. Locatelli, Julia Kreutzer, Nick
Frosst, Phil Blunsom, Marzieh Fadaee, A. Ustun,
and Sara Hooker. 2024. Aya 23: Open weight
releases to further multilingual progress. Arxiv,
abs/2405.15032.

Saurav K. Aryal, Howard Prioleau, and Surakshya
Aryal. 2023. Sentiment analysis across multiple
african languages: A current benchmark. Preprint,
arXiv:2310.14120.

Akari Asai, Sneha Kudugunta, Xinyan Yu, Terra
Blevins, Hila Gonen, Machel Reid, Yulia Tsvetkov,
Sebastian Ruder, and Hannaneh Hajishirzi. 2024.
BUFFET: Benchmarking large language models for
few-shot cross-lingual transfer. In Proceedings of
the 2024 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies (Volume 1: Long
Papers), pages 1771-1800, Mexico City, Mexico. As-
sociation for Computational Linguistics.

Jesse Atuhurra, Hiroyuki Shindo, Hidetaka Kamigaito,
and Taro Watanabe. 2024. Introducing syllable tok-
enization for low-resource languages: A case study
with swahili. ArXiv, abs/2406.15358.

Busayo Awobade, Mardiyyah Oduwole, and Steven
Kolawole. 2024. What happens when small is
made smaller? exploring the impact of compression
on small data pretrained language models. ArXiv,
abs/2404.04759.

Israel Abebe Azime and Nebil Mohammed. 2021.
An amharic news text classification dataset. In
AfricaNLP.

Israel Abebe Azime, Atnafu Lambebo  Tonja,
Tadesse Destaw Belay, Mitiku Yohannes Fuge,
Aman Kassahun Wassie, Eyasu Shiferaw Jada,
Yonas Chanie, Walelign Tewabe Sewunetie, and
Seid Muhie Yimam. 2024. Walia-LLM: Enhancing
Amharic-LLaMA by integrating task-specific and
generative datasets. In Findings of the Association
for Computational Linguistics: EMNLP 2024, pages
432-444, Miami, Florida, USA. Association for
Computational Linguistics.

Paul Azunre, Salomey Osei, Salomey Addo,
Lawrence Asamoah Adu-Gyamfi, Stephen E.
Moore, Bernard Adabankah, Bernard Opoku,
Clara Asare-Nyarko, Samuel Nyarko, Cynthia
Amoaba, Esther Dansoa Appiah, Felix Akwerh,
Richard Nii Lante Lawson, Joel Budu, Emmanuel
Debrah, Nana Adowaa Boateng, Wisdom Ofori,
Edwin Buabeng-Munkoh, Franklin Adjei, and 8
others. 2021a. Nlp for ghanaian languages. ArXiv,
abs/2103.15475.

Paul Azunre, Salomey Osei, Salomey Afua Addo,
Lawrence Asamoah Adu-Gyamfi, Stephen E. Moore,
Bernard Adabankah, Bernard Opoku, Clara Asare-
Nyarko, Samuel Nyarko, Cynthia Amoaba, Es-
ther Dansoa Appiah, Felix Akwerh, Richard


Nii Lante Lawson, Joel Budu, Emmanuel Debrah,
Nana Adowaa Boateng, Wisdom Ofori, Edwin
Buabeng-Munkoh, Franklin Adjei, and 8 others.
2021b. English-twi parallel corpus for machine trans-
lation. ArXiv, abs/2103.15625.

Arun Babu, Changhan Wang, Andros Tjandra, Kushal
Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh,
Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei
Baevski, Alexis Conneau, and Michael Auli. 2022.
Xls-r: Self-supervised cross-lingual speech represen-
tation learning at scale. In Interspeech 2022, pages
2278-2282.

David Bamutura, Peter Ljungléf, and Peter Nebende.
2020. Towards computational resource grammars
for Runyankore and rukiga. In Proceedings of the
Twelfth Language Resources and Evaluation Confer-
ence, pages 2846-2854, Marseille, France. European
Language Resources Association.

Lucas Bandarkar, Davis Liang, Benjamin Muller, Mikel
Artetxe, Satya Narayan Shukla, Donald Husa, Naman
Goyal, Abhinandan Krishnan, Luke Zettlemoyer, and
Madian Khabsa. 2024. The belebele benchmark: a
parallel reading comprehension dataset in 122 lan-
guage variants. In Proceedings of the 62nd Annual
Meeting of the Association for Computational Lin-
guistics (Volume I: Long Papers), pages 749-775,
Bangkok, Thailand. Association for Computational
Linguistics.

Paul Bandia. 1996. Code-switching and code-mixing in
african creative writing: Some insights for translation
studies. TTR: traduction, terminologie, rédaction,
9(1):139-153.

Andrew Michael Bean, Simeon Hellsten, Harry Mayne,
Jabez Magomere, Ethan A Chi, Ryan Andrew Chi,
Scott A. Hale, and Hannah Rose Kirk. 2024. LIN-
GOLY: A benchmark of olympiad-level linguistic
reasoning puzzles in low resource and extinct lan-
guages. In The Thirty-eight Conference on Neural
Information Processing Systems Datasets and Bench-
marks Track.

Emily M. Bender. 2019. The benderrule: On naming
the languages we study and why it matters. In The
Gradient.

Abhik Bhattacharjee, Tahmid Hasan, Wasi Uddin Ah-
mad, Yuan-Fang Li, Yong-Bin Kang, and Rifat
Shahriyar. 2023. CrossSum: Beyond English-centric
cross-lingual summarization for 1,500+ language
pairs. In Proceedings of the 61st Annual Meeting of
the Association for Computational Linguistics (Vol-
ume I: Long Papers), pages 2541-2564, Toronto,
Canada. Association for Computational Linguistics.

Yuri Bizzoni, Tom S Juzek, Cristina Espafia-Bonet, Koel
Dutta Chowdhury, Josef van Genabith, and Elke Te-
ich. 2020. How human is machine translationese?
comparing human and machine translations of text
and speech. In Proceedings of the 17th International
Conference on Spoken Language Translation, pages

280-290, Online. Association for Computational Lin-
guistics.

Laurie Burchell, Alexandra Birch, Nikolay Bogoychev,
and Kenneth Heafield. 2023. An open dataset and
model for language identification. In Proceedings
of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 2: Short Papers),
pages 865-879, Toronto, Canada. Association for
Computational Linguistics.

Antoine Caubriére and Elodie Gauthier. 2024. Africa-
centric self-supervised pretraining for multilingual
speech representation in a sub-saharan context. In 5th
Workshop on African Natural Language Processing.

Emie Chang, David Ifeoluwa Adelani, Xiaoyu Shen,
and Vera Demberg. 2020. Unsupervised pidgin text
generation by pivoting english data and self-training.
ArXiv, abs/2003.08272.

Tyler A. Chang, Catherine Arnett, Zhuowen Tu, and
Benjamin Bergen. 2024. Goldfish: Monolin-
gual language models for 350 languages. ArXiv,
abs/2408.10441.

Jiaao Chen, Derek Tam, Colin Raffel, Mohit Bansal, and
Diyi Yang. 2023. An empirical survey of data aug-
mentation for limited data learning in NLP. Transac-
tions of the Association for Computational Linguis-
tics, 11:191-211.

Wei-Rui Chen, Ife Adebara, and Muhammad Abdul-
Mageed. 2024a. Interplay of machine translation, dia-
critics, and diacritization. In Proceedings of the 2024
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies (Volume 1: Long Papers),
pages 7559-7601, Mexico City, Mexico. Association
for Computational Linguistics.

Wei-Rui Chen, Ife Adebara, Khai Doan, Qisheng Liao,
and Muhammad Abdul-Mageed. 2024b. Fumbling
in babel: An investigation into ChatGPT‘s language
identification ability. In Findings of the Association
for Computational Linguistics: NAACL 2024, pages
4387-4413, Mexico City, Mexico. Association for
Computational Linguistics.

William Chen, Wangyou Zhang, Yifan Peng, Xinjian
Li, Jinchuan Tian, Jiatong Shi, Xuankai Chang,
Soumi Maiti, Karen Livescu, and Shinji Watanabe.
2024c. Towards robust speech representation learn-
ing for thousands of languages. In Proceedings of the
2024 Conference on Empirical Methods in Natural
Language Processing, pages 10205-10224, Miami,
Florida, USA. Association for Computational Lin-
guistics.

Yaqi Chen, Xukui Yang, Hao Zhang, Wenlin Zhang,
Dan Qu, and Cong Chen. 2024d. Meta adversarial
learning improves low-resource speech recognition.
Computer Speech & Language, 84:101576.


Yaqi Chen, Hao Zhang, Xukui Yang, Wenlin Zhang,
and Dan Qu. 2024e. Improving cross-lingual low-
resource speech recognition by task-based meta poly-
loss. Computer Speech & Language, 87:101648.

Everlyn Asiko Chimoto and Bruce A. Bassett. 2022.
COMET-QE and active learning for low-resource
machine translation. In Findings of the Association
for Computational Linguistics: EMNLP 2022, pages
4735-4740, Abu Dhabi, United Arab Emirates. As-
sociation for Computational Linguistics.

Everlyn Asiko Chimoto, Jay Gala, Orevaoghene Ahia,
Julia Kreutzer, Bruce A. Bassett, and Sara Hooker.
2024. Critical learning periods: Leveraging early
training dynamics for efficient data pruning. In Find-
ings of the Association for Computational Linguistics:
ACL 2024, pages 9407-9426, Bangkok, Thailand. As-
sociation for Computational Linguistics.

Yu Ying Chiu, Liwei Jiang, Bill Yuchen Lin,
Chan Young Park, Shuyue Stella Li, Sahithya Ravi,
Mehar Bhatia, Maria Antoniak, Yulia Tsvetkov,
Vered Shwartz, and Yejin Choi. 2024. Cultural-
bench: a robust, diverse and challenging benchmark
on measuring the (lack of) cultural knowledge of Ilms.
ArXiv, abs/2410.02677.

Rochelle Choenni, Dan Garrette, and Ekaterina Shutova.
2023. Cross-lingual transfer with language-specific
subnetworks for low-resource dependency parsing.
Computational Linguistics, pages 613-641.

Chiamaka Chukwuneke, Ignatius Ezeani, Paul Rayson,
and Mahmoud El]-Haj. 2022. IgboBERT models:
Building and training transformer models for the
Igbo language. In Proceedings of the Thirteenth Lan-
guage Resources and Evaluation Conference, pages
5114-5122, Marseille, France. European Language
Resources Association.

Hyung Won Chung, Thibault Févry, Henry Tsai, Melvin
Johnson, and Sebastian Ruder. 2020. Rethinking
embedding coupling in pre-trained language models.
ArXiv, abs/2010.12821.

Jonathan H. Clark, Eunsol Choi, Michael Collins, Dan
Garrette, Tom Kwiatkowski, Vitaly Nikolaev, and
Jennimaria Palomaki. 2020. TyDi QA: A benchmark
for information-seeking question answering in typo-
logically diverse languages. Transactions of the As-
sociation for Computational Linguistics, 8:454—470.

Alexis Conneau, Alexei Baevski, Ronan Collobert, Ab-
del rahman Mohamed, and Michael Auli. 2020a. Un-
supervised cross-lingual representation learning for
speech recognition. ArXiv, abs/2006.13979.

Alexis Conneau, Kartikay Khandelwal, Naman Goyal,
Vishrav Chaudhary, Guillaume Wenzek, Francisco
Guzman, Edouard Grave, Myle Ott, Luke Zettle-
moyer, and Veselin Stoyanov. 2020b. Unsupervised
cross-lingual representation learning at scale. In Pro-
ceedings of the 58th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 8440-
8451, Online. Association for Computational Lin-
guistics.

Alexis Conneau and Guillaume Lample. 2019. Cross-
lingual language model pretraining. In Proceedings
of the 33rd International Conference on Neural In-
formation Processing Systems.

Alexis Conneau, Min Ma, Simran Khanuja, Yu Zhang,
Vera Axelrod, Siddharth Dalmia, Jason Riesa, Clara
Rivera, and Ankur Bapna. 2022. Fleurs: Few-shot
learning evaluation of universal representations of
speech. 2022 IEEE Spoken Language Technology
Workshop (SLT), pages 798-805.

Levi Corallo and Aparna S. Varde. 2023. Optical char-
acter recognition and transcription of berber signs
from images in a low-resource language amazigh.
ArXiv, abs/2303.13549.

Marta Costa-jussa, Christine Basta, Oriol Domingo, and
André Rubungo. 2022. Occgen: Selection of real-
world multilingual parallel data balanced in gender
within occupations. In Advances in Neural Infor-
mation Processing Systems, volume 35, pages 1445—
1457. Curran Associates, Inc.

Marta R. Costa-jussa, Joy Chen, Ife Adebara, Joe
Chuang, Christophe Ropers, and Eduardo Sanchez.
2025. Y-NQ: English- Yoruba evaluation dataset for
open-book reading comprehension with open-ended
questions. In Proceedings of the Sixth Workshop on
African Natural Language Processing (AfricaNLP
2025), pages 248-254, Vienna, Austria. Association
for Computational Linguistics.

Marta Ruiz Costa-jussa, Christine Basta, Oriol
Domingo, and Andre Niyongabo Rubungo. 2022.
Occgen: Selection of real-world multilingual par-
allel data balanced in gender within occupations. In
Neural Information Processing Systems.

Ona de Gibert, Graeme Nail, Nikolay Arefyev, Marta
Bafién, Jelmer van der Linde, Shaoxiong Ji, Jaume
Zaragoza-Bermabeu, Mikko Aulamo, Gema Ramirez-
Sanchez, Andrey Kutuzov, Sampo Pyysalo, Stephan
Oepen, and Jorg Tiedemann. 2024. A new massive
multilingual dataset for high-performance language
technologies. In Proceedings of the 2024 Joint In-
ternational Conference on Computational Linguis-
tics, Language Resources and Evaluation (LREC-
COLING 2024), pages 1116-1128, Torino, Italia.
ELRA and ICCL.

Mountaga Diallo, Chayma Fourati, and Hatem Had-
dad. 2021. Bambara language dataset for sentiment
analysis. In Practical ML for Developing Countries
Workshop. ICLR 2021, Virtual Event.

Cheikh M. Bamba Dione. 2020. Implementation and
evaluation of an LFG-based parser for Wolof. In
Proceedings of the Twelfth Language Resources and
Evaluation Conference, pages 5128-5136, Marseille,
France. European Language Resources Association.

Cheikh M. Bamba Dione. 2021. Multilingual depen-
dency parsing for low-resource African languages:
Case studies on Bambara, Wolof, and Yoruba. In
Proceedings of the 17th International Conference


on Parsing Technologies and the IWPT 2021 Shared
Task on Parsing into Enhanced Universal Dependen-
cies (IWPT 2021), pages 84-92, Online. Association
for Computational Linguistics.

Cheikh M. Bamba Dione, David Ifeoluwa Adelani,
Peter Nabende, Jesujoba Alabi, Thapelo Sindane,
Happy Buzaaba, Shamsuddeen Hassan Muhammad,
Chris Chinenye Emezue, Perez Ogayo, Anuoluwapo
Aremu, Catherine Gitau, Derguene Mbaye, Jonathan
Mukiibi, Blessing Sibanda, Bonaventure F. P. Dossou,
Andiswa Bukula, Rooweither Mabuya, Allahsera Au-
guste Tapo, Edwin Munkoh-Buabeng, and 25 others.
2023. MasakhaPOS: Part-of-speech tagging for typo-
logically diverse African languages. In Proceedings
of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers),
pages 10883-10900, Toronto, Canada. Association
for Computational Linguistics.

Konstantin Dobler and Gerard de Melo. 2023. FOCUS:
Effective embedding initialization for monolingual
specialization of multilingual models. In Proceed-
ings of the 2023 Conference on Empirical Methods in
Natural Language Processing, pages 13440-13454,
Singapore. Association for Computational Linguis-
tics.

Bonaventure F. P. Dossou and Chris C. Emezue. 2021.
Okwugbé: End-to-end speech recognition for fon and
igbo. ArXiv, abs/2103.07762.

Bonaventure F. P. Dossou, Iffanice B. Houndayi, Pamely
Zantou, and Gilles Hacheme. 2023. Fonmtl: To-
wards multitask learning for the fon language. ArXiv,
abs/2308.14280.

Bonaventure F. P. Dossou, Atnafu Lambebo Tonja,
Oreen Yousuf, Salomey Osei, Abigail Oppong,
Tyanuoluwa Shode, Oluwabusayo Olufunke Awoy-
omi, and Chris Emezue. 2022. AfroLM: A self-
active learning-based multilingual pretrained lan-
guage model for 23 African languages. In Proceed-
ings of The Third Workshop on Simple and Efficient
Natural Language Processing (SustaiNLP), pages
52-64, Abu Dhabi, United Arab Emirates (Hybrid).
Association for Computational Linguistics.

Moussa Doumbouya, Lisa Einstein, and Chris Piech.
2021. Using radio archives for low-resource speech
recognition: Towards an intelligent virtual assistant
for illiterate users. In Proceedings of the AAAI Con-
ference on Artificial Intelligence, volume 35.

Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,
Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,
Akhil Mathur, Alan Schelten, Amy Yang, Angela
Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang,
Archi Mitra, Archie Sravankumar, Artem Korenev,
Arthur Hinsvark, Arun Rao, Aston Zhang, and 514
others. 2024. The Llama 3 Herd of Models. Preprint,
arXiv:2407.21783.

Jacob Eisenstein, Vinodkumar Prabhakaran, Clara
Rivera, Dorottya Demszky, and Devyani Sharma.

16

2023. Md3: The multi-dialect dataset of dialogues.
In Interspeech.

Ahmed El-Kishky, Vishrav Chaudhary, Francisco
Guzman, and Philipp Koehn. 2020. CCAligned: A
massive collection of cross-lingual web-document
pairs. In Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 5960-5969, Online. Association for
Computational Linguistics.

Ahmed Elhagry and Rawan Gla. 2021. Egyptian sign
language recognition using cnn and Istm. ArXiv,
abs/2107.13647.

AbdelRahim Elmadany, Ife Adebara, and Muhammad
Abdul-Mageed. 2024. Toucan: Many-to-many trans-
lation for 150 African language pairs. In Findings of
the Association for Computational Linguistics: ACL
2024, pages 13189-13206, Bangkok, Thailand. As-
sociation for Computational Linguistics.

Chris C. Emezue and Bonaventure F. P. Dossou. 2020a.
Lanfrica: A participatory approach to documenting
machine translation research on african languages.
ArXiv, abs/2008.07302.

Chris Chinenye Emezue and Femi Pancrace Bonaven-
ture Dossou. 2020b. FFR v1.1: Fon-French neural
machine translation. In Proceedings of the Fourth
Widening Natural Language Processing Workshop,
pages 83-87, Seattle, USA. Association for Compu-
tational Linguistics.

Chris Chinenye Emezue, Ifeoma Okoh, Chinedu Em-
manuel Mbonu, Chiamaka Chukwuneke,
Daisy Monika Lal, Ignatius Ezeani, Paul Rayson,
jemma Onwuzulike, Chukwuma Onyebuchi Okeke,
Gerald Okey Nweya, Bright Ikechukwu Ogbonna,
Chukwuebuka Uchenna Oraegbunam, Esther Chid-
inma Awo-Ndubuisi, and Akudo Amarachukwu
Osuagwu. 2024. The IgboAPI dataset: Empowering
Igbo language technologies through multi-dialectal
enrichment. In Proceedings of the 2024 Joint
International Conference on Computational Lin-
guistics, Language Resources and Evaluation
(LREC-COLING 2024), pages 15932-15941, Torino,
Italia. ELRA and ICCL.

Fahim Faisal, Orevaoghene Ahia, Aarohi Srivastava,
Kabir Ahuja, David Chiang, Yulia Tsvetkov, and An-
tonios Anastasopoulos. 2024. DIALECTBENCH:
An NLP benchmark for dialects, varieties, and
closely-related languages. In Proceedings of the
62nd Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
14412-14454, Bangkok, Thailand. Association for
Computational Linguistics.

Fahim Faisal, Sharlina Keshava, Md Mahfuz Ibn Alam,
and Antonios Anastasopoulos. 2021. SD-QA: Spo-
ken dialectal question answering for the real world.
In Findings of the Association for Computational
Linguistics: EMNLP 2021, pages 3296-3315, Punta
Cana, Dominican Republic. Association for Compu-
tational Linguistics.


Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi
Ma, Ahmed El-Kishky, Siddharth Goyal, Man-
deep Baines, Onur Celebi, Guillaume Wenzek,
Vishrav Chaudhary, Naman Goyal, Tom Birch, Vi-
taliy Liptchinsky, Sergey Edunov, Edouard Grave,
Michael Auli, and Armand Joulin. 2020. Beyond
english-centric multilingual machine translation. J.
Mach. Learn. Res., 22:107:1—107:48.

Christian Federmann, Tom Kocmi, and Ying Xin. 2022.
NTREX-128 — news test references for MT evalua-
tion of 128 languages. In Proceedings of the First
Workshop on Scaling Up Multilingual Evaluation,
pages 21-24, Online. Association for Computational
Linguistics.

Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Ari-
vazhagan, and Wei Wang. 2022. Language-agnostic
BERT sentence embedding. In Proceedings of the
60th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
878-891, Dublin, Ireland. Association for Computa-
tional Linguistics.

Jack FitzGerald, Christopher Hench, Charith Peris,
Scott Mackie, Kay Rottmann, Ana Sanchez, Aaron
Nash, Liam Urbach, Vishesh Kakarala, Richa Singh,
Swetha Ranganath, Laurie Crist, Misha Britan,
Wouter Leeuwis, Gokhan Tur, and Prem Natara-
jan. 2023. MASSIVE: A IM-example multilin-
gual natural language understanding dataset with
51 typologically-diverse languages. In Proceedings
of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers),
pages 4277-4302, Toronto, Canada. Association for
Computational Linguistics.

Fitsum Gaim, Wonsuk Yang, and Jong C. Park. 2021.
Tlmd: Tigrinya language modeling dataset.

Iker Garcia-Ferrero, Rodrigo Agerri, and German Rigau.
2023. T-projection: High quality annotation projec-
tion for sequence labeling tasks. In Findings of the
Association for Computational Linguistics: EMNLP
2023, pages 15203-15217, Singapore. Association
for Computational Linguistics.

Tanja Gaustad, Ansu Berg, Rigardt Pretorius, and Roald
Eiselen. 2024. The first Universal Dependency tree-
bank for Tswana: Tswana-popapolelo. In Pro-
ceedings of the Fifth Workshop on Resources for
African Indigenous Languages @ LREC-COLING
2024, pages 55-65, Torino, Italia. ELRA and ICCL.

Tanja Gaustad and Roald Eiselen. 2023. Exploring
afrikaans word embeddings with analogies and near-
est neighbours. Journal of the Digital Humanities
Association of Southern Africa (DHASA).

Elodie Gauthier, Aminata Ndiaye, and Abdoulaye
Guissé. 2024. Kallaama: A transcribed speech
dataset about agriculture in the three most widely
spoken languages in Senegal. In Proceedings of the
Fifth Workshop on Resources for African Indigenous
Languages @ LREC-COLING 2024, pages 10-19,
Torino, Italia. ELRA and ICCL.

Sebastian Gehrmann, Sebastian Ruder, Vitaly Nikolaev,
Jan Botha, Michael Chavinda, Ankur Parikh, and
Clara Rivera. 2023. TaTA: A multilingual table-to-
text dataset for African languages. In Findings of the
Association for Computational Linguistics: EMNLP
2023, pages 1719-1740, Singapore. Association for
Computational Linguistics.

Gemma Team, Morgane Riviere, Shreya Pathak,
Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupati-
raju, Léonard Hussenot, Thomas Mesnard, Bobak
Shahriari, Alexandre Ramé, Johan Ferret, Peter Liu,
Pouya Tafti, Abe Friesen, Michelle Casbon, Sabela
Ramos, Ravin Kumar, Charline Le Lan, Sammy
Jerome, and 178 others. 2024. Gemma 2: Improving
open language models at a practical size. Preprint,
arXiv:2408.00118.

Andargachew Mekonnen Gezmu, Tirufat Tesifaye
Lema, Binyam Ephrem Seyoum, and A. Niirnberger.
2021a. Manually annotated spelling error corpus for
amharic. In AfricaNLP.

Andargachew Mekonnen Gezmu, Binyam Ephrem
Seyoum, Michael Gasser, and A. Niirnberger.
2021b. Contemporary amharic corpus: Automati-
cally morpho-syntactically tagged amharic corpus.
ArXiv, abs/2106.07241.

Naman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-
Jen Chen, Guillaume Wenzek, Da Ju, Sanjana Kr-
ishnan, Marc’ Aurelio Ranzato, Francisco Guzman,
and Angela Fan. 2022. The Flores-101 evaluation
benchmark for low-resource and multilingual ma-
chine translation. Transactions of the Association for
Computational Linguistics, 10:522-538.

Marissa Griesel and Sonja E. Bosch. 2020. Navigating
challenges of multilingual resource development for
under-resourced languages: The case of the african
wordnet project. In RAIL.

Richard Griscom. 2020. Mobilizing metadata: Open
data kit (odk) for language resource development in
east africa. In RAIL.

Dagmar Gromann, Hugo Goncalo Oliveira, Lu-
cia Pitarch, Elena-Simona Apostol, Jordi Bernad,
Eliot Bytyci, Chiara Cantone, Sara Carvalho,
Francesca Frontini, Radovan Garabik, Jorge Gra-
cia, Letizia Granata, Fahad Khan, Timotej Knez,
Penny Labropoulou, Chaya Liebeskind, Maria Pia
Di Buono, Ana Ostroski Ani¢é, Sigita Rackevi¢iené,
and 12 others. 2024. MultiLexBATS: Multilingual
dataset of lexical semantic relations. In Proceedings
of the 2024 Joint International Conference on Compu-
tational Linguistics, Language Resources and Evalu-
ation (LREC-COLING 2024), pages 11783-11793,
Torino, Italia. ELRA and ICCL.

Aditi Sharma Grover, Karen Calteaux, Gerhard van
Huyssteen, and Marthinus Pretorius. 2010. An
overview of hits for south african bantu languages.
In Proceedings of the 2010 Annual Research Con-
ference of the South African Institute of Computer


Scientists and Information Technologists, SAICSIT
°10, page 370-375, New York, NY, USA. Association
for Computing Machinery.

Shester Gueuwou, Sophie Siake, Colin Leong, and
Mathias Miiller. 2023a. JWSign: A highly multi-
lingual corpus of Bible translations for more diver-
sity in sign language processing. In Findings of the
Association for Computational Linguistics: EMNLP
2023, pages 9907-9927, Singapore. Association for
Computational Linguistics.

Shester Gueuwou, Kate Takyi, Mathias Miller,
Marco Nyarko, Richard Adade, and Rose-Mary
Owusuaa Mensah Gyening. 2023b. Afrisign: Ma-
chine translation for african sign languages. In
AfricaNLP.

Elisa Gugliotta and Marco Dinarelli. 2020. TArC:
Incrementally and semi-automatically collecting a
Tunisian Arabish corpus. In Proceedings of the
Twelfth Language Resources and Evaluation Confer-
ence, pages 6279-6286, Marseille, France. European
Language Resources Association.

Barry Haddow, Rachel Bawden, Antonio Valerio
Miceli Barone, Jindfich Helcl, and Alexandra Birch.
2022. Survey of low-resource machine translation.
Computational Linguistics, 48(3):673-732.

Asmelash Teka Hadgu, Abel Aregawi, and Adam Beau-
doin. 2021. Lesan - machine translation for low re-
source languages. ArXiv, abs/2112.08191.

Tjerk Hagemeijer, Amalia Mendes, Rita Gongalves,
Catarina Cornejo, Raquel Madureira, and Michel
Généreux. 2022a. The PALMA corpora of African
varieties of Portuguese. In Proceedings of the Thir-
teenth Language Resources and Evaluation Confer-
ence, pages 5047-5053, Marseille, France. European
Language Resources Association.

Tjerk Hagemeijer, Amalia Mendes, Rita Gongalves,
Catarina Cornejo, Raquel Madureira, and Michel
Généreux. 2022b. The palma corpora of african vari-
eties of portuguese. In International Conference on
Language Resources and Evaluation.

Goitom Ybrah Hailu and Shishay Welay. 2024. Deep
learning based amharic chatbot for faqs in universi-
ties. ArXiv, abs/2402.01720.

Injy Hamed, Fadhl Eryani, David Palfreyman, and Nizar
Habash. 2024. ZAEBUC-spoken: A multilingual
multidialectal Arabic-English speech corpus. In Pro-
ceedings of the 2024 Joint International Conference
on Computational Linguistics, Language Resources
and Evaluation (LREC-COLING 2024), pages 17770-
17782, Torino, Italia. ELRA and ICCL.

Injy Hamed, Nizar Habash, and Thang Vu. 2023. Data
augmentation techniques for machine translation of
code-switched texts: A comparative study. In Find-
ings of the Association for Computational Linguistics:
EMNLP 2023, pages 140-154, Singapore. Associa-
tion for Computational Linguistics.

18

H Hammarstrém, R Forkel, and M Haspelmath. 2024.
Bank, s. glottolog/glottolog: Glottolog database 5.1.
Zenodo https://doi. org/10.5281/zenodo, 10804357.

Tahmid Hasan, Abhik Bhattacharjee, Md. Saiful Is-
lam, Kazi Mubasshir, Yuan-Fang Li, Yong-Bin Kang,
M. Sohel Rahman, and Rifat Shahriyar. 2021. XL-
sum: Large-scale multilingual abstractive summariza-
tion for 44 languages. In Findings of the Association
for Computational Linguistics: ACL-IJCNLP 2021,
pages 4693-4703, Online. Association for Computa-
tional Linguistics.

Ali Hatami, Shubhanker Banerjee, Mihael Arcan, Paul
Buitelaar, and John Philip McCrae. 2024. English-to-
low-resource translation: A multimodal approach for
Hindi, Malayalam, Bengali, and Hausa. In Proceed-
ings of the Ninth Conference on Machine Translation,
pages 815-822, Miami, Florida, USA. Association
for Computational Linguistics.

Pengcheng He, Jianfeng Gao, and Weizhu Chen. 2021.
Debertav3: Improving deberta using electra-style pre-
training with gradient-disentangled embedding shar-
ing. ArXiv, abs/2111.09543.

Michael A. Hedderich, David I. Adelani, Dawei Zhu,
Jesujoba Alabi, Udia Markus, and Dietrich Klakow.
2020. Transfer learning and distant supervision for
multilingual transformer models: A study on African
languages. In Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 2580-2591, Online. Association for
Computational Linguistics.

Michael A. Hedderich, Lukas Lange, Heike Adel, Jan-
nik Strdtgen, and Dietrich Klakow. 2021. A survey
on recent approaches for natural language process-
ing in low-resource scenarios. In Proceedings of
the 2021 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, pages 2545-2568,
Online. Association for Computational Linguistics.

Kevin Heffernan, Onur Celebi, and Holger Schwenk.
2022. Bitext mining using distilled sentence repre-
sentations for low-resource languages. In Findings
of the Association for Computational Linguistics:
EMNLP 2022, pages 2101-2112, Abu Dhabi, United
Arab Emirates. Association for Computational Lin-
guistics.

Lars Hellan. 2020. A computational grammar of ga. In
RAIL.

Santiago Herrera, Caio Corro, and Sylvain Kahane.
2024. Sparse logistic regression with high-order fea-
tures for automatic grammar rule extraction from tree-
banks. In Proceedings of the 2024 Joint International
Conference on Computational Linguistics, Language
Resources and Evaluation (LREC-COLING 2024),
pages 15114-15125, Torino, Italia. ELRA and ICCL.

Junjie Hu, Sebastian Ruder, Aditya Siddhant, Gra-
ham Neubig, Orhan Firat, and Melvin Johnson.
2020. Xtreme: A massively multilingual multi-task


benchmark for evaluating cross-lingual generaliza-
tion. ArXiv, abs/2003.11080.

Catherine Ikae and Mascha Kurpicz-Briki. 2024. Cur-
rent state-of-the-art of bias detection and mitigation
in machine translation for african and european lan-
guages: a review. ArXiv, abs/2410.21126.

Comfort Ilevbare, Jesujoba Alabi, David Ifeoluwa
Adelani, Firdous Bakare, Oluwatoyin Abiola, and
Oluwaseyi Adeyemo. 2024. EkoHate: Abusive lan-
guage and hate speech detection for code-switched
political discussions on Nigerian Twitter. In Proceed-
ings of the 8th Workshop on Online Abuse and Harms
(WOAH 2024), pages 28-37, Mexico City, Mexico.
Association for Computational Linguistics.

Ayyoob Imani, Peiqin Lin, Amir Hossein Kargaran,
Silvia Severini, Masoud Jalili Sabet, Nora Kass-
ner, Chunlan Ma, Helmut Schmid, André Martins,
Francois Yvon, and Hinrich Schiitze. 2023. Glot500:
Scaling multilingual corpora and language models to
500 languages. In Proceedings of the 61st Annual
Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers), pages 1082-1117,
Toronto, Canada. Association for Computational Lin-
guistics.

Isa Inuwa-Dutse. 2025. Naijanlp:
of nigerian low-resource languages.
arXiv:2502.19784.

A survey
Preprint,

Olajidé Ishola and Daniel Zeman. 2020. Yortiba de-
pendency treebank (YTB). In Proceedings of the
Twelfth Language Resources and Evaluation Confer-
ence, pages 5178-5186, Marseille, France. European
Language Resources Association.

Amel Issa. 2023. Durational and non-durational corre-
lates of lexical and derived geminates in arabic. In
Interspeech 2023, pages 4753-4757.

Sheriff M Issaka, Zhaoyi Zhang, Mihir Heda, Keyi
Wang, Yinka Ajibola, Ryan DeMar, and Xuefeng
Du. 2024. The ghanaian nlp landscape: A first look.
ArXiv, abs/2405.068 18.

Christiaan Jacobs. 2024. Multilingual acoustic word
embeddings for zero-resource languages. ArXiv,
abs/2401.10543.

Chris Jenkins, Shantanu Agarwal, Joel Barry, Steven
Fincke, and Elizabeth Boschee. 2023. Massively
multi-lingual event understanding: Extraction, visu-
alization, and search. In Proceedings of the 61st
Annual Meeting of the Association for Computa-
tional Linguistics (Volume 3: System Demonstra-
tions), pages 247-256, Toronto, Canada. Association
for Computational Linguistics.

Shaoxiong Ji, Zihao Li, Indraneil Paul, Jaakko Paavola,
Peiqin Lin, Pinzhen Chen, Dayy’an O’ Brien, Hengyu
Luo, Hinrich Schtitze, Jorg Tiedemann, and Barry
Haddow. 2024. Emma-500: Enhancing massively
multilingual adaptation of large language models.
ArXiv, abs/2409.17892.

19

Toheeb A. Jimoh, Tabea De Wille, and Nikola S.
Nikolov. 2025. Bridging gaps in natural lan-
guage processing for yoruba: a systematic review
of a decade of progress and prospects. Preprint,
arXiv:2502.17364.

Pratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika
Bali, and Monojit Choudhury. 2020. The state and
fate of linguistic diversity and inclusion in the NLP
world. In Proceedings of the 58th Annual Meeting of
the Association for Computational Linguistics, pages
6282-6293, Online. Association for Computational
Linguistics.

Odunayo Jude Ogundepo, Akintunde Oladipo, Mofe-
toluwa Adeyemi, Kelechi Ogueji, and Jimmy Lin.
2022. AfriTeVA: Extending ?small data? pretrain-
ing approaches to sequence-to-sequence models. In
Proceedings of the Third Workshop on Deep Learn-
ing for Low-Resource Natural Language Processing,
pages 126-135, Hybrid. Association for Computa-
tional Linguistics.

Amir Hossein Kargaran, Ayyoob Imani, Francois Yvon,
and Hinrich Schuetze. 2023. GlotLID: Language
identification for low-resource languages. In Find-
ings of the Association for Computational Linguis-
tics: EMNLP 2023, pages 6155-6218, Singapore.
Association for Computational Linguistics.

Amir Hossein Kargaran, Franccois Yvon, and Hinrich
Schutze. 2024a. Glotcc: An open broad-coverage
commoncrawl corpus and pipeline for minority lan-
guages. ArXiv, abs/2410.23825.

Amir Hossein Kargaran, Francois Yvon, and Hinrich
Schiitze. 2024b. GlotScript: A resource and tool for
low resource writing system identification. In Pro-
ceedings of the 2024 Joint International Conference
on Computational Linguistics, Language Resources
and Evaluation (LREC-COLING 2024), pages 7774—
7784, Torino, Italia. ELRA and ICCL.

Catharina Maria Keet. 2022. Bootstrapping nlp tools
across low-resourced african languages: an overview
and prospects. ArXiv, abs/2210.12027.

Mamadou K. Keita, Christopher Homan, Sofiane
Hamani, Adwoa Bremang, Marcos Zampieri, Habiba-
tou Abdoulaye Alfari, Elysabhete Amadou Ibrahim,
and Dennis Owusu. 2024. Grammatical error correc-
tion for low-resource languages: The case of zarma.
ArXiv, abs/2410.15539.

Lennart Keller and Goran Glavas. 2024. Speechtaxi: On
multilingual semantic speech classification. ArXiv,
abs/2409.06372.

Aditi Khandelwal, Utkarsh Agarwal, Kumar Tanmay,
and Monojit Choudhury. 2024. Do moral judgment
and reasoning capability of LLMs change with lan-
guage? a study using the multilingual defining issues
test. In Proceedings of the 18th Conference of the
European Chapter of the Association for Computa-
tional Linguistics (Volume I: Long Papers), pages
2882-2894, St. Julian’s, Malta. Association for Com-
putational Linguistics.


Nataliia Kholodna, Sahib Julka, Mohammad Khodadadi,
Muhammed Nurullah Gumus, and Michael Granitzer.
2024. Llms in the loop: Leveraging large language
model annotations for active learning in low-resource
languages. ArXiv, abs/2404.02261.

Ussen Kimanuka, Ciira wa Maina, and Osman Bityiik.
2024. Speech recognition datasets for low-resource
congolese languages. Data in Brief, 52:109796.

Steven Kolawole, Opeyemi Osakuade, Nayan Saxena,
and Babatunde Kazeem Olorisade. 2022. Sign-to-
speech model for sign language understanding: A
case study of nigerian sign language. In Proceedings
of the Thirty-First International Joint Conference on
Artificial Intelligence, IJCAI-22, pages 5924-5927.
International Joint Conferences on Artificial Intelli-
gence Organization. Demo Track.

Moshe Koppel and Noam Ordan. 2011. Translationese
and its dialects. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, pages
1318-1326, Portland, Oregon, USA. Association for
Computational Linguistics.

Julia Kreutzer, Isaac Caswell, Lisa Wang, Ahsan Wahab,
Daan van Esch, Nasanbayar Ulzii-Orshikh, Allah-
sera Tapo, Nishant Subramani, Artem Sokolov, Clay-
tone Sikasote, Monang Setyawan, Supheakmungkol
Sarin, Sokhar Samb, Benoit Sagot, Clara Rivera,
Annette Rios, Isabel Papadimitriou, Salomey Osei,
Pedro Ortiz Suarez, and 33 others. 2022. Quality
at a glance: An audit of web-crawled multilingual
datasets. Transactions of the Association for Compu-
tational Linguistics, 10:50-72.

Sneha Kudugunta, Isaac Caswell, Biao Zhang, Xavier
Garcia, Christopher A. Choquette-Choo, Katherine
Lee, Derrick Xin, Aditya Kusupati, Romi Stella,
Ankur Bapna, and Orhan Firat. 2023. Madlad-400:
A multilingual and document-level large audited
dataset. ArXiv, abs/2309.04662.

Heather Lent, Kushal Tatariya, Raj Dabre, Yiyi Chen,
Marcell Fekete, Esther Ploeger, Li Zhou, Ruth-
Ann Armstrong, Abee Eijansantos, Catriona Malau,
Hans Erik Heje, Ernests Lavrinovics, Diptesh Kano-
jia, Paul Belony, Marcel Bollmann, Loic Grobol,
Miryam de Lhoneux, Daniel Hershcovich, Michel
DeGraff, and 2 others. 2024. CreoleVal: Multilin-
gual multitask benchmarks for creoles. Transactions
of the Association for Computational Linguistics,
12:950-978.

Colin Leong, Joshua Nemecek, Jacob Mansdorfer, Anna
Filighera, Abraham Owodunni, and Daniel White-
nack. 2022. Bloom library: Multimodal datasets in
300+ languages for a variety of downstream tasks.
In Proceedings of the 2022 Conference on Empiri-
cal Methods in Natural Language Processing, pages
8608-8621, Abu Dhabi, United Arab Emirates. As-
sociation for Computational Linguistics.

Xinjian Li, Florian Metze, David R. Mortensen, Alan W
Black, and Shinji Watanabe. 2022. Asr2k: Speech

20

recognition for around 2000 languages without audio.
In Interspeech 2022, pages 4885-4889.

Xinjian Li, Shinnosuke Takamichi, Takaaki Saeki,
William Chen, Sayaka Shiota, and Shinji Watanabe.
2023. Yodas: Youtube-oriented dataset for audio and
speech. 2023 IEEE Automatic Speech Recognition
and Understanding Workshop (ASRU), pages 1-8.

Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu
Wang, Shuohui Chen, Daniel Simig, Myle Ott, Na-
man Goyal, Shruti Bhosale, Jingfei Du, Ramakanth
Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav
Chaudhary, Brian O’ Horo, Jeff Wang, Luke Zettle-
moyer, Zornitsa Kozareva, Mona Diab, and 2 others.
2022. Few-shot learning with multilingual generative
language models. In Proceedings of the 2022 Con-
ference on Empirical Methods in Natural Language
Processing, pages 9019-9052, Abu Dhabi, United
Arab Emirates. Association for Computational Lin-
guistics.

Yu-Hsiang Lin, Chian-Yu Chen, Jean Lee, Zirui Li,
Yuyan Zhang, Mengzhou Xia, Shruti Rijhwani, Junx-
ian He, Zhisong Zhang, Xuezhe Ma, Antonios Anas-
tasopoulos, Patrick Littell, and Graham Neubig. 2019.
Choosing transfer languages for cross-lingual learn-
ing. In Proceedings of the 57th Annual Meeting of
the Association for Computational Linguistics, pages
3125-3135, Florence, Italy. Association for Compu-
tational Linguistics.

Yihong Liu, Peiqin Lin, Mingyang Wang, and Hinrich
Schuetze. 2024. OFA: A framework of initializing
unseen subword embeddings for efficient large-scale
multilingual continued pretraining. In Findings of the
Association for Computational Linguistics: NAACL
2024, pages 1067-1097, Mexico City, Mexico. Asso-
ciation for Computational Linguistics.

Yihong Liu, Haotian Ye, Leonie Weissweiler, Renhao
Pei, and Hinrich Schuetze. 2023. Crosslingual trans-
fer learning for low-resource languages based on mul-
tilingual colexification graphs. In Findings of the
Association for Computational Linguistics: EMNLP
2023, pages 8376-8401, Singapore. Association for
Computational Linguistics.

Yinquan Lu, Wenhao Zhu, Lei Li, Yu Qiao, and Fei
Yuan. 2024. LLaMAX: Scaling linguistic horizons
of LLM by enhancing translation capabilities beyond
100 languages. In Findings of the Association for
Computational Linguistics: EMNLP 2024, pages
10748-10772, Miami, Florida, USA. Association for
Computational Linguistics.

Florian Lux, Sarina Meyer, Lyonel Behringer, Frank
Zalkow, Phat Do, Matt Coler, Emanuél A. P. Habets,
and Ngoc Thang Vu. 2024. Meta Learning Text-
to-Speech Synthesis in over 7000 Languages. In
Interspeech 2024, pages 4958-4962.

Chunlan Ma, Ayyoob ImaniGooghari, Haotian Ye,
Ehsaneddin Asgari, and Hinrich Schiitze. 2023.
Taxil500: A multilingual dataset for text classifica-
tion in 1500 languages. Preprint, arXiv:2305.08487.


Min Ma, Yuma Koizumi, Shigeki Karita, Heiga Zen, Ja-
son Riesa, Haruko Ishikawa, and Michiel Bacchiani.
2024. Fleurs-r: A restored multilingual speech cor-
pus for generation tasks. In Interspeech 2024, pages
1835-1839.

Ronny Mabokela, Mpho Roborife, and Turguy Celik.
2023. Investigating sentiment-bearing words- and
emoji-based distant supervision approaches for sen-
timent analysis. In Proceedings of the Fourth work-
shop on Resources for African Indigenous Languages
(RAIL 2023), pages 115-125, Dubrovnik, Croatia.
Association for Computational Linguistics.

Aymen Ben Elhaj Mabrouk, Moez Ben Haj Hmida,
Chayma Fourati, Hatem Haddad, and Abir Mes-
saoudi. 2021. A multilingual african embedding for
faq chatbots. ArXiv, abs/2103.09185.

Jabez Magomere, Shu Ishida, Tejumade Afonja, Aya
Salama, Daniel Kochin, Yuehgoh Foutse, Imane
Hamzaoui, Raesetje Sefala, Aisha Alaagib, Samantha
Dalal, Beatrice Marchegiani, Elizaveta Semenova,
Lauren Crais, and Siobhan Mackenzie Hall. 2025.
The world wide recipe: A community-centred frame-
work for fine-grained data collection and regional
bias operationalisation. In Proceedings of the 2025
ACM Conference on Fairness, Accountability, and
Transparency, FAccT ’25, page 246-282, New York,
NY, USA. Association for Computing Machinery.

Lucas Maison and Y. Estéve. 2023. Improving ac-
cented speech recognition with multi-domain train-
ing. ICASSP 2023 - 2023 IEEE International Con-
ference on Acoustics, Speech and Signal Processing
(ICASSP), pages 1-5.

Vukosi Marivate, Moseli Mots’ oehli, Valencia Wagner,
Richard Lastrucci, and Isheanesu Dzingirai. 2023.
Puoberta: Training and evaluation of a curated lan-
guage model for setswana. ArXiv, abs/2310.09141.

Vukosi Marivate, T. Sefara, Vongani Chabalala, Keamo-
getswe Makhaya, Tumisho Billson Mokgonyane,
Rethabile Mokoena, and Abiodun Modupe. 2020.
Investigating an approach for low resource lan-
guage dataset creation, curation and classification:
Setswana and sepedi. In RAIL.

Gati Martin, Medard Edmund Mswahili, Young-Seob
Jeong, and Jiyoung Woo. 2022. SwahBERT: Lan-
guage model of Swahili. In Proceedings of the
2022 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 303-313, Seattle,
United States. Association for Computational Lin-
guistics.

Pierrette Mahoro Mastel, Ester Namara, Aime
Munezero, Richard Kagame, Zihan Wang, Allan An-
zagira, Akshat Gupta, and Jema David Ndibwile.
2023. Natural language understanding for african
languages. In AfricaNLP.

Kaushal Maurya and Maunendra Desarkar. 2022. Meta-
Xwic: A meta-learning approach based on language

21

clustering for zero-shot cross-lingual transfer and
generation. In Findings of the Association for Com-
putational Linguistics: ACL 2022, pages 269-284,
Dublin, Ireland. Association for Computational Lin-
guistics.

Rendani Mbuvha, David Ifeoluwa Adelani, Tendani
Mutavhatsindi, Tshimangadzo Rakhuhu, Aluwani
Mauda, Tshifhiwa Joshua Maumela, Andisani
Masindi, Seani Rananga, Vukosi Marivate, and
T. Marwala. 2023. Mphayaner: Named entity recog-
nition for tshivenda. ArXiv, abs/2304.03952.

Amanuel Mersha and Stephen Wu. 2020. Morphology-
rich alphasyllabary embeddings. In Proceedings of
the Twelfth Language Resources and Evaluation Con-
ference, pages 2590-2595, Marseille, France. Euro-
pean Language Resources Association.

Francois Meyer and Jan Buys. 2022. Subword segmen-
tal language modelling for nguni languages. In Find-
ings of the Association for Computational Linguistics:
EMNLP 2022, pages 6636-6649, Abu Dhabi, United
Arab Emirates. Association for Computational Lin-
guistics.

Francois Meyer, Haiyue Song, Abhisek Chakrabarty,
Jan Buys, Raj Dabre, and Hideki Tanaka. 2024.
NGLUEni: Benchmarking and adapting pretrained
language models for nguni languages. In Proceed-
ings of the 2024 Joint International Conference on
Computational Linguistics, Language Resources and
Evaluation (LREC-COLING 2024), pages 12247-
12258, Torino, Italia. ELRA and ICCL.

Josh Meyer, David Adelani, Edresson Casanova, Alp
Oktem, Daniel Whitenack, Julian Weber, Salomon
KABONGO KABENAMUALJU, Elizabeth Salesky,
Iroro Orife, Colin Leong, Perez Ogayo, Chris Chi-
nenye Emezue, Jonathan Mukiibi, Salomey Osei,
Apelete AGBOLO, Victor Akinode, Bernard Opoku,
Olanrewaju Samuel, Jesujoba Alabi, and Sham-
suddeen Hassan Muhammad. 2022. Bibletts: a
large, high-fidelity, multilingual, and uniquely african
speech corpus. In Interspeech 2022, pages 2383-
2387.

Seyed Morteza Mirbostani, Yasaman Boreshban, Salam
Khalifa, SeyedAbolghasem Mirroshandel, and Owen
Rambow. 2023. Deep active learning for mor-
phophonological processing. In Proceedings of the
61st Annual Meeting of the Association for Compu-
tational Linguistics (Volume 2: Short Papers), pages
793-803, Toronto, Canada. Association for Compu-
tational Linguistics.

Nikita Moghe, Evgeniia Razumovskaia, Liane Guillou,
Ivan Vuli¢é, Anna Korhonen, and Alexandra Birch.
2023. Multi3NLU++: A multilingual, multi-intent,
multi-domain dataset for natural language under-
standing in task-oriented dialogue. In Findings of
the Association for Computational Linguistics: ACL
2023, pages 3732-3755, Toronto, Canada. Associa-
tion for Computational Linguistics.


Shafie Abdi Mohamed and Muhidin A. Mohamed.
2023. Lexicon and rule-based word lemmatization
approach for somali language. In AfricaNLP.

Alireza Mohammadshahi, Vassilina Nikoulina, Alexan-
dre Berard, Caroline Brun, James Henderson, and
Laurent Besacier. 2022a. SMaLL-100: Introduc-
ing shallow multilingual machine translation model
for low-resource languages. In Proceedings of the
2022 Conference on Empirical Methods in Natu-
ral Language Processing, pages 8348-8359, Abu
Dhabi, United Arab Emirates. Association for Com-
putational Linguistics.

Alireza Mohammadshahi, Vassilina Nikoulina, Alexan-
dre Berard, Caroline Brun, James Henderson, and
Laurent Besacier. 2022b. What do compressed mul-
tilingual machine translation models forget? In Find-
ings of the Association for Computational Linguistics:
EMNLP 2022, pages 4308-4329, Abu Dhabi, United
Arab Emirates. Association for Computational Lin-
guistics.

Jama Hussein Mohamud, Lloyd Thompson, Aissatou
Ndoye, and Laurent Besacier. 2021. Fast devel-
opment of asr in african languages using self su-
pervised speech representation learning. ArXiv,
abs/2103.08993.

Mahmud Mohammed Momoh. 2024. Lateral inversions,
word form/order, unnamed grammatical entities and
ambiguities in the constituency parsing and anno-
tation of the Igala syntax through the English lan-
guage. In Proceedings of the Fifth Workshop on Re-
sources for African Indigenous Languages @ LREC-
COLING 2024, pages 152-162, Torino, Italia. ELRA
and ICCL.

Marius Mosbach, Vagrant Gautam, Tomas Ver-
gara Browne, Dietrich Klakow, and Mor Geva. 2024.
From insights to actions: The impact of interpretabil-
ity and analysis research on NLP. In Proceedings
of the 2024 Conference on Empirical Methods in
Natural Language Processing, pages 3078-3105, Mi-
ami, Florida, USA. Association for Computational
Linguistics.

Leila Moudjari, Karima Akli-Astouati, and Farah Be-
namara. 2020. An Algerian corpus and an annota-
tion platform for opinion and emotion analysis. In
Proceedings of the Twelfth Language Resources and
Evaluation Conference, pages 1202-1210, Marseille,
France. European Language Resources Association.

Basel Mousi, Nadir Durrani, Fatema Ahmad, Md Arid
Hasan, Maram Hasanain, Tameem Kabbani, Fahim
Dalvi, Shammur A. Chowdhury, and Firoj Alam.
2024. Aradice: Benchmarks for dialectal and cul-
tural capabilities in IIms. ArXiv, abs/2409.11404.

Niklas Muennighoff, Thomas Wang, Lintang Sutawika,
Adam Roberts, Stella Biderman, Teven Le Scao,
M Saiful Bari, Sheng Shen, Zheng Xin Yong, Hai-
ley Schoelkopf, Xiangru Tang, Dragomir Radev,
Alham Fikri Aji, Khalid Almubarak, Samuel Al-
banie, Zaid Alyafeai, Albert Webson, Edward Raff,

22

and Colin Raffel. 2023. Crosslingual generaliza-
tion through multitask finetuning. In Proceedings
of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers),
pages 15991-16111, Toronto, Canada. Association
for Computational Linguistics.

Shamsuddeen Hassan Muhammad, Idris Abdulmumin,

Abinew Ali Ayele, Nedjma Ousidhoum, David Ife-
oluwa Adelani, Seid Muhie Yimam, Ibrahim Sa’id
Ahmad, Meriem Beloucif, Saif M. Mohammad, Se-
bastian Ruder, Oumaima Hourrane, Pavel Brazdil,
Alipio Jorge, Felermino Dario Mario Anténio Ali,
Davis David, Salomey Osei, Bello Shehu Bello,
Falalu Ibrahim, Tajuddeen Gwadabe, and 8 others.
2023. AfriSenti: A Twitter sentiment analysis bench-
mark for African languages. In Proceedings of the
2023 Conference on Empirical Methods in Natural
Language Processing, pages 13968-13981, Singa-
pore. Association for Computational Linguistics.

Shamsuddeen Hassan Muhammad, David Ifeoluwa Ade-

lani, Sebastian Ruder, Ibrahim Sa’id Ahmad, Idris
Abdulmumin, Bello Shehu Bello, Monojit Choud-
hury, Chris Chinenye Emezue, Saheed Salahudeen
Abdullahi, Anuoluwapo Aremu, Alipio Jorge, and
Pavel Brazdil. 2022. NaijaSenti: A Nigerian Twitter
sentiment corpus for multilingual sentiment analy-
sis. In Proceedings of the Thirteenth Language Re-
sources and Evaluation Conference, pages 590-602,
Marseille, France. European Language Resources
Association.

Benson K. Muite and Kichakato Kizito. 2022. An open

source system for crowd sourcing an african language
short story corpus. Journal of the Digital Humanities
Association of Southern Africa (DHASA), 3(03).

Joaquim Mussandi and Andreas Wichert. 2024. NLP

tools for African languages: Overview. In Proceed-
ings of the 16th International Conference on Com-
putational Processing of Portuguese - Vol. 2, pages
73-82, Santiago de Compostela, Galicia/Spain. As-
sociation for Computational Lingustics.

Junho Myung, Nayeon Lee, Yi Zhou, Jiho Jin,

Rifki Afina Putri, Dimosthenis Antypas, Hsuvas
Borkakoty, Eunsu Kim, Carla Perez-Almendros,
Abinew Ali Ayele, Victor Gutierrez Basulto, Yazmin
Ibanez-Garcia, Hwaran Lee, Shamsuddeen Hassan
Muhammad, Kiwoong Park, Anar Sabuhi Rzayev,
Nina White, Seid Muhie Yimam, Mohammad Taher
Pilehvar, and 3 others. 2024a. BLEnd: A benchmark
for LLMs on everyday knowledge in diverse cultures
and languages. In The Thirty-eight Conference on
Neural Information Processing Systems Datasets and
Benchmarks Track.

Junho Myung, Nayeon Lee, Yi Zhou, Jiho Jin,

Rifki Afina Putri, Dimosthenis Antypas, Hsuvas
Borkakoty, Eunsu Kim, Carla Pérez-Almendros,
Abinew Ali Ayele, Victor Guti’errez-Basulto,
Yazm’in Ib’anez-Garce’ia, Hwaran Lee, Shamsud-
deen Hassan Muhammad, Kiwoong Park, Anar


Rzayev, Nina White, Seid Muhie Yimam, Mo-
hammad Taher Pilehvar, and 3 others. 2024b.
Blend: A benchmark for Ilms on everyday knowI-
edge in diverse cultures and languages. ArXiv,
abs/2406.09948.

Shravan Nayak, Kanishk Jain, Rabiul Awal, Siva
Reddy, Sjoerd Van Steenkiste, Lisa Anne Hendricks,
Karolina Stanczak, and Aishwarya Agrawal. 2024.
Benchmarking vision language models for cultural
understanding. In Proceedings of the 2024 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 5769-5790, Miami, Florida, USA.
Association for Computational Linguistics.

Innocent Ndubuisi-Obi, Sayan Ghosh, and David Jur-
gens. 2019. Wetin dey with these comments? model-
ing sociolinguistic factors affecting code-switching
behavior in Nigerian online discussions. In Proceed-
ings of the 57th Annual Meeting of the Association for
Computational Linguistics, pages 6204-6214, Flo-
rence, Italy. Association for Computational Linguis-
tics.

Elhadji Mamadou Nguer, Alla Lo, Cheikh M. Bamba
Dione, Sileye O. Ba, and Moussa Lo. 2020. SEN-
CORPUS: A French-Wolof parallel corpus. In Pro-
ceedings of the Twelfth Language Resources and
Evaluation Conference, pages 2803-2811, Marseille,
France. European Language Resources Association.

Thao Nguyen, Matthew Wallingford, Sebastin Santy,
Wei-Chiu Ma, Sewoong Oh, Ludwig Schmidt,
Pang Wei Koh, and Ranjay Krishna. 2024a. Multilin-
gual diversity improves vision-language representa-
tions. In Advances in Neural Information Processing
Systems, volume 37, pages 91430-91459. Curran As-
sociates, Inc.

Thuat Nguyen, Chien Van Nguyen, Viet Dac Lai,
Hieu Man, Nghia Trung Ngo, Franck Dernoncourt,
Ryan A. Rossi, and Thien Huu Nguyen. 2024b. Cul-
turaX: A cleaned, enormous, and multilingual dataset
for large language models in 167 languages. In Pro-
ceedings of the 2024 Joint International Conference
on Computational Linguistics, Language Resources
and Evaluation (LREC-COLING 2024), pages 4226—
4237, Torino, Italia. ELRA and ICCL.

Hellina Hailu Nigatu, Atnafu Lambebo Tonja, Benjamin
Rosman, Thamar Solorio, and Monojit Choudhury.
2024. The zeno‘s paradox of ‘low-resource’ lan-
guages. In Proceedings of the 2024 Conference on
Empirical Methods in Natural Language Processing,
pages 17753-17774, Miami, Florida, USA. Associa-
tion for Computational Linguistics.

Charles Nimo, Tobi Olatunji, Abraham Toluwase
Owodunni, Tassallah Abdullahi, Emmanuel Ayo-
dele, Mardhiyah Sanni, Ezinwanne C. Aka, Fola-
funmi Omofoye, Foutse Yuehgoh, Timothy Faniran,
Bonaventure F. P. Dossou, Moshood O. Yekini, Jonas
Kemp, Katherine A Heller, Jude Chidubem Omeke,
Chidi Asuzu Md, Naome A Etori, Aimérou Ndiaye,
Ifeoma Okoh, and 7 others. 2025. AfriMed-QA:

23

A pan-African, multi-specialty, medical question-
answering benchmark dataset. In Proceedings of the
63rd Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
1948-1973, Vienna, Austria. Association for Compu-
tational Linguistics.

Rubungo Andre Niyongabo, Qu Hong, Julia Kreutzer,
and Li Huang. 2020. KINNEWS and KIRNEWS:
Benchmarking cross-lingual text classification for
Kinyarwanda and Kirundi. In Proceedings of the
28th International Conference on Computational Lin-
guistics, pages 5507-5521, Barcelona, Spain (On-
line). International Committee on Computational Lin-
guistics.

NLLB Team and | others. 2024. Scaling neural machine
translation to 200 languages. Nature, 630(8018):841.

Leanne Nortje, Dan Oneata, and Herman Kamper. 2024.
Improved visually prompted keyword localisation in
real low-resource settings. ArXiv, abs/2409.06013.

Ebelechukwu Nwafor and Anietie Andy. 2022. A sur-
vey of machine translation tasks on Nigerian lan-
guages. In Proceedings of the Thirteenth Language
Resources and Evaluation Conference, pages 6480—
6486, Marseille, France. European Language Re-
sources Association.

Antoine Nzeyimana. 2020. Morphological disambigua-
tion from stemming data. In Proceedings of the 28th
International Conference on Computational Linguis-
tics, pages 4649-4660, Barcelona, Spain (Online).
International Committee on Computational Linguis-
tics.

Antoine Nzeyimana and Andre Niyongabo Rubungo.
2022. KinyaBERT: a morphology-aware Kin-
yarwanda language model. In Proceedings of the
60th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
5347-5363, Dublin, Ireland. Association for Compu-
tational Linguistics.

Saint Germes Bienvenu Bengono Obiang, Norbert
Tsopze, Paulin Melatagia Yonta, Jean-Francois
Bonastre, and Tania Jiménez. 2024. Improving tone
recognition performance using wav2vec 2.0-based
learned representation in yoruba, a low-resourced
language. ACM Trans. Asian Low Resour. Lang. Inf.
Process., 23:172:1-172:11.

Perez Ogayo, Graham Neubig, and Alan W Black. 2022.
Building african voices. In Interspeech 2022, pages
1263-1267.

Kelechi Ogueji, Yuxin Zhu, and Jimmy Lin. 2021.
Small data? no problem! exploring the viability
of pretrained multilingual language models for low-
resourced languages. In Proceedings of the Ist Work-
shop on Multilingual Representation Learning, pages
116-126, Punta Cana, Dominican Republic. Associa-
tion for Computational Linguistics.


Sewade Ogun, Abraham Owodunni, Tobi Olatunji,
Eniola Alese, Babatunde Oladimeji, Tejumade
Afonja, Kayode Olaleye, Naome A. Etori, and
Tosin P. Adewumi. 2024a. 1000 african voices: Ad-
vancing inclusive multi-speaker multi-accent speech
synthesis. ArXiv, abs/2406.11727.

Sewade Ogun, Abraham T. Owodunni, Tobi Olatunji,
Eniola Alese, Babatunde Oladimeji, Tejumade
Afonja, Kayode Olaleye, Naome A. Etori, and Tosin
Adewumi. 2024b. 1000 african voices: Advancing
inclusive multi-speaker multi-accent speech synthe-
sis. In Interspeech 2024, pages 1855-1859.

Odunayo Ogundepo, Tajuddeen R. Gwadabe, Clara E.
Rivera, Jonathan H. Clark, Sebastian Ruder,
David Ifeoluwa Adelani, Bonaventure F. P. Dos-
sou, Abdou Aziz Diop, Claytone Sikasote, Gilles
Hacheme, Happy Buzaaba, Ignatius Ezeani, Roowei-
ther Mabuya, Salomey Osei, Chris Emezue, Al-
bert Njoroge Kahira, Shamsuddeen Hassan Muham-
mad, Akintunde Oladipo, Abraham Toluwase
Owodunni, and 33 others. 2023. AfriQA: Cross-
lingual open-retrieval question answering for African
languages. In Findings of the Association for Com-
putational Linguistics: EMNLP 2023, pages 14957—
14972, Singapore. Association for Computational
Linguistics.

Tolulope Ogunremi, Kola Tubosun, Anuoluwapo
Aremu, Iroro Orife, and David Ifeoluwa Adelani.
2024. IrdyinSpeech: A multi-purpose Yortba
speech corpus. In Proceedings of the 2024 Joint
International Conference on Computational Linguis-
tics, Language Resources and Evaluation (LREC-
COLING 2024), pages 9296-9303, Torino, Italia.
ELRA and ICCL.

Jessica Ojo, Odunayo Ogundepo, Akintunde Oladipo,
Kelechi Ogueji, Jimmy Lin, Pontus Stenetorp, and
David Ifeoluwa Adelani. 2025. AfroBench: How
good are large language models on African lan-
guages? In Findings of the Association for Computa-
tional Linguistics: ACL 2025, pages 19048-19095,
Vienna, Austria. Association for Computational Lin-
guistics.

Alp Oktem, Eric DeLuca, Rodrigue Bashizi, Eric
Paquin, and Grace Tang. 2021. Congolese swahili
machine translation for humanitarian response.
ArXiv, abs/2103.10734.

Akintunde Oladipo. 2024. Scaling pre-training data and
language models for african languages. MSc Thesis,
University of Waterloo.

Akintunde Oladipo, Mofetoluwa Adeyemi, Ore-
vaoghene Ahia, Abraham Toluwalase Owodunni,
Odunayo Ogundepo, David Ifeoluwa Adelani, and
Jimmy Lin. 2023. Better quality pre-training data and
t5 models for African languages. In Proceedings of
the 2023 Conference on Empirical Methods in Natu-
ral Language Processing, pages 158-168, Singapore.
Association for Computational Linguistics.

24

Kayode Olaleye, Dan Oneata, and Herman Kamper.
2022. Yfacc: A yoruba speech—image dataset for
cross-lingual keyword localisation through visual
grounding. 2022 IEEE Spoken Language Technology
Workshop (SLT), pages 731-738.

Tobi Olatunji, Tejumade Afonja, Bonaventure F. P. Dos-
sou, Atnafu Lambebo Tonja, Chris Chinenye Emezue,
Amina Mardiyyah Rufai, and Sahib Singh. 2023a.
Afrinames: Most asr models "butcher" african names.
In Interspeech 2023, pages 5077-5081.

Tobi Olatunji, Tejumade Afonja, Aditya Yadavalli,
Chris Chinenye Emezue, Sahib Singh, Bonaventure
F. P. Dossou, Joanne Osuchukwu, Salomey Osei,
Atnafu Lambebo Tonja, Naome Etori, and Clinton
Mbataku. 2023b. AfriSpeech-200: Pan-African ac-
cented speech dataset for clinical and general domain
ASR. Transactions of the Association for Computa-
tional Linguistics, 11:1669-1685.

Akindele Michael Olawole, Jesujoba Oluwadara AI-
abi, Aderonke Busayo Sakpere, and David Ifeoluwa
Adelani. 2024. Yad: Leveraging t5 for improved
automatic diacritization of yortba text. ArXiv,
abs/2412.20218.

Opeyemi Osakuade and Simon King. 2024. Do dis-
crete self-supervised representations of speech cap-
ture tone distinctions? ArXiv, abs/2410.19935.

Adama Ouane and Christine Glanz. 2010. Why and
How Africa Should Invest in African Languages and
Multilingual Education: An Evidence-and Practice-
Based Policy Advocacy Brief: ERIC.

Nedjma Ousidhoum, Shamsuddeen Hassan Muhammad,
Mohamed Abdalla, Idris Abdulmumin, Ibrahim Said
Ahmad, Sanchit Ahuja, Alham Fikri Aji, Vladimir
Araujo, Meriem Beloucif, Christine De Kock,
Oumaima Hourrane, Manish Shrivastava, Thamar
Solorio, Nirmal Surange, Krishnapriya Vishnubhotla,
Seid Muhie Yimam, and Saif M. Mohammad. 2024.
SemEval task 1: Semantic textual relatedness for
African and Asian languages. In Proceedings of the
18th International Workshop on Semantic Evalua-
tion (SemEval-2024), pages 1963-1978, Mexico City,
Mexico. Association for Computational Linguistics.

Jessica Ouyang, Boya Song, and Kathy McKeown.
2019. A robust abstractive system for cross-lingual
summarization. In Proceedings of the 2019 Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies, Volume 1 (Long and Short Pa-
pers), pages 2025-2031, Minneapolis, Minnesota.
Association for Computational Linguistics.

Wuraola Fisayo Oyewusi, Olubayo Adekanmbi, Ife
Okoh, Vitus Onuigwe, Mary Idera Salami, Opeyemi
Osakuade, Sharon Ibejih, and Usman Abdullahi
Musa. 2021. Naijaner : Comprehensive named en-
tity recognition for 5 nigerian languages. ArXiv,
abs/2105.008 10.


Xiaoman Pan, Boliang Zhang, Jonathan May, Joel Noth-
man, Kevin Knight, and Heng Ji. 2017. Cross-lingual
name tagging and linking for 282 languages. In Pro-
ceedings of the 55th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), pages 1946-1958, Vancouver, Canada. As-
sociation for Computational Linguistics.

Rock Yuren Pang, Hope Schroeder, Kynnedy Simone
Smith, Solon Barocas, Ziang Xiao, Emily Tseng,
and Danielle Bragg. 2025. Understanding the Ilm-
ification of chi: Unpacking the impact of Ilms at chi
through a systematic literature review. In Proceed-
ings of the 2025 CHI Conference on Human Factors
in Computing Systems, CHI’25, New York, NY, USA.
Association for Computing Machinery.

Guilherme Penedo, Hynek Kydlicek, Loubna Ben Al-
lal, Anton Lozhkov, Margaret Mitchell, Colin Raffel,
Leandro von Werra, and Thomas Wolf. 2024. The
fineweb datasets: Decanting the web for the finest
text data at scale. ArXiv, abs/2406.17557.

Jonas Pfeiffer, Francesco Piccinno, Massimo Nicosia,
Xinyi Wang, Machel Reid, and Sebastian Ruder.
2023. mmT5: Modular multilingual pre-training
solves source language hallucinations. In Findings
of the Association for Computational Linguistics:
EMNLP 2023, pages 1978-2008, Singapore. Associ-
ation for Computational Linguistics.

Jonas Pfeiffer, Ivan Vuli¢, Iryna Gurevych, and Sebas-
tian Ruder. 2021. UNKs everywhere: Adapting mul-
tilingual language models to new scripts. In Proceed-
ings of the 2021 Conference on Empirical Methods in
Natural Language Processing, pages 10186-10203,
Online and Punta Cana, Dominican Republic. Asso-
ciation for Computational Linguistics.

Edoardo Maria Ponti, Goran GlavaS, Olga Majewska,
Qianchu Liu, Ivan Vuli¢é, and Anna Korhonen. 2020.
XCOPA: A multilingual dataset for causal common-
sense reasoning. In Proceedings of the 2020 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), pages 2362-2376, Online. As-
sociation for Computational Linguistics.

Vineel Pratap, Andros Tjandra, Bowen Shi, Paden
Tomasello, Arun Babu, Sayani Kundu, Ali Elkahky,
Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi,
Alexei Baevski, Yossi Adi, Xiaohui Zhang, Wei-Ning
Hsu, Alexis Conneau, and Michael Auli. 2024. Scal-
ing speech technology to 1,000+ languages. Journal
of Machine Learning Research, 25(1).

Martin J. Puttkammer and Jakobus S. Du Toit. 2021.
Canonical segmentation and syntactic morpheme tag-
ging of four resource- scarce nguni languages. Jour-
nal of the Digital Humanities Association of Southern
Africa (DHASA).

Faisal Qarah. 2024. Egybert: A large language model
pretrained on egyptian dialect corpora. ArXiv,
abs/2408.03524.

25

Osvaldo Luamba Quinjica and David Ifeoluwa Adelani.
2024. Angofa: Leveraging ofa embedding initializa-
tion and synthetic data for angolan language model.
ArXiv, abs/2404.02534.

Afshin Rahimi, Yuan Li, and Trevor Cohn. 2019. Mas-
sively multilingual transfer for NER. In Proceedings
of the 57th Annual Meeting of the Association for
Computational Linguistics, pages 151-164, Florence,
Italy. Association for Computational Linguistics.

Jenalea Rajab, Anuoluwapo Aremu, Everlyn Asiko Chi-
moto, Dale Dunbar, Graham Morrissey, Fadel Thior,
Luandrie Potgieter, Jessico Ojo, Atnafu Lambebo
Tonja, Maushami Chetty, Onyothi Nekoto, Pelonomi
Moiloa, Jade Abbott, Vukosi Marivate, and Benjamin
Rosman. 2025. The esethu framework: Reimagin-
ing sustainable dataset governance and curation for
low-resource languages. ArXiv, abs/2502.15916.

Sello Ralethe. 2020. Adaptation of deep bidirectional
transformers for Afrikaans language. In Proceedings
of the Twelfth Language Resources and Evaluation
Conference, pages 2475-2478, Marseille, France. Eu-
ropean Language Resources Association.

Simon P. Ramalepe, Thipe Isaiah Modipa, and Mare-
lie Hattingh Davel. 2023. The analysis of the sepedi-
english code-switched radio news corpus. Journal
of the Digital Humanities Association of Southern
Africa (DHASA).

Falia Ramanantsoa. 2023. Voxmg: An automatic speech
recognition dataset for malagasy. In AfricaNLP.

Vipul Rathore, Rajdeep Dhingra, Parag Singla, and
Mausam. 2023. ZGUL: Zero-shot generalization to
unseen languages using multi-source ensembling of
language adapters. In Proceedings of the 2023 Con-
ference on Empirical Methods in Natural Language
Processing, pages 6969-6987, Singapore. Associa-
tion for Computational Linguistics.

Machel Reid, Junjie Hu, Graham Neubig, and Yutaka
Matsuo. 2021. AfroMT: Pretraining strategies and
reproducible benchmarks for translation of 8 African
languages. In Proceedings of the 2021 Conference
on Empirical Methods in Natural Language Process-
ing, pages 1306-1320, Online and Punta Cana, Do-
minican Republic. Association for Computational
Linguistics.

Sandy Ritchie, Daan van Esch, Uche Okonkwo, Shikhar
Vashishth, and Emily Drummond. 2024. Linguameta:
Unified metadata for thousands of languages. In
Proceedings of the Joint International Conference
on Computational Linguistics, Language Resources
and Evaluation, pages 10530—-10538, Torino, Italy.
European Language Resources Association.

Nathaniel Robinson, Raj Dabre, Ammon Shurtz, Ra-
sul Dent, Onenamiyi Onesi, Claire Monroc, Loic
Grobol, Hasan Muhammad, Ashi Garg, Naome
Etori, Vijay Murari Tiyyala, Olanrewaju Samuel,
Matthew Stutzman, Bismarck Odoom, Sanjeev Khu-
danpur, Stephen Richardson, and Kenton Murray.


2024. Kreyol-MT: Building MT for Latin American,
Caribbean and colonial African creole languages. In
Proceedings of the 2024 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies
(Volume 1: Long Papers), pages 3083-3110, Mexico
City, Mexico. Association for Computational Lin-
guistics.

David Romero, Chenyang Lyu, Haryo Akbarianto Wi-
bowo, Teresa Lynn, Injy Hamed, Aditya Nanda
Kishore, Aishik Mandal, Alina Dragonetti, Artem
Abzaliev, Atnafu Lambebo Tonja, Bontu Fufa Balcha,
Chenxi Whitehouse, Christian Salamea, Dan John
Velasco, David Ifeoluwa Adelani, David Le Meur,
Emilio Villa-Cueva, Fajri Koto, Fauzan Farooqui, and
56 others. 2024. Cvqa: Culturally-diverse multilin-
gual visual question answering benchmark. Preprint,
arXiv:2406.05967.

Sebastian Ruder, Jonathan H. Clark, Alexander Gutkin,
Mihir Kale, Min Ma, Massimo Nicosia, Shruti Rijh-
wani, Parker Riley, Jean-Michel A Sarr, Xinyi Wang,
John Wieting, Nitish Gupta, Anna Katanova, Christo
Kirov, Dana L. Dickinson, Brian Roark, Bidisha
Samanta, Connie Tao, David I. Adelani, and 8 oth-
ers. 2023. XTREME-UP: A user-centric scarce-data
benchmark for under-represented languages. In Find-
ings of the Association for Computational Linguis-
tics: EMNLP 2023, pages 1856-1884, Singapore.
Association for Computational Linguistics.

Muhammed Saeed, Peter Bourgonje, and Vera Demberg.
2024. Implicit discourse relation classification for
nigerian pidgin. Preprint, arXiv:2406.18776.

Ramon Sanabria, Nikolay Bogoychev, Nina Markl, An-
drea Carmantini, Ondrej Klejch, and Peter Bell. 2023.
The edinburgh international accents of english cor-
pus: Towards the democratization of english asr.
ICASSP 2023 - 2023 IEEE International Confer-
ence on Acoustics, Speech and Signal Processing
(ICASSP), pages 1-5.

Felipe Sanchez-Martinez, Victor M. Sanchez-Cartagena,
Juan Antonio Pérez-Ortiz, Mikel L. Forcada, Miquel
Espla-Gomis, Andrew Secker, Susie Coleman, and
Julie Wall. 2020. An English-Swahili parallel cor-
pus and its use for neural machine translation in the
news domain. In Proceedings of the 22nd Annual
Conference of the European Association for Machine
Translation, pages 299-308, Lisboa, Portugal. Euro-
pean Association for Machine Translation.

Teven Le Scao, Angela Fan, Christopher Akiki, El-
lie Pavlick, Suzana Ili’c, Daniel Hesslow, Roman
Castagn’e, Alexandra Sasha Luccioni, Frangois
Yvon, Matthias Gallé, Jonathan Tow, Alexan-
der M. Rush, Stella Biderman, Albert Webson,
Pawan Sasanka Ammanamanchi, Thomas Wang,
Benoit Sagot, Niklas Muennighoff, Albert Villanova
del Moral, and 7 others. 2022. Bloom: A 176b-
parameter open-access multilingual language model.
ArXiv, abs/2211.05100.

26

Fabian David Schmidt, Ivan Vuli¢, and Goran Glavas.
2023a. Free lunch: Robust cross-lingual transfer
via model checkpoint averaging. In Proceedings
of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers),
pages 5712-5730, Toronto, Canada. Association for
Computational Linguistics.

Fabian David Schmidt, Ivan Vulié, and Goran Glava§s.
2023b. One for all & all for one: Bypassing hy-
perparameter tuning with model averaging for cross-
lingual transfer. In Findings of the Association for
Computational Linguistics: EMNLP 2023, pages
12186-12193, Singapore. Association for Compu-
tational Linguistics.

Jonathan Schoots. 2023. Analyzing political forma-
tion through historical isixhosa text analysis: Using
frequency analysis to examine emerging african na-
tionalism in south africa. In RAIL.

Holger Schwenk, Vishray Chaudhary, Shuo Sun,
Hongyu Gong, and Francisco Guzman. 2021. Wiki-
Matrix: Mining 135M parallel sentences in 1620 lan-
guage pairs from Wikipedia. In Proceedings of the
16th Conference of the European Chapter of the Asso-
ciation for Computational Linguistics: Main Volume,
pages 1351-1361, Online. Association for Computa-
tional Linguistics.

Djamé Seddah, Farah Essaidi, Amal Fethi, Matthieu
Futeral, Benjamin Muller, Pedro Javier Ortiz Suarez,
Benoit Sagot, and Abhishek Srivastava. 2020. Build-
ing a user-generated content North-African Arabizi
treebank: Tackling hell. In Proceedings of the 58th
Annual Meeting of the Association for Computational
Linguistics, pages 1139-1150, Online. Association
for Computational Linguistics.

Sheikh Shafayat, Eunsu Kim, Juhyun Oh, and Alice Oh.
2024. Multi-FAct: Assessing factuality of multilin-
gual LLMs using FActscore. In First Conference on
Language Modeling.

Alexander Shan, John Bauer, Riley Carlson, and Christo-
pher Manning. 2023. Do “English” named entity
recognizers work well on global englishes? In Find-
ings of the Association for Computational Linguis-
tics: EMNLP 2023, pages 11778-11791, Singapore.
Association for Computational Linguistics.

Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang,
Suraj Srivats, Soroush Vosoughi, Hyung Won Chung,
Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das,
and Jason Wei. 2023. Language models are multi-
lingual chain-of-thought reasoners. In The Eleventh
International Conference on Learning Representa-
tions.

Oleh Shliazhko, Alena Fenogenova, Maria Tikhonova,
Anastasia Kozlova, Vladislav Mikhailov, and Tatiana
Shavrina. 2024. mGPT: Few-shot learners go multi-
lingual. Transactions of the Association for Compu-
tational Linguistics, 12:58-79.


Tyanuoluwa Shode, David Ifeoluwa Adelani, JIng Peng,
and Anna Feldman. 2023. NollySenti: Leveraging
transfer learning and machine translation for Nige-
rian movie sentiment classification. In Proceedings
of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 2: Short Papers),
pages 986-998, Toronto, Canada. Association for
Computational Linguistics.

Johannes Sibeko and Mmasibidi Setaka. 2022. An
overview of sesotho blark content. Journal of the
Digital Humanities Association of Southern Africa,
401).

Johannes Sibeko and Mmasibidi Setaka. 2023. Eval-
uating the sesotho rule-based syllabification system
on sepedi and setswana words. In Proceedings
of the Fourth workshop on Resources for African
Indigenous Languages (RAIL 2023), pages 76-85,
Dubrovnik, Croatia. Association for Computational
Linguistics.

Johannes Sibeko and Menno van Zaanen. 2024. Devel-
oping and testing syllabification systems for south
african sesotho. Language Resources and Evalua-
tion.

Claytone Sikasote, Eunice Mukonde, Md Mahfuz Ibn
Alam, and Antonios Anastasopoulos. 2023a. BIG-
C: a multimodal multi-purpose dataset for Bemba.
In Proceedings of the 61st Annual Meeting of the
Association for Computational Linguistics (Volume
1: Long Papers), pages 2062-2078, Toronto, Canada.
Association for Computational Linguistics.

Claytone Sikasote, Kalinda Siaminwe, Stanly Mwape,
Bangiwe Zulu, Mofya Phiri, Martin Phiri, David
Zulu, Mayumbo Nyirenda, and Antonios Anasta-
sopoulos. 2023b. Zambezi voice: A multilingual
speech corpus for zambian languages. In Interspeech
2023, pages 3984-3988.

Shivalika Singh, Freddie Vargus, Daniel D’souza,
Borje Karlsson, Abinaya Mahendiran, Wei- Yin Ko,
Herumb Shandilya, Jay Patel, Deividas Mataciu-
nas, Laura O’Mahony, Mike Zhang, Ramith Het-
tiarachchi, Joseph Wilson, Marina Machado, Luisa
Moura, Dominik Krzeminski, Hakimeh Fadaei, Irem
Ergun, Ifeoma Okoh, and 14 others. 2024. Aya
dataset: An open-access collection for multilingual
instruction tuning. In Proceedings of the 62nd An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 11521-
11567, Bangkok, Thailand. Association for Compu-
tational Linguistics.

Abderrahman Skiredj, Ferdaous Azhari, Ismail Berrada,
and Saad Ezzini. 2024. Darijabanking: A new re-
source for overcoming language barriers in banking
intent detection for moroccan arabic speakers. ArXiv,
abs/2405.16482.

Nikita Soni, Lucie Flek, Ashish Sharma, Diyi Yang,
Sara Hooker, and H. Andrew Schwartz, editors. 2024.
Proceedings of the Ist Human-Centered Large Lan-
guage Modeling Workshop. ACL, TBD.

27

Kenneth Steimel and Sandra Kiibler. 2023. Towards a
Swahili Universal Dependency treebank: Leveraging
the annotations of the Helsinki corpus of Swahili. In
Proceedings of the Fourth workshop on Resources for
African Indigenous Languages (RAIL 2023), pages
86—96, Dubrovnik, Croatia. Association for Compu-
tational Linguistics.

Martha Yifiru Tachbelie, Solomon Teferra Abate, and
Tanja Schultz. 2020. Development of multilingual
asr using globalphone for less-resourced languages:
The case of ethiopian languages. In Interspeech.

Ephrem Tadesse, Rosa Tsegaye, and Kuulaa Qaqqabaa.
2020. Event extraction from unstructured Amharic
text. In Proceedings of the Twelfth Language Re-
sources and Evaluation Conference, pages 2103-
2109, Marseille, France. European Language Re-
sources Association.

Tilahun Abedissa Taffa, Ricardo Usbeck, and Yaregal
Assabie. 2024. Low resource question answering:
An Amharic benchmarking dataset. In Proceedings
of the Fifth Workshop on Resources for African In-
digenous Languages @ LREC-COLING 2024, pages
124-132, Torino, Italia. ELRA and ICCL.

Elvis Mboning Tchiaze, Jean Marc Bassahak, Daniel
Baleba, Ornella Wandji, and Jules Assoumou. 2020.
Building collaboration-based resources in endowed
african languages: Case of ntealan dictionaries plat-
form. In RAIL.

Mesmin Tchindjang, Athanase Bopda, and Louise Angé-
line Ngamgne. 2008. Languages and cultural identi-
ties in africa. Museum International, 60(3):37-S0.

Daniela Teodorescu and Saif Mohammad. 2023. Eval-
uating emotion arcs across languages: Bridging the
global divide in sentiment analysis. In Findings of the
Association for Computational Linguistics: EMNLP
2023, pages 4124-4137, Singapore. Association for
Computational Linguistics.

Jan W. F. Thirion, Charl Johannes van Heerden,
Oluwapelumi Giwa, and Marelie Hattingh Davel.
2020. The south african directory enquiries (sade)
name corpus. Language Resources and Evaluation,
54: 155-184.

Huu Nguyen Thuat Nguyen and Thien Nguyen. 2024.
Culturay: A large cleaned multilingual dataset of 75
languages.

Atnafu. Lambebo Tonja, Israel Abebe Azime,
Tadesse Destaw Belay, Mesay Gemeda Yigezu,
Moges Ahmed Ah Mehamed, Abinew Ali Ayele,
Ebrahim Chekol Jibril, Michael Melese Woldeyohan-
nis, Olga Kolesnikova, Philipp Slusallek, Dietrich
Klakow, and Seid Muhie Yimam. 2024a. EthioLLM:
Multilingual large language models for Ethiopian
languages with task evaluation. In Proceedings
of the 2024 Joint International Conference on
Computational Linguistics, Language Resources
and Evaluation (LREC-COLING 2024), pages
6341-6352, Torino, Italia. ELRA and ICCL.


Atnafu Lambebo Tonja, Tadesse Destaw Belay, Is-
rael Abebe Azime, Abinew Ali Ayele, Moges Ahmed
Mehamed, Olga Kolesnikova, and Seid Muhie
Yimam. 2023. Natural language processing in
Ethiopian languages: Current state, challenges, and
opportunities. In Proceedings of the Fourth work-
shop on Resources for African Indigenous Languages
(RAIL 2023), pages 126-139, Dubrovnik, Croatia.
Association for Computational Linguistics.

Atnafu Lambebo Tonja, Bonaventure F. P. Dossou, Jes-
sica Ojo, Jenalea Rajab, Fadel Thior, Eric Peter
Wairagala, Aremu Anuoluwapo, Pelonomi Moiloa,
Jade Abbott, Vukosi Marivate, and Benjamin
Rosman. 2024b. Inkubalm: A small language
model for low-resource african languages. ArXiv,
abs/2408.17024.

Chau Tran, Shruti Bhosale, James Cross, Philipp Koehn,
Sergey Edunov, and Angela Fan. 2021. Facebook
AI‘s WMT21 news translation task submission. In
Proceedings of the Sixth Conference on Machine
Translation, pages 205-215, Online. Association for
Computational Linguistics.

Kosei Uemura, Mahe Chen, Alex Pejovic, Chika Madu-
abuchi, Yifei Sun, and En-Shiun Annie Lee. 2024.
Afrilnstruct: Instruction tuning of African languages
for diverse tasks. In Findings of the Association
for Computational Linguistics: EMNLP 2024, pages
13571-13585, Miami, Florida, USA. Association for
Computational Linguistics.

Ahmet Ustiin, Viraat Aryabumi, Zheng Yong, Wei-Yin
Ko, Daniel D’souza, Gbemileke Onilude, Neel Bhan-
dari, Shivalika Singh, Hui-Lee Ooi, Amr Kayid, Fred-
die Vargus, Phil Blunsom, Shayne Longpre, Niklas
Muennighoff, Marzieh Fadaee, Julia Kreutzer, and
Sara Hooker. 2024. Aya model: An instruction fine-
tuned open-access multilingual language model. In
Proceedings of the 62nd Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers), pages 15894—15939, Bangkok, Thai-
land. Association for Computational Linguistics.

David Uthus, Santiago Ontanon, Joshua Ainslie, and
Mandy Guo. 2023. mLongT5: A multilingual and
efficient text-to-text transformer for longer sequences.
In Findings of the Association for Computational Lin-
guistics: EMNLP 2023, pages 9380-9386, Singapore.
Association for Computational Linguistics.

Jérgen Valk and Tanel Alumae. 2020. Voxlingual07: A
dataset for spoken language recognition. 202] [EEE
Spoken Language Technology Workshop (SLT), pages
652-658.

Jesus Villalba, Nanxin Chen, David Snyder, Daniel
Garcia-Romero, Alan McCree, Gregory Sell, Jonas
Borgstrom, Fred Richardson, Suwon Shon, Francois
Grondin, Réda Dehak, Leibny Paola Garcia-Perera,
Daniel Povey, Pedro A. Torres-Carrasquillo, Sanjeev
Khudanpur, and Najim Dehak. 2019. State-of-the-art
speaker recognition for telephone and video speech:
The jhu-mit submission for nist sre18. In Interspeech
2019, pages 1488-1492.

28

Apoorv Vyas, Srikanth R. Madikeri, and Hervé

Bourlard. 2020. Lattice-free mmi adaptation of self-
supervised pretrained acoustic models. ICASSP 2021
- 2021 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP), pages 6219-
6223.

Jiayi Wang, David Ifeoluwa Adelani, Sweta Agrawal,

Marek Masiak, Ricardo Rei, Eleftheria Briakou,
Marine Carpuat, Xuanli He, Sofia Bourhim, An-
diswa Bukula, Muhidin Mohamed, Temitayo Ola-
toye, Tosin Adewumi, Hamam Mokayed, Christine
Mwase, Wangui Kimotho, Foutse Yuehgoh, An-
uoluwapo Aremu, Jessica Ojo, and 39 others. 2024a.
AfriMTE and AfriCOMET: Enhancing COMET to
embrace under-resourced African languages. In Pro-
ceedings of the 2024 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies (Volume
1; Long Papers), pages 5997-6023, Mexico City,
Mexico. Association for Computational Linguistics.

Jiayi Wang, David Ifeoluwa Adelani, and Pontus Stene-

torp. 2024b. Evaluating WMT 2024 metrics shared
task submissions on AfriMTE (the African challenge
set). In Proceedings of the Ninth Conference on Ma-
chine Translation, pages 505-516, Miami, Florida,
USA. Association for Computational Linguistics.

Xinyi Wang, Sebastian Ruder, and Graham Neubig.

2022. Expanding pretrained models to thousands
more languages via lexicon-based adaptation. In Pro-
ceedings of the 60th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), pages 863-877, Dublin, Ireland. Association
for Computational Linguistics.

Barack W. Wanjawa, Lilian D. A. Wanzare, Florence

Indede, Owen Mconyango, Lawrence Muchemi, and
Edward Ombui. 2023. Kenswquad—a question an-
swering dataset for swahili low-resource language.
ACM Trans. Asian Low-Resour. Lang. Inf. Process.,
22(4).

Nick Wilkinson, Astik Biswas, Emre Yilmaz, Febe

De Wet, Ewald Van der westhuizen, and Thomas
Niesler. 2020. Semi-supervised acoustic mod-
elling for five-lingual code-switched ASR using
automatically-segmented soap opera speech. In Pro-
ceedings of the Ist Joint Workshop on Spoken Lan-
guage Technologies for Under-resourced languages
(SLTU) and Collaboration and Computing for Under-
Resourced Languages (CCURL), pages 70-78, Mar-
seille, France. European Language Resources associ-
ation.

Genta Indra Winata, Frederikus Hudi, Patrick Amadeus

Irawan, David Anugraha, Rifki Afina Putri, Yutong
Wang, Adam Nohejl, Ubaidillah Ariq Prathama, Ned-
jma Djouhra Ousidhoum, Afifa Amriani, Anar Rza-
yev, Anirban Das, Ashmari Pramodya, Aulia Adila,
Bryan Wilie, Candy Olivia Mawalim, Ching Lam
Cheng, Daud Olamide Abolade, Emmanuele Cher-
soni, and 32 others. 2024a. Worldcuisines: A


massive-scale benchmark for multilingual and multi-
cultural visual question answering on global cuisines.
ArXiv, abs/2410.12705.

Genta Indra Winata, Ruochen Zhang, and David Ife-
oluwa Adelani. 2024b. MINERS: Multilingual lan-
guage models as semantic retrievers. In Findings
of the Association for Computational Linguistics:
EMNLP 2024, pages 2742-2766, Miami, Florida,
USA. Association for Computational Linguistics.

Linjuan Wu, Zongyi Guo, Baoliang Cui, Haihong Tang,
and Weiming Lu. 2023. Good meta-tasks make a
better cross-lingual meta-transfer learning for low-
resource languages. In Findings of the Association
for Computational Linguistics: EMNLP 2023, pages
7431-7446, Singapore. Association for Computa-
tional Linguistics.

Linting Xue, Aditya Barua, Noah Constant, Rami AI-
Rfou, Sharan Narang, Mihir Kale, Adam Roberts,
and Colin Raffel. 2022. ByT5: Towards a token-free
future with pre-trained byte-to-byte models. Transac-
tions of the Association for Computational Linguis-
tics, 10:291—306.

Linting Xue, Noah Constant, Adam Roberts, Mihir Kale,
Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and
Colin Raffel. 2021. mT5: A massively multilingual
pre-trained text-to-text transformer. In Proceedings
of the 2021 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, pages 483-498, On-
line. Association for Computational Linguistics.

An Yang, Anfeng Li, Baosong Yang, Beichen Zhang,
Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao,
Chengen Huang, Chenxu Lv, Chujie Zheng, Dayi-
heng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge,
Haoran Wei, Huan Lin, Jialong Tang, and 41 others.
2024. Qwen3 technical report. on GitHub.

Binwei Yao, Ming Jiang, Tara Bobinac, Diyi Yang, and
Junjie Hu. 2024. Benchmarking machine translation
with cultural awareness. In Findings of the Associ-
ation for Computational Linguistics: EMNLP 2024,
pages 13078-13096, Miami, Florida, USA. Associa-
tion for Computational Linguistics.

Tilahun Yeshambel, Josiane Mothe, and Yaregal Assa-
bie. 2021. Morphologically annotated amharic text
corpora. Proceedings of the 44th International ACM
SIGIR Conference on Research and Development in
Information Retrieval.

Michelle Yuan, Mozhi Zhang, Benjamin Van Durme,
Leah Findlater, and Jordan Boyd-Graber. 2020. Inter-
active refinement of cross-lingual word embeddings.
In Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP),
pages 5984-5996, Online. Association for Computa-
tional Linguistics.

Bolaji Yusuf and Murat Saraclar. 2019. An empirical
evaluation of dtw subsampling methods for keyword
search. In Interspeech.

29

Amr M. Zaki, Mahmoud I. Khalil, and Hazem M. Ab-
bas. 2020. Amharic abstractive text summarization.
ArXiv, abs/2003.13721.

Marcely Zanon Boito, Fethi Bougares, Florentin Bar-
bier, Souhir Gahbiche, Loic Barrault, Mickael Rou-
vier, and Yannick Estéve. 2022. Speech resources in
the Tamasheq language. In Proceedings of the Thir-
teenth Language Resources and Evaluation Confer-
ence, pages 2066-2071, Marseille, France. European
Language Resources Association.

Marcely Zanon Boito, Vivek Iyer, Nikolaos Lagos, Lau-
rent Besacier, and Ioan Calapodescu. 2024. mhubert-
147: A compact multilingual hubert model. In Jnter-
speech 2024, pages 3939-3943.

Armel Randy Zebaze, Benoit Sagot, and Rachel Baw-
den. 2025. In-context example selection via simi-
larity search improves low-resource machine trans-
lation. In Findings of the Association for Computa-
tional Linguistics: NAACL 2025, pages 1222-1252,
Albuquerque, New Mexico. Association for Compu-
tational Linguistics.

Miaoran Zhang, Vagrant Gautam, Mingyang Wang, Je-
sujoba Alabi, Xiaoyu Shen, Dietrich Klakow, and
Marius Mosbach. 2024a. The impact of demonstra-
tions on multilingual in-context learning: A mul-
tidimensional analysis. In Findings of the Asso-
ciation for Computational Linguistics: ACL 2024,
pages 7342-7371, Bangkok, Thailand. Association
for Computational Linguistics.

Miaoran Zhang, Mingyang Wang, Jesujoba Alabi, and
Dietrich Klakow. 2024b. AAdaM at SemEval-2024
task 1: Augmentation and adaptation for multilingual
semantic textual relatedness. In Proceedings of the
18th International Workshop on Semantic Evalua-
tion (SemEval-2024), pages 800-810, Mexico City,
Mexico. Association for Computational Linguistics.

Xinyu Zhang, Xueguang Ma, Peng Shi, and Jimmy Lin.
2021. Mr. TyDi: A multi-lingual benchmark for
dense retrieval. In Proceedings of the Ist Workshop
on Multilingual Representation Learning, pages 127-
137, Punta Cana, Dominican Republic. Association
for Computational Linguistics.

Xinyu Zhang, Nandan Thakur, Odunayo Ogundepo,
Ehsan Kamalloo, David Alfonso-Hermelo, Xi-
aoguang Li, Qun Liu, Mehdi Rezagholizadeh, and
Jimmy Lin. 2023. MIRACL: A multilingual retrieval
dataset covering 18 diverse languages. Transactions
of the Association for Computational Linguistics,
11:1114-1131.

D. Zhu, Michael A. Hedderich, Fangzhou Zhai,
David Ifeoluwa Adelani, and Dietrich Klakow. 2022.
Task-adaptive pre-training for boosting learning with
noisy labels: A study on text classification for african
languages. ArXiv, abs/2206.01476.

Dawei Zhu, Xiaoyu Shen, Michael Hedderich, and Di-
etrich Klakow. 2023. Meta self-refinement for ro-
bust learning with weak supervision. In Proceed-


ings of the 17th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 1043-1058, Dubrovnik, Croatia. Association
for Computational Linguistics.

Yi Zhu, Benjamin Heinzerling, Ivan Vuli¢, Michael
Strube, Roi Reichart, and Anna Korhonen. 2019. On
the importance of subword information for morpho-
logical tasks in truly low-resource languages. In
Proceedings of the 23rd Conference on Computa-
tional Natural Language Learning (CoNLL), pages
216-226, Hong Kong, China. Association for Com-
putational Linguistics.

A. Data collection venue

We collected data from 11 venue categories, as
shown in Table 2. While we report both the total
number of papers initially retrieved and those ul-
timately analyzed, not all venues had retrievable
papers, and not all contributed to the final analysis
(for example, CSCW, UIST). The ACL Summit cat-
egory had the fewest papers retrieved, while ArXiv,
as expected, had the most. Due to the size, and
presence of several irrelevant papers from ArXiv
and HCI venues, we filtered them using GPT-4o0,
as described in Section B. In addition to the auto-
matically retrieved papers, we also included expert-
recommended papers from various venues. Here,
experts refers to African researchers who have con-
tributed to African language research over the past
five years.

The following are full names of the conferences,
journals and workshop names

1. AAAT: Association for the Advancement of
Artificial Intelligence

2. CHI: ACM Conference on Human Factors in
Computing Systems

3. ACL: Annual Meeting of the Association for
Computational Linguistics

4. EACL: European Chapter of the Association
for Computational Linguistics

5. LREC: International Conference on Language
Resources and Evaluation

6. EMNLP: Conference on Empirical Methods
in Natural Language Processing

7. COLING: International Conference on Com-
putational Linguistics

8. ELRA: Language Resources and Evaluation
Journal

30

10.

11.

12.

13.

14.

15.

16.

17.

18.

19.
20.

21.

22.

23.

24.

25.

26.

27.

28.

. TACL: Transactions of the Association for

Computational Linguistics

TALLIP: ACM Transactions on Asian and
Low-Resource Language Information Pro-
cessing

RAIL: Workshop on Resources for African
Indigenous Languages

ICASSP: International Conference on Acous-
tics, Speech, and Signal Processing

INTERSPEECH: International Speech Com-
munication Association

SLT: IEEE Spoken Language Technology
Workshop

AfricaNLP: Workshop on African Natural
Language Processing

DeepLo: Workshop on Deep Learning Ap-
proaches for Low-Resource NLP

MRL: Workshop on Multilingual Representa-
tion Learning

WOAH: Workshop on Online Abuse and
Harms

WMT: Conference on Machine Translation

EAMT: European Association for Machine
Translation

MT Summit: Machine Translation Summit

TASLP: IEEE/ACM Transactions on Audio,
Speech, and Language Processing

NeurIPS: Conference on Neural Information
Processing Systems

ICLR: International Conference on Learning
Representations

ICML: International Conference on Machine
Learning

CSCW: Conference on Computer-Supported
Cooperative Work & Social Computing

UIST: The ACM Symposium on User Inter-
face Software and Technology

CIKM: The Conference on Information and
Knowledge Management


29. SIGIR: Special Interest Group on Information

Retrieval

30. TREC: Text Retrieval Conference

31. WWW: International World Wide Web Con-

ference

32. FAccT: ACM Conference on Fairness, Ac-

countability, and Transparency

33. RANLP: International Conference Recent Ad-

vances in Natural Language Processing

B Data filtering

Due to the large volume of papers retrieved from
ArXiv and the presence of many irrelevant ones,
we opted for a coarse filtering approach rather
than a fine-grained one. Specifically, we filtered
papers based on whether they were related to
natural language processing. To assist with this
process, we used GPT-40. Additionally, we in-
cluded papers from HCI conferences in this filter-
ing step. To address this, we filtered the papers
by prompting GPT-40!" to classify them into two
categories—relevant and not-relevant—based on
their title and abstract (our prompt is provided in
Listing 1). We then manually evaluated 100 papers
from the automatic filtering—S0O from each cate-
gory—and obtained an accuracy of 99%, with all
errors being false negatives.

C_ Other tasks researchers work on

Semantics Work on semantics include semantic
textual relatedness (Ousidhoum et al., 2024) which
was run as a shared task, lexical semantic rela-
tions (Gromann et al., 2024), and word analogy
tasks (Mersha and Wu, 2020; Gaustad and Eiselen,
2023) mostly in the context of word embeddings.

Phonology and Morphology We observed from
our analysis that there are papers under phonol-
ogy, such as those on phonetics (Issa, 2023; Ahn
et al., 2023) and syllabification (Sibeko and Se-
taka, 2023; Sibeko and van Zaanen, 2024), study-
ing these phenomena in both text and speech. In the
area of morphology, some papers focus on lemma-
tization (Mohamed and Mohamed, 2023), mor-
phological segmentation and analysis (Nzeyimana,
2020; Puttkammer and Toit, 2021), and under word
segmentation, on tasks like tokenization (Atuhurra
et al., 2024; Meyer and Buys, 2022).

Othe 2024-08-06 version

31

Dialogue and Interactive Systems We found
a few papers in this category, including the cre-
ation of dialogue datasets for some African lan-
guages (Adewumi et al., 2023), conversational
data for dialects of English such as Nigerian En-
glish (Eisenstein et al., 2023), and the development
of chatbots (Mabrouk et al., 2021; Hailu and Welay,
2024).

Text with Images or Video: There are a few
works on multimodality that combine text with
images or video, such as image captioning (Abdul-
mumin et al., 2022), keyword localization (Olal-
eye et al., 2022; Nortje et al., 2024), multimodal
machine translation (MT) (Abdulmumin et al.,
2022; Hatami et al., 2024), text-to-image gener-
ation (Leong et al., 2022; Magomere et al., 2025),
and visual question answering (Leong et al., 2022).
A notable contribution is the development of a
multimodal LLM for Amharic (Andersland, 2024).
Sign languages, which are inherently multimodal
due to their use of visual and spatial cues, have also
received attention, with few resource-focused pa-
pers addressing sign language recognition (Elhagry
and Gla, 2021), sign-to-speech (Kolawole et al.,
2022), and sign language translation (Gueuwou
et al., 2023b,a).

Language Generation: Our analysis shows that
sequence generation tasks—such as text genera-
tion (Chang et al., 2020; Ramalepe et al., 2023),
text summarization (Ouyang et al., 2019; Zaki et al.,
2020; Uthus et al., 2023; Hasan et al., 2021; Pfeif-
fer et al., 2023), and spelling or grammatical error
correction (Adouane et al., 2019; Gezmu et al.,
2021a; Keita et al., 2024)—are among the least
explored for African languages. Within the text
generation category, existing work also includes
data-to-text (Gehrmann et al., 2023), question gen-
eration (Asai et al., 2024), title or topic genera-
tion (Adebara et al., 2024; Meyer et al., 2024), para-
graph generation, and automatic diacritization (Ola-
wole et al., 2024; Ojo et al., 2025).

Others: There is also work on discourse rela-
tion classification for Nigerian Pidgin (Saeed et al.,
2024), and in the context of computational social
science and cultural analytics on historical text
analysis (Schoots, 2023), dialectal variation analy-
sis (Gugliotta and Dinarelli, 2020; Eisenstein et al.,
2023), and modeling social linguistic factors in
creoles (Ndubuisi-Obi et al., 2019).


Category Venues #papers #relevant
Semantic Scholar
AI Conferences AAAI, IJCAI 2222 6
ARXIV arXiv.org 11680 188
HCI Conferences CHI, AfriCHI, CSCW, UIST 1290 8
IR Knowledge CIKM, SIGIR, TREC, WWW 1507 8
ML Conferences Neurips, ICML, ICLR, FAccT 4804 10
NLP Conferences ACL, COLING, EACL, EMNLP, LREC, NAACL, RANLP 2654 209
NLP Journals LREA, TACL, TALLIP 124 14
Speech Conference | ICASSP, INTERSPEECH, SLT 2412 92
Speech Journal TASLP, Speech Communication 279 11
Workshops AfricaNLP, DeepLo, MRL, WOAH, WMT 360 124
ACL Summits EAMT, MT Summit 52 5
Expert Collection

Same venues as above, and others e.g. RAIL 209 209
Total 27617 884

Table 2: Data statistics the venues considered for paper collection, the number of unique papers retrieved, and the

number of papers that are relevant after annotation.

D_ Other low-resource techniques

Meta Learning has increasingly been applied
to African and other low-resource languages, ad-
dressing challenges like scarce labeled data (Lux
et al., 2024), noisy supervision (Zhu et al., 2023),
and cross-lingual transfer (Wu et al., 2023). Ap-
proaches range from cross-lingual adaptation in
NLP tasks (e.g., text classification (Zhu et al.,
2023), question answering (Wu et al., 2023), depen-
dency parsing (Choenni et al., 2023), text genera-
tion (Maurya and Desarkar, 2022)) to low-resource
speech recognition (Chen et al., 2024d,e) and even
text-to-speech synthesis (Lux et al., 2024), using
techniques such as MAML, task-based meta-loss
optimization, adversarial representation learning,
and dynamic subnetworks. These methods enable
models to generalize from resource-rich languages
to underrepresented African languages, improve
performance in zero- or few-shot settings, and han-
dle noisy or weak supervision effectively.

Annotation Projection (AP) a technique used
to transfer labels from a labeled source dataset to
an unlabeled target dataset is also used for African
languages. Text classification benchmarks covering
several African languages like SIB-200 (Adelani
et al., 2024) and Taxi-1500 (Ma et al., 2023) are
based on this technique, and it has also been shown
to work for sequence labeling (Garcia-Ferrero et al.,
2023).

Ensemble Learning a technique that combines
multiple models usually either by aggregating pre-
dictions or representations—is also used in some

32

of the surveyed literature, including approaches
like model fusion (Rathore et al., 2023; Tran et al.,
2021).

Multi-task learning (MTL) an approach where
a model is trained to perform multiple tasks si-
multaneously, leveraging shared knowledge across
related tasks is also in the reviewed papers (Dossou
et al., 2023; Adebara et al., 2023a; Aduragba et al.,
2023; Chen et al., 2024a; Wang et al., 2024a).

Active Learning a machine learning approach
where models dynamically select the data to train-
was shown to be effective for African languages in
tasks such as morphophonological processing (Mir-
bostani et al., 2023), NER (Kholodna et al., 2024),
language modeling (Dossou et al., 2022), and
MT (Chimoto and Bassett, 2022).

Pruning & Compression (Awobade et al., 2024)
studied the effect of compression of language, (Mo-
hammadshahi et al., 2022b) studied the impact of
NMT model compression on translation quality,
(Ahia et al., 2021)

Dictionary-based NLP There are a few papers
in this category. Some focus on creating lexi-
cons for African languages (Emezue et al., 2024),
while others explore how to use these existing lexi-
cons—particularly for tasks such as data augmenta-
tion (Reid et al., 2021; Wang et al., 2022). Lexicon-
based augmentation has proven useful for generat-
ing more data for language modeling. Additionally,
a few works have shown their usefulness in tasks
such as sentiment and emotional analysis (Teodor-
escu and Mohammad, 2023; Mabokela et al., 2023)
for African languages.


Listing 1: Prompt used for filtering the ArXiv and HCI papers

You are an expert research assistant

Given a paper's title and abstract,
"relevant” or "not relevant”.

in Natural Language Processing (NLP).

decide whether the paper should be classified as

A paper should be classified as relevant if it is about:

Speech processing (e.g.,
Multimodal tasks
with text processing, audio-text)
Dataset curation, annotation,
Core NLP tasks (e.g.,
translation, summarization,
dialogue systems,
classification,
Information retrieval,
understanding

text mining,

Natural language processing (NLP) or computational linguistics
recognition,
involving language (e.g.,

synthesis, spoken dialogue)

vision-language, speech-text, OCR

or benchmarks for NLP/multimodal tasks
text classification,
information extraction,
sentiment analysis,
misinformation detection)

parsing, entity linking,
question answering,

semantics, discourse, topic

or data mining involving text or language

- Evaluation metrics for NLP tasks (e.g., BLEU, ROUGE, COMET, etc.)

- Language modeling

- Language generation

- Ethics, bias, fairness, interpretability, safety in language technology
systems

- Human-centered NLP (e.g., user-centered design of language technology, human-
LLM interaction, social impact of language technology)

- Applied NLP in specialized domains (e.g., agriculture, biomedical, legal,

education, cultural analytics,
good)
Otherwise, the paper should be classified
Output only one label: "relevant” or "not
Title: "{title}”
Abstract: "{abstract}"

computational social science,

NLP for social

as not relevant.

relevant”.

Rule-based NLP Several papers involve rule-
based NLP in different contexts, including gram-
mar induction (Herrera et al., 2024) and develop-
ment (Bamutura et al., 2020) through corpus-based
rule extraction, rule-based syntactic parsing using
formal grammars (Dione, 2020), and event extrac-
tion systems that combine handcrafted rules with
machine learning (Tadesse et al., 2020). Addition-
ally, rule-based approaches are evaluated for gram-
matical error correction. These studies showcase
the diverse roles rule-based methods continue to
play across linguistic resource creation and tasks.

E Comprehensive list of available African
language resources

Several language resources have been created for
different languages over the last half decade. These
resources include datasets, models, toolkits, and
lexicons, all designed for various tasks. Some of
these developments are supported by different fund-
ing sources and community initiatives such as Hau-

33

saNLP!!, and GhanaNLP!”.

E.1 Comprehensive list of datasets and
benchmarks

In Table 3, we provide a list of some of the created
and publicly released labeled and unlabeled text
and audio datasets for African languages across
various tasks. While some of these datasets are
part of large, curated multilingual language re-
sources, others are tailored to a single language
or a small group of languages. The list also in-
cludes datasets created for African variants of En-
glish (Afonja et al., 2021; Eisenstein et al., 2023;
Ogun et al., 2024a). Although a few works were
done on African French (Alumie et al., 2023; Mai-
son and Estéve, 2023) and Portuguese (Hagemeijer
et al., 2022b), there were no datasets created.
Although they are not highlighted in the ta-
bles, there are also multimodal, multilingual,
and multitask benchmarks that have been created

“https: //hausanlp. github. io/
https: //ghananlp.org/



Transfer Learning
Zero-shot transfer Learning
Data Augmentation

Adaptive Pretraining

Efficient/Low-Resource Methods for NLP
Ensemble Learning

Data Audit & Filtering

Meta Learning

Rule-based NLP

Distant & Weak Supervision

Multi-task Learning

Knowledge Distillation

Active Learning

Annotation Projection

Dictionary-based NLP

Pruning & Compression

Cross-lingual Alignment

Low-resource Technique

100 200 300

Paper Count

400

Figure 7: Low-resource techniques used in the analyzed
papers.

over the years surveyed—especially in the era of
LLMs—to evaluate their generalization and rea-
soning abilities. They include benchmarks such
as BLEnD (Myung et al., 2024b), XTREME (Hu
et al., 2020), XTREME-UP (Ruder et al., 2023),
IrokoBench (Adelani et al., 2025), MEGA-
VERSE (Ahuja et al., 2024), and AfroBench (Ojo
et al., 2025). There are those specifically tailored
towards dialects of languages includes dialects of
African languages (Mousi et al., 2024; Faisal et al.,
2024) and also creoles which are spoken across
Africa (Robinson et al., 2024; Lent et al., 2024).

In addition to data collection, there are also ar-
ticles focused on African language data curation
methodology, identifying challenges and propos-
ing solutions such as creating platforms to support
creation and storage (Tchiaze et al., 2020; Griesel
and Bosch, 2020; Griscom, 2020; Marivate et al.,
2020).

E.2 Comprehensive list of models, toolkits
and platforms

Several models have been developed and published
for African languages in the surveyed period, span-
ning a variety of NLP tasks. Two key areas that
have seen a proliferation of models are machine
translation and language modeling. These mod-
els include both language-specific (Emezue and
Dossou, 2020b; Adelani et al., 2022a) and multi-
lingual systems (Fan et al., 2020; Elmadany et al.,
2024; Mohammadshahi et al., 2022a), largely en-
abled by the creation of extensive multilingual
datasets—such as web-mined bi-texts.

Although these multilingual resources can be

34

used directly, multiple studies have shown that
such models tend to underperform in African lan-
guages compared to high-resource languages such
as German, French and English (Adelani et al.,
2024, 2025). To address this disparity, transfer
learning has emerged as an effective strategy: pre-
trained multilingual models are adapted to low-
resource African languages via task-specific fine-
tuning or adaptive pretraining, followed by fine-
tuning. These transfer learning techniques help
bridge the performance gap by allowing models to
leverage knowledge from high-resource languages
or related tasks.

Examples of pretrained translation models used
in this way include M2M-100 (Fan et al., 2020)
and NLLB (NLLB Team et al., 2024), which sup-
port a wide range of African languages. For lan-
guage modeling, models vary across architectural
paradigms—encoder-only (Ogueji et al., 2021;
Oladipo, 2024; Conneau et al., 2020b; Imani et al.,
2023), decoder-only (Xue et al., 2021; Adebara
et al., 2024), and encoder-decoder—and in their
scope as monolingual (Abdaoui et al., 2021; Chuk-
wuneke et al., 2022; Martin et al., 2022; Nzey-
imana and Niyongabo Rubungo, 2022; Olawole
et al., 2024) or multilingual systems (Ogueji et al.,
2021; Oladipo, 2024; Adebara et al., 2023b).

In recent years, including the period covered by
this survey, there has been a surge in the devel-
opment of general-purpose LLMs, often multilin-
gual and containing billions of parameters. These
models support zero-shot and few-shot learning
through the in-context learning paradigm, making
them adaptable to a wide range of downstream
tasks with minimal task-specific supervision.

These LLMs include open-source and propri-
etary models. Although the training data and lan-
guage coverage for proprietary models are often
undisclosed, open models are typically trained on
data from high-resource languages. Evaluations of
both open and closed models on a range of tasks in
African languages consistently show relatively poor
performance, highlighting persistent challenges in
cross-lingual generalization and data representation
for low-resource languages.

We highlight several models’ names in Table 4.
For models and datasets covering a single language,
we include the ISO-3 code for that language. In
cases where the data pertain to dialects of non-
indigenous African languages, such as African Por-
tuguese (APs) and African English (AEAs), we use
appropriate dialectal labels instead.


Name Task Number
NLU Tasks

Taxi-1500 (Ma et al., 2023) 420
SIB-200 (Adelani et al., 2024) 53.
MasakhaNEWS (Adelani et al., 2023) 16
KINNEWS and KIRNEWS (Niyongabo et al., 2020) 2
Amharic TC (Azime and Mohammed, 2021) 1 (amh)
Emakhuwa TC (Ali et al., 2024a) text classification 1 (vmw)
AfriNLI (Adelani et al., 2025) NLI 16
AfriSenti (Muhammad et al., 2023) sentiment anal: 14
NaijaSenti (Muhammad et al., 2022) sentiment anal: 4
NollySenti (Shode et al., 2023) sentiment analysis 4
OMCD (Sibeko and van Zaanen, 2024) off. lang. detection 1 (ary)
MT Tasks

FLORES-200 (NLLB Team et al., 2024) MT 53
NTREX-128 (Federmann et al., 2022) MT 24
MAFAND-MT (Adelani et al., 2022a) MT 16
TICO-19 (Anastasopoulos et al., 2020) MT 12
WikiMatrix MT

MENYO-20k (Akinade et al., 2023) MT 1 (yor)
AGE (Ademtew and Birbo, 2024) MT 1 (amh)
Emakhuwa News MT (Ali et al., 2024a) MT 1 (vmw)
Emakhuwa-FLORES (Ali et al., 2024b) MT 1 (vmw)
Question Answering

Belebele (Bandarkar et al., 2024) MRC 53:
AfriMMLU (Adelani et al., 2025) QA 16
AfriQA (Ogundepo et al., 2023) QA 10
NaijaRC (Aremu et al., 2024) MRC 3

TyDi QA (Clark et al., 2020) QA 1 (swh)
KenSwQuAD (Wanjawa et al., 2023) QA 1 (swh)
Amh-QuAD (Taffa et al., 2024) QA 1 (amh)
Y-NQ (Costa-jussa et al., 2025) QA 1 (yor)
Reasoning

AfriMGSM (Adelani et al., 2025) Math 17
LINGOLY (Bean et al., 2024) Linguistic 13
MGSM (Shi et al., 2023) Math 1 (swh)
XCOPA (Bean et al., 2024) Commonsense 1 (swh)
Information Extraction

MasakhaNER 2.0 (Adelani et al., 2022b) IE 20
MasakhaNER (Adelani et al., 2021a) IE 10
MphayaNER (Mbuvha et al., 2023) NER 1 (ven)
Information Retrieval

AfriQA (Ogundepo et al., 2023) IR 10
CIRAL (Adeyemi et al., 2024) IR 4
MIRACL (Zhang et al., 2023) IR 2

Mr. TyDi (Zhang et al., 2021) IR 1 (swh)
Syntax: Parsing

MasakhaPOS (Dione et al., 2023) POS 20
NguniPOS (Sibeko and van Zaanen, 2024) POS 4

YTB (Ishola and Zeman, 2020) DP 1 (yor)
Tswana TB (Gaustad et al., 2024) DP 1 (tsn)
Swahili TB (Steimel and Kiibler, 2023) DP 1 (swh)
CACO (Gezmu et al., 2021b) POS 1 (amh)
PALMA (Hagemeijer et al., 2022a) POS 0 (APs)
NArabizi treebank (Seddah et al., 2020) DP 0 (NAA)
{Spoken} Language/Dialect Identification

OpenLID (Burchell et al., 2023) LID 53:
VoxLingual07 (Valk and Alumiie, 2020) SLID 13:

Text Generation

AfriWOZ (Adewumi et al., 2023) Dialogue Generation 6
TATA (Gehrmann et al., 2023) Table-to-text 6

YAD (Olawole et al., 2024) ADR 1 (yor)
SepediRadio Corpus (Ramalepe et al., 2023) Text Generation 1 (nso)
Text Summarization

CrossSum (Bhattacharjee et al., 2023) Summarization 6
XL-Sum (Hasan et al., 2021) Summarization 6
Speech Tasks

BibleMMS (Lux et al., 2024) TTS 59
Yodas (Li et al., 2023) ASR 56
FLEURS (Conneau et al., 2022) ASR 20
FLEURS-R (Ma et al., 2024) TTS 20
SpeechTaxi (Keller and Glavas, 2024) Speech Classification 8
SD-QA (Faisal et al., 2021) Spoken QA 7 (AEAs)
BibleTTS (Meyer et al., 2022) TTS 6
Zambezi Voice (Sikasote et al., 2023b) ASR 4
African Voices (Ogayo et al., 2022) TTS 6
Nicolingua (Doumbouya et al., 2021) ASR 3
Kallaama (Gauthier et al., 2024) ASR 3
LRSC (Kimanuka et al., 2024) ASR 1 (lin)
VoxMg (Ramanantsoa, 2023) ASR 1 (pit)
EYASE (Abdel-Hamid, 2020) Sp. emotion recog 1 (arz)
SADA (Alharbi et al., 2024) ASR 1 (arz)
AfriSpeech-200 (Olatunji et al., 2023b) ASR 0 (AEAs)
EdAcc (Sanabria et al., 2023) ASR 0 (AEAs)
Afro-TTS (Ogun et al., 2024b) TTS 0 (AEAs)
PidginASR (Ajisafe et al., 2020) ASR 1 (pem)
Unlabeled Text / Language Modeling

GlotCC (Kargaran et al., 2024a) LM 251
EMMA-500 (Ji et al., 2024) LM 217
FineWeb (Penedo et al., 2024) LM 90
MADLAD-400 (Kudugunta et al., 2023) LM 87
Bloom (Leong et al., 2022) LM 87
WURA (Oladipo et al., 2023) LM 16
mC4 (Xue et al., 2021) LM 13
CulturaX (Nguyen et al., 2024b) LM 7
CulturaY (Thuat Nguyen and Nguyen, 2024) LM 3
HPLT (de Gibert et al., 2024) LM 3
TLMD (Gaim et al., 2021) LM 1 (tir)
Unlabeled Speech / Speech Representation Learning

MMS ulab v2 (Pratap et al., 2024; Chen et al., 2024c) SRL 1450
Jesus Dramas (Chen et al., 2024c) SRL 88
Nicolingua (Doumbouya et al., 2021) SRL 10
Zambezi Voice (Sikasote et al., 2023b) SRL 4
CSRC (Kimanuka et al., 2024) SRL 4

Table 3: Some publicly available datasets including
African languages published between 2019 and 2024.

35

Name Task Number
Translation Models

Toucan (Elmadany et al., 2024) MT 517
NLLB-200 (NLLB Team et al., 2024) MT 53
MADLAD-MT (Kudugunta et al., 2023) MT 19
M2M- 100 (Fan et al., 2020) MT 17
SMaLL-100 (Mohammadshahi et al., 2022a) MT 17
Encoder Language Models

Serengeti (Adebara et al., 2023b) Encoder LM 517
Glot500-m (Imani et al., 2023) Encoder LM 517
AfroXLMR-76L (Adelani et al., 2024) Encoder LM 76
AfroLM (Dossou et al., 2022) Encoder LM 23
AfriBERTaV2 (Oladipo, 2024) Encoder LM 23
AfroXLMR (Alabi et al., 2022) Encoder LM 17
AfriBERTa (Ogueji et al., 2021) Encoder LM 11
RemBERT (Chung et al., 2020) Encoder LM 11
mDeBERTaV3 (He et al., 2021) debrt LM 11
XLM-R (Conneau et al., 2020b) Encoder LM 8
EthioLLM (Tonja et al., 2024a) Encoder LM 5
Nguni-XLMR (Meyer et al., 2024) Encoder LM 4
KinyaBERT (Nzeyimana and Niyongabo Rubungo, 2022) Encoder LM 1 (kin)
PuoBERTa (Marivate et al., 2023) Encoder LM 1 (tsn)
SwahBERT (Martin et al., 2022) Encoder LM 1 (swh)
IgboBERT (Chukwuneke et al., 2022) Encoder LM 1 (ibo)
DziriBERT (Abdaoui et al., 2021) Encoder LM 1 (arq)
EgyBERT (Qarah, 2024) Encoder LM 1 (arz)
Decoder Language Models

MADLAD (Kudugunta et al., 2023) Decoder LM 87
Goldfish (Chang et al., 2024) Decoder LM 63
BLOOM (Scao et al., 2022) Decoder LM 92:
XGLM (Lin et al., 2022) Decoder LM 20
LLaMAX (Lu et al., 2024) Decoder LM 20
LLaMAX-Alpaca (Lu et al., 2024) Decoder LM/MT 20
Afrilnstruct (Uemura et al., 2024) Decoder LM 19
AfroLLaMa"? Decoder LM 5
InkubaLM (Tonja et al., 2024b) Decoder LM 5
mGPT (Shliazhko et al., 2024) Decoder LM 3
Walia-LLM (Azime et al., 2024) Decoder LM 1 (amh)
Amharic-LLaMA (Andersland, 2024) Decoder LM 1 (amh)
Encoder-Decoder Language Models

Cheetah (Adebara et al., 2024) Enc-Dec LM 517
AfriMBART (Adelani et al., 2022a) Enc-Dec LM 1%
Afri{M,By}TS5 (Adelani et al., 2022a) Enc-Dec LM 17
AfriTeVa V2 (Oladipo et al., 2023) Enc-Dec LM 16
Aya-101 (Ustiin et al., 2024) Enc-Dec LM 15
mTO (Muennighoff et al., 2023) Enc-Dec LM 14
mT5 (Xue et al., 2021) Enc-Dec LM 13
ByTS (Xue et al., 2022) Enc-Dec LM 13
mLongTS (Uthus et al., 2023) Enc-Dec LM 13
AfriTeVa (Jude Ogundepo et al., 2022) Enc-Dec LM 11
EthioMTS (Tonja et al., 2024a) Enc-Dec LM 5
OyoTS5 (Olawole et al., 2024) Enc-Dec LM 1 (yor)
Speech encoders

XEUS (Chen et al., 2024c) Speech Rep. 1439
MMS (Pratap et al., 2024) Speech Rep. 1396
AfriHuBERT (Alabi et al., 2024b) Speech Rep. 1226
SSA-HuBERT (Caubriére and Gauthier, 2024) Speech Rep. 21
mHuBERT- 147 (Zanon Boito et al., 2024) Speech Rep. 16
XLSR-128 (Babu et al., 2022) Speech Rep. 12
Toolkits

OccGen (Costa-jussa et al., 2022) Bias, Data selection 1 (swh)
Lesan (Hadgu et al., 2021) MT 1 (amh)
AfroLID (Adebara et al., 2022b) LID 517
OpenLID (Burchell et al., 2023) LID 53
GlotScript (Kargaran et al., 2024b) LID 2250

Platforms
Mozilla Common Voice (Ardila et al., 2020)
Lanfrica (Emezue and Dossou, 2020a)

Table 4: Some publicly available models, toolkits and
platforms including African languages published be-

tween 2019 and 2024.
