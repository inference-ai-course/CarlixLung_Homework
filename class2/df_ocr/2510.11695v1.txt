2510.11695v1 [cs.CL] 13 Oct 2025

arXiv

When Agents Trade: Live Multi-Market Trading Benchmark for

Lingfei Qian
The Fin AI
New Haven

Connecticut, USA

Xueqing Peng
The Fin AI
New Haven

Connecticut, USA

LLM Agents

Yan Wang
The Fin AI
New Haven

Connecticut, USA

Vincent Jim
Zhang
The Fin AI

New Haven
Connecticut, USA

Yueru He
Columbia University
New York, New York
USA

Peng Lu
Université de
Montréal
Montréal, Quebec
Canada

Sophia
Ananiadou
National Centre for
Text Mining, University
of Manchester
Manchester, United
Kingdom

Huan He

The Fin AI

New Haven
Connecticut, USA

Haohang Li
Stevens Institute of
Technology

Hoboken, New Jersey
USA

Jian-Yun Nie
Université de
Montréal
Montréal, Quebec
Canada

Zehan Li Hanley Smith Yi Han
DeepKin PAAL AI Georgia Institute of
New Haven Toronto, Ontario Technology
Connecticut, USA Canada Atlanta, Georgia, USA
Yupeng Cao Yangyang Yu Alejandro
Stevens Institute of Stevens Institute of Lopez-Lira
Technology Technology University of Florida
Hoboken, New Jersey Hoboken, New Jersey Gainesville, Florida
USA USA USA
Guojun Xiong Jimin Huang”
Harvard University The Fin AI
Cambridge New Haven
Massachusetts, USA Connecticut, USA
National Centre for
Text Mining, University
of Manchester
Manchester, United
Kingdom
Abstract

Although Large Language Model (LLM)-based agents are increas-
ingly used in financial trading, it remains unclear whether they
can reason and adapt in live markets, as most studies test models
instead of agents, cover limited periods and assets, and rely on
unverified data. To address these gaps, we introduce Agent Market
Arena (AMA), the first lifelong, real-time benchmark for evalu-
ating LLM-based trading agents across multiple markets. AMA
integrates verified trading data, expert-checked news, and diverse
agent architectures within a unified trading framework, enabling
fair and continuous comparison under real conditions. It imple-
ments four agents, including InvestorAgent as a single-agent base-
line, TradeAgent and HedgeFundAgent with different risk styles,
and DeepFundAgent with memory-based reasoning, and evaluates

“Corresponding Author

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

Conference acronym ‘XX, Woodstock, NY

© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-XXXX-X/2018/06

https://doi.org/XXXXXXX.XXXXXXX

them across GPT-40, GPT-4.1, Claude-3.5-haiku, Claude-sonnet-4,
and Gemini-2.0-flash. Live experiments on both cryptocurrency
and stock markets demonstrate that agent frameworks display
markedly distinct behavioral patterns, spanning from aggressive
risk-taking to conservative decision-making, whereas model back-
bones contribute less to outcome variation. AMA thus establishes
a foundation for rigorous, reproducible, and continuously evolv-
ing evaluation of financial reasoning and trading intelligence in
LLM-based agents.

CCS Concepts

- Information systems — Data analytics; Data stream min-
ing; - Computing methodologies — Multi-agent systems; -
Applied computing — Economics.

Keywords

Live trading benchmark, Multi-agent, Large language models, Fi-
nancial decision systems

ACM Reference Format:

Lingfei Qian, Xueqing Peng, Yan Wang, Vincent Jim Zhang, Huan He, Zehan
Li, Hanley Smith, Yi Han, Yueru He, Haohang Li, Yupeng Cao, Yangyang
Yu, Alejandro Lopez-Lira, Peng Lu, Jian-Yun Nie, Guojun Xiong, Jimin
Huang, and Sophia Ananiadou. 2018. When Agents Trade: Live Multi-
Market Trading Benchmark for LLM Agents. In Proceedings of Make sure


Conference acronym ’XX, June 03-05, 2018, Woodstock, NY

to enter the correct conference title from your rights confirmation email
(Conference acronym ’XX). ACM, New York, NY, USA, 12 pages. https:
//doi.org/XXXXXXX.XXXXXXX

1 Introduction

Can large language model (LLM)-based agents truly trade in real
time? This question sits at the cutting edge of financial artificial in-
telligence, where language models are transforming from static text
generators into autonomous decision-making systems that perceive,
plan, and act in dynamic environments [11, 21]. Financial markets,
which are volatile, high-dimensional, and unforgiving, offer per-
haps the most stringent test of this emerging intelligence [1, 20, 28].
Trading is not about isolated predictions, but about making sequen-
tial, high-stakes decisions in a world that changes every second. To
succeed, agents must not only understand market narratives but
also adapt continuously to unfolding events, uncertain feedback,
and adversarial forces [7, 19, 39].

There are multiple efforts attempting to answer this question.
DeepFund [17] marks a significant step forward, introducing a
multi-agent framework that integrates live data streams to simu-
late real-time decision-making. InvestorBench [18] expanded static
evaluation into trading simulations, replaying historical data to
assess hypothetical returns. Beyond these, benchmarks focused on
financial sentiment analysis [24, 25], event extraction [12, 16], and
financial text understanding [42, 46] advanced domain comprehen-
sion but did not capture adaptivity or feedback, the hallmarks of
real-world trading.

Despite all these efforts, it is still nontrivial to answer the ques-
tion, as existing benchmarks continue to face three fundamental
challenges. Firstly, existing work mainly evaluates models rather
than agents. Frameworks such as DeepFund [17] and Investor-
Bench [18] are tied to fixed agent structures, which evaluate model
backbones rather than the agents themselves. Even when different
LLMs are substituted, performance trends remain similar, suggest-
ing that identical frameworks lead to convergent decision behaviors.
Secondly, the evaluation scope is extremely limited. DeepFund
tests agent with only a limited time period of 24 days that focuses
only on U.S. stocks (Apple, American Express, Bank of America,
Coca-Cola, and Chevron), meaning just 24 decisions per stock in
total. Such a narrow setup offers little insight into how agents gener-
alize across diverse market regimes, particularly when transitioning
between bullish and bearish conditions, or longer trading horizons.
Thirdly, the input data lacks consistency and verification. Exist-
ing trading benchmarks rely on heterogeneous data sources, such
as yfinance! and Finnhub’, to retrieve market prices and news.
However, existing benchmarks do not follow a unified data acquisi-
tion protocol, and their news feeds frequently overlap or contradict
caused by leveraging multi API sources. The same market event
may appear multiple times or with varying emphasis across sources,
introducing redundancy and inconsistency. Such unverified and
noisy inputs distort the informational environment available to
agents, thereby undermining the reliability and interpretability of
their trading decisions.

‘https://pypi.org/project/yfinance/
“https://finnhub.io/

Lingfei et al.

To fill this gap, we propose Agent Market Arena (AMA), the first
lifelong, real-time, and multi-class-asset evaluation framework for
LLM-based trading agents, built entirely on verified and continu-
ously updated market data. AMA has been live for two months and
will remain active as an open, evolving benchmark that grows along-
side real markets. The defining features of AMA lie in its unified
protocol, verified information streams, and multi-class-asset market
coverage. The protocol standardizes how agents interact with the
market. Every agent starts with the same initial capital, trades at a
fixed daily time, and follows identical execution and feedback rules,
ensuring fair and reproducible evaluation. AMA also maintains
a verified information pipeline that continuously integrates price
data, financial news, and company reports. Each stream is standard-
ized, summarized, and checked for factual accuracy, consistency,
and neutrality through a expert verification, providing reliable and
unbiased inputs for trading decisions. In addition, AMA connects
to diverse markets spanning equities and cryptocurrencies, offering
a realistic and dynamic testbed for adaptive reasoning.

Based on it, for the first time, a set of state-of-the-art LLM—based
agent systems has been deployed to operate continuously in two
stocks (TESLA (TSLA) and BIoMARIN PHARMACEUTICAL (BMRN))
and two cryptocurrencies (ETHEREUM (ETH) and Bitco1n (BTC)).
The deployment began two months ago and has since run with-
out interruption, executing daily trades and adapting to real-time
market fluctuations. The system includes InvestorBench [18],

TradeAgent [40], HedgeFundAgent [37], and DeepFundAgent [17],

each representing distinct reasoning strategies, ranging from ag-
gressive trading to conservative hedging, and from role-based to
memory-adaptive decision-making. For each agent framework, we
further test multiple LLM backbones, enabling AMA to disentangle
the effects of agent architecture and model choice under identi-
cal trading conditions. All trading activities are logged through
the AMA evaluation pipeline’, producing a continuously growing
dataset of real-world decisions and outcomes. Performance is mea-
sured using standard financial metrics, including cumulative return,
annualized volatility, maximum drawdown, and sharpe ratio, al-
lowing consistent and interpretable comparison across agents and
markets.

Our two-month live trading results show that LLM-based agents
can consistently show promising capabilities in making trading deci-
sions, demonstrating genuine reasoning ability in dynamic financial
environments. Across all assets and sessions, agent architecture
proved to be the dominant factor shaping behavior. InvestorAgent
achieved Sharpe ratios of 6.47 on TSLA, outperforming Buy &
Hold with smoother returns and lower drawdowns. DeepFundA-
gent reached 2.45 on BTC, showing that memory-based reason-
ing improves adaptability under volatility. TradeAgent and Hedge-
FundAgent favored aggressive risk selection, delivering remarkable
returns accompanied by elevated volatility. Changing the LLM
backbone among GPT-40[15], GPT-4.1[27], Claude-3.5-haiku[2],
Claude-sonnet-4[3], and Gemini-2.0-flash[10] shifted outcomes by
less than agent switching, confirming that these patterns are stable
and reproducible across models.

Our contributions could be summarized as follows.

3https://finai-interface.vercel.app/paper-trading


When Agents Trade: Live Multi-Market Trading Benchmark for LLM Agents

>Firstly, we introduce Agent Market Arena, the first lifelong,
real-time benchmark for evaluating LLM-based financial agents
under live market conditions.

>Secondly, we construct a verified dataset that covers multi mar-
kets, integrating real trading data with expert-reviewed financial
news to ensure factual accuracy, neutrality, and continuous updates.

> Thirdly, we implement a diverse suite of trading agents, in-
cluding single-agent, multi-agent, with various role and memory-
adaptive designs, to examine how agent structures and the trading
style shape performance across assets.

> Finally, we build a transparent leaderboard that records prof-
itability and adaptability over time, offering an open and repro-
ducible platform for studying intelligent financial agents.

2 Related Work
2.1 Benchmarking LLMs in Financial Domain

There is now a growing body of work on financial benchmarks.
Early financial NLP benchmarks [5, 6, 22, 33, 38, 42] such as Fin-
Ben [41] expanded evaluation beyond sentiment and QA to include
retrieval augmented tasks and multi-step decision-making prob-
lems, yet they remained largely static and English-centric. There
were also efforts [29, 47] introduced benchmarks broadening the
linguistic focus beyond English and Chinese, while MultiFinBen[30]
extended these observations to multilingual and multimodal evalu-
ation. FinReason[31] further introduced financial reasoning tasks,
showing that generic reasoning models degrade on financial data.

2.2 Trading Agents and Live Benchmark

There is also a growing line of research that explores using LLMs or
agents to make decisions and study their performance in decision-
making. A growing set of studies has begun to design and an-
alyze trading agents. FinMem[44] and InvestorBench[18] intro-
duced memory-augmented LLM agents and benchmarked them
over backtesting market information. FLAG-TRADER[43] com-
bined language models with policy-gradient training for sequential
decision making. FinCon[45] extended the memory updating to
multi-agent interaction, proposing a framework for single-stock
trading and portfolio management, incorporating hierarchical com-
munication and risk control. HedgeFundAgents[37] advanced this
direction by modeling a hedge-fund hierarchy, coordinating a cen-
tral manager with hedging experts to achieve more robust re-
turns. TradeAgents[40] further explored decentralized coordina-
tion among specialized trading agents, highlighting how division
of labor can improve market decision making. Yet these systems
often operate in static environments. To address benchmark leak-
age and excessive intervention, DeepFund[17] proposed a live
multi-agent arena for fund investment, enabling dynamic eval-
uation of LLM-driven strategies.

3 Agent Market Arena: Real-time trading and
competition
The overall framework of Agent Market Arena is illustrated in

Figure 1. It is designed to evaluate how different agent frameworks
perform when given access to the real-time market environment.

Conference acronym XX, June 03-05, 2018, Woodstock, NY

1. Market Intelligence Stream

Multiple Sources

QB vr cve © YiFinance © Binance
@ Finnhub (3) CryptoNews
YS AA
11d

Quality Control by Human Expert

= Finnhub
Se

GPT-5-nano News

Filter
rele

i Y Prices

¥ RY
| PRICE Y

Daily Market | 5==

Information | 3 —

2. Agent Execution Protocol tb

Summarize

1. Time accuracy
2. Coverage
3. Bias awareness

3. Performance Analysis Interface

ea aaa eee aaa ~“
| ee :
q 1
InvestorAgent ! ! HedgeFundAgent I
| = | 0)
| 0 |
| )

TradeAgent 5) DeepFundAgent
i Sst

Figure 1: Overall framework of Agent Market Arena.

It consists of three main components. First, the Market Intel-
ligence Stream (MIS) continuously aggregates data from multiple
sources and generates high-quality daily summaries of market con-
ditions. The summary is reviewed by financial experts to ensure
accuracy, completeness, and neutrality. Second, the Agent Execu-
tion Protocol (AEP) provides a unified environment for deploying
multiple trading agents, allowing each to access the verified updates
and make independent trading decisions across evaluated assets.
Finally, the Performance Analytics Interface (PAI) offers a continu-
ously updated dashboard that tracks and compares the real-time
performance of all agents built on different LLM backbones, provid-
ing a transparent view of profitability, stability, and adaptability.

3.1 Market Intelligence Stream (MIS)

We begin by collecting real-time market data from a wide range
of heterogeneous sources to ensure both coverage and accuracy.
These include general-purpose APIs and online news aggregators.
We leverage sources such as OpenAI Web Search 4, Finnhub, News-
Data’, yifinance, CryptoNews®, and Binance’, which provide access
not only to news streams from established financial outlets, but
also to social media content. This ensures that both API-driven

‘https://platform.openai.com/docs/guides/tools-web-search?api-mode=responses
Shttps://newsdata.io/

Shttps://cryptonews.com/

Thttps://www.binance.com/en


Conference acronym ’XX, June 03-05, 2018, Woodstock, NY

feeds, direct news content, and integrated social media signals from
platforms such as Twitter® and Reddit? are incorporated to cap-
ture emerging sentiment. This multi-source integration reduces the
bias of relying on a single channel and provides a broader, more
balanced, and truly real-time view of the market environment.

Despite the diversity of sources, much of the content may par-
tially overlap, which could introduce bias if the same information
repeatedly appears to the agents. To address this, we apply a sum-
marization step to consolidate the news and prevent redundancy
from distorting the evaluation. We use GPT-5-nano for this task,
with implementation details provided in Appendix A.

Quality control. To rigorously evaluate the quality of the sum-
marized news, we randomly sample 20 daily items from the gener-
ated outputs, covering both equities and cryptocurrencies, 20 days
for each. Following the focus of previous works, two independent
annotators assess each item according to the following criteria: (1)
Date Accuracy[8]: Each item must correspond precisely to the
intended trading date and the associated assets. (2) Coverage[36]:
The sample must include all major news of the day directly related
to the target assets across the principal categories that drive prices,
ensuring that no significant asset-related information is omitted.
(3) Bias Awareness[9]: Determine whether the summarization
process introduces any additional or noticeable bias that is absent
from the original content. For each criterion, we adopt a three-level
scale: 0 indicates not satisfied, 1 indicates partially satisfied, and 2
indicates fully satisfied.

The evaluation was conducted independently by two annotators
using the 20-day samples for both equities and cryptocurrencies.
Results show strong consistency: date accuracy agreement reached
87.5%, coverage 92.5%, and bias awareness 100%. Most date dis-
crepancies (7 cases, score = 1) were due to API latency, where the
retrieved link was current but the article content lagged by one
or two days. Four cases received a score of 1 for coverage, pri-
marily due to partially incomplete summaries that omitted minor
updates—such as relevant company name changes, indicating shifts
in business direction. These omissions were considered acceptable,
as all major market-moving events were accurately captured within
the evaluated summaries. For the bias awareness, no summariza-
tion was found to introduce bias or sentiment beyond what existed
in the original news sources. This rigorous daily quality control
ensures that the benchmark reflects high-fidelity, real-time market
narratives and minimizes the propagation of outdated or biased
information into agent evaluation.

3.2 Agent Execution Protocol (AEP)

The Agent Execution Protocol (AEP) defines how all agents in AMA
interact with the market environment. It standardizes three core
components, including inputs, outputs, and configuration, to ensure
that performance differences arise from reasoning ability rather
than implementation variance.

Inputs. Each agent receives identical daily inputs, including
verified market data and the summarized news from the MIS. The
information is structured into a unified prompt format contain-
ing asset identifiers, historical prices, recent news summaries, and

Shttps://x.com/?lang=en
°https://www.reddit.com

Lingfei et al.

contextual trading metadata. This consistent input design guaran-
tees that all agents operate under the same market knowledge and
temporal conditions.

Outputs. Agents produce discrete daily actions from the same
action space: BUY, SELL, HOLD. These actions are used to update
the simulated portfolio and compute next-day returns. A BUY action
means the agent expects the asset’s value to rise and increases its po-
sition; a SELL action indicates the opposite expectation; and a HOLD
action reflects neutrality or uncertainty, keeping the current posi-
tion unchanged. All trading decisions are executed synchronously
at the same fixed time, ensuring fair comparison across models and
markets.

Prompts and Hyperparameters. Each agent is additionally
guided by a structured system prompt that defines trading strategy
and action descriptions. To maintain fairness, generation parame-
ters such as temperature, retry times are fixed across all agents and
backbones ?°.

InvestorAgent([18] is a single-agent framework that integrates a
memory module to store historical trading decisions and contextual
information. It analyzes past outcomes to extract actionable insights,
which are then used to refine future optimization and decision-
making processes.

TradeAgent[40] follows a multi-agent architecture inspired
by real-world trading firms. Rather than relying solely on fixed
technical indicators, it orchestrates specialized roles—such as fun-
damental, sentiment, news, and technical analysts—whose insights
are debated by researcher agents and then aggregated by a trader
agent. Final trade proposals are checked by risk management and a
portfolio manager before execution.

HedgefundAgent([37] models a hedge-fund team by orches-
trating specialized agents that follow characters of famous trading
people, like Aswath Damodaran and Ben Graham, among others,
each simulate distinct roles in the investment process. Their signals
are aggregated by a portfolio manager to produce trade intents,
while a risk manager computes risk metrics and enforces position
limits.

DeepFundAgent[17] is designed to test adaptability by pro-
cessing streaming inputs, generating trade signals, and updating
positions based on history portfolio updates that stored in mem-
ories, as well as the media, technical analysis. This setup enables
an assessment of how LLM-based decision systems perform in dy-
namic environments compared to rule-based or static benchmarks.

3.3 Performance Analytics Interface (PAI)

Each agent makes one trading decision per day, represented as
a signal w, € {1,—-1,0}, where w; = 1 means buying the asset,

wr = —1 means selling it, and w; = 0 means holding the current
=Pi-i

position. The agent’s daily return is: r; = w; He , and its overall

performance over time is tracked through cumulative return: R, =

W147i) -1.

1For more details, please check Appendix B


When Agents Trade: Live Multi-Market Trading Benchmark for LLM Agents

Conference acronym XX, June 03-05, 2018, Woodstock, NY

=] iC) TSLA BMRN BTC ETH

# = 3 > EN =
cS) € 3s 2, s & € 3s 2, s € € Fs ps €& € FS nz 8

SS SS SS = 8 Ss & ss S 8 Ss & SS S 8 Ss s Sy Ras 8

§ <¢ & &§ § & <= = § &§ § 3 & § §& & <= & & &
Buy & Hold - 46.88 962.13 40.89 6.00 6.34 -6.89 -35.53 29.03 -1.37 15.03 0.66 4.02 30.05 0.28 11.95 18.56 176.92 FAs. 1.77 20.23
GPT-40 33.01 783.38 42.32 5.37 6.34 -5.33 -25.93 26.99 -0.98 14.36 -1.22 -7.10 20.77 = -0.25 8.79 -1.98 -11.29 55.58 0.06 22.13
GPT-4.1 40.83 764.39 34.35 6.47 4.38 3.79 23:19. 24.33 0.98 7.35 -3.34 -18.40 20.32 -0.90 9.92 1.35 8.38 50.73 0.41 23.76
InvestorAgent Gemini-2.0-flash 10.57 80.22 42.30 1.60 8.50 -13.88 -53.62 25.23 -2.92 19.57 -2.78 -15.51 19.58 -0.76 10.20 -6.39 -32.64 64.98  -0.28 32.27
Claude-3.5-haiku 11.55 124.83 38.35 2.30 8.35 -8.35 -41.48 25.49 -1.97 15.24 -7.06 -35.46 30.02 -1.31 15.18 5.05 34.29 71.94 0.76 22.98
Claude-sonnet-4 28.91 328.14 41.01 3.76 8.41 -6.89 -34.58 28.34 -1.36 15.12 -6.48 -33.04 25.93 -1.42 12.62 5.56 38.20 61.40 0.83 27.17.
Vote 29.13 293.80 37.68 3.83 8.37 -5.47 -28.08 27.50 -1.06 13.64 -2.19 -12.43 22.16 -0.49 9.68 -1.97 -11.20 58.80 0.09 28.80
GPT-40 -4.25 -54.22 22.36 = -3.38 5.73 -1.95 -22.97 21.56 -1.11 7.81 -5.05  -26.67 7.50 -4.09 5.05 -6.23 -31.95 31.78 -1.05 15.95
GPT-4.1 -38.72 -94.33 50.68 -5.38 38.72 4.84 27.51 23.39 1.15 6.20 -5.65 -29.41 28.83 -1.07 9.76 -11.42 -51.61 68.44 = -0.72 24.75
TradeAgent Gemini-2.0-flash 21.91 203.20 30.23 3.82 6.41 -0.31 -1.61 22:11 0.04 9.46 5.02 34.09 24.27 1.33 5.83 9.78 74.78 52.88 1.32 16.01
Claude-3.5-haiku -6.62 -36.48 25.72 -1.64 11.05 -9.45 -40.61 16.81 3.01 13.85 -14.51 -60.85 24.07 -3.77 16.37  -12.93 -56.31 50.12 -1.40 15.21
Claude-sonnet-4 -5.43 -24.10 26.42 -0.91 12.89 14.57 121.92 21.86 3.76 3.81 -13.02 -5661 26.36 -3.03 15.02 -12.35 -54.57 41.10 -1.71 20.50.
Vote -0.36 -2.30 24.44 0.02 9.03 1:22 7.55 18.90 0.48 6.70 -7.28 -36.39 23.83 -1.78 11.53 -9.89 -46.39 40.12 -1.35 14.57
GPT-40 -29.15 -84.86 40.94 -4.39 29.15 23.70 247.76 26.59 4.83 5.59 -9.09 -43.46 29.97 -1.76 11.14 39.66 638.04 69.75 3.21 14.63
GPT-4.1 -29.15 -84.86 40.94 -4.39 29.15 23.70 247.76 26.59 4.83 5.59 -9.09 -43.46 29.97 -1.76 11.14 39.66 638.04 69.75 3.21 14.63
HedgeFundAgent Gemini-2.0-flash -29.15 -84.86 40.94 -4.39 29.15 23.70 247.76 26.59 4.83 5.59 -9.09 -43.46 29.97 -1.76 11.14 39.66 638.04 69.75 3.21 14.63
Claude-3.5-haiku —-29.15 -84.86 40.94 -4.39 29.15 23.70 247.76 26.59 4.83 5.59 -9.09 -43.46 29.97 -1.76 11.14 39.66 638.04 69.75 3.21 14.63
Claude-sonnet-4 -29.15 -84.86 40.94 -4.39 29.15 23.70 247.76 26.59 4.83 5.59 -9.09 -43.46 29.97 -1.76 11.14 39.66 638.04 69.75, 3.21 14.63
Vote -29.15 -84.86 40.94 -4.39 29.15 23.70 247.76 26.59 4.83 5.59 -9.09 -43.46 29.97 -1.76 11.14 39.66 638.04 69.75 3.21 14.63
GPT-40 13.89 95.19 37.14 1.98 7.61 3.72 22.68 25.89 0.92 8.92 -0.30 -1.80 24.35 0.04 7.98 18.03 169.68 71.07 1.74 21.86
GPT-4.1 -5.52 -27.77 37.30 -0.69 19.22 4.86 29.67 16.67 1.64 3.49 0.44 2.68 1.08 2.45 0.00 2.89 18.56 58.62 0.57 26.08
DeepFundAgent Gemini-2.0-flash -8.04 -55.62 20.40 -3.88 8.04 3.59 20.84 24.77 0.89 6.57 0.00 0.00 0.00 0.00 0.00 -13.11 -56.85 40.55 -1.87 22.20
Claude-3.5-haiku —-15.43 -57.76 38.49 -2.04 28.48 -1.12 -6.01 26.80 -0.10 12.25 1.67 10.40 27.51 0.50 7.91 10.74 84.08 69.93 1.21 23,11
Claude-sonnet-4 -6.96 -32.07 35.81 -0.90 12.99 5.48 34.81 25.27 1.31 8.52 ~-8.24 -40.23 21.91 -2.24 10.18 8.20 60.29 56.87 1:11 18.58
Vote 8.61 55.75, 36.68 1.39 10.14 9.45 52.43 22.82 1.96 6.42 -0.54 -3.20 1.33 -2.45 0.54 4.91 33.22 65.65 0.75 13.00

Table 1: Merged live trading outcomes for four agents across five backbone models on two stock assets (TSLA, BMRN) and two
crypto assets (BTC, ETH), from Aug 1 to Sep 30. Metrics: CR (Cumulative Return), AR (Annualized Return), AV (Annualized
Volatility), SR (Sharpe Ratio), and MDD (Maximum Drawdown). “Vote” denotes majority-vote ensembles across the backbones.

To assess trading performance, we employ five widely used finan-
cial indicators. The Cumulative Return (CR) [13] measures the to-
tal growth of an agent’s portfolio over the evaluation period, captur-
ing its overall profitability. The Annualized Return (AR) [34] ad-
justs this value toa yearly rate, Rannual = (1+R;) FP 4 allowing com-
parisons across different time spans. To quantify risk, we compute
the Annualized Volatility (AV) [14] as Cannual = V252 x std(r;),
which reflects how much the agent’s daily returns fluctuate. The

Sharpe Ratio (SR) [35], given by S = f

annual

ciently the agent converts risk into return, assuming a risk-free rate
rf = 0. Finally, the Maximum Drawdown (MDD) [23] is defined

, evaluates how effi-

maxi<t Ri-Rr
max;<; Rj

as Dmax = max; ( ) capturing the largest observed loss

from a peak to a trough and indicating downside exposure.

All metrics are updated daily and displayed on a real-time leader-
board that compares the profitability, stability, and adaptability of
agents across different LLM backbones and market types.

4 Experiment Settings

LLM selection. For each agent, we evaluate five different backbone
models from OpenAI, Claude, and Gemini. Specifically, we include
GPT-40, GPT-4.1, Gemini-2.0-flash, Claude-3.5-haiku, and Claude-
sonnet-4.

Assets. We evaluate both equity and cryptocurrency markets to
capture distinct market dynamics and behavioral patterns. Our
representative test assets include Bitcoin (BTC) and Ethereum (ETH)
from the cryptocurrency space, and two publicly traded stocks,
Tesla (TSLA) and BioMarin Pharmaceutical (BMRN), representing
the high-technology and biomedicine sectors, respectively.

Cryptocurrencies such as BTC and ETH operate in highly volatile,
sentiment-driven environments that react rapidly to macroeco-
nomic and policy signals, providing a rigorous test of model adapt-
ability under extreme market fluctuations. [4] In contrast, equities
like TSLA and BMRN are influenced by sector-specific fundamen-
tals—technological innovation, production metrics, or clinical trial
results—allowing us to assess how well the system handles struc-
tured, information-rich contexts. [32] By combining these hetero-
geneous assets, we ensure that the evaluation spans diverse asset
classes, time sensitivities, offering a comprehensive benchmark for
decision-making agents in real-world trading conditions.

Agent initialization and evaluation. To establish historical ground-
ing and construct contextual memory, agents undergo an initializa-
tion phase with data from 2025-05-01 to 2025-07-31, during which
they adapt to recent market dynamics, simulate realistic trading en-
vironments, and form representative portfolio positions. Real-time
evaluation begins on 2025-08-01. As of the paper’s drafting date:
2025-09-30, the agents have completed two months of live trading
and continue to operate autonomously, producing daily trading
actions and performance evaluations in real time.

5 Results

In this section, we examine how different agents perform in a
continuously evolving live trading environment to address the
following research questions (RQs):

e RQ1: Can LLM-based agents truly trade, meaning make
profitable and consistent decisions that outperform simple
Buy & Hold strategies in live markets?


Conference acronym ’XX, June 03-05, 2018, Woodstock, NY

TSLA

25

—254

BMRN

205

BTC

-104

50 + ETH

25

2025-08-01 2025-08-15 2025-09-01 2025-09-15 2025-10-01

—— Deepfundagent —— Hedgefundagent

Investoragent —— Tradeagent

(a) Comparison of aggregated performance of different agents
across four assets.

Lingfei et al.

TSLA

—50

BMRN

20

—10

25

0

—25
2025-08-01 2025-08-15

2025-09-01 2025-09-15 2025-10-01

—— Claude-sonnet-4-20250514 —— GPT-4o — Vote
— GPT-4.1 —— Gemini-2.0-flash © —— claude-3-5-haiku-20241022

(b) Comparison of aggregated performance of different LLMs
across four assets.

Figure 2: Aggregated performance of different agents and LLMs across four assets. The solid line represents the average
cumulative return, while the shaded area indicates the range between the maximum and minimum CR observed when

switching LLMs or agent frameworks.

e RQ2: Which factor contributes more to trading performance,
the agent’s structural framework or the reasoning ability of
its underlying LLM backbone?

e RQ3: How effectively can agents interpret and translate
complex market information into trading decisions that an-
ticipate and adapt to price fluctuations?

e RQ4: How do different trading philosophies, from aggres-
sive to conservative strategies, influence decision-making
behavior and overall profitability across markets?

5.1 Performance of Agents in Live Trading
(RQ1)

Table 1 summarizes the live trading results of all agents across both
cryptocurrency and stock markets. Overall, the findings confirm
that LLM-based agents can indeed trade profitably in real time,
often surpassing simple buy-and-hold strategies while maintaining
stability across dynamic market conditions. The outcomes, however,
vary significantly across agents and asset types, illustrating that
performance depends heavily on design philosophy and market
context.

Among the evaluated systems, DeepFundAgent delivers the
most balanced and consistent results, achieving cumulative returns

of 8.61% on TSLA and 9.45% on BMRN, with annualized volatilities
of 36.68% and 22.82% and Sharpe ratios of 1.39 and 1.96, respectively.
InvestorAgent also performs competitively, particularly under
GPT-4.1, reaching 40.83% cumulative return with a Sharpe ratio of
6.47 on TSLA. It also shows sensitivity to backbone models and as-
sets, with its CR on BMRN dropping from 3.79% (GPT-4.1) to -6.89%
(Claude-sonnet-4). TradeAgent and HedgeFundAgent display
wider fluctuations, with TradeAgent’s returns on TSLA ranging
from —38.72% (GPT-4.1) to 21.91% (Gemini-2.0-Flash). HedgeFundA-
gent demonstrates mixed outcomes, achieving 39.66% CR on ETH
in one setup but negative returns on BTC. Yet it maintains relative
robustness across backbones due to its hierarchical coordination
with sixteen specialized sub-agents feed two managerial agents
that aggregate signals, reducing variance introduced by individual
LLMs.

Across these experiments, no single LLM or agent consistently
outperforms others across all assets. Nevertheless, the results reveal
clear evidence of agent-model complementarity, where certain pair-
ings yield notably stronger outcomes. For instance, TradeAgent cou-
pled with Gemini-2.0-flash attains leading performance on TSLA,
ETH, and BTC, and ranks second on BMRN. InvestorAgent per-
forms best when paired with GPT-4.1, delivering strong results on


When Agents Trade: Live Multi-Market Trading Benchmark for LLM Agents

Conference acronym XX, June 03-05, 2018, Woodstock, NY

‘Agent (color) =

om Buy & Hold
— Tradeagent
— InvestorAgent
1.06 TradeAgent (Gemini-2.0-flash) >
TradeAgent (Gemini-2.0-flash)

SP

LLM (linestyle)

Cumulative Return (x)

08-26 08-31

Date

08-06

Political capital in BTC mining :
jan institutional accumulation H 0.08
Bitcoin-native finance

Difference (x)

—0.02

-0.04

-0.06

09-05 09-10 09-15

09-20

09-25 09-30

Figure 3: Agent performance on BTC under different market events. The bars represent the profit gap between TradeAgent

(Gemini-2.0-flash) and InvestorAgent (GPT-4.1).

both TSLA and BMRN. Similarly, DeepFundAgent achieves its high-
est returns with GPT-4o, exhibiting robust performance on ETH
and TSLA and maintaining competitiveness across remaining as-
sets. This underscores the importance of conducting multi-market
evaluations, which offer broader insights compared to analyses
restricted to a limited set of assets and results.

5.2 Which Matters More: Agent Architecture or
LLM Backbone? (RQ2)

To disentangle the relative influence of agent design and LLM back-
bone on live trading performance, we aggregate outcomes across all
agent-model pairings, as illustrated in Figure 2. Figure 2a reports
the performance of each agent under different LLMs, while Figure
2b summarizes how each LLM performs across agent architectures.

Overall, the results reveal that modifying the underlying LLM
within a fixed agent framework produces only modest changes
in profitability, whereas varying the agent design while holding
the LLM constant leads to far greater performance divergence. For
instance, in Figure 2a, the InvestorAgent results on TSLA cluster
tightly, showing minimal spread across LLM configurations, indi-
cating that switching models has limited effect. By contrast, Figure
2b shows GPT-4.1 (light blue) spanning a wide range of returns
across agents, demonstrating that the structural design of the agent
exerts a stronger influence on trading outcomes than the reasoning
capability of the backbone itself.

These findings suggest that an agent’s architecture, includ-
ing its decision logic, coordination strategy, and risk control
mechanisms, plays a more decisive role in shaping profitabil-
ity and stability than merely upgrading to a more powerful model.
Within the AMA environment, enhancing the way agents utilize
LLM may thus yield greater gains than improving the LLMs alone.

5.3 Understanding Agents’ Decision-Making
Driven by Market Signals (RQ3)

To better understand how agents make trading decisions under real-
time and volatile market conditions, we analyzed the behavior of
TradeAgent and InvestorAgent on BTC, using Gemini-2.0-flash
and GPT-4.1 as backbones. BTC was selected for its high sensitivity
to market news and sentiment. We compared their cumulative

return trajectories against the Buy & Hold baseline (Figure 3) and
examined how each agent interpreted macroeconomic signals and
adapted its strategy during major volatility events. We focus on
three key episodes: August 13, August 28, and September 28, which
capture both successful trades and failed forecasts.

On August 13-14, global equity markets entered a period of
broad-based bullish momentum, with major indices across the U.S.,
Europe, and Asia reaching record highs. This synchronized up-
swing, fueled by policy-easing expectations and renewed sovereign
inflows, was widely described by media as one of the most coordi-
nated global rallies in recent years. [26] Despite overwhelmingly
bullish sentiment, TradeAgent identified the fragility of this ex-
treme optimism, recognizing that an “unprecedented” event lacked
historical equilibrium. It correctly hedged risk near the peak, prof-
iting when prices normalized. On August 28-29, During August
28-29, several rare structural shifts occurred: (1) Political capital
met mining, as the Trump-backed American Bitcoin Corp. listed on
NASDAQ via its merger with Gryphon Digital Mining, marking one
of the first clear intersections between politics and Bitcoin infras-
tructure. (2) Institutional accumulation surged in Asia, with major
Japanese and Korean firms announcing plans to integrate Bitcoin
into their fiscal reserves. (3) Ecosystem innovation advanced, driven
by the RGB protocol and Tether’s integration on the Bitcoin net-
work, expanding Bitcoin’s role beyond a store of value. Although
these were long-term bullish signals, TradeAgent detected short-
term exhaustion in technicals and executed a SELL, accurately
anticipating a short-term correction. By contrast, on September
28-29, the agent’s short position, initially justified by ETF outflows
and synchronized drawdowns, was reversed by a sudden surge
in liquidity and sovereign inflows, leading to a short squeeze. All
agents shared this misjudgment, reflecting the difficulty of reacting
to abrupt macro reversals.

Figure 4 shows that for most of the period, the performance
gap between InvestorAgent (GPT-4.1) and TradeAgent (Gemini-
2.0-flash) remained narrow. InvestorAgent captured the early rally
around August 13 but missed later turning points, allowing TradeAgent
to overtake it by capitalizing on volatility and adapting more dy-
namically to shifting sentiment. These results suggest that the
most successful agents are those capable of exploiting pe-
riods of volatility rather than merely following long-term


Conference acronym ’XX, June 03-05, 2018, Woodstock, NY

Lingfei et al.

—— Buy & Hold
mmm BUY
HOLD

mmm SELL
Bullish

Neutral

108 Bearish

mal
\
1.06 f

.
0.98

HedgeFundAgent:vote

OPP

TradeAgent:vote

InvestorAgent:vote

_ pi
3 1 1
‘1.04 SS
3 . Pe fo eerie npeenens
oO x
Z 1 1 ry ~
N
@ 1.02 ' 1 ry ire | ere
$ é ~
2 a J 1 1\ n 1
8 . weyennnenenen . “A Josnee seenpeee SewEeeae ae ae Ae aan se
\ é 1
£ v aXe : \
§ 100] 3 Wy \ DeepFundAgent:vote i LA p
q at J
/’ a if H
i ees 17
1 MM 1 I
a 1 pal
3 ¥

. CP
aN

o~ Ul

08-01
08-06
08-11
08-16
08-21

08-26

09-05
09-10
09-15
09-20
09-25
09-30

Figure 4: Cumulative return comparison of Buy-and-Hold baseline for BTC (Aug-Sep 2025), annotated with daily news sentiment
(green = bullish, gray = neutral, red = bearish) and agent voting signals (squares: blue = BUY, gray = HOLD, orange = SELL.

trends, as agents that take advantages of volatility fits more for
the daily trading frequency of AMA.

This analysis also highlights the value of a continuously up-
dating, multi-class-asset benchmark built on verified and diverse
market data. Real-time developments across both equities and cryp-
tocurrencies demonstrate that agent performance cannot be fairly
assessed through static or single-market evaluations. By integrating
verified data streams and standardized decision protocols, AMA
enables systematic comparison of multiple agents under consistent
and dynamic market conditions. This design provides a more com-
prehensive and generalizable understanding of how different agent
architectures interpret across real-world financial environments.

5.4 Revealing the Influence of Agent Trading
Styles and Patterns (RQ4)

We further investigate how trading styles shape agent behavior in
the AMA framework. Figure 4 shows the interplay between daily
market sentiment, BTC price dynamics, and agent voting behaviors.
Although all agents operate on identical market information,
their trading strategies diverge from the first day. HedgeFundAgent
and InvestorAgent favored short positions, whereas DeepFundA-
gent preferred buying and TradeAgent tended to hold. These strate-
gic contrasts became more distinct as trading progressed, reflecting
each framework’s inherent risk preferences and decision logic.
Across the two-month live trading period, overall market sen-
timent remained optimistic. Nevertheless, HedgeFundAgent per-
sistently maintained short positions, revealing its contrarian and
high-risk nature. TradeAgent, despite being generally more volatile,
chose to hold positions on most days, indicating that while inher-
ently aggressive, it could exhibit conservative behavior depending
on its backbone model. InvestorAgent’s decisions largely followed
prevailing market trends, as reflected in its cumulative return curve
(Figure 2a), which outperformed others for most of the trading pe-
riod. The agent frequently executed buy and sell actions, exhibiting
a proactive and risk-taking trading style. Nevertheless, its overall
profitability remained moderate across assets, suggesting that it
adopted a relatively cautious stance during periods of elevated risk.

In contrast, DeepFundAgent demonstrated a more conservative
decision pattern, frequently opting for the “vote” action and main-
taining stable returns across multiple assets. The prudence observed
in both agents’ strategies may stem from their memory-adaptive
mechanisms, which enable them to draw on prior high-risk experi-
ences and adjust decisions toward more risk-averse behaviors.

These findings, consistent with Table 1, underscore that trading
style is a key determinant of profitability and risk exposure.
DeepFundAgent achieved consistent, moderate gains, while the
aggressive HedgeFundAgent generated substantial profits in ETH
and BMRN, which are 39.66% and 23.70% respectively, but incurred
significant losses in TSLA and BTC. Together, these results reaffirm
a fundamental market principle, higher risk can lead to greater
reward but also greater potential loss.

6 Conclusion

In this work, we introduced AMA, the first continuously updat-
ing, multi class-asset benchmark for evaluating LLM-based trading
agents in real time. Built upon three core components, including
verified multi-market information streams, a unified trading proto-
col, and a transparent performance interface, AMA establishes a
reproducible and dynamic foundation for studying financial trading
agents under genuine market conditions. It bridges the gap between
language understanding and live decision-making.

Our findings reveal four key insights. First, LLM-based agents
can trade effectively and consistently outperform simple buy & hold
strategies in live environments. Second, agent architecture, rather
than the choice of LLM backbone, exerts the strongest influence on
profitability and adaptability. Third, agents demonstrate distinct rea-
soning behaviors when interpreting complex, fast-changing market
signals, with more adaptive frameworks proving better at navigat-
ing volatility. Finally, trading styles, ranging from aggressive to
conservative, shape each agent’s risk—return profile and stability
over time. In future work, we plan to extend AMA with inter-agent
communication, cross-asset dynamics, and reinforcement learning
feedback, advancing toward a deeper understanding of autonomous
financial intelligence in LLM-driven systems.


When Agents Trade: Live Multi-Market Trading Benchmark for LLM Agents

References

1

[10

{11

[12

[13
[14

[15

[16

[17

[18

[19

[20

[21

[22

[23

[24

[25

Mahmoud Ahmad Al-Khasawneh, Asif Raza, Saif Ur Rehman Khan, and Zia Khan.
2024. Stock market trend prediction using deep learning approach. Computational
Economics (2024), 1-32.

Anthropic. 2025. Claude 3.5 Haiku. https://www.anthropic.com/claude/haiku.
Anthropic. 2025. Introducing Claude 4. https://www.anthropic.com/news/claude-
4.

Eugene Msizi Buthelezi. 2025. Cryptocurrency responses to us monetary policy
shocks: a data-driven exploration of price and volatility patterns. The American
Economist 70, 1 (2025), 94-119.

Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Jana Borova, Dylan
Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan Routledge, et al.
2021. Finga: A dataset of numerical reasoning over financial data. arXiv preprint
arXiv:2109.00122 (2021).

Zhiyu Chen, Shiyang Li, Charese Smiley, Zhiqiang Ma, Sameena Shah, and
William Yang Wang. 2022. Convfinqa: Exploring the chain of numerical reasoning
in conversational finance question answering. arXiv preprint arXiv:2210.03849
(2022).

Nina Deliu. 2024. Reinforcement learning for sequential decision making in
population research. (2024).

Casey Dougal, Joseph Engelberg, Diego Garcia, and Christopher A Parsons. 2012.
Journalists and the stock market. The Review of Financial Studies 25, 3 (2012),
639-679.

Matthew Gentzkow and Jesse M Shapiro. 2006. Media bias and reputation. Journal
of political Economy 114, 2 (2006), 280-316.

GoogleCloudPlatform generative-AI. 2025. intro_gemini_2_0_flash.ipynb.
https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/
getting-started/intro_gemini_2_0_flash.ipynb.

Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V
Chawla, Olaf Wiest, and Xiangliang Zhang. 2024. Large language model based
multi-agents: A survey of progress and challenges. arXiv preprint arXiv:2402.01680
(2024).

Cuiyun Han, Jinchuan Zhang, Xinyu Li, Guojin Xu, Weihua Peng, and Zengfeng
Zeng. 2022. Duee-fin: A large-scale dataset for document-level event extraction.
In CCF International Conference on Natural Language Processing and Chinese
Computing. Springer, 172-183.

John Hull. 2012. Risk management and financial institutions,+ Web Site. Vol. 733.
John Wiley & Sons.

John C. Hull. 2018. Options, Futures, and Other Derivatives (10 ed.). Pearson
Education.

Aaron Hurst, Adam Lerer, Adam P Goucher, Adam Perelman, Aditya Ramesh,
Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. 2024.
Gpt-4o system card. arXiv preprint arXiv:2410.21276 (2024).

Gilles Jacobs and Veronique Hoste. 2020. Extracting fine-grained economic events
from business news. In Proceedings of the 1st joint workshop on financial narrative
processing and multiling financial summarisation. 235-245.

Changlun Li, Yao Shi, Chen Wang, Qiqi Duan, Runke Ruan, Weijie Huang, Haonan
Long, Lijun Huang, Yuyu Luo, and Nan Tang. 2025. Time Travel is Cheating:
Going Live with DeepFund for Real-Time Fund Investment Benchmarking. arXiv
preprint arXiv:2505.11065 (2025).

Haohang Li, Yupeng Cao, Yangyang Yu, Shashidhar Reddy Javaji, Zhiyang Deng,
Yueru He, Yuechen Jiang, Zining Zhu, Koduvayur Subbalakshmi, Guojun Xiong,
et al. 2024. Investorbench: A benchmark for financial decision-making tasks with
Ilm-based agent. arXiv preprint arXiv:2412.18174 (2024).

Zhenglong Li, Vincent Tam, and Kwan L Yeung. 2024. Developing a multi-agent
and self-adaptive framework with deep reinforcement learning for dynamic
portfolio risk management. arXiv preprint arXiv:2402.00515 (2024).

Chin Yang Lin and Joao Alexandre Lobo Marques. 2024. Stock market prediction
using artificial intelligence: A systematic review of systematic reviews. Social
Sciences & Humanities Open 9 (2024), 100864.

Alejandro Lopez-Lira. 2025. Can Large Language Models Trade? Simulating
Financial Theories and Experiments using LLM Agents. (2025).

Lefteris Loukas, Manos Fergadiotis, Ilias Chalkidis, Eirini Spyropoulou, Pro-
dromos Malakasiotis, Ion Androutsopoulos, and Georgios Paliouras. 2022.
FiNER: Financial numeric entity recognition for XBRL tagging. arXiv preprint
arXiv:2203.06482 (2022).

Malik Magdon-Ismail and Amir F Atiya. 2004. Maximum drawdown. Risk
Magazine 17, 10 (2004), 99-102.

Pekka Malo, Ankur Sinha, Pekka Korhonen, Jyrki Wallenius, and Pyry Takala.
2014. Good debt or bad debt: Detecting semantic orientations in economic texts.
Journal of the Association for Information Science and Technology 65, 4 (2014),
782-796.

Dimitrios K Nasiopoulos, Konstantinos I Roumeliotis, Damianos P Sakas, Kanellos
Toudas, and Panagiotis Reklitis. 2025. Financial Sentiment Analysis and Classifi-
cation: A Comparative Study of Fine-Tuned Deep Learning Models. International
Journal of Financial Studies 13, 2 (2025), 75.

26

27

28

29

30

31

32

33

34

35

36

37

38

39

Conference acronym XX, June 03-05, 2018, Woodstock, NY

Chibuike Oguh. 2025. World equities hit record highs, US yields fall on optimism
for Fed rate cut. Reuters (2025). https://www.reuters.com/world/china/global-
markets-update-6- graphic-2025-08-13/

OpenAI. 2025. Introducing GPT-4.1 in the API. https://openai.com/index/gpt-4-
1/.

Antonio Pagliaro. 2025. Artificial intelligence vs. efficient markets: A critical
reassessment of predictive models in the big data era. Electronics 14, 9 (2025),
1721.

Xueqing Peng, Triantafillos Papadopoulos, Efstathia Soufleri, Polydoros Gian-
nouris, Ruoyu Xiang, Yan Wang, Lingfei Qian, Jimin Huang, Qiangian Xie, and
Sophia Ananiadou. 2025. Plutus: Benchmarking large language models in low-
resource greek finance. arXiv preprint arXiv:2502.18772 (2025).

Xueqing Peng, Lingfei Qian, Yan Wang, Ruoyu Xiang, Yueru He, Yang Ren,
Mingyang Jiang, Jeff Zhao, Huan He, Yi Han, et al. 2025. MultiFinBen: A Multilin-
gual, Multimodal, and Difficulty-Aware Benchmark for Financial LLM Evaluation.
arXiv preprint arXiv:2506.14028 (2025).

Lingfei Qian, Weipeng Zhou, Yan Wang, Xueqing Peng, Jimin Huang, and Qian-
qian Xie. 2025. Finol: On the transferability of reasoning enhanced Ilms to
finance. arXiv e-prints (2025), arXiv—2502.

Scott Richardson, Richard Sloan, and Haifeng You. 2012. What makes stock prices
move? Fundamentals vs. investor recognition. Financial Analysts Journal 68, 2
(2012), 30-50.

Soumya Sharma, Tapas Nayak, Arusarka Bose, Ajay Kumar Meena, Koustuv
Dasgupta, Niloy Ganguly, and Pawan Goyal. 2022. FinRED: A dataset for relation
extraction in financial domain. In Companion Proceedings of the Web Conference
2022. 595-597.

William F. Sharpe. 1966. Mutual Fund Performance. Journal of Business 39, 1
(1966), 119-138. doi:10.1086/294846

William F Sharpe. 1998. The sharpe ratio. Streetwise—the Best of the Journal of
Portfolio Management 3, 3 (1998), 169-85.

Paul C Tetlock. 2007. Giving content to investor sentiment: The role of media in
the stock market. The Journal of finance 62, 3 (2007), 1139-1168.

virattt. 2025. AI Hedge Fund Team. https://github.com/virattt/ai- hedge-fund.
Accessed: YYYY-MM-DD.

Yan Wang, Yang Ren, Lingfei Qian, Xueqing Peng, Keyi Wang, Yi Han, Dongji
Feng, Xiao-Yang Liu, Jimin Huang, and Qianqian Xie. 2025. FinTagging: An
LLM-ready Benchmark for Extracting and Structuring Financial Information.
arXiv preprint arXiv:2505.20650 (2025).

Mengxi Xiao, Zihao Jiang, Lingfei Qian, Zhengyu Chen, Yueru He, Yijing Xu,
Yuecheng Jiang, Dong Li, Ruey-Ling Weng, Min Peng, et al. 2025. Retrieval-
augmented large language models for financial time series forecasting. arXiv
preprint arXiv:2502.05878 (2025).

Yijia Xiao, Edward Sun, Di Luo, and Wei Wang. 2024. TradingAgents: Multi-
agents LLM financial trading framework. arXiv preprint arXiv:2412.20138 (2024).
Qianqian Xie, Weiguang Han, Zhengyu Chen, Ruoyu Xiang, Xiao Zhang, Yueru
He, Mengxi Xiao, Dong Li, Yongfu Dai, Duanyu Feng, et al. 2024. Finben: A
holistic financial benchmark for large language models. Advances in Neural
Information Processing Systems 37 (2024), 95716-95743.

Qianqian Xie, Weiguang Han, Xiao Zhang, Yanzhao Lai, Min Peng, Alejandro
Lopez-Lira, and Jimin Huang. 2023. Pixiu: A comprehensive benchmark, instruc-
tion dataset and large language model for finance. Advances in Neural Information
Processing Systems 36 (2023), 33469-33484.

Guojun Xiong, Zhiyang Deng, Keyi Wang, Yupeng Cao, Haohang Li, Yangyang
Yu, Xueqing Peng, Mingquan Lin, Kaleb E Smith, Xiao-Yang Liu, et al. 2025.
FLAG-Trader: Fusion LLM-Agent with Gradient-based Reinforcement Learning
for Financial Trading. arXiv preprint arXiv:2502. 11433 (2025).

Yangyang Yu, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Jordan W Suchow,
Denghui Zhang, and Khaldoun Khashanah. 2025. Finmem: A performance-
enhanced Ilm trading agent with layered memory and character design. IEEE
Transactions on Big Data (2025).

Yangyang Yu, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yuechen Jiang, Yupeng
Cao, Zhi Chen, Jordan Suchow, Zhenyu Cui, Rong Liu, et al. 2024. Fincon: A
synthesized llm multi-agent system with conceptual verbal reinforcement for
enhanced financial decision making. Advances in Neural Information Processing
Systems 37 (2024), 137010-137045.

Liwen Zhang, Weige Cai, Zhaowei Liu, Zhi Yang, Wei Dai, Yujie Liao, Qianru Qin,
Yifei Li, Xingyu Liu, Zhiqiang Liu, et al. 2023. Fineval: A chinese financial domain
knowledge evaluation benchmark for large language models. arXiv preprint
arXiv:2308.09975 (2023).

Xiao Zhang, Ruoyu Xiang, Chenhan Yuan, Duanyu Feng, Weiguang Han, Ale-
jandro Lopez-Lira, Xiao-Yang Liu, Meikang Qiu, Sophia Ananiadou, Min Peng,
et al. 2024. Dolares or dollars? unraveling the bilingual prowess of financial llms
between spanish and english. In Proceedings of the 30th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining. 6236-6246.



Conference acronym ’XX, June 03-05, 2018, Woodstock, NY

A Details of quality control

To ensure the daily market information delivered to agents is of
high quality, we conducted multiple iterative refinements of the
summarization prompt. Initially, we performed a preliminary re-
view and adjustment based on data collected from May 1 to May
10, which significantly improved generation quality. Subsequently,
we sampled 20 days of BTC and TSLA news from cryptocurrency
and stock markets, respectively, and had two domain experts inde-
pendently verify their accuracy and coverage to ensure the quality
and reliability of the generated summaries.

This iterative process ensured that the final summaries captured
both market breadth and factual precision, minimizing redundancy
and bias across sources. As a result, the refined daily inputs pro-
vided agents with consistent, verified, and information-rich market
contexts for decision-making.

Purpose. This guideline outlines the procedures to ensure
high-quality and unbiased daily news summaries used by
agents.

1. Objective
Daily summarized news must accurately represent the key
information from multiple sources without introducing
bias. Each asset’s daily summary should be:
e Accurate: Correctly aligned with the trading date.
e Comprehensive: Cover all major price-driving cat-
egories.
e Unbiased: Maintain balanced sentiment and tone.
e Diverse: Incorporate multiple independent sources.

2. Rules and Scoring
Rule 1: Date Accuracy — Ensure all articles correspond
to the correct trading date.

e 0 = Not aligned — multiple off-date items.

e 1= Mostly aligned — minor off-date presence.

e 2 = Fully aligned — all sources match the target date.
Rule 2: Coverage of Key News Drivers — Include all
major asset-specific developments.

e 0 = Very limited — one category only.

e 1 = Partial — two to three categories.

e 2 = Comprehensive — all four key drivers.

Rule 3: Bias Awareness — Evaluate sentiment balance
across sources and summaries.

e 0 = Skewed — one-sided sentiment.

e 1= Moderate — partial balance.

e 2 = Balanced — neutral overall tone.

Rule 4: Source Diversity — Verify multi-outlet represen-
tation.

e 0 = Low diversity — one outlet dominant.

e 1= Moderate — two to three outlets.

e 2 = High diversity — four or more outlets.

Lingfei et al.

Task: Analyze the provided {symbol} news articles from
{date_str} and produce a clear, comprehensive, and well-
structured summary.

Instructions:

e Use only the provided articles for your analysis.

e Do not retrieve or reference any external informa-
tion.

e Refrain from including current prices or speculative
forecasts.

e Focus strictly on the events, sentiment, and con-
textual details presented in the articles.

e Do not mention or enumerate article IDs in the out-
put.

Articles from {date_str}:
{articles_text}

Output Requirements:

(1) Provide a cohesive summary highlighting the key
developments for {symbol}.

(2) Identify major themes or emerging narratives within
the content.

(3) Assess and articulate the overall market sentiment
reflected in the articles.

Compose your response as a coherent and polished narra-
tive that maintains logical flow and clarity throughout.

Details of agent execution protocol

You are a professional financial decision-making agent spe-
cialized in quantitative and fundamental reasoning with
a daily trading frequency. Your primary task is to analyze
the reasoning outputs of other agent roles and integrate
their insights into a unified, evidence-based conclusion.
Based on your analysis and the provided definitions, deter-
mine the most appropriate trading decision for the target
asset [ASSET] given its current market price [PRICES ]and
contextual signals.

Your possible actions are defined as follows:

- Buy: Indicates a bullish outlook or perceived undervalu-
ation, suggesting the asset price is likely to rise. And you
choose to be in long position.

- Sell: Indicates a bearish outlook or perceived overvalu-
ation, suggesting the asset price is likely to fall. And you
choose to be in short position.

- Hold: Indicates market uncertainty or equilibrium, sug-
gesting no immediate trading action. And you choose to
go flat position.

Return your final output strictly in the following format:
[Decision]: Buy / Sell / Hold


When Agents Trade: Live Multi-Market Trading Benchmark for LLM Agents

System Prompt Definition. Each agent operates under a struc-
tured system prompt that defines its analytical objective and reason-
ing behavior. The prompt guides the model to integrate multi-source
financial information and produce consistent, interpretable trading
decisions. Specifically, the agent is assigned the following role and
task. This design ensures interpretability and reproducibility across
agents and backbones. For consistency and fairness, all LLM-based
agents share identical generation settings, including temperature,
top-p, and maximum token length, as detailed below.

Hyperparameters. Table 2 summarizes the key parameters
used in DeepFund. These parameters control model randomness,
retry behaviors, data coverage, and decision memory. All settings
remain fixed during evaluation to ensure a fair comparison across
models and runs.

C Performance analysis interface

To enable transparent and reproducible evaluation of live trading
behaviors, we built an interactive web-based monitoring interface
(Figures 5-6) for AMA. This platform allows users to observe, ana-
lyze, and compare the performance of LLM-driven trading agents
in real time.

Overview Dashboard. The main interface (Figure 5) aggregates
all agent performances under live market conditions. It displays
core metrics including total balance, cumulative return (with and
without fees), Sharpe ratio, and win rate. Agents are dynamically
ranked by returns, while an automatic refresh mechanism (default:
every 30 seconds) ensures synchronization with real-time market
data streams. Users can quickly identify outperforming agents and
drill down for detailed performance trajectories.

The filtering panel supports four orthogonal dimensions:

e Agents: TradeAgent, InvestorAgent, HedgeFundAgent, and
DeepFundAgent.

e Assets: e.g., BTC, ETH, TSLA, and BMRN, covering both finan-
cial and crypto markets.

e Models: backbones including GPT-4.1, GPT-4o, et.al.

e Strategies: such as Baseline, Flip on Reversal, and
Pyramid Exit, supporting customized evaluation modes.

This multi-axis filtering framework allows flexible comparison
across model architectures, market domains, and trading strate-
gies.

Equity Comparison View. The second interface (Figure 6) intro-
duces an interactive visualization module for cross-agent equity
analysis. Users can select subsets of agents, assets, and LLM mod-
els to render synchronized equity curves that represent portfo-
lio growth trajectories over time. Each line denotes one agent-
model combination (e.g., InvestorAgent-BTC-GPT40), with dy-
namic tooltips revealing daily balance, model type, and strategy.

This design enables detailed visual inspection of relative perfor-
mance dynamics, stability, and divergence patterns under identical
market signals. Researchers can thus examine how agents differ in
volatility tolerance, recovery behavior, and decision consistency,
offering an intuitive complement to tabular metrics.

Analytical Utility. Together, the two interfaces provide both a
macro-level snapshot and a micro-level analytical view:

Conference acronym XX, June 03-05, 2018, Woodstock, NY

e The Overview Dashboard facilitates longitudinal tracking
and ranking of live agents.

e The Equity Comparison View supports temporal and inter-
agent analysis for understanding decision-making robust-
ness.

By integrating these views, the system allows researchers to sys-
tematically assess the interplay between agent architectures, LLM
backbones, and strategy adaptability under continuously evolving
market environments.

Received 20 February 2007; revised 12 March 2009; accepted 5 June 2009


Conference acronym ’XX, June 03-05, 2018, Woodstock, NY Lingfei et al.

Parameter Default Value Usage

Controls randomness of the LLM inference.

Number of retries for LLM inference if the LLM do not give correct response.
Trading days that used to initialize the agents.

Number of past recent actions and price history for decision-making.

LLM temperature 0.5
Retry times 3
Warm-up windows 90
Decision memory size 7

Table 2: DeepFund parameter settings.

Paper Trading Agents

Monitor and analyze live paper trading agent performance

Select Agent Showing 96 of 96 agents Sortby | Retum (wifees)
Agent Names [i Assets [an lo Models GQ we Strategies wre
DeepFundAgent BMRN claude 3 5 haiku 20241022 Baseline (96)

HedgeFundAgent are claude_sonnet 4 20250514 0
© InvestorAgent ETH gemini_2.0_ flash (0)
TradeAgent TSLA ota
gpt_4o
vote
TradeAgent (TSLA) - sc InvestorAgent (TSLA) - 29 investorAgent (TSLA) - sf | deepFundagent (ETH) - a
gemini_2.0_flash gpt_4o gpt_4.1

gemini, + action based action based

oh Baseline Baseline
Balance (w/ —_-Retum (w/ fees) Sharpe Ratio Ratio Sterne
fees) +50.01% «= 5.35 fe fees} Balance (wi Return (w! fees). Sharpe Ratio
$149,934.594 $149,620.614 $141,098.353 fees) +37.75% = 2.94
Retum(no Buy &Hold. «Vs Buy & Hold Retun(no Buy & Hold Vs Buy & Hold Retum (no /s Buy & Hok EAD)
fees} +49.70% ——_(ees} fo +49.70% s) fee (ees) Return (no Buy Hold Vs Buy & Hold
+50.54% +0.31% +49.77% +0.00% +41.66% 8.53% fees} +33.84% (ees
Trading Days Win Rate Trading Days Win Rate Trading Days Win Rate +38.93% #3.91%
46 75.0% 46 100.0% 46 75.0% rading Days Win Rate

67 44.4%

rAgont + TSLA + gpt_4o +

Figure 5: Agent Market Arena Dashboard (Overview View). The
and analyzing the real-time performance of LLM-based trading agents across assets, models, and strategies.

claude_3_5_haiku_20241022

interface provides a unified view for monitoring, comparing,

Select Agent Showing 8 of 96 agents Reset Filters Sort by | Retum (w/fees)
Agent Names ED vore Assets All| | None Models All None Strategies ‘All| None
DeepFundAgent ) BMRN Gi claude_s_5_haiku_20241022 Baseline (00)

HedgeFundAgent BTC CO claude sonnet 4 20250514 o

InvestorAgent Oe Gi gemini_2.0 flash fa) ©)

TradeAgent } TSLA OD opt 44 0
gpt4o
vote

Equity Curve Comparison
2288
9/15/2025

rAgent+BTC+Base $103,141.05

@ DeepFundAgent + BTC + Base $101,639.53,

@ InvestorAgent+BTC+Base $98,950.56

Model: gpt_40

PA

Figure 6: Equity Comparison View. Users can select specific agents, assets, and models to visualize comparative equity curves,
enabling multi-dimensional evaluation of performance dynamics.
