arXiv:1707.04244v1 [cs.AI] 13 Jul 2017

Lithium NLP: A System for Rich Information Extraction from
Noisy User Generated Text on Social Media

Preeti Bhargava and Nemanja Spasojevic and Guoning Hu
Lithium Technologies | Klout
San Francisco, CA
preeti.bhargava, nemanja.spasojevic, guoning.hu@lithium.com

Abstract

In this paper, we describe the Lithium
Natural Language Processing (NLP)
system - a resource-constrained, high-
throughput and language-agnostic sys-
tem for information extraction from
noisy user generated text on social me-
dia. Lithium NLP extracts a rich set
of information including entities, top-
ics, hashtags and sentiment from text.
We discuss several real world applica-
tions of the system currently incorpo-
rated in Lithium products. We also
compare our system with existing com-
mercial and academic NLP systems in
terms of performance, information ex-
tracted and languages supported. We
show that Lithium NLP is at par with
and in some cases, outperforms state-
of-the-art commercial NLP systems.

1 Introduction

Social media has become one of the major
means for communication and content produc-
tion. As a result, industrial systems that pos-
sess the capability to process rich user gener-
ated content from social media platform have
several real-world applications. Furthermore,
due to the content style, size and heterogene-
ity of information (e.g. text, emoticons, hash-
tags etc.) available on social media, novel
NLP techniques and systems that are designed
specifically for such content and can poten-
tially integrate or learn information from dif-
ferent sources are highly useful and applicable.

However, NLP on social media data can be
significantly complex and challenging due to
several reasons:

e Noisy unnormalized data - Social me-
dia data is much more informal than tra-
ditional text and less consistent in lan-
guage in terms of style, tone etc. It
involves heavy usage of slang, jargons,
emoticons, or abbreviations which usually
do not follow formal grammatical rules.
Hence, novel NLP techniques need to be
developed for such content.

e Multi-lingual content - Social media
data poses an additional challenge to NLP
practitioners because the user generated
content on them is often multi-lingual.
Hence, any NLP system processing real
world data from the web should be able
to support multiple languages in order to
be practical and applicable.

e Large scale datasets - State-of-the-art
NLP systems should be able to work on
large scale datasets such as social me-
dia data, often involving millions of doc-
uments. Moreover, these systems need to
have low resource consumption in order to
scale to such datasets in a finite amount of
time. In addition, in order to be applica-
ble and practical, they should be able to
run on off-the-shelf commodity machines.

e Rich set of information - In order to
be cost-efficient, state-of-the-art NLP sys-
tems need to be exhaustive in terms of
information extracted! from social media
text. This includes extracting entities of
different types (such as professional ti-
tles, sports, activities etc.) in addition
to just named entities (such as persons,
organizations, locations etc.), inferring

‘https: //en.wikipedia. org/wiki/Information_

extraction


Andrew Ng

1e top 0.1% of peop!

Figure 1: A user’s inferred expertise topics

fine-grained and coarse-grained subject
matter topics (sports, politics, health-
care, basketball), text sentiment, hash-
tags, emoticons etc.

In this paper, we present the Lithium NLP?
system which addresses these challenges. It is
a resource-constrained, high-throughput and
language-agnostic system for information ex-
traction from noisy user generated text such
as that available on social media. It is capable
of extracting a rich set of information includ-
ing entities, topics, hashtags and sentiment.
Lithium NLP currently supports multiple lan-
guages including Arabic, English, French, Ger-
man, Italian and Spanish. It supports large
scale data from several social media platforms
such as Twitter, Facebook, Linkedin, etc. by
processing about 500M new social media mes-
sages, and 0.5™ socially relevant URLs shared
daily. Since it employs statistical NLP tech-
niques, it uses the large scale of the data to
help overcome the noisiness.

Lithium NLP is currently incorporated in
several Lithium products. It enables con-
sumer products like Klout® - a platform which
integrates users’ data from multiple social
networks such as Twitter, Facebook, Insta-
gram, Linkedin, GooglePlus, Youtube, and
Foursquare, in order to measure their online
social influence via the Klout Score* (Rao
et al., 2015). On Klout, it is used to model
users’ topics of interest (Spasojevic et al.,
2014) and expertise (Spasojevic et al., 2016) by
building their topical profiles. Figure 1 shows

2A screencast video demonstrating the system is
available at https: //youtu. be/U-o6Efh6TZc

3nttps://klout.com
“nttps://klout .com/corp/score

@ EcoTourismCampaign 2017 Discover

This red clay village in Iran is an
inthropological museum

Germany just generated a record 85% of its
energy from renewable sources

Figure 2: Content Personalization

an example of a user’s topics of expertise, as
inferred on Klout. Currently, we build topi-
cal profiles for more than 600M users. These
profiles are further used to recommend person-
alized content to these users by matching their
topics of interest or expertise with content top-
ics as this leads to better user engagement. An
example of content personalization is shown in
Figure 2. The user scores and topics are also
available via the GNIP PowerTrack API°.

Lithium NLP also enables enterprise prod-
ucts such as Lithium’s social media manage-
ment tools® - Lithium Reach and Lithium Re-
sponse. It is used to analyze 20+ M new daily
engagements across Lithium’s 400+ communi-
ties’. In the past, a version of Lithium NLP
had been used to enable user targeting applica-
tions such as Klout Perks® (influencer reward
platform), Cinch? (Q&A app), and Who-To-
Follow recommendations. These involved se-
lecting a group of users for targeting based on
given topics and other filtering criteria.

2 Knowledge Base

Our Knowledge Base (KB) consists of about 1
million Freebase machine ids for entities that
were chosen from a subset of all Freebase enti-
ties that map to Wikipedia entities. We prefer
to use Freebase rather than Wikipedia as our
KB since in Freebase, the same id represents a
unique entity across multiple languages. Due
to limited resources and usefulness of the enti-

http: //support .gnip.com/enrichments/klout.
oS attps://www lithium .con/products/
social-media-management/

"https: //www.lithium.com/products/
online-communities/

Snttps://goo.gl1/vtZDqE#Klout_Perks
°nttps: //goo.gl1/CLcx9p#Cinch


ties, our KB contains approximately 1 million
most important entities from among all the
Freebase entities. This gives us a good bal-
ance between coverage and relevance of enti-
ties for processing common social media text.
Section 3.1 explains how entity importance is
calculated, which enables us to rank the top 1
million Freebase entities.

In addition to the KB entities, we also em-
ploy two special entities: NIL and MISC.
NIL entity indicates that there is no entity as-
sociated with the mention, eg. mention ‘the’
within the sentence may link to entity NIL.
This entity is useful especially when it comes
to dealing with stop words and false positives.
MISC indicates that the mention links to an
entity which is outside the selected entity set
in our KB.

3 System Overview

Figure 3 shows a high level overview of the
Lithium NLP system. It has two phases:

3.1 Offline Resource Generation

In this phase, we generate several dictionar-
ies that capture language models, probabili-
ties and relations across entities and topics, by
leveraging various multi-lingual data sources.
Some of these dictionaries are derived using
our DAWT"? data set (Spasojevic et al., 2017)
that consists of densely annotated wikipedia
pages across multiple languages. It is 4.8 times
denser than Wikipedia and is designed to be
exhaustive across several domains.

The dictionaries generated from the DAWT
dataset are:

e Mention-Entity Co-occurrence - This
dictionary captures the prior probability
that a mention M; refers to an entity E;
(including NIL and MISC) within the
DAWT dataset and is equivalent to the
cooccurrence probability of the mention
and the entity:

count(M; > E;)
count(M;)

For instance, mention Michael Jordan can
link to Michael Jordan (Professor) or
Michael Jordan (Basketball player)

nttps://github. com/klout/opendata/tree/
master/wiki_annotation

with different prior probabilities. More-
over, we generate a separate dictionary for
each language.

e Entity-Entity Co-occurrence - This
dictionary captures co-occurrence fre-
quencies among entities by counting all
the entities that simultaneously appear
within a sliding window of 50 tokens.
Moreover, this data is accumulated across
all languages and is language independent
in order to capture better relations and
create a smaller memory footprint when
supporting additional languages. Also,
for each entity, we consider only the top
30 co-occurring entities which have at
least 10 or more co-occurrences across
all supported languages. For instance,
entity Michael Jordan (Basketball
player) co-occurs with entities Basket-
ball, NBA etc. while entity Michael
Jordan (Professor) co-occurs with enti-
ties Machine Learning, Artificial In-
telligence, UC Berkeley etc.

We also generate additional dictionaries:

e Entity Importance - The entity impor-
tance score (Bhattacharyya and Spaso-
jevic, 2017) is derived as a global score
identifying how important an extracted
entity is for a casual observer. ‘This
score is calculated using linear regression
with features capturing popularity within
Wikipedia links, and importance of the
entity within Freebase. We used signals
such as Wiki page rank, Wiki and Free-
base incoming and outgoing links, and
type descriptors within our KB etc.

e Topic Parents - This dictionary contains
the parent topics for each topic in the
Klout Topic Ontology !t (KTO) - a manu-
ally curated ontology built to capture so-
cial media users’ interests and expertise
scores, in different topics, across multi-
ple social networks. As of April 2017, it
consists of roughly 8,030 topic nodes and
13,441 edges encoding hierarchical rela-
tionships among them.

“nttps: //github.com/klout/opendata/tree/
master/klout_topic_ontology


(~ Offline Resource Generation

Mention Entity Entity Entity Entity Topic Topic |
Co-occurrence Co-occurrence Importance Parents Hashtags '
( Text Processing ; : Annotated
Document : Li i . Entry . i Hasht Sentiment Entity Document
| i_,| Language |__|] Text  sentnc [rtenzavon - Entity |. Disambiguation Topic asnteg L al Metadata [, Te
Text : Detection Normalization Breaking Extraction and Linking Projection Recommendation Analysis Decoration J | fext

Lithium NLP

Stage output with information extracted and added as semantic annotation

Pipeline Stage

Text: “ Google CEO Eric Schmidt said that the competition between Apple and Google and iOS vs. Android is the defining fight of the tech industry !!! “

Language Detection Language: en

Text Normalization

Normalized text: “Google CEO Eric Schmidt said that the competition between Apple and Google and iOS vs . Android is ' the defining fight of the tech industry. ””

Sentence Breaking

tech industry . ’ </s>

Text with sentence breaks: <s> Google CEO Eric Schmidt said that the competition between Apple and Google and iOS vs . Android is ' the defining fight of the

Tokenization

Tokens: <Google, CEO, Eric, Schmidt, said, that, the, competition, between, Apple, and, Google, and, iOS, vs, Android, is, the, defining, fight, of, the, tech, industry>

Text: Google CEO fric Schmidt said that the competition between App/e and Google and iOS vs. Android is ‘the defining fight of the tech industry.’
Extraction L ™. +
nit |] Google | | ni Chief NIL Eric Apple | | nit | | Apple | | Apple ios |[ we nit] | Android | | Android | [Technology
Executive Schmidt Inc. (fruit) | | Records (Os)

Entity ee CEQ Eric Schmidt said that the competition between App/e and Te and iOS vs. Android is ‘the defining fight of the tech industry.’
|
Disambiguation ek a ’ | t

er Google Hel ric Apple Inc. Google ” Android
and Linking Ine. Executive Schmidt pple Inc. ine. ios (0s) Technology

u

Topic Projection

Topics for entities: Google Inc: <Google, Technology, Search Engines...>, Eric Schmidt: <Eric Schmidt, Google, CEOs and Execs, Technology...>, Apple inc.: <Apple,
Technology, Computers, Tablets...>, (OS: <iOS, Software, Technology...>, Android: <Android, Smartphones, Software...>

Hashtag
Recommendation

#AppStore, #Technology....>, Android: <#AndroidOS, #Android .... >

Hashtags recommended for topics: Google: <#SEO, #tech, #Google

>, Eric Schmidt: <#EricSchmidt, ...>, Apple : <#Jobs, #tech, #iPhone, #Apple...>, (OS: <#iOS,

Sentiment Analysis

Entity Metadata

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I Inc.
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
! ©
1 Decoration
I

Sentiment: Neutral
4
Entity Metadata: <Google Inc: ORGANIZATION, £ric Schmidt: PERSON, Apple Inc: ORGANIZATION, iOS: MISC, Android: MISC, Technology: MISC>

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
(Robot) |
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

Figure 4: An example demonstrating the information extracted and added as semantic annota-
tion at each stage of the Lithium NLP pipeline (best viewed in color)

e Topic Hashtags - This dictionary con-
tains hashtags recommended for topics
in KTO. We determine the hashtags via
co-occurrence counts of topics and hash-
tags, importance, recency and popularity
of hashtags as well popularity of topics.

3.2 Text Processing

In the Lithium NLP system, an input text doc-
ument is stored as a Protocol Buffers!? mes-
sage. The Text Processing phase of the system
processes the input text document through
several stages and the information (entities,

“nttps://developers.google.com/
protocol-buffers/

topics etc.) extracted at every stage is added
as a semantic annotation to the text. Not
all annotations are added to a document, the
Lithium NLP API (explained in Section 3.3)
allows a client application to select specific an-
notations. However, certain annotations such
as language and tokens are prerequisites for
later stages.
The Text Processing pipeline stages are:

e Language Detection - This stage de-
tects the language of the input document
using an open source language detector!’.
This detector employs a naive Bayesian

https: //github.com/shuyo/
language-detection


filter which uses character, spellings and
script as features to classify language and
estimate its probability. It has a precision
of 99% for 49 languages.

Text Normalization - This stage nor-
malizes the text by escaping unescaped
characters and replacing special charac-
ters (e.g. diacritical marks) based on the
detected language. It replaces non-ASCII
punctuations and hyphens with spaces,
multiple spaces with single space, con-
verts accents to regular characters etc.

Sentence Breaking - This stage breaks
the normalized text into sentences using
Java Text API’. It can distinguish sen-
tence breakers from other marks, such
as periods within numbers and abbrevia-
tions, according to the detected language.

Tokenization - This stage converts each
sentence into a sequence of tokens via the
Lucene Standard Tokenizer! for all lan-
guages and the Lucene Smart Chinese An-
alyzer!® for Chinese.

Entity Extraction - This stage extracts
mentions in each sentence using the Men-
tion Entity Co-occurrence dictionary gen-
erated offline (Section 3.1). A mention
may contain a single token or several con-
secutive tokens, but a token can belong to
at most one mention.

To make this task computationally effi-
cient, we apply a simple greedy strategy
that analyzes windows of n-grams (n €
[1,6]) and extracts the longest mention
found in each window. For each extracted
mention, we generate multiple candidate
entities. For instance, mention Android
can link to candidate entities Android
(OS) or Android (Robot).

Entity Disambiguation and Linking
(EDL) - This stage disambiguates and
links an entity mention to the correct

candidate entity in our KB (Bhargava
et al., 2017). It uses several features ob-
tained from the dictionaries generated of-
fline (Section 3.1). These include context-
independent features, such as mention-
entity co-occurrence, mention-entity Jac-
card similarity and entity importance,
and context-dependent features such as
entity entity co-occurrence and entity
topic semantic similarity. It employs ma-
chine learning models, such as decision
trees and logistic regression, generated
using these features to correctly disam-
biguate a mention and link to the corre-
sponding entity. This stage has a pre-
cision of 63%, recall of 87% and an F-
score of 73% when tested on an in-house
dataset.

Topic Projection - In this stage, we
associate each entity in our KB to upto
10 most relevant topics in KTO. For in-
stance, entity Android (OS) will be as-
sociated with the topics such as Smart-
phones, Software etc.

We use a weighted ensemble of several
semi-supervised models that employ en-
tity co-occurrences, GloVe (Pennington
et al., 2014) word vectors, Freebase hi-
erarchical relationships and Wikipedia in
order to propagate topic labels. A com-
plete description of this algorithm is be-
yond the scope of this paper.

Hashtag Recommendation - In this
stage, we annotate the text with hashtags
recommended based on the topics asso-
ciated with the text in Topic Projection.
This uses the Topic Hashtags dictionary
generated offline (Section 3.1)

Sentiment Analysis - In this stage, we
determine the sentiment of the text (pos-
itive, negative or neutral) via lexicons
and term counting with negation handling
(Spasojevic and Rao, 2015). For this, we

used several lexicons of positive and nega-
tive words (including SentiWordNet (Bac-
cianella et al., 2010; Esuli and Sebastiani,
2007) and AFINN (Nielsen, 2011)) as well
as emoticons. We compute the sentiment

“nttps://docs.oracle.com/javase/7/docs/api/
java/text/BreakIterator .html

nttp://lucene.apache.org/core/4_5_0/
analyzers-common/org/apache/lucene/analysis/
standard/StandardTokenizer.html

'Snttps://lucene.apache.org/core/4_5_0/
analyzers-smartcn/org/apache/lucene/analysis/
cn/smart/SmartChineseAnalyzer.html score as


WPos _ Weg
Log(Total # of words in text) + €

where Wpo, is the weighted strength of
positive words and emoticons, Wyeg is the
weighted strength of negative words and
emoticons in the text and e€ is a smooth-
ing constant. If the score is positive and
above a certain threshold, the text is clas-
sified as ‘Positive’. If it is below a cer-
tain threshold, the text is classified as
‘Negative’. If it lies within the boundary
between ‘Positive’ and ‘Negative’ classes,
the text is classified as ‘Neutral’.

To handle negations, we use a lookback
window. Every time, we encounter a word
from our sentiment lexicons, we look back
at a window of size 3 to see if any negation
words precede it and negate the weight of
the sentiment word. Overall, this stage
has a precision of 47%, recall of 48% and
an F-score of 46% when tested on an in-
house dataset.

e Entity Metadata Decoration - In this
stage, we add the entity metadata such as
its type (Person, Organization, Location,
Film, Event, Book) and Location (Popu-
lation, Time Zone, Latitude/Longitude).

Figure 4 demonstrates how the Lithium
NLP pipeline processes a sample text “Google
CEO Eric Schmidt said that the competition
between Apple and Google and iOS vs. An-
droid is ‘the defining fight of the tech indus-

try?” and adds the annotations at every stage.

3.3 REST API

The Lithium NLP system provides a REST
API via which client applications can send
a text document as request and receive the
annotated text as JSON response. A snippet
of an annotated response (which is in our
text proto format!’) received through the
API is shown in Listing 1. Note that the
disambiguated entities are also linked to their
Freebase ids and Wikipedia links.

https: //github.com/klout/opendata/blob/
master/wiki_annotation/Text.proto

I I T
TEXT_NORMALIZATION ——
SENTENCE_BREAKER ———
250 - TOKENIZE ——— a]
ENTITY_EXTRACTION ——
ENTITY_DISAMBIGUATION —
TOPIC_PROJECTION ——
DECORATOR ——
HASHTAG_ RECOMMENDATION

150

Time Spent [ms]

100

0 2000 4000 6000 8000 10000 12000
Text Length [characters]

Figure 5: Lithium NLP performance per pro-
cessing stage (best viewed in color)

Listing 1: JSON of annotated text summary
{

text”: ”Vlade Divac Serbian NBA player
used to play for LA Lakers.” ,
“language”: "”en”,
”annotation_summary”: | {
*type”: "ENTITY”,
"annotation_identifier”: [{
Pidestr 2 201lvpr3 4,
"id_url”: ”https://en. wikipedia.org
/wiki/Vlade_Divac”,
™"score”: 0.9456,
*type”: ”PERSON”

*id_-str”’: "O5jvx”,

"id_url”: ”https://en. wikipedia.org
/ wiki/NBA” ,

™score”: 0.8496,

*type”: ”"ORGANIZATION”

’

3)

aw

"type": “"KLOUT.TOPIC”,
”"annotation_identifier”: [{
idestr?: "6467 710261455026125" 5
*id_readable”: "”nba”,
*™score”: 0.7582

» {

~id_str”: ”8311852403596174326”,
"id_readable”: ”los—angeles—lakers”,
*"score”: 0.66974

™"id=str”: ”8582816108322807207”,
”"id_readable”: ”basketball”,
™score”: 0.5445
bee
},
{
*type”: ”HASHTAG” ,
”"annotation_identifier”: [{
”id_-str”: ”NBA”,
*™score”: 54285.7515
Tro Al
"id_str”: ”NBAPlayoffs”,
*score”: 28685.6006

*sentiment”: 0.0



a a ee 10° aa A RC
_10F aida E aida
240% — lithium 4 t lithium
5104 4
fe} E
O F§
r= |
ie b) 7d
SE it i i i Cl | f
10"0.01 0.1 1 10 100 'Bo1 04 1 10 100

Text Length [kb] Text Length [kb

Figure 6: AIDA vs. Lithium NLP Comparison
on a) Text processing runtime b) Extracted
entity count (best viewed in color)

3.4 Performance

Figure 5 shows the computational perfor-
mance per processing stage of the Lithium
NLP system. The overall processing speed is
about 22ms per 1kb of text. As shown, the
time taken by the system is a linear function
of text size. The EDL stage takes about 80%
of the processing time.

4 Comparison with existing NLP
systems

Currently, due to limited resources at our end
and also due to inherent differences in the
Knowledge Base (Freebase vs Wikipedia and
others), test dataset, and types of informa-
tion extracted (entities, topics, hashtags etc.),
a direct comparison of the Lithium NLP sys-
tem’s performance (in terms of precision, re-
call and f-score) with existing academic and
commercial systems such as Google Cloud NL
API'8, Open Calais!?, Alchemy API?°, Stan-
ford CoreNLP?! (Manning et al., 2014), Am-
biverse/AIDA?? (Nguyen et al., 2014) and
Twitter NLP?? (Ritter et al., 2011, 2012) is
not possible. Hence, we compare our system
with some of them on a different set of metrics.

4.1 Comparison on runtime and
entity density

We compare the runtime of Lithium NLP and
AIDA across various text sizes. As shown in
Figure 6, Lithium NLP is on an average 40,000

'Shttps://cloud.google.com/natural-language/

http: //www.opencalais.com/opencalais—demo/

?°nttps ://alchemy-language-demo.mybluemix.
net/

2lnttp://corenlp.run/

22nttps://www.ambiverse.com/

*3nttps://github.com/aritter/twitter_nlp

times faster than AIDA whose slow runtime
can be attributed mainly to Stanford NER. In
addition to speed, we also compare the number
of entities extracted per kb of text. As shown,
Lithium NLP extracts about 2.8 times more
entities than AIDA.

4.2 Comparison on information
extracted

Table 1 compares the types of information ex-
tracted by Lithium NLP system with exist-
ing systems. In this comparison, we explicitly
differentiate between named entities (Person,
Location etc.) and other entity types (Sports,
Activities) as well as fine-grained topics (Bas-
ketball) and coarse-grained topics (Sports) to
demonstrate the rich set of information ex-
tracted by Lithium NLP. As evident, most
other systems do not provide the rich set of
semantic annotations that Lithium NLP pro-
vides. A majority of the systems focus on rec-
ognizing named entities and types with only a
few focusing on sentiment and coarse-grained
topics as well. In contrast, Lithium NLP ex-
tracts, disambiguates and links named and
other entities, extracts subject matter topics,
recommends hashtags and also infers the sen-
timent of the text.

4.3. Comparison on languages

Table 2 compares the languages supported by
the Lithium NLP system with existing sys-
tems. As evident, Lithium supports 6 different
languages which is at par and in some cases,
more than existing systems.

5 Conclusion and Future Work

In this paper, we described the Lithium
NLP system - a resource-constrained, high-
throughput and language-agnostic system for
information extraction from noisy user gener-
ated text on social media. Lithium NLP ex-
tracts a rich set of information including enti-
ties, topics, hashtags and sentiment from text.
We discussed several real world applications of
the system currently incorporated in Lithium
products. We also compared our system with
existing commercial and academic NLP sys-
tems in terms of performance, information ex-
tracted and languages supported. We showed
that Lithium NLP is at par with and in some


Lithium NLP | Google NL | Open Calais | Alchemy API | Stanford CoreNLP | Ambiverse | Twitter NLP
Named Entities x Xx Xx Xx Xx x Xx
Other Entities x x Xx xX Xx
Topics (fine-grained) xX
Topics (coarse-grained) xX X xX
Hashtags xX
Document Sentiment x XxX Xx
Entity level Sentiment xX x
Entity types xX xX x x xX xX x
Relationships xX x x
Events xX
Table 1: Comparison of information extracted by Lithium NLP with existing NLP systems
Lithium NLP Google NL Open Calais Alchemy API Stanford CoreNLP Ambiverse Twitter NLP
Supported | Arabic, English, Chinese, English, French, English, English, French, German, Arabic, Chinese, English, German, English
Languages | French, German, | German, Italian, Japanese, French, Italian, Portuguese, Russian, English, French, Spanish,
Italian, Spanish | Korean, Portugese, Spanish Spanish Spanish, Swedish German, Spanish Chinese

Table 2: Comparison of languages supported by Lithium NLP with existing NLP systems

cases, outperforms state-of-the-art commercial
NLP systems.

In future, we plan to extend the capabilities
of Lithium NLP to include entity level senti-
ment as well. We also hope to collaborate ac-
tively with academia and open up the Lithium
NLP API to academic institutions.

Acknowledgements

The authors would like to thank Prantik Bhat-
tacharya, Adithya Rao and Sarah Ellinger for
their contributions to the Lithium NLP sys-
tem. They would also like to thank Mike Ot-
tinger and Armin Broubakarian for their help
with building the Lithium NLP UI and demo.

References

Stefano Baccianella, Andrea Esuli, and Fabrizio
Sebastiani. 2010. Sentiwordnet 3.0: An en-
hanced lexical resource for sentiment analysis
and opinion mining. In LREC, volume 10, pages
2200-2204.

Preeti Bhargava, Nemanja Spasojevic, and Guon-
ing Hu. 2017. High-throughput and language-
agnostic entity disambiguation and linking on
user generated data. In Proceedings of WWW
2017 workshop on Linked Data on the Web.

Prantik Bhattacharyya and Nemanja Spasojevic.
2017. Global entity ranking across multiple
languages. In Companion Proceedings of the
WWW, pages 761 — 762.

Andrea Esuli and Fabrizio Sebastiani. 2007. Sen-
tiwordnet: A high-coverage lexical resource for
opinion mining. Evaluation, pages 1-26.

Christopher D Manning, Mihai Surdeanu, John
Bauer, Jenny Rose Finkel, Steven Bethard, and
David McClosky. 2014. The stanford corenlp

natural language processing toolkit. In ACL
(System Demonstrations), pages 55-60.
Dat Ba Nguyen, Johannes Hoffart, Martin

Theobald, and Gerhard Weikum. 2014. Aida-
light: High-throughput named-entity disam-
biguation. In LDOW’14.

Finn Arup Nielsen. 2011. A new anew: Evalua-
tion of a word list for sentiment analysis in mi-
croblogs. arXiv preprint arXiv:1103.2908.

Jeffrey Pennington, Richard Socher, and Christo-
pher D Manning. 2014. Glove: Global vec-
tors for word representation. In Proceedings of
EMNLP, pages 1532 — 1543.

Adithya Rao, Nemanja Spasojevic, Zhisheng Li,
and Trevor Dsouza. 2015. Klout score: Mea-
suring influence across multiple social networks.
In IEEE Intl. Conf. on Big Data.

Alan Ritter, Mausam Clark, Sam, and Oren Et-
zioni. 2011. Named entity recognition in tweets:
an experimental study. In Empirical Methods in
Natural Language Processing.

Alan Ritter, Mausam, Oren Etzioni, and Sam
Clark. 2012. Open domain event extraction
from twitter. In KDD.

Nemanja Spasojevic, Preeti Bhargava, and Guon-
ing Hu. 2017. Dawt: Densely annotated
wikipedia texts across multiple languages. In
Companion Proceedings of WWW, pages 1655 —
1662.

Nemanja Spasojevic, Prantik Bhattacharyya, and
Adithya Rao. 2016. Mining half a billion topical
experts across multiple social networks. Social
Network Analysis and Mining, 6(1):1-14.

Nemanja Spasojevic and Adithya Rao. 2015. Iden-
tifying actionable messages on social media. In
IEEE International Conference on Big Data,
IEEE BigData ’15.


Nemanja Spasojevic, Jinyun Yan, Adithya Rao,
and Prantik Bhattacharyya. 2014. Lasta: Large
scale topic assignment on multiple social net-
works. In Proc. of ACM KDD, pages 1809 —
1818.
