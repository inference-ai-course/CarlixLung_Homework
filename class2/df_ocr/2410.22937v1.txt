2410.22937v1 [cs.HC] 30 Oct 2024

arXiv

Thoughtful Adoption of NLP for Civic Participation:
Understanding Differences Among Policymakers

JOSE A. GURIDI, Cornell University, United States
CRISTOBAL CHEYRE, Cornell University, United States
QIAN YANG, Cornell University, United States

Natural language processing (NLP) tools have the potential to boost civic participation and enhance democratic
processes because they can significantly increase governments’ capacity to gather and analyze citizen opinions.
However, their adoption in government remains limited, and harnessing their benefits while preventing
unintended consequences remains a challenge. While prior work has focused on improving NLP performance,
this work examines how different internal government stakeholders influence NLP tools’ thoughtful adoption.
We interviewed seven politicians (politically appointed officials as heads of government institutions) and
thirteen public servants (career government employees who design and administrate policy interventions),
inquiring how they choose whether and how to use NLP tools to support civic participation processes. The
interviews suggest that policymakers across both groups focused on their needs for career advancement and
the need to showcase the legitimacy and fairness of their work when considering NLP tool adoption and
use. Because these needs vary between politicians and public servants, their preferred NLP features and tool
designs also differ. Interestingly, despite their differing needs and opinions, neither group clearly identifies
who should advocate for NLP adoption to enhance civic participation or address the unintended consequences
of a poorly considered adoption. This lack of clarity in responsibility might have caused the governments’
low adoption of NLP tools. We discuss how these findings reveal new insights for future HCI research. They
inform the design of NLP tools for increasing civic participation efficiency and capacity, the design of other
tools and methods that ensure thoughtful adoption of AI tools in government, and the design of NLP tools for
collaborative use among users with different incentives and needs.

CCS Concepts: « Computing methodologies — Artificial intelligence; Natural language processing; «
Information systems — Information retrieval; « Social and professional topics — Computing / technology
policy.

Additional Key Words and Phrases: Artificial Intelligence, Public Participation, Stakeholders, eGovernment,
Policymakers, Natural Language Processing

ACM Reference Format:

Jose A. Guridi, Cristobal Cheyre, and Qian Yang. 2024. Thoughtful Adoption of NLP for Civic Participation:
Understanding Differences Among Policymakers. 1, 1 (October 2024), 28 pages. https://doi.org/XXXXXXX.
XXXXXXX

1 INTRODUCTION

Natural language processing (NLP) systems can increase policymakers’ ability to analyze citizens’
comments on policy issues or drafts, a process known as civic participation in policymaking. In

Authors’ addresses: Jose A. Guridi, jg2222@cornell.edu, Cornell University, Ithaca, United States; Cristobal Cheyre, cac555@
cornell.edu, Cornell University, Ithaca, United States; Qian Yang, qy242@cornell.edu, Cornell University, Ithaca, United
States.

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires
prior specific permission and/or a fee. Request permissions from permissions@acm.org.

© 2024 Association for Computing Machinery.

XXXX-XXXX/2024/10-ART $15.00

https://doi.org/XXXXXXX.XXXXXXX

, Vol. 1, No. 1, Article . Publication date: October 2024.


2 Jose A. Guridi, Cristobal Cheyre, and Qian Yang

prior research, NLP systems have shown promising results in helping policymakers to organize and
make sense of large volumes of citizen comments and opinions and even in helping policymakers to
respond to constituents promptly [9, 23, 46, 47, 101, 102]. However, NLP tool adoption in government
remains limited, perhaps because of the concerns that careless deployment of NLP tools can harm
the democratic processes and erode public trust in government [17, 23, 29, 52, 115]. How can the
design of NLP tools and their use protocols effectively enhance civic participation capacity and
efficiency while mitigating potential risks and unintended consequences?

CSCW research has long focused on how technology influences collaborative work [44] and
how the design of new socio-technical systems can address conflicting stakeholder needs and
enhance teamwork [e.g., 68, 82, 89, 103, 132, 140]. These complexities also apply to adopting
and using NLP tools in government. Prior research has highlighted the sometimes conflicting
interest among government’s internal and external stakeholders [20, 21, 30, 38, 84, 110]. These
organizational dynamics differ from those in the private sector because value within government
is primarily associated with how citizens perceive and evaluate policy outcomes rather than
corporate interest [19-21, 84, 105]. Interestingly, despite CSCW’s increasing interest in civic tech
and governments [8, 117], little research has studied the internal dynamics of governments around
NLP tools’ adoption and use.

This paper asks: How do politicians and public servants—the two primary groups involved in policy-
making within government—consider whether and how to use NLP tools to enhance civic participation?
How do they consider possible ways to address potential risks and challenges? We focused on two Latin
American countries—Chile and Uruguay-as our study sites. Latin America has a long-standing
civic participatory tradition. As most countries transitioned to democracy in the last 30 years, it is a
fertile ground for studying the use and innovation of technology for democratic processes [87]. Yet,
the canon research literature—in HCI and beyond—has rarely studied these countries [87, 94, 134].
With HCI and CSCW communities increasingly advocating for the inclusion of the Global South in
their research agendas [7, 94, 95, 121, 134], now is an opportune time to address this critical gap.

We conducted an interview study with seven politicians and thirteen public servants from
five ministries in Chile and a public agency in Uruguay. Our findings suggest that policymakers
across both groups focused on their needs for career advancement and the need to strengthen the
legitimacy of their work when considering NLP tools’ adoption and use. Because these needs vary
between politicians and public servants, their preferred NLP features and tool designs also differ.
Politicians’ legitimacy was rooted in their constituents’ trust and approval; therefore, they wanted
NLP features that could showcase the fairness and capacity of their public participation processes
and the use of cutting-edge technologies. Public servants, in contrast, were internally oriented.
Their jobs’ legitimacy came from the approval of their superiors; consequently, they looked for NLP
features that could help them become both more efficient and more empathetic in analyzing citizen
comments at the current volume. Interestingly, despite their differing needs and opinions, neither
group clearly identified who should advocate for NLP adoption to enhance civic participation or
address the unintended consequences of a poorly considered adoption. Instead, they blamed each
other for NLP tools’ low adoption in government.

Our study makes two key contributions. First, it provides a rich description of how different
policymakers in Latin America considered the adoption of NLP tools and their use in civic par-
ticipation processes. It offers a valuable reference point for future research on similar topics in
other government contexts and for innovating NLP tools for the public sector. Second, it challenges
the common assumptions in HCI and AI literature that the adoption of AI tools in government
is solely about algorithmic performance or fairness and that "policymakers" are a homogeneous
group. By illuminating the complexities and differences among various types of policymakers, this
work opens up new research and design opportunities for AI tools in the public sector.

, Vol. 1, No. 1, Article . Publication date: October 2024.


Thoughtful Adoption of NLP for Civic Participation 3

2 RELATED WORK
2.1. Civic Participation in Policymaking

In this paper, we use the term “civic participation” to broadly refer to the processes by which
individuals and organizations can influence the design and implementation of governmental
policies [10, 15, 29, 48]. The level of empowerment and mode of engagement may vary based on
the government and policy contexts [139].

Civic participation in policy rule-making and implementation offers many important benefits.
For citizens, it serves as a crucial component of civic education and engagement and increases
trust in governmental processes [4, 60]. For policymakers, civic participation processes provide
access to a broad range of experience-based knowledge at a low cost, enabling them to create better
policy [4, 6, 9, 65, 85]. At a higher level, civic engagement enhances the inclusiveness, transparency,
and accountability of democratic processes; it is a pillar of democracy itself [4, 9, 10].

However, poorly implemented civic participation processes can cause more harm than good. For
instance, when the participation process—or the use of AI tools within it—is unfair or opaque, it
could inadvertently amplify the voices of powerful organizations or individuals, harming the less
powerful citizens [10, 18, 29]. Over time, if citizens perceive the government as a passive listener that
neither properly analyzes information nor responds and acts promptly, it could erode the public trust
in both the participatory process and the government agency itself [5, 18, 23, 35, 74, 109, 114, 118].
In summary, the benefits of incorporating rich, diverse citizen input in policymaking must be
balanced with the need to maintain transparency and fairness.

This dual requirement poses significant challenges to policymakers and public institutions,
who often struggle to read or synthesize the large volume and wide variety of citizen inputs
promptly [5, 9, 23, 52, 66, 70, 93, 112]. This issue is especially pronounced when dealing with
unstructured citizen input, such as free texts [24, 39, 51]. To address these challenges, policymakers
use heuristics to filter citizen inputs and prioritize those deemed more substantive. However, this
approach has been criticized for potentially dismissing too many contributions, thereby biasing
policy outcomes [23, 83, 98].

2.2 NLP Tools that Facilitate Civic Participation Processes

With the rapid advances in AI in recent years, NLP tools have become capable of assisting poli-
cymakers in processing and synthesizing citizen inputs in many valuable ways [e.g., 46, 59, 101,
102, 112, 130]. Prior NLP research has demonstrated these tools’ usefulness in pre-processing data
(e.g., voice-to-text transcription, detecting duplicates, identifying spams), summarizing data (e.g.,
identifying topics and themes in citizen comments), and clustering data (e.g., grouping citizen
comments with similar sentiments) within civic participation contexts [9, 23, 101, 102]. In recent
years, Large Language Models (LLMs) have greatly improved NLP models’ performances across
various tasks, further increasing the potential of NLP tools to assist policymakers [62].

However, adopting NLP tools in civic participation involves complexities beyond model perfor-
mance or tool usefulness [122, 131]. To ensure public trust in the civic participation process, NLP
tools need to ensure that they offer sufficient transparency to the public [32, 64, 92, 122, 128], treat
diverse citizen comments fairly [50, 63, 122], and protect citizen privacy [63, 122, 131]. Even after
these basic requirements are met, the decisions on whether governments should adopt NLP tools
and how to use those tools in practice are contentious ones, highly dependent on different stake-
holders’ normative perspectives [104, 105, 107]. After all, the legitimacy of democratic governments
fundamentally rests on the intrinsic right of citizens to be served by their representatives [105, 120].
Therefore, how citizens perceive NLP tool use and the outcomes of policymaking processes is
paramount [19-21, 84, 105].

, Vol. 1, No. 1, Article . Publication date: October 2024.


4 Jose A. Guridi, Cristobal Cheyre, and Qian Yang

Using NLP tools in civic participation also involves significant complexities within government
institutions. Prior research suggests that governments often lack the expertise, infrastructure,
and adoption mechanisms for thoughtfully adopting AI systems themselves [40, 86, 122, 131].
Consequently, they often rely on third-party vendors to provide NLP systems through procurement
processes. Even so, policymakers within government institutions frequently lack the expertise to
effectively evaluate these systems and do not have access to proper guidelines for doing so [31, 69,
79, 113].

Moreover, internal tensions within government institutions can further complicate the adoption
and use of NLP tools [20, 21, 30, 38, 84, 110]. Policymakers may have differing opinions based on
their roles and affiliations [104, 107]. Prior research on policymaking processes suggests at least
four types of internal stakeholders in government [28, 54, 80, 107, 120]:

e Politicians are authorities within government institutions elected or designated by a central
elected authority such as the president, governor, or mayor. They are usually the heads of
government institutions;

e Public servants are administrators and advisors working at public institutions whose primary
function is to design and implement policies following their institution’s mandate and the
government’s political agenda. They may be hired by the politician and/or share their political
agenda, but this is only sometimes the case, depending on the position, role, and type of
contract.

e Support staff are public employees performing day-to-day administrative tasks such as
running administrative procedures, maintaining the IT infrastructure, running legal and
financial controls, etc.

e Front-line workers are government employees that usually have occupations that bring them
in direct contact with the communities their institutions serve. Their roles are not designing
policies but interacting with the public to provide their institutions’ services.

Interestingly, despite CSCW’s increasing interest in civic tech and governments [8, 117], little
research has studied these internal dynamics of governments around NLP tools’ adoption and
use [54—56, 63, 108]. One exception is Kawakami et al. [54], who analyzed how the interactions
between front-line workers and agency leaders influence AI design and adoption decisions in public
agencies. This paper adds to this emergent line of research.

3 METHOD
3.1 Participants

We wanted to understand how different stakeholders within government institutions consider
whether and how to use NLP tools to enhance civic participation, as well as how they consider
possible ways to address potential risks and challenges. We hope these insights will inform better
NLP tool design and illuminate new social practices to ensure thoughtful adoption and use of
these tools. To extend prior research that focused on public agencies, we chose to focus on the
internal stakeholder dynamics within central government institutions. Instead of studying front-
line workers, we focus on politicians and public servants—the two primary groups involved in
policymaking within government. Additionally, we focused on two Latin American countries—Chile
and Uruguay~—as our study sites.

We conducted IRB-approved semi-structured interviews with 20 politicians and policymakers. We
recruited participants from five ministries in Chile and one agency in Uruguay. These institutions
are all under the executive branch of government, which more often manages civic participation
processes than other branches. The institutions vary in terms of legal mandate, the type of policies
they develop, and how they conduct participation processes. Interviewees were initially recruited

, Vol. 1, No. 1, Article . Publication date: October 2024.


Thoughtful Adoption of NLP for Civic Participation 5

Legislative
Branch

Deputies

Executive
Branch
President Constitutional
autonomous

Institutions
Courts of
Ministries Legal Appeals
autonomous
5 institutions
‘ocus of our

research
Central Local Others
Bank Governments

Fig. 1. An illustration of the role of interviewees’ institutions within the overall structure of Chile’s and
Uruguay’s government frameworks.

Judicial Branch

from contacts of one of the authors who served in a fraction of both government periods in Chile
and increased through snowball sampling. Table 1 details the institutions from which we recruited
the participants. Figure 1 illustrates the role of these institutions within the overall structure of
Chile’s and Uruguay’s government frameworks. Appendix A offers additional context about the
countries, their institutions, and their civic participation processes. Within the appendix, figure 2
provides an overview of how institutions are organized and where our participants worked within
them.

Policymaking Institution Politician Public Servant
Interviewees Interviewees

Uruguay - Agency for Electronic Government and Informa- 0 3
tion and Knowledge Society

Chile - Ministry General Secretary of the Presidency
Chile - Ministry of Economy, Development, and Tourism
Chile - Ministry of Education

Chile - Ministry General Secretary of Government

Chile - Ministry of Science, Technology, Knowledge and
Innovation

NO a NO
RRP RP Ww

Table 1. The institutions our interviewees come from. We interviewed 20 politicians and public servants from
six different government agencies across two Latin American countries.

We selected participants who served during the last two government periods in Chile and Uruguay
from these institutions. To collect diverse opinions, we selected participants from opposing political

, Vol. 1, No. 1, Article . Publication date: October 2024.


6 Jose A. Guridi, Cristobal Cheyre, and Qian Yang

coalitions’ and across cabinets and technical divisions. Additionally, we selected politicians and
policymakers who worked concurrently for at least part of their appointments, which allowed us
to contrast their visions and experiences. Table 2 provides details on the participants.

Politicians
Participant Education Gender YRs in Gov Experience Using NLP
PT1 Master Male 5-10 No
PT2 Master Male 10+ No
PT3 Ph.D. Male 0-5 Yes
PT4 & PT5 Master Male 5-10 Yes
PT6 Ph.D. Male 0-5 No
PT7 Ph.D. Female 0-5 Yes

Public Servants

Participant Education Gender YRs in Gov Experience Using NLP
PS1 Master Female 5-10 No
PS2 & PS9 Master Female 10+ No
PS3 Master Male 0-5 Yes
PS4 Bachelor Female 0-5 Yes
PS5 & PS10 Master Female 0-5 Yes
PS6 Bachelor Female 10+ No
PS7 & PS13 Bachelor Female 0-5 No
PS8 Ph.D. Female 0-5 No
PS11 Master Female 0-5 No
PS12 Bachelor Male 5-10 No

Table 2. Interviewees description. Our interviewees come from varied professional backgrounds, have diverse
experience in the public sector, possess different levels of familiarity with NLP tools, and hold different
political affiliations.

3.2 Interview Data Collection

We conducted the interviews remotely in Spanish, the participants’ native language. Each interview
lasted about about 60 minutes. In each interview, we started by inviting the interviewees to describe
their experience in government briefly, choosing at least one participation process and describing
it from conception to implementation in detail. We asked follow-up questions to better understand
how they engaged with citizens and how they recorded, systematized, and analyzed the information
to produce policy outputs. For participants who had used NLP tools in civic participatory processes,
we proceeded to ask how they had used NLP tools in their participatory processes, how they
perceived the advantages and challenges of using NLP tools, and changes compared to how they
work without NLP. For participants without related NLP use experience, we invited them to describe
their rationale and how they considered whether or not to use NLP tools in their future work. Based
on the tools and processes they described, we asked follow-up questions to distill perceived barriers
and risks and how they would approach them when using NLP in participation processes. We
focused on NLP tools performing the functions related to the Related Work section. We recorded
and transcribed all interviews.

1The last two governments in both countries have been from opposing political coalitions. Some participants were part

of only one of the two, and others served in both. We cannot provide specific details about who is who to protect their
anonymity, but there were no differences in results when comparing both groups.

, Vol. 1, No. 1, Article . Publication date: October 2024.


Thoughtful Adoption of NLP for Civic Participation 7

3.3. Interview Data Analysis

We analyzed the interview recordings using a two-phase coding technique and the qualitative
data analysis software MaxQDA. The first phase of open coding contrasts the data and builds a
broad set of codes, which are then connected in the second phase of axial coding [25]. The first
author conducted the open coding stage, producing 73 codes with 735 coded sentences. All the
authors discussed the findings and related work, and the first author refined the coding, classifying
them into 24 second-level codes, which were grouped into four categories that are presented in the
Findings section 4 in Tables 3, 4, 5, and 6.

4 FINDINGS

Our interviews revealed three major findings. The first two findings are interrelated. First, both
groups of policymakers—politicians and public servants—focused on their needs for career ad-
vancement and the need to strengthen the legitimacy of their work when considering NLP tools’
adoption and use. Second, because these needs varied between politicians and public servants, their
preferred NLP features and tool designs also differed. Politicians’ legitimacy was rooted in their
constituents’ trust and approval; therefore, they wanted NLP features that could showcase the
fairness and capacity of their public participation process and the use of cutting-edge technologies.
Public servants, in contrast, were internally oriented. Their jobs’ legitimacy came from the approval
of their superiors; consequently, they looked for NLP features that could help them become both
more efficient and more empathetic in analyzing citizen comments at the current volume. Finally,
despite their differing needs and opinions, neither group clearly identified who should advocate for
NLP adoption to enhance civic participation or address the unintended consequences of a poorly
considered adoption. Instead, they blamed each other for NLP tools’ low adoption in government.

We compared politicians and public servants in different categories (e.g., general and institutional
level, experience using NLP) but only found relevant differences at a general level (politicians-public
servants) and some particular cases for experience using NLP, which we highlight. Below, we report
our findings using textual quotes from the interviews translated from Spanish by the authors,
paraphrasing multiple quotes, and summarizing exemplary cases narrated by the interviewees.
When using quotes within paragraphs, fragments are selected without changing the original quote’s
intention, context, and meaning.

4.1 Differing Motivations of Using NLP Tools

Politicians and public servants differed in their incentives when deciding whether to use NLP
to support participatory processes. Politicians focused on increasing legitimacy towards their
constituents and managing power, while public servants were primarily interested in reducing their
workload, increasing efficiency, and avoiding being replaced. Table 3 summarizes the percentage of
interviewees in each group that discussed each motivation.

4.1.1 Politicians prioritized building legitimacy towards external stakeholders. Politicians highlighted
that using NLP could increase objectivity and rigor, increasing their legitimacy by promoting con-
stituents’ trust. There was a shared belief among politicians that “when there is human intervention
concerning the comments and responses of those who participated, there is always manipulation
stemming from who takes notes and then informs the authority” (PT1). Using NLP tools, politicians
could “identify the true conversations and the words people used to refer to the different topics without
the filters and biases of who listened and systematized” (PT4). Politicians tended to believe that NLP
tools were “not interpreting, only processing data” (PT1), which was essential to achieve their goal
of “estimating frequencies of converging responses to identify topics you can incorporate with more

, Vol. 1, No. 1, Article . Publication date: October 2024.


8 Jose A. Guridi, Cristobal Cheyre, and Qian Yang

Motivation Public Servants (13) Politicians (7)
Increasing legitimacy 23% 100%
Managing power 0% 86%
Increasing efficiency 85% 29%
Reducing workload 100% 14%
Human core role in the pro- 77% 29%

cess

Table 3. Motivations to Use NLP tools

assurance of people adhering to them [...] to give the process a scientific approach through technology”
(PT3). PT5 summarized this idea well:

I think we can establish mechanisms [when using NLP tools] that [...] make the process
more objective, leaving aside note-takers and moderators’ manipulations in real-time
and eliminating bias when systematizing. Maybe we could even do something like the
academia, have more representative samples, or fix them ex-post. (PT5)

Although some politicians recognized that “NLP tools might have some bias” (PT4), they believed
Al’s biases could be identified more precisely and efficiently than biases from people taking
notes (PT4, PT5). Politicians considered machines superior to humans, so using them would increase
their constituents’ trust in the process. For example, PT4 explained that “there is no mechanism
without bias [...], for example, how a topic modeling algorithm groups topics can be directed. However,
eliminating the first intermediary, the policymaker, allows the raw data to be considered better when
first processed by a machine” (PT4).

Some politicians argued that using NLP tools could increase their public approval through
positive press: “Technology has good selling, and politicians like that. Authorities would implement
technology to support participation because it will sell; it has a certain glamour and attractiveness”
(PT2). Politicians argued that although some citizens were afraid of AI, most people believed that
using it would improve the quality of policymaking, especially since trust in governments in Latin
America was shallow. One public servant mentioned that emphasizing the public image benefits
of AI adoption might help convince authorities to implement technology: “Politicians would use
AI because they think it is interesting. They would be able to say they are at the frontier, and that is
something you can communicate. Authorities will always consider how they benefit from the method,
so using technology can be an element of marketing” (PS2).

4.1.2 Politicians perceived NLP could help them manage power dynamics. Politicians thought NLP
tools could help them manage power among stakeholders and align the processes to their political
agendas by including new groups that could change power dynamics. The role of NLP tools here
was dual. On the one hand, politicians saw NLP as a tool to identify trends in data, increase the
salience of marginalized stakeholders, and build a case against stakeholders that are traditionally
more vocal and visible to the public in traditional participatory processes. PT1 explained their
needs: “We could identify trends from majorities that usually don’t voice their demands or are not
able to articulate as a group, that would give us more support for certain policies, distributing power”
(PT 1). On the other hand, politicians saw NLP tools as capable of decreasing biases in participation
processes, which suffer from self-selection. Politicians believed working with NLP could decrease
barriers for underrepresented groups by enabling them to work with raw data and a larger pool

, Vol. 1, No. 1, Article . Publication date: October 2024.


Thoughtful Adoption of NLP for Civic Participation 9

of participants. The latter would dilute specific interest groups’ power, making processes more
objective and legitimate. PT4 described an example during the COVID-19 pandemic:

Our problem was that, although we had scientific evidence for our policies, the most recog-
nized voices were attacking our ideas ad hominem: anything proposed by the government
was wrong. We had to find and give voice to people suffering from COVID-19 daily, so we
gathered information from a broader set of stakeholders. Every opinion was considered,
and we analyzed the data using NLP techniques such as topic modeling. We built the
Opening Plan based on that input. Without our methodology, including NLP, we would
not have had the same legitimacy, and the Opening Plan could have failed. By gathering
more people, we had more legitimate voices supporting our policy. (PT4)

Politicians would only implement NLP tools if they considered it would not harm their legitimacy
with relevant external stakeholders. For example, PS5 explained how NLP was discarded from
a massive consultation in education because politicians considered that using AI would not be
accepted by core stakeholders (i.e., teachers’ unions) and thus reduce the process’ legitimacy. PS5
argued that NLP tools could enable them to consult a broader set of stakeholders, but politicians
preferred to reduce the number of participants and ask less specific questions while keeping the
analysis manual.

4.1.3 Public servants prioritized efficiency to build their legitimacy towards their superiors. Public
servants wanted NLP to alleviate their workload and make the processes more efficient by “broad-
ening the reach while cutting down time demands” (PS3). Public servants argued that analyzing
participatory data manually was hard or impossible since it took too much time and they had to
fulfill multiple roles in government (PS3, PS5, PS10, PS12). Public servants were usually asked to
deliver quickly, which they argued to be incompatible with an in-depth analysis of qualitative
information (PS3, PS4, PS5, PS8, PS9). Many times, public servants had to narrow down questions
to collect less information to be able to analyze and respond to citizens promptly (PS5), which they
believed could change using NLP tools (PS3, PS5).

Public servants believed NLP tools could support organizing, filtering, navigating, and summa-
rizing information. Interviewees wanted NLP tools to efficiently identify the most frequent topics
and core ideas (PS7, PS9, PS10, PS12), propose relationships between topics, build clusters, and
extract the most relevant quotes (PS1, PS5, PS8) that they could connect to political priorities (PS8).

Public servants approached the representation issue from an efficiency perspective: they needed
more efficient strategies to engage with the right stakeholders and find missing minority groups
in less time (PS7). Public servants needed support from NLP to “identify actors” (PS5) and “be
able to map stakeholders because the public is so broad that it is hard to identify which groups are
relevant” (PS10) or “which institutions need to be involved” (PS12). Additionally, public servants
discussed the possibility of using AI tools to “have more representative samples of participants or
warn potential missing groups from alternative sources such as social media data” (PS4). The latter
was not necessarily related to NLP tools, but they did mention analyzing textual data to identify
similar stakeholders within the data and compare it to textual data in other sources, such as social
media.

4.1.4 Public servants’ use of NLP was mediated by their perception of their role in the process. Public
servants did not see NLP tools replacing their role in analyzing participatory data or policy design.
Public servants wanted to have a tool that “could automate systematizing and summarizing the
information, not to a final document, to something where we can explore the main ideas efficiently”
(PS4). Public servants envisioned NLP as “a team member with better capacities to systematize and
summarize the information and that then I can interrogate” (PS1).

, Vol. 1, No. 1, Article . Publication date: October 2024.


10 Jose A. Guridi, Cristobal Cheyre, and Qian Yang

Public servants who did not have previous experience with NLP tools insisted that there were
elements of the participatory process that machines should never perform. This group argued they
had to use the data to “build the public policy document that can be communicated, and that they
would not trust an AI system to build the political narrative” (PS2). They argued that NLP tools
could never replace human analysis since humans were the ones who could provide theoretical
explanations for correlations (PS7) and understand human sensitivities (PS11).

4.2 Differing Considerations on How to Use NLP Tools

Politicians and public servants differed in how they perceived and approached risks from NLP,
depending on their legitimacy-building orientation (i.e., from whom they draw legitimacy) and
relationship with the NLP tools. Politicians’ interaction with external stakeholders was more direct
and core to their legitimacy, so their orientation was often external. However, politicians’ interaction
with the NLP tools was usually indirect, so they were less conscious of the risks. In contrast, public
servants’ legitimacy depended less on external stakeholders than on their superiors’ opinions about
their role, so their orientation was often internal. Moreover, public servants usually interacted
more intensively with the NLP system, which put them at greater risk of being replaced and often
made them more conscious of the risks. Table 4 summarizes the percentage of interviewees that
discussed each risk, and table 5 summarizes the percentage of interviewees that discussed different
mechanisms for a thoughtful adoption of NLP.

Risk Public Servants (13) Politicians (7)
Manipulation 15% 43%
Black box 23% 14%
Data protection 46% 14%
Errors in analysis 46% 0%
Illusion of objectivity 23% 57%
Surveillance 23% 0%
Biases 46% 57%

Table 4. Perceived risks in using NLP tools.

Orientation Mechanism Public Servants Politicians (7)
(13)
Provider reputation 38% 71%
External Replicability 8% 71%
Audit mechanisms 31% 43%
Internal Human validation 69% 14%
Traceability 77% 43%
Both Tailored explanations 62% 71%
Transparency 100% 71%

Table 5. Considerations for thoughtful adoption

, Vol. 1, No. 1, Article . Publication date: October 2024.


Thoughtful Adoption of NLP for Civic Participation 11

4.2.1 Politicians were less aware of risks than public servants. Relying on external validation and
seeing themselves far from the tool, politicians were less aware of the risks of using NLP in
participatory processes. In contrast, public servants saw themselves as key actors in implementing
NLP tools, so they were more conscious and knowledgeable. Public servants identified risks and
challenges such as errors in analysis (e.g., hallucinations, misclassification), lack of explainability,
surveillance, biases, and privacy breaches. The only risk both groups were equally aware of was
potential biases. However, politicians tended to think that although NLP tools could be biased, they
would probably be less biased than humans (PT1 & PT4) and that reducing bias was just a technical
problem (PT3).

Politicians tended to believe that “AI could help since it provides an objective perspective” (PT1),
revealing an illusion of objectivity. Public servants recognized the risk that politicians could argue
that the machine was objective because it is not human and use NLP systems to claim neutrality
and manipulate citizens (intentionally or unintentionally). PS7 voiced this fear:

Some politicians believe the machine is objective because it is not human. Thus, it is
trustworthy. I fear that if we cannot explain why algorithms are not necessarily better
than humans, they will replace people with no considerations. (PS7)

Politicians discussed the risks of political manipulation from a different perspective. For politi-
cians, the risk was present if someone intentionally altered the code or tampered with the results,
which could put democracy at risk and harm citizens (PT2, PT4, PT5). Politicians analyzed the risk,
considering that it did not stem from the system’s characteristics or use but from the users’ direct
intervention. The latter was consistent with their external orientation, which usually expected
attacks from opposing political forces.

4.2.2 Politicians favored external-facing mechanisms towards responsible Al. Politicians built legiti-
macy towards the public (external orientation), favoring external-facing mechanisms. Politicians
considered providers’ reputation and replicability as the most critical elements in thoughtfully
adopting NLP. Politicians explained they needed information about providers’ previous experi-
ence and team composition to assess their reputation and fit to safely develop and implement an
NLP (PT1, PT3, PT4). PT1 explained that providers had to “prove neutrality and capacities before the
project implementation” (PT1).

Politicians highlighted the role of civil society and academia in replicating and challenging
results, so data needed to be made available along with well-crafted documentation so that external
reviewers could audit the processes and results (PT2, PT3, PT5, PT6). PT3 argued that involvement
from academia could increase trust in the system: “Despite academia not being a default honest
broker, under certain conditions, it can be trustworthy and increase trust in the process and systems
when involved” (PT3).

Regarding the system, politicians sought signals and information about the systems’ trustworthi-
ness in standards, certifications, and compliance with existing regulations (PT1, PT3, PT4, PT5). PT1,
PT3, and PT4 mentioned how providing certifications such as ISO would help increase citizens’ trust
and reliance on AI. Moreover, certifications and standards could be linked to the legal process, such
as procurements: “We have to incorporate technical requirements and certifications in the procurement
process to support institutions with no technical capacities” (PT6).

4.2.3. Public servants favored human-in-the-loop internal-facing approaches towards responsible Al.
Public servants built legitimacy within the organization (internal orientation) by validating their
roles and capacities towards their superiors. Thus, they tended to favor internal-facing mechanisms
where they played a relevant role: human validation, piloting periods, improving their knowledge
to serve as internal counterparts, and using guidelines/standards.

, Vol. 1, No. 1, Article . Publication date: October 2024.


12 Jose A. Guridi, Cristobal Cheyre, and Qian Yang

Public servants favored internal controls through human involvement (humans-in-the-loop)
to ensure thoughtful adoption processes by validating the algorithms throughout their life cycle.
Public servants argued the need to “access the raw data and check if the analysis made sense and
correct when it is wrong” (PS7). Even in non-analytical tasks like transcriptions, they believed
they should review the results: “When there is too much jargon, we need to check the automated
transcription and correct it” (PS9).

Public servants discussed that NLP systems would not replace them but change their role into
acting more as reviewers. Interviewees argued that the processes should have “stages where the
human has the role of revising, supervising, and ensuring the data quality and analysis is right” (PS6).
The associated challenge was that public servants had to be competent counterparts for third parties
providing the NLP systems, which was not always the case. To this point, public servants believed
they “did not need to understand the algorithm in-depth but to have some basic understanding and a
critical approach” (PS3) to work “hand in hand with the provider to understand all the decisions and
results” (PS8).

Public servants recognized the lack of knowledge and considered either bringing technical people
to the team (PS7), using existing guidelines and standards (PS7 & PS12), or connecting to third
parties (PS9 & PS12). Thus, external validation was an option when the expertise was unavailable,
but public servants still required strong connections and involvement with the review board. Some
mechanisms were discussed, such as having third parties “randomly revising a sample of raw quotes”
(PS12), adapting “universities ethics revision boards and revision processes [...] or creating ad honorem
advisory boards” (PS9).

Public servants emphasized that adoption processes should include piloting periods and strong
collaborations with the providers (PS1 & PS12). To do so, public servants agreed they needed
“guidelines to know what to do when evaluating [NLP] projects” (PS13) and “sectorial standards which
lower the knowledge asymmetries [with providers] when implementing NLP systems” (PS7).

4.2.4 Politicians and public servants manifested different transparency and explainability needs.
Transparency and explainability were operationalized differently depending on which stakeholder
was relevant to the politician or public servant. Both groups agreed that data should be open when
it was allowed by regulation and privacy was adequately protected. Moreover, most participants
emphasized that traceability from results to the raw data should be easy and interactive. However,
they disagreed on how, to whom, and how much data/code to open.

Politicians were prone to argue about opening data/code and making it explainable to the public
or external reviewers. Politicians argued that tailored explanations were needed for citizens to
understand, replicate, and audit the analysis (PT2, PT5): “authorities need to explain to citizens how
they did the analysis, so they need a semi-technical explanation of the system they can understand to
have a legitimate process” (PT6). Thus, politicians’ core goal was to increase trust in the process
among external stakeholders.

Public servants usually discussed transparency and explainability when working with the system
and explaining results to their superiors. Public servants prioritized explanations from providers
to understand the process themselves in elements such as “how the insights were extracted” (PS1)
and “how the system filtered and classified information” (PS4). Public servants argued that despite
explanations to external stakeholders being needed, they would not completely open the code since
it could increase costs and decrease providers, making the process less efficient (PS1, PS3, PS12).
For example, PS12 argued that “providers will not open the code of their systems, and probably it is
not viable nor desirable because that would increase costs and providers’ availability” (PS12).

, Vol. 1, No. 1, Article . Publication date: October 2024.


Thoughtful Adoption of NLP for Civic Participation 13

4.3. Who is Responsible for NLP Tool Adoption and Proper Use?

Politicians and public servants blamed each other on who was responsible for the lack of widespread
thoughtful use of NLP for participation processes. Both groups highlighted bureaucracy and lack
of knowledge about NLP as the main barriers to its use. However, there were subtleties related to
how they interpreted the implications of these barriers. Politicians believed that lack of knowledge
made public servants resist change, blaming them for not exploring and not being open to using
new technology. Public servants countered, blaming politicians’ lack of leadership for their lack of
knowledge, infrastructure, and support. Table 6 summarizes the percentage of interviewees who
discussed each barrier.

Barrier Public Servants Politicians (7)
(13)

Bureaucracy 46% 71%

Lack of knowledge 69% 57%

Resistance to change in policymakers 8% 57%

Lack of infrastructure 46% 0%

Lack of leadership in politicians 31% 0%

Table 6. Barriers for adoption of NLP tools

4.3.1 Politicians and public servants agreed bureaucracy was a relevant burden to adopt NLP tools.
Public servants and politicians agreed that excessive or unfit bureaucracy and inadequate procure-
ment processes were relevant barriers to adoption. Interviewees believed “the problem is institutional;
it is bureaucracy” (PT2) because in the public sector “you will always have a limitation which is that
you need an enabling regulation” (PS12). Procurement processes are not suited for technology, as one
participant explained: “we were trying to hire a massive mailing service for over a year because paying
a monthly license did not fit the procurement processes” (PS1). Moreover, interviewees complained
that many “regulation frameworks are outdated; when they were created, technology had other business
models. We have issues even for maintaining web pages” (PS5).

4.3.2 There was a lack of knowledge about NLP, but no clarity on who was responsible for it. The
most relevant consensual barrier was the lack of knowledge within the government, but the two
groups perceived it differently. Politicians argued that public servants resisted change because they
lacked the technical knowledge about what NLP could do and how to implement it. Politicians
highlighted the importance of fostering “an educational effort on understanding AI systems for public
servants” (PT3). PT2 explained:

NLP tools are complex systems that people in, for example, the acquisitions department

will not understand. They will not risk authorizing anything they do not understand that

could lead to potential sanctions. Public servants resist change, especially when it will

affect their comfort and way of doing things. (PT2)

Public servants agreed that the government lacked knowledge about NLP, but this was not
necessarily a reason for resisting change. Public servants acknowledged that background hetero-
geneity could create barriers (e.g., PS8 highlighted legal and procurement teams) or particular
sectors that did not trust technology (e.g., interviewees exemplified education and culture public
servants). Still, it was not usually the reason for stopping the adoption of NLP. Lack of knowledge
was often a barrier because public servants did not know what NLP tools could do nor how to

, Vol. 1, No. 1, Article . Publication date: October 2024.


14 Jose A. Guridi, Cristobal Cheyre, and Qian Yang

design and implement them (PS4, PS10, PS12). Moreover, governments usually did not have the
required technological infrastructure regarding computation capacities or budget (PS7, PS8, PS10).
Public servants said they did not necessarily resist; they did not know the available tools and had
no time to explore.

Public servants argued that the lack of knowledge was partly due to politicians’ lack of leadership,
which made adoption harder. They believed that “educating people who will implement NLP tools
depends on the head of the organization, but bosses often do not see the relevance of using them” (PS2).
Public servants contended that having the time and flexibility to explore methodologies and tools
was critical to acquiring knowledge and successfully implementing new tools, but politicians often
did not allow that. For example, PS1 explained that “exploration is incredibly valuable to learn what
new technologies could do, now I can tell because I could do it with my former supervisor, but now
I have to fight too hard to be able to learn and try new tools” (PS1). Public servants argued that
resistance to change has to be managed by politicians, which does not always happens: “Change
and human management are critical, but they need the authority to be convinced. If the person in
charge sees the value, they will bring the necessary people and resources to the team; if not, there is
nothing to do, and change will be impossible” (PS7).

5 DISCUSSION

Our findings examined why NLP tools have failed to be widely adopted thoughtfully for civic
participation processes by governments despite recent technical advancements [e.g., 9, 47, 100, 102].
Previous research in NLP for participation has focused on efficiency and technical limitations of
offering consistent and reliable support to public servants [e.g., 9, 47, 101, 102]. Still, that body
of work has little connection to research about the complexities of internal stakeholders when
implementing technological tools in the public sector [54, 104, 105, 107] in combination with the
complexities of designing human-Al interaction [135, 136]. While multiple value positions have
been addressed in prior CSCW work [e.g., 43, 68, 132], it is not necessarily tailored and adequate
to government contexts [54, 55, 104, 105] and might fail to inform thoughtful adoption of NLP
tools in civic participation processes. We contribute to a nascent line of work within CSCW that
analyzes the complexities of AI adoption in government, considering different internal stakeholder
groups [54].

Our findings inform how to approach the design and adoption of NLP tools for participation
processes, considering the nuances of politicians and public servants within the public sector. We
discuss research and design implications and opportunities around three areas: (1) Designing NLP
tools for more than efficiency in participation processes, (2) Designing tools and methods for a
thoughtful use of NLP in participation processes and (3) Designing tools and methods not for
single-user but for collaborative use in government.

5.1 Designing NLP Tools for More Than Efficiency in Participation Processes

Our findings suggest that NLP tools for supporting participation processes should not focus only
on efficiency, which has been the primary goal of most prior work [9, 23, 66, 102]. Participation
processes are moments when the government faces the public, so they are at the core of politicians’
legitimacy. Politicians will accommodate the use of NLP tools to get good press and engage with
more participants who share their political agendas. Our findings suggest that prior works’ single-
objective approach might fail to promote adoption because the efficiency objective [9, 23, 101, 102]
might not be compelling to politicians.

We do not argue that increasing efficiency does not matter. Rather, our findings surface a potential
tension between politicians and public servants regarding their motivations because they construct
their legitimacy differently. Both motivations are not necessarily incompatible, but they can be

, Vol. 1, No. 1, Article . Publication date: October 2024.


Thoughtful Adoption of NLP for Civic Participation 15

misaligned. If politicians need to efficiently process the information and showcase the results,
they will probably be aligned with public servants’ needs as users. However, if politicians are not
aware of public servants’ needs, are only concerned with getting good press, and/or have relevant
stakeholders resistant to AI, public servants probably will not be able to convince them to use
NLP tools. As prior work in electronic participation initiatives has shown, failing to address the
motivations of the most salient stakeholder (i.e., the one with the higher power, urgency, and
legitimacy) can prevent adoption [120].

In contrast, focusing solely on how NLP contributes to politicians’ legitimacy and not considering
efficiency could also lead to failed adoption processes or the design of spurious tools. Politicians
could mandate the implementation of NLP tools without acknowledging technical limitations [12, 47,
67], infrastructural requirements [5, 58, 101, 130], and ethical considerations [55, 63]. Furthermore,
politicians’ drive to replace humans to increase objectivity is directly in tension with public servants’
belief in humans’ intrinsic value. Politicians could force the adoption of NLP systems, but this could
worsen the participation process by making it less efficient and harming public servants and the
public [29, 52].

When public servants strongly believe that humans should not be replaced, our findings suggest
that efficiency gains and reduced workloads might be insufficient. Public servants might prefer man-
ual analysis even if the time and effort are high [81, 106] since they see an intrinsic value in having
humans supervising and translating data to policy. Our findings suggest convincing public servants
to adopt NLP tools is more complex than just achieving better results and making algorithms more
readily available through software [69, 102, 122, 131]. Instead, a nuanced understanding of the
political and organizational context of the public institution where they will be deployed is required.
Acquiring this understanding can help design strategies that address the right mix of requirements
for the AI tool. For instance, strategically leveraging the power of politicians who wish to implement
AI tools to increase their own public acceptance could help open spaces for experimentation, letting
public servants explore, learn, and reduce resistance. Incorporating early-stage deliberation about
whether to adopt an NLP tool [55] and what the right mix of functions incorporated in the system
is should be at the center of future research.

Our findings show how politicians and public servants have heterogeneous needs from the AI
system that are related to their career needs. The HCI and NLP communities could explore how
NLP tools can be designed to address heterogeneous career-related needs, such as making processes
more transparent, enabling a broader base of participants, increasing citizens’ engagement and
ownership of the policies they participate in, improving communication with constituents, etc.
Moreover, deliberation methods and participatory tools could be explored to collaboratively design
the right mix of functions to address internal stakeholders’ needs. However, building NLP tools for
specific requirements is not straightforward, given all the human data required to train the models,
the computing requirements, and the technical challenges of working with language. Furthermore,
a core challenge in future research would be identifying which requirements from different in-
ternal stakeholders are to be addressed through technical solutions (e.g., developing/tailoring the
algorithm) and which require designing the right human-AI interaction, organizational change,
and policy intervention.

NLP tools offer limited options for politicians and public servants to engage the public. Most of our
findings were focused on NLP tools without considering the latest advancements in large language
models (LLMs). Future research should explore how LLMs can both support participation processes
considering areas such as improving existing NLP tools [e.g., 16, 62], supporting the public in
deliberative processes [116], and changing government interaction with citizens [36]. Similarly,
to promote tools beyond efficiency, future research should explore other AI applications such as
image-generative AI [45, 127] and AI + Virtual reality [88]) that could enhance the participatory

, Vol. 1, No. 1, Article . Publication date: October 2024.


16 Jose A. Guridi, Cristobal Cheyre, and Qian Yang

design of public policies. However, all potential new applications bring along new risks [129] that
need to be explored considering the nuances of the public sector.

5.2 Designing Tools and Methods for a Thoughtful Use of NLP in Participation
Processes

5.2.1 Failing to understand the nuances of legitimacy can lead to a lack of use of NLP tools in
the right context or its use in the wrong context. Lack of use of NLP in the right context can hurt
citizens by preventing the government from properly implementing participation processes due
to challenges such as cognitive overload that could have been addressed [23]. Using NLP for
participation in the wrong context or for the wrong reasons can harm citizens differently, from
using constituents’ money with no positive (or even a negative) impact to discrimination and
political manipulation [18, 29, 63, 122, 131].

To move towards a thoughtful adoption of NLP tools, designers must address the gap in risk
perception between public servants and politicians. Public servants are more aware than politicians
of the risks of NLP tools and their complexities but hold less power in the hierarchical government
structure [54], and oftentimes worry more about their acceptance by their bosses, not the public [28].
Our findings show the importance of considering how politicians’ involvement in the design process
can shape how the risks and challenges of using NLP are effectively addressed. However, there
is a lack of guidelines to implement AI in government [31, 79, 113] considering politicians when
navigating the complexities of public institutions [54, 55]. Moreover, tools to inform politicians
about the risks of AI and to asses the ‘right level’ of unremarkableness of the tools to prevent ill-use
are scarce [119, 123, 137].

Explanations are crucial to mitigate asymmetries between stakeholders and improve under-
standing of NLP systems and their risks. Both groups asked for multiple levels of explanations
and traceability from insights to the raw data. More research is needed following a user-centered,
explainable AI approach [128] to operationalize what politicians and public servants require for
specific sectors and policies, acknowledging their knowledge and power asymmetries. Moreover,
future work should tailor existing research on how to open the ’black box’ of algorithms [e.g.,
32, 33, 53, 64, 92, 128] to the needs of specific users within the public sector [11, 34, 54].

Visualization can play a relevant role in promoting the use of NLP in the right context. Our
findings highlight the importance of promoting research on how to represent the data and how
to build interactive platforms that can achieve tailored explanations to different stakeholders and
provide easy access to raw data to extract individual cases for political narratives or confirm
insights [e.g., 22, 77, 78, 141]. Since legitimacy is at the center of politicians’ and public servants’
decisions, visualization will also be at the core of their interest since it is the vehicle through which
they showcase results to their relevant stakeholders. Future research should continue working on
representing the data and building interactive platforms that incorporate politicians’ and public
servants’ different requirements to tailor visualizations to different stakeholders.

5.2.2 Future research should explore how the misalignment of legitimacy could be addressed when
using Responsible AI toolkits. Our findings regarding the external/internal legitimacy-building
orientation when assessing AI risks call for the CSCW community to rethink responsible AI
tools and methods for government context. Prior work has developed audit mechanisms [e.g.,
61, 126] and toolkits [e.g., 11, 13, 55, 68, 111], but most of them have been designed for industry
contexts and/or have not been implemented in practice [55]. As a result, most toolkits and audit
mechanisms fail to provide guidance on how to navigate the organizational and institutional power
dynamics [54, 55, 133], which are at the core of adopting technologies in government [104, 105].
Responsible AI methods should consider how internal stakeholders perceive the role of AI in

, Vol. 1, No. 1, Article . Publication date: October 2024.


Thoughtful Adoption of NLP for Civic Participation 17

their legitimacy-building efforts and how they distribute responsibility when failing to deploy AI
systems.

Responsible AI tools and methods should be adapted to suit internal processes required by
public servants and external validation mechanisms sought by politicians. Here, our findings
are aligned with the emerging call for complementary tools to address the differences between
internal stakeholders in the public sector [55]. However, future research should carefully examine
if responsible AI methods through participatory design are enough when navigating the public
sector [18, 29]. Prior work has shown that participatory design is not necessarily a universal
and effective fix [29, 115], especially when elements such as power and legitimacy dynamics in
government are not understood [54, 120]. Complementary tools and methods should be explored
when participatory design is not feasible or can cause more harm than good due to asymmetries in
knowledge or power between internal stakeholders.

Future research should also consider when it is impossible to holistically address the differences
between politicians and public servants. Particular caution should be taken in exploring how
power and knowledge asymmetries could lead to exploitation dynamics. For example, politicians
could force public servants into becoming mere algorithmic tools to check standards and provide
information to external reviewers [72]. Similarly, public servants could exploit politicians’ distance
from the tools or lack of knowledge to avoid responsibility and blame the system for mistakes
to preserve their legitimacy [63]. Moreover, politicians were often overconfident about NLP and
technical solutions to risks, which is not consistent with the state-of-the-art research in NLP and
human-Al interaction. Even when confronted with risks, politicians still believed the systems could
be better than humans (public servants) or that technical experts could easily solve risks. Designers
could explore embedded technical fixes when alignment is impossible (or too hard/costly) to prevent
ill-use from one or many groups within the government.

This research should complement analyses of how to reduce excessive or unfit bureaucratic
processes, adapt AI governance, and improve procurement processes for technological tools. Pro-
curement processes can be a hurdle for acquiring technological tools, legal requirements, and
technical guides are crucial in a thoughtful adoption of AI [31]. However, there is still a lack of
guidelines to address challenges unique to NLP in procurement processes [31, 79, 113]. Future
research should work on policies to reduce bureaucratic burden and/or use procurement as tools
to improve AI governance [31] and to address politicians’ and public servants’ heterogeneous
demands and understanding of AI tools. This is aligned with recent calls in the HCI community for
researching how to prototype technology and policy simultaneously [49, 138, 139].

Finally, there are increasing risks considering advancements in LLMs if internal legitimacy
dynamics in government are poorly understood. Our research surfaces the complexities of thought-
fully adopting NLP in a participatory process in a context where knowledge and infrastructure
constraints still play a significant role. Tools based on LLMs [16, 62, 116]) could lower the techni-
cal/knowledge barriers mentioned in prior work [102]. Potential risks associated with AI, such as
discrimination, privacy, and misinformation, evolve with LLMs [129] and impact both internal and
external stakeholders in public institutions.

5.3 Designing Tools and Methods Not for a Single User, but for Collaborative Use in
Government

Designers should take a strategic design approach, shifting from a solo user-centered design
paradigm to an organizational perspective. To do so, our findings suggest that a strategic approach
should develop tools through processes that incorporate mechanisms to deal with shifting power
and legitimacy-building dynamics. Drawing from eGovernment literature, we suggest exploring
incorporating stakeholders’ salience into CSCW methods. Salience considers the power, legitimacy,

, Vol. 1, No. 1, Article . Publication date: October 2024.


18 Jose A. Guridi, Cristobal Cheyre, and Qian Yang

and urgency each stakeholder group holds, which can change over time [104, 120]. Future research
should analyze how to plan the design, adoption, and diffusion of AI systems within government
and shape them to the dynamic evolution of internal stakeholders’ salience. For example, when
politicians’ salience is high, designers should collaborate with public servants to develop persuasion
strategies (e.g., good press, influencing power distribution between stakeholders) and narratives
aligning with politicians’ focus on external acceptance.

When designing NLP tools for multiple stakeholders, our findings highlight the importance of
evaluating the assets, capabilities, organizational culture, and leadership [40, 69, 86]. Both groups
perceived similar barriers to adoption; however, they approached them differently. Designers need
to assess knowledge and infrastructure gaps in both groups and design mechanisms to either
reduce them or reconcile the tensions between the groups (e.g., resistance to change vs. lack of
leadership). Future research should assess how to design AI tools and implementation guidelines
that incorporate mechanisms of dealing with knowledge and infrastructure gaps in both groups
alongside how they distribute responsibilities. For example, if resistance is mainly from politicians,
using NLP as a communication asset could unlock the chicken-and-egg problem between the lack
of leadership and knowledge, prompting politicians to give public servants space to learn and
explore.

6 LIMITATIONS AND CONCLUSION

Our study aimed to understand the nuances between politicians and public servants when deciding
to use and implement NLP tools for civic participation processes. To do so, we conducted twenty
interviews with politicians and public servants in Latin America. Our findings extend prior work
on NLP tools for participation, which focused on a singular type of user within governments and
its technical challenges [102]. Moreover, it contributes to an emerging trend in HCI analyzing
the nuances of different internal stakeholders adopting AI in government [54]. Our work reveals
new research opportunities around (1) designing NLP tools for more than efficiency in public
participation processes, (2) developing tools and methods to thoughtfully use NLP in participation
process considering differences between internal stakeholders, and (3) designing AI tools for
organizational contexts in governments and not just a single-homogeneous user.

We acknowledge that the country-specific institutional arrangement and regulatory environment
are limitations. However, given the nature of our findings and the generality of our interviewees
across institutions, experience, and professional backgrounds, our findings are likely to hold in
other democratic regimes with nuances depending on how politicians and public servants develop
their careers. Moreover, as we discussed, research on language techniques is moving quickly, so
some of the details of our findings might be constrained by the current state-of-the-art NLP and
LLM systems. Moreover, our specific context provides value by bringing insights from the Global
South to the Global North, an ongoing need in HCI [7, 95]. Future research could delve deeper
into comparing North/South contexts and different public agencies to identify further nuances
that inform how to navigate the tensions within the public sector. Additionally, user studies and
real-world experiments could advance more specific design and process recommendations to adapt
existing toolkits and guidelines for these contexts [55].

Finally, given the advances in AI tools of the last few years, we encourage researchers to consider
the unique complexities of governments’ multiple internal stakeholders. Developers and designers
should work closely with public policy researchers and practitioners to look for pragmatic solutions
that strategically address the differences between public servants and politicians. Current interest
in the CSCW community on civic tech [8, 117] requires investigating how these tools are starting
to be deployed in real-world settings to prevent citizens from being intentionally or unintentionally
harmed by politicians and public servants when it is done carelessly. To do so, pragmatism and

, Vol. 1, No. 1, Article . Publication date: October 2024.


Thoughtful Adoption of NLP for Civic Participation 19

Appoints’ Appoints ‘Appoints

: Agency Ministry :
: Board of i
Directors Renershigs Minister Undersecretaries
and (5 participants) (2 participants)

dependency
varies

Appoint and
oversee

Appoints and oversees

Minister's
Cabinet

Oversees
Undersecretaries'

Executive
Director
Cabinet

‘Oversees (3 participants) Oversee | (3 participants) :

Work together in Ouecee i

; i policymaking Oversee i
Technical Work together in ;
igi Support olicymakin: i
Divisions eas policy! 9 ;
(3 participants) Divisions :
Technical Divisions Work together in | i

Work together (6 participants) administrative issues Support Divisions
in administrative

issues

Fig. 2. A simplified and generalized illustration of the Ministries and Agencies structure in Chile and Uruguay.
Details can vary depending on the specific Ministry and Agency.

strategic approaches to AI governance and using AI tools in government call for new ways of
developing tools and policies simultaneously [138, 139]. We expect our work to spark further
interest in this area and promote future research that enables the widespread adoption of AI tools
in the public sector that are thoughtfully deployed to improve democracy.

ACKNOWLEDGMENTS

We thank the public servants and authorities of Chile and Uruguay for their dedication, time, and
valuable insights. We are also very grateful to our colleagues who read previous versions of the
paper and provided us with valuable insights to improve it. The last author, Qian Yang’s effort in
this project, was supported by the Schmidt Futures’ AI2050 Early Career Fellowship. Include in
non anonymized version.

APPENDIX
A STUDY CONTEXT: CIVIC PARTICIPATION PROCESSES IN CHILE AND URUGUAY

We conducted our study in two Latin American countries: Chile and Uruguay. Latin America has
unique characteristics such as a tense socio-political context, colonial relationships, infrastructure
and institutional gaps, a more collectivist culture, a deep appreciation of participatory methods, and
a deeply social orientation in HCI research [7, 95, 96, 134]. Despite Latin America’s longstanding
participatory tradition, it is often overlooked by the canon literature [90, 94, 134].

Chile is one of Latin America’s most economically and socially stable and advanced countries. It
has a GDP per capita of US $17,093.2 [14], it is ranked 21st in the world in economic freedom [57],
and it is ranked 25th in the Democracy Index [125]. Moreover, Chile is one of the leading countries
regarding AI in Latin America, being always in the top 3 positions across different AI indexes [27,
71, 99]. In particular, Chile has a strong ICT infrastructure. It was the first country to finish Unesco’s
AI readiness assessment and it published an AI strategy in 2021, which is being implemented,
and that was updated in 2024 [27, 75, 76, 124]. Chile is a democratic republic with a unitary state

, Vol. 1, No. 1, Article . Publication date: October 2024.


20 Jose A. Guridi, Cristobal Cheyre, and Qian Yang

divided into sixteen regions. The president leads the executive branch and is elected by direct vote
every four years. The legislative branch is constituted by the Congress, which is composed of two
chambers: the Chamber of Deputies, which has 155 members elected every four years, and the
Senate, which has 50 members elected every eight years. The Chilean government (2022-2026) is led
by President Gabriel Boric, who governs with his left-wing and center-left coalition. The previous
government (2018-2022) was led by Sebastian Pifera, who governed with his center-right coalition.

Uruguay is also one of the most stable and developed democracies in the region. It has a high
GDP per capita of US $22,564.5 [14], it is ranked 27th in economic freedom [57], and it is considered
a full democracy ranked 15th in the Democracy Index [125]. Moreover, Uruguay has a strong
performance in AI [27] and developed a strategy to incorporate AI in government in 2019, which
is currently being updated with the new version expected in August 2024 [1, 2]. Uruguay is a
democratic republic with a unitary state divided into nineteen departments. The president leads the
executive branch and is elected by direct vote every five years. The legislative branch is constituted
by the General Assembly, which consists of two chambers: the Chamber of Representatives, which
has 99 members, and the Senate, which has 30 members, both elected every five years. Uruguay’s
government (2020-2025) is led by President Luis Lacalle Pou, who governs with his center-right
coalition. The previous government (2015-2020) was led by Tabaré Vasquez, who governed with
his center-left coalition.

Technology use in civic participation processes. Chile and Uruguay have several experiences
using technology (and sometimes Al) in public participation. For example, Chile has experimented
with initiatives such as using NLP algorithms to analyze citizen dialogues to update its constitu-
tion [26, 37, 91, 141], to deliberate about future scenarios [41, 42], and to analyze its AI policy [46].
Similarly, Uruguay is well-known for its digital government practices [73] and has experimented
with using different ICTs to promote civic engagement areas such as open government [3, 97].

REFERENCES

[1] AGESIC. 2021. Estrategia de Inteligencia Artificial. https://www.gub.uy/agencia-gobierno-electronico-sociedad-
informacion-conocimiento/comunicacion/publicaciones/estrategia-inteligencia- artificial

[2] AGESIC. 2023. Proceso de revision Estrategia de Inteligencia Artificial y creacion de la Estrategia Nacional de
Datos - Plataforma de Participacion Ciudadana Digital. https://plataformaparticipacionciudadana.gub.uy/processes/
estrategia-ia-datos

[3] Carolina Aguerre and Carla Bonina. 2024. Open government, civic tech and digital platforms in Latin America: A
governance study of Montevideo’s urban app ‘Por Mi Barrio’. Information Systems Journal 34, 4 (2024), 1037-1067.
https://doi.org/10.1111/isj.12468 _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/isj.12468.

[4] Tanja Aitamurto and Kaiping Chen. 2017. The value of crowdsourcing in public policymaking: epistemic, democratic
and economic value. The Theory and Practice of Legislation 5, 1 (Jan. 2017), 55-72. https://doi.org/10.1080/20508840.
2017.1282665

[5] Tanja Aitamurto and Héléne Landemore. 2016. Crowdsourced Deliberation: The Case of the Law on Off-Road Traffic
in Finland. Policy & Internet 8, 2 (2016), 174-196. https://doi.org/10.1002/poi3.115

[6] Tanja Aitamurto, Héléne Landemore, and Jorge Saldivar Galli. 2017. Unmasking the crowd: participants’ mo-
tivation factors, expectations, and profile in a crowdsourced law reform. Information, Communication & Soci-
ety 20, 8 (Aug. 2017), 1239-1260. https://doi.org/10.1080/1369118X.2016.1228993 Publisher: Routledge _eprint:
https://doi.org/10.1080/1369118X.2016.1228993.

[7] Adriana Alvarado Garcia, Karla Badillo-Urquiola, Mayra D. Barrera Machuca, Franceli L. Cibrian, Marianela Ciolfi Fe-
lice, Laura S. Gaytan-Lugo, Diego Gomez-Zara, Carla F. Griggio, Monica Perusquia-Hernandez, Soraia Silva-Prietch,
Carlos E. Tejada, and Marisol Wong-Villacres. 2020. Fostering HCI Research in, by, and for Latin America. In Extended
Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems (CHI EA ’20). Association for Computing
Machinery, New York, NY, USA, 1-4. https://doi.org/10.1145/3334480.3381055

Pablo Aragon, Adriana Alvarado Garcia, Christopher A. Le Dantec, Claudia Flores-Saviaga, and Jorge Saldivar. 2020.
Civic Technologies: Research, Practice and Open Challenges. In Conference Companion Publication of the 2020 on
Computer Supported Cooperative Work and Social Computing (CSCW ’20 Companion). Association for Computing
Machinery, New York, NY, USA, 537-545. https://doi.org/10.1145/3406865.3430888

[8

oa

, Vol. 1, No. 1, Article . Publication date: October 2024.


Thoughtful Adoption of NLP for Civic Participation 21

[9]

[10]

[11

a

[13

14
15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

Miguel Arana-Catania, Felix-Anselm Van Lier, Rob Procter, Nataliya Tkachenko, Yulan He, Arkaitz Zubiaga, and
Maria Liakata. 2021. Citizen Participation and Machine Learning for a Better Democracy. Digital Government:
Research and Practice 2, 3 (July 2021), 1-22. https://doi.org/10.1145/3452118

Sherry R. Arnstein. 1969. A Ladder Of Citizen Participation. Journal of the American Institute of Plan-
ners 35, 4 (July 1969), 216-224.  https://doi.org/10.1080/01944366908977225 Publisher: Routledge _eprint:
https://doi.org/10.1080/01944366908977225.

Vijay Arya, Rachel K. E. Bellamy, Pin-Yu Chen, Amit Dhurandhar, Michael Hind, Samuel C. Hoffman, Stephanie
Houde, Q. Vera Liao, Ronny Luss, Aleksandra Mojsilovic, Sami Mourad, Pablo Pedemonte, Ramya Raghavendra,
John Richards, Prasanna Sattigeri, Karthikeyan Shanmugam, Moninder Singh, Kush R. Varshney, Dennis Wei, and
Yunfeng Zhang. 2019. One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI Explainability Techniques.
https://doi.org/10.48550/arXiv.1909.03012 arXiv:1909.03012 [cs, stat].

Jordan T. Ash, Chicheng Zhang, Akshay Krishnamurthy, John Langford, and Alekh Agarwal. 2020. Deep Batch Active
Learning by Diverse, Uncertain Gradient Lower Bounds. https://doi.org/10.48550/arXiv.1906.03671 arXiv:1906.03671
[cs, stat].

Agathe Balayn, Mireia Yurrita, Jie Yang, and Ujwal Gadiraju. 2023. “Fairness Toolkits, A Checkbox Culture?” On the
Factors that Fragment Developer Practices in Handling Algorithmic Harms. In Proceedings of the 2023 AAAI/ACM
Conference on AI, Ethics, and Society (AIES ’23). Association for Computing Machinery, New York, NY, USA, 482-495.
https://doi.org/10.1145/3600211.3604674

World Bank. 2023. World Bank Open Data. https://data.worldbank.org

Howell S. Baum. 2015. Citizen Participation. In International Encyclopedia of the Social & Behavioral Sciences (Second
Edition), James D. Wright (Ed.). Elsevier, Oxford, 625-630. https://doi-org/10.1016/B978-0-08-097086-8.74005-0
Maike Behrendt, Stefan Sylvius Wagner, Marc Ziegele, Lena Wilms, Anke Stoll, Dominique Heinbach, and Stefan
Harmeling. 2024. AQuA - Combining Experts’ and Non-Experts’ Views To Assess Deliberation Quality in Online
Discussions Using LLMs. https://doi.org/10.48550/arXiv.2404.02761 arXiv:2404.02761 [cs].

Abeba Birhane. 2021. Algorithmic injustice: a relational ethics approach. Patterns 2, 2 (Feb. 2021), 100205. https:
//doi.org/10.1016/j.patter.2021.100205

Abeba Birhane, William Isaac, Vinodkumar Prabhakaran, Mark Diaz, Madeleine Clare Elish, Iason Gabriel, and Shakir
Mohamed. 2022. Power to the People? Opportunities and Challenges for Participatory AI. In Equity and Access in
Algorithms, Mechanisms, and Optimization (EAAMO ’22). Association for Computing Machinery, New York, NY, USA,
1-8. https://doi.org/10.1145/3551624.3555290

Carla Bonina and Antonio Cordella. 2009. Public Sector Reforms and the Notion of ’Public Value’: Implications for
eGovernment Deployment. AMCIS 2009 Proceedings (Jan. 2009). https://aisel.aisnet.org/amcis2009/15

George A. Boyne. 2002. Public and Private Management: What’s the Difference? Journal of Management Studies 39, 1
(2002), 97-122. https://doi.org/10.1111/1467-6486.00284 _ eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-
6486.00284.

Stuart Bretschneider. 1990. Management Information Systems in Public and Private Organizations: An Empirical Test.
Public Administration Review 50, 5 (1990), 536-545. https://doi.org/10.2307/976784 Publisher: [American Society for
Public Administration, Wiley].

Guoray Cai, Feng Sun, and Yongzhong Sha. 2018. Interactive Visualization for Topic Model Curation. In ESIDA ’18.
Kaiping Chen and Tanja Aitamurto. 2019. Barriers for Crowd’s Impact in Crowdsourced Policymaking: Civic
Data Overload and Filter Hierarchy. International Public Management Journal 22, 1 (Jan. 2019), 99-126. https:
//doi.org/10.1080/10967494.2018.1488780

Soon Chun, Stuart Shulman, Rodrigo Sandoval Almazan, and Eduard Hovy. 2010. Government 2.0: Making Connections
Between Citizens, Data and Government. Information Polity 15 (April 2010), 1-9. https://doi.org/10.3233/IP- 2010-0205
Juliet M. Corbin and Anselm L. Strauss. 2014. Basics of qualitative research: techniques and procedures for developing
grounded theory (fourth edition ed.). SAGE, Los Angeles.

Andrés Cruz, Zachary Elkins, Roy Gardner, Matthew Martin, and Ashley Moran. 2023. Measuring constitutional
preferences: A new method for analyzing public consultation data. PLOS ONE 18, 12 (2023), e0295396. https:
//doi.org/10.1371/journal.pone.0295396 Publisher: Public Library of Science.

Centro Nacional de Inteligencia Artificial. 2023. Indice latinoamericano de inteligencia artificial. Technical Report.
Centro Nacional de Inteligencia Artificial, Santiago, Chile.

Rikki Dean. 2023. Deliberating Like a State: Locating Public Administration Within the Deliberative System. Political
Studies (April 2023), 00323217231166285. https://doi.org/10.1177/00323217231166285 Publisher: SAGE Publications
Ltd.

Fernando Delgado, Stephen Yang, Michael Madaio, and Qian Yang. 2023. The Participatory Turn in AI Design:
Theoretical Foundations and the Current State of Practice. In Proceedings of the 3rd ACM Conference on Equity and
Access in Algorithms, Mechanisms, and Optimization (EAAMO ’23). Association for Computing Machinery, New York,

, Vol. 1, No. 1, Article . Publication date: October 2024.


22

30

31

32

33

34

35

36

37

38

39.

40

41

42

43

44

45

46

47

48

49

, Vol

Jose A. Guridi, Cristobal Cheyre, and Qian Yang

NY, USA, 1-23. https://doi.org/10.1145/3617694.3623261

Rahul De’ and Sandeep Sarkar. 2010. Rituals in E-Government Implementation: An Analysis of Failure. In Electronic
Government (Lecture Notes in Computer Science), Maria A. Wimmer, Jean-Loup Chappelet, Marijn Janssen, and Hans J.
Scholl (Eds.). Springer, Berlin, Heidelberg, 226-237. https://doi.org/10.1007/978-3-642-14799-9_20

Lavi M. Ben Dor and Cary Coglianese. 2021. Procurement as AI Governance. IEEE Transactions on Technology and
Society 2, 4 (Dec. 2021), 192-199. https://doi-org/10.1109/TTS.2021.3111764 Conference Name: IEEE Transactions on
Technology and Society.

Lilian Edwards and Michael Veale. 2017. Slave to the Algorithm? Why a ’right to an explanation’ is probably not the
remedy you are looking for. preprint. LawArXiv. https://doi.org/10.31228/osf.i0/97upg

Upol Ehsan, Q. Vera Liao, Michael Muller, Mark O. Ried], and Justin D. Weisz. 2021. Expanding Explainability: Towards
Social Transparency in AI systems. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
(CHI ’21). Association for Computing Machinery, New York, NY, USA, 1-19. https://doi.org/10.1145/3411764.3445188
Upol Ehsan, Samir Passi, Q. Vera Liao, Larry Chan, I.-Hsiang Lee, Michael Muller, and Mark O. Ried]. 2021. The Who in
Explainable AI: How AI Background Shapes Perceptions of AI Explanations. https://doi.org/10.48550/arXiv.2107.13509
arXiv:2107.13509 [cs].

Peter Esaiasson. 2010. Will citizens take no for an answer? What government officials can do to enhance decision
acceptance. European Political Science Review 2, 3 (Nov. 2010), 351-371. https://doi.org/10.1017/S1755773910000238
Publisher: Cambridge University Press.

Dina Fares. 2023. The Role of Large Language Models (LLMs) Driven Chatbots in Shaping the Future of Government
Services and Communication with Citizens in UAE. Theses (Dec. 2023). https://repository.rit.edu/theses/11694
Constanza Fierro, Claudio Fuentes, Jorge Pérez, and Mauricio Quezada. 2017. 200K+ Crowdsourced Political Arguments
for a New Chilean Constitution. In Proceedings of the 4th Workshop on Argument Mining. Association for Computational
Linguistics, Copenhagen, Denmark, 1-10. https://doi.org/10.18653/v1/W17-5101

L.S. Flak and S. Nordheim. 2006. Stakeholders, Contradictions and Salience: An Empirical Study of a Norwegian
G2G Effort. In Proceedings of the 39th Annual Hawaii International Conference on System Sciences (HICSS’06), Vol. 4.
75a-75a. https://doi.org/10.1109/HICSS.2006.436 ISSN: 1530-1605.

Joan Font, Sara Pasadas del Amo, and Graham Smith. 2016. Tracing the Impact of Proposals from Participatory
Processes: Methodological Challenges and Substantive Lessons. Journal of Deliberative Democracy 12, 1 (June 2016).
https://doi.org/10.16997/jdd.243 Number: 1 Publisher: University of Westminster Press.

Sarah Giest. 2017. Big data for policymaking: fad or fasttrack? Policy Sciences 50, 3 (Sept. 2017), 367-382. https:
//doi.org/10.1007/s11077-017-9293-1

Julian “Tfiaki” Gofii, Claudio Fuentes, and Maria Paz Raveau. 2023. An experiential account of a large-scale interdisci-
plinary data analysis of public engagement. AI & SOCIETY 38, 2 (April 2023), 581-593. https://doi.org/10.1007/s00146-
022-01457-4

Julian “Taki” Gofii, Maria Paz Raveau, and Claudio Fuentes Bravo. 2024. Analytical categories to describe imaginations
about the collective futures: From theory to linguistics to computational analysis. Futures 156 (Feb. 2024), 103324.
https://doi.org/10.1016/j.futures.2024.103324

Colin M. Gray and Shruthi Sai Chivukula. 2019. Ethical Mediation in UX Practice. In Proceedings of the 2019 CHI
Conference on Human Factors in Computing Systems. ACM, Glasgow Scotland Uk, 1-11. https://doi.org/10.1145/
3290605.3300408

Jonathan Grudin and Steven Poltrock. 2012. Taxonomy and Theory in Computer Supported Cooperative Work. In
The Oxford Handbook of Organizational Psychology, Volume 2 (1 ed.), Steve W. J. Kozlowski (Ed.). Oxford University
Press, 1323-1348. https://doi.org/10.1093/oxfordhb/9780199928286.013.0040

Jose A. Guridi, Cristobal Cheyre, Maria Goula, Duarte Santo, Lee Humphreys, Aishwarya Shankar, and Achilleas
Souras. 2024. Image Generative AI to Design Public Spaces: a Reflection of how AI Could Improve Co-Design of
Public Parks. Digital Government: Research and Practice (2024). https://doi.org/10.1145/3656588 Just Accepted.

Jose A. Guridi, Julio A. Pertuze, and Catalina Zamora. 2024. Supporting Participation Processes Using NLP in
Constrained Resources Settings. In Proceedings of the Ongoing Research, Practitioners, Posters, Workshops, and Projects
of the International Conference EGOV-CeDEM-ePart 2024, Vol. 3737. Ghent University and KU Leuven, Belgium.
https://ceur-ws.org/Vol-3737/paper30.pdf

Loni Hagen. 2018. Content analysis of e-petitions with topic modeling: How to train and evaluate LDA models?
Information Processing & Management 54, 6 (Nov. 2018), 1292-1307. https://doi.org/10.1016/j.ipm.2018.05.006
Renée A. Irvin and John Stansbury. 2004. Citizen Participation in Decision Making: Is It Worth the Effort?
Public Administration Review 64, 1 (2004), 55-65. _ https://doi.org/10.1111/j.1540-6210.2004.00346.x _ eprint:
https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1540-6210.2004.00346.x.

Steven J. Jackson, Tarleton Gillespie, and Sandy Payette. 2014. The policy knot: re-integrating policy, practice
and design in cscw studies of social computing. In Proceedings of the 17th ACM conference on Computer supported

. 1, No. 1, Article . Publication date: October 2024.


Thoughtful Adoption of NLP for Civic Participation 23

[50

53

54

55

56

57

58

59,

60

61

62

63

64

65

66

=

cooperative work & social computing (CSCW ’14). Association for Computing Machinery, New York, NY, USA, 588-602.
https://doi.org/10.1145/2531602.2531674

Abigail Z. Jacobs, Su Lin Blodgett, Solon Barocas, Hal Daumé, and Hanna Wallach. 2020. The meaning and
measurement of bias: lessons from natural language processing. In Proceedings of the 2020 Conference on Fair-
ness, Accountability, and Transparency (FAT* ’20). Association for Computing Machinery, New York, NY, USA, 706.
https://doi.org/10.1145/3351095.3375671

Marijn Janssen, Yannis Charalabidis, and Anneke Zuiderwijk. 2012. Benefits, Adoption Barriers and Myths of Open
Data and Open Government. Information Systems Management 29, 4 (Sept. 2012), 258-268. https://doi.org/10.1080/
10580530.2012.716740

Mahmood Jasim, Enamul Hoque, Ali Sarvghad, and Narges Mahyar. 2021. CommunityPulse: Facilitating Community
Input Analysis by Surfacing Hidden Insights, Reflections, and Priorities. In Proceedings of the 2021 ACM Designing
Interactive Systems Conference (DIS ’21). Association for Computing Machinery, New York, NY, USA, 846-863.
https://doi.org/10.1145/3461778.3462132

Harmanpreet Kaur, Eytan Adar, Eric Gilbert, and Cliff Lampe. 2022. Sensible AI: Re-imagining Interpretability and
Explainability using Sensemaking Theory. In 2022 ACM Conference on Fairness, Accountability, and Transparency (FAccT
°22). Association for Computing Machinery, New York, NY, USA, 702-714. https://doi.org/10.1145/3531146.3533135
Anna Kawakami, Amanda Coston, Hoda Heidari, Kenneth Holstein, and Haiyi Zhu. 2024. Studying Up Public Sector
Al: How Networks of Power Relations Shape Agency Decisions Around AI Design and Use. http://arxiv.org/abs/
2405.12458 arXiv:2405.12458 [cs].

Anna Kawakami, Amanda Coston, Haiyi Zhu, Hoda Heidari, and Kenneth Holstein. 2024. The Situate AI Guidebook:
Co-Designing a Toolkit to Support Multi-Stakeholder Early-stage Deliberations Around Public Sector AI Proposals.
https://doi.org/10.1145/3613904.3642849 arXiv:2402.18774 [cs].

Anna Kawakami, Venkatesh Sivaraman, Hao-Fei Cheng, Logan Stapleton, Yanghuidi Cheng, Diana Qing, Adam Perer,
Zhiwei Steven Wu, Haiyi Zhu, and Kenneth Holstein. 2022. Improving Human-AlI Partnerships in Child Welfare:
Understanding Worker Practices, Challenges, and Desires for Algorithmic Decision Support. In Proceedings of the
2022 CHI Conference on Human Factors in Computing Systems (CHI ’22). Association for Computing Machinery, New
York, NY, USA, 1-18. https://doi.org/10.1145/3491102.3517439

Anthony Kim. 2024. 2024 Index of Economic Freedom. Technical Report. The Heritage Foundation, Washington DC,
USA.

Byungjun Kim, Minjoo Yoo, Keon Chul Park, Kyeo Re Lee, and Jang Hyun Kim. 2021. A value of civic voices
for smart city: A big data analysis of civic queries posed by Seoul citizens. Cities 108 (Jan. 2021), 102941. https:
//doi.org/10.1016/j.cities.2020.102941

Taewook Kim, Hyunwoo Kim, Juho Kim, and Xiaojuan Ma. 2021. Improving Readers’ Awareness of Divergent
Viewpoints by Displaying Agendas of Comments in Online News Discussions. In Companion Publication of the 2021
Conference on Computer Supported Cooperative Work and Social Computing (CSCW ’21). Association for Computing
Machinery, New York, NY, USA, 99-103. https://doi-org/10.1145/3462204.3481761

Karolina Koc-Michalska and Darren Lilleker. 2017. Digital Politics: Mobilization, Engagement, and Participation.
Political Communication 34, 1 (Jan. 2017), 1-5. https://doi-org/10.1080/10584609.2016.1243178

Michelle S. Lam, Ayush Pandit, Colin H. Kalicki, Rachit Gupta, Poonam Sahoo, and Danaé Metaxa. 2023. Sociotechnical
Audits: Broadening the Algorithm Auditing Lens to Investigate Targeted Advertising. Proceedings of the ACM on
Human-Computer Interaction 7, CSCW2 (Oct. 2023), 360:1-360:37. https://doi-org/10.1145/3610209

Michelle S. Lam, Janice Teoh, James A. Landay, Jeffrey Heer, and Michael S. Bernstein. 2024. Concept Induction:
Analyzing Unstructured Text with High-Level Concepts Using LLooM. In Proceedings of the CHI Conference on
Human Factors in Computing Systems (CHI ’24). Association for Computing Machinery, New York, NY, USA, 1-28.
https://doi.org/10.1145/3613904.3642830

Karen Levy, Kyla E. Chasalow, and Sarah Riley. 2021. Algorithms and Decision-Making in the Public Sector. Annual
Review of Law and Social Science 17, 1 (2021), 309-334. https://doi.org/10.1146/annurev-lawsocsci-041221-023808
_eprint: https://doi.org/10.1146/annurev-lawsocsci-041221-023808.

QWera Liao and S. Shyam Sundar. 2022. Designing for Responsible Trust in AI Systems: A Communication Perspective.
In Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency (FAccT ’22). Association for
Computing Machinery, New York, NY, USA, 1257-1268. https://doi.org/10.1145/3531146.3533182

Helen K. Liu. 2017. Crowdsourcing Government: Lessons from Multiple Disciplines. Pub-
lic Administration Review 77, 5 (2017), 656-667. https://doi.org/10.1111/puar.12808 _eprint:
https://onlinelibrary.wiley.com/doi/pdf/10.1111/puar.12808.

Michael A. Livermore, Vladimir Eidelman, and Brian Grom. 2017. Computationally Assisted Regulatory Participation.
Notre Dame Law Review 93, 3 (2017), 977-1034. https://heinonline.org/HOL/P?h=hein.journals/tndl93&i=1011

, Vol. 1, No. 1, Article . Publication date: October 2024.


24

67

68

69

70

Fel

72

73

74

75

76

ZL.

78

79

80

81

Jose A. Guridi, Cristobal Cheyre, and Qian Yang

Baojun Ma, Nan Zhang, Guannan Liu, Lianggiang Li, and Hua Yuan. 2016. Semantic search for public opinions on
urban affairs: A probabilistic topic modeling-based approach. Information Processing & Management 52, 3 (May 2016),
430-445. https://doi.org/10.1016/j.ipm.2015.10.004

Michael A. Madaio, Luke Stark, Jennifer Wortman Vaughan, and Hanna Wallach. 2020. Co-Designing Checklists
to Understand Organizational Challenges and Opportunities around Fairness in AI. In Proceedings of the 2020 CHI
Conference on Human Factors in Computing Systems. ACM, Honolulu HI USA, 1-14. https://doi-org/10.1145/3313831.
3376445

Rohit Madan and Mona Ashok. 2023. AI adoption and diffusion in public administration: A systematic literature
review and future research agenda. Government Information Quarterly 40, 1 (Jan. 2023), 101774. https://doi.org/10.
1016/j.giq.2022.101774

Narges Mahyar, Diana V. Nguyen, Maggie Chan, Jiayi Zheng, and Steven P. Dow. 2019. The Civic Data Deluge:
Understanding the Challenges of Analyzing Large-Scale Community Input. In Proceedings of the 2019 on Designing
Interactive Systems Conference (DIS ’19). Association for Computing Machinery, New York, NY, USA, 1171-1181.
https://doi.org/10.1145/3322276.3322354

Nestor Maslej, Loredana Fattorini, Erik Brynjolfsson, John Etchemendy, Katrina Ligett, Terah Lyons, James Manyika,
Helen Ngo, Juan Carlos Niebles, Vanessa Parli, Yoav Shoham, Russell Wald, Jack Clark, and Raymond Perrault.
2023. The AI Index 2023 Annual Report. Technical Report. Stanford University. https://aiindex.stanford.edu/wp-
content/uploads/2023/04/HAI_AI-Index-Report_2023.pdf

Colten Meisner, Brooke Erin Duffy, and Malte Ziewitz. 2022. The labor of search engine evaluation: Making
algorithms more human or humans more algorithmic? New Media & Society (Jan. 2022), 14614448211063860. https:
//doi.org/10.1177/14614448211063860 Publisher: SAGE Publications.

Maria Laura Rodriguez Mendaro. 2020. The Uruguayan Digital Data Journey. Patterns 1, 3 (June 2020). https:
//doi.org/10.1016/j.patter.2020.100047 Publisher: Elsevier.

Nina A. Mendelson. 2012. Should Mass Comments Count? Response Essay. Michigan Journal of Environmental &
Administrative Law 2, 1 (2012), 173-184. https://heinonline.org/HOL/P?h=hein.journals/michjo2&i=173

MinCTCI. 2021. Politica Nacional de Inteligencia Artificial. Technical Report. Ministerio de Ciencia Tecnologia
Conocimiento e Innovacion, Chile. https://minciencia.gob.cl/uploads/filer_public/bc/38/bc389daf- 45 14-4306-867c-
760ae7686e2c/documento_politica_ia_digital_.pdf

MinCTCL. 2024. Politica Nacional de Inteligencia Artificial - Actualizacién 2024. Technical Report. Ministerio de Ciencia
Tecnologia Conocimiento e Innovacion. https://drive.google.com/file/d/11OLxLp8NyKgpeRFLe45X0zStY7SFEJIC/
view?usp=sharing&usp=embed_facebook

Gonzalo Gabriel Méndez, Katherine Chiluiza, Javier Tibau, Vanessa Ines Cedeno-Mieles, Oscar Moreno, Miguel
Murillo, and Marisol Wong-Villacres. 2022. Exploring Open Parliament Initiatives in Ecuador Through Technology.
In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems (CHI EA ’22). Association
for Computing Machinery, New York, NY, USA, 1-8. https://doi.org/10.1145/3491101.3519763

Gonzalo Gabriel Méndez, Oscar Moreno, and Patricio Mendoza. 2022. LegisLatio: A visualization Tool for Legislative
Roll-call Vote Data. In Proceedings of the 15th International Symposium on Visual Information Communication and
Interaction (VINCI ’22). Association for Computing Machinery, New York, NY, USA, 1-8. https://doi-org/10.1145/
3554944.3554957

Pross Oluka Nagitta, Godfrey Mugurusi, Peter Adoko Obicci, and Emmanuel Awuor. 2022. Human-centered artificial
intelligence for the public sector: The gate keeping role of the public procurement professional. Procedia Computer
Science 200 (Jan. 2022), 1084-1092. https://doi.org/10.1016/j.procs.2022.01.308

Graham Orange, Alan Burke, Tony Elliman, and Ah Lian Kor. 2007. CARE: An Integrated Framework to Support
Continuous, Adaptable, Reflective Evaluation of E-Government Systems. International Journal of Cases on Electronic
Commerce (IJCEC) 3, 3 (July 2007), 18-32. https://doi.org/10.4018/jcec.2007070102 Publisher: IGI Global.

Eleni Panopoulou, Efthimios Tambouris, and Konstantinos Tarabanis. 2010. eParticipation Initiatives in Europe:
Learning from Practitioners. In Electronic Participation (Lecture Notes in Computer Science), Efthimios Tambouris, Ann
Macintosh, and Olivier Glassey (Eds.). Springer, Berlin, Heidelberg, 54-65. hhttps://doi.org/10.1007/978-3-642-15158-
3.5

Samir Passi and Steven J. Jackson. 2018. Trust in Data Science: Collaboration, Translation, and Accountability in
Corporate Data Science Projects. Proceedings of the ACM on Human-Computer Interaction 2, CSCW (Nov. 2018),
136:1-136:28. https://doi.org/10.1145/3274405

Oren Perez. 2008. Complexity, Information Overload, and Online Deliberation Online Consultation and Democratic
Communication. I/S: A Journal of Law and Policy for the Information Society 5, 1 (2008), 43-86. https://heinonline.
org/HOL/P?h=hein.journals/isjlpsoc5&i=53

Anders Persson and Goran Goldkuhl. 2010. Government Value Paradigms—Bureaucracy, New Public Management,
and E-Government. Communications of the Association for Information Systems 27, 1 (July 2010). https://doi.org/10.

, Vol. 1, No. 1, Article . Publication date: October 2024.


4

85

86

87

88

[89

fa)

=
‘oO
o

=

[91

oa

92

93

94

95

96

o7

98

99

[100

[101

houghtful Adoption of NLP for Civic Participation 25

17705/1CAIS.02704

Mirko Peéarié. 2017. Can a group of people be smarter than experts? The Theory and Practice of Legislation 5, 1 (Jan.
2017), 5-29. https://doi.org/10.1080/20508840.2016.1259823

Martijn Poel, Eric T. Meyer, and Ralph Schroeder. 2018. Big Data for Policymaking: Great Expectations, but
with Limited Progress? Policy & Internet 10, 3 (2018), 347-367. _https://doi.org/10.1002/poi3.176 _eprint:
https://onlinelibrary.wiley.com/doi/pdf/10.1002/poi3.176.

Thamy Pogrebinschi. 2021. Thirty Years of Democratic Innovations in Latin America. (2021). https://www.econstor.
eu/handle/10419/235143 Publisher: Berlin: WZB Berlin Social Science Center.

Lukasz Porwol, Agustin Garcia Pereira, and Catherine Dumas. 2022. Transforming e-participation: VR-dialogue —
building and evaluating an Al-supported framework for next-gen VR-enabled e-participation research. Transforming
Government: People, Process and Policy 17, 2 Jan. 2022), 233-250. https://doi-org/10.1108/TG- 12-2021-0205 Publisher:
Emerald Publishing Limited.

Pablo-Alejandro Quinones. 2014. Cultivating practice & shepherding technology use: supporting appropriation
among unanticipated users. In Proceedings of the 17th ACM conference on Computer supported cooperative work
& social computing (CSCW ’14). Association for Computing Machinery, New York, NY, USA, 305-318. https:
//doi.org/10.1145/2531602.2531698

J Rappaport. 2020. Cowards Don’t Make History: Orlando Fals Borda and the Origins of Participatory Action Research.
Duke University Press, Durnham. _https://books.google.cl/books?id=p2n9DwAAQBAJ

Maria Paz Raveau, Juan Pablo Couyoumdjian, Claudio Fuentes-Bravo, Carlos Rodriguez-Sickert, and Cristian Candia.
2022. Citizens at the forefront of the constitutional debate: Voluntary citizen participation determinants and emergent
content in Chile. PLOS ONE 17, 6 (June 2022), e0267443. https://doi.org/10.1371/journal.pone.0267443 Publisher:
Public Library of Science.

Amy Rechkemmer and Ming Yin. 2022. When Confidence Meets Accuracy: Exploring the Effects of Multiple
Performance Indicators on Trust in Machine Learning Models. In Proceedings of the 2022 CHI Conference on Human
Factors in Computing Systems (CHI ’22). Association for Computing Machinery, New York, NY, USA, 1-14. https:
//doi.org/10.1145/3491102.3501967

Brandon Reynante, Steven P. Dow, and Narges Mahyar. 2021. A Framework for Open Civic Design: Integrating Public
Participation, Crowdsourcing, and Design Thinking. Digital Government: Research and Practice 2, 4 (Oct. 2021), 1-22.
https://doi.org/10.1145/3487607

Pedro Reynolds-Cuéllar, Claudia Grisales, Marisol Wong-Villacrés, Bibiana Serpa, Julian Ifaki Gofii, and Oscar A.
Lemus. 2022. Reviews Gone South: A Subversive Experiment on Participatory Design Canons. In Participatory Design
Conference 2022: Volume 1. ACM, New York, NY, USA, 206-217. https://doi.org/10.1145/3536169.3537794

Pedro Reynolds-Cuéllar, Marisol Wong-Villacres, Karla Badillo-Urquiola, Mayra Donaji Barrera Machuca, Franceli L.
Cibrian, Marianela Ciolfi Felice, Carolina Fuentes, Laura Sanely Gaytan-Lugo, Vivian Genaro Motti, Monica Perusquia-
Hernandez, and Oscar A Lemus. 2023. Para Cima y Pa’ Abajo: Building Bridges Between HCI Research in Latin
America and in the Global North. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems.
ACM, Hamburg Germany, 1-19. https://doi.org/10.1145/3544548.3581138

Paola Ricaurte, Edgar Gomez-Cruz, and Ignacio Siles. 2024. Algorithmic governmentality in Latin America: So-
ciotechnical imaginaries, neocolonial soft power, and authoritarianism. Big Data & Society 11, 1 (March 2024),
20539517241229697. https://doi.org/10.1177/20539517241229697 Publisher: SAGE Publications Ltd.

Ana Rivoir and Javier Landinelli. 2017. ICT-mediated Citizen Engagement - Case Study: Open Government National
Action Plan in Uruguay. In Proceedings of the 10th International Conference on Theory and Practice of Electronic
Governance (ICEGOV ’17). Association for Computing Machinery, New York, NY, USA, 214-217. https://doi.org/10.
1145/3047273.3047359

Peter Gordon Roetzel. 2019. Information overload in the information age: a review of the literature from business
administration, business psychology, and related disciplines with a bibliometric approach and framework development.
Business Research 12, 2 (Dec. 2019), 479-522. https://doi.org/10.1007/s40685-018-0069-z

Annys Rogerson, Emma Hankins, Pablo Fuentes, and Sulamaan Rahim. 2022. Government AI Readiness Index 2022.
Technical Report. Oxford Insights.

Julia Romberg. 2022. Is Your Perspective Also My Perspective? Enriching Prediction with Subjectivity. In Proceedings
of the 9th Workshop on Argument Mining. International Conference on Computational Linguistics, Online and in
Gyeongju, Republic of Korea, 115-125. https://aclanthology.org/2022.argmining- 1.11

Julia Romberg and Tobias Escher. 2022. Automated Topic Categorisation of Citizens’ Contributions: Reducing Manual
Labelling Efforts Through Active Learning. In Electronic Government (Lecture Notes in Computer Science), Marijn
Janssen, Csaba Csaki, Ida Lindgren, Euripidis Loukis, Ulf Melin, Gabriela Viale Pereira, Manuel Pedro Rodriguez Bolivar,
and Efthimios Tambouris (Eds.). Springer International Publishing, Cham, 369-385. https://doi.org/10.1007/978-3-
031-15086-9_24

, Vol. 1, No. 1, Article . Publication date: October 2024.


26

[102

[103

[104

[105

[106

[107

[108

[109

[110

[111

[112

[113

[114

[115

[116

eo

[117

oo

[118

fey

[119]

Jose A. Guridi, Cristobal Cheyre, and Qian Yang

Julia Romberg and Tobias Escher. 2023. Making Sense of Citizens’ Input through Artificial Intelligence: A Review of
Methods for Computational Text Analysis to Support the Evaluation of Contributions in Public Participation. Digital
Government: Research and Practice (June 2023). https://doi.org/10.1145/3603254 Just Accepted.

Emma Rose and Josh Tenenberg. 2016. Arguing about design: A taxonomy of rhetorical strategies deployed by user
experience practitioners. In Proceedings of the 34th ACM International Conference on the Design of Communication
(SIGDOC ’16). Association for Computing Machinery, New York, NY, USA, 1-10. https://doi.org/10.1145/2987592.
2987608

Jeremy Rose, Leif Skiftenes Flak, and @ystein Seebg. 2018. Stakeholder theory for the E-government context:
Framing a value-oriented normative core. Government Information Quarterly 35, 3 (Sept. 2018), 362-374. https:
//doi.org/10.1016/j-gig.2018.06.005

Jeremy Rose, John Stouby Persson, Lise Tordrup Heeager, and Zahir Irani. 2015. Managing e-Government: value
positions and relationships. Information Systems Journal 25, 5 (2015), 531-571. https://doi.org/10.1111/isj.12052
Jeremy Rose and @ystein Sebg. 2010. Designing Deliberation Systems. The Information Society
26, 3 (April 2010), 228-240. https://doi.org/10.1080/01972241003712298 Publisher: Routledge _eprint:
https://doi.org/10.1080/01972241003712298.

Jennifer Rowley. 2011. e-Government stakeholders—Who are they and what do they want? International Journal of
Information Management 31, 1 (Feb. 2011), 53-62. https://doi.org/10.1016/j.ijinfomgt.2010.05.005

Devansh Saxena, Karla Badillo-Urquiola, Pamela J. Wisniewski, and Shion Guha. 2021. A Framework of High-Stakes
Algorithmic Decision-Making for the Public Sector Developed through a Case Study of Child-Welfare. Proc. ACM
Hum.-Comput. Interact. 5, CSCW2 (Oct. 2021), 348:1-348:41. https://doi.org/10.1145/3476089

Vivien A. Schmidt. 2013. Democracy and Legitimacy in the European Union Revisited: Input, Output and “Through-
put’. Political Studies 61, 1 (March 2013), 2-22. https://doi.org/10.1111/j.1467-9248.2012.00962.x Publisher: SAGE
Publications Ltd.

Hans J. Scholl. 2004. Involving Salient Stakeholders: Beyond the Technocratic View on Change. Action Research 2, 3
(Sept. 2004), 277-304. https://doi.org/10.1177/1476750304045940 Publisher: SAGE Publications.

Hong Shen, Leijie Wang, Wesley H. Deng, Ciell Brusse, Ronald Velgersdijk, and Haiyi Zhu. 2022. The Model Card
Authoring Toolkit: Toward Community-centered, Deliberation-driven AI Design. In 2022 ACM Conference on Fairness,
Accountability, and Transparency (FAccT ’22). Association for Computing Machinery, New York, NY, USA, 440-451.
https://doi.org/10.1145/3531146.3533110

Anthony Simonofski, Jeréme Fink, and Corentin Burnay. 2021. Supporting policy-making with social media and
e-participation platforms data: A policy analytics framework. Government Information Quarterly 38, 3 (July 2021),
101590. https://doi.org/10.1016/j.gig.2021.101590

Mona Sloane, Rumman Chowdhury, John C. Havens, Tomo Lazovich, and Luis Rincon Alba. 2021. AI and Procurement
- A Primer. Working Paper. https://doi.org/10.17609/bxzf-df18 Accepted: 2021-06-25T16:16:18Z.

Mona Sloane, Emanuel Moss, Olaitan Awomolo, and Laura Forlano. 2020. Participation is not a Design Fix for Machine
Learning. https://doi.org/10.48550/arXiv.2007.02423 arXiv:2007.02423 [cs].

Mona Sloane, Emanuel Moss, Olaitan Awomolo, and Laura Forlano. 2022. Participation Is not a Design Fix for Machine
Learning. In Proceedings of the 2nd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization
(EAAMO ’22). Association for Computing Machinery, New York, NY, USA, 1-6. https://doi.org/10.1145/3551624.
3555285

Christopher T. Small, Ivan Vendrov, Esin Durmus, Hadjar Homaei, Elizabeth Barry, Julien Cornebise, Ted Suzman,
Deep Ganguli, and Colin Megill. 2023. Opportunities and Risks of LLMs for Scalable Deliberation with Polis.
https://doi.org/10.48550/arXiv.2306.11932 arXiv:2306.11932 [cs].

Logan Stapleton, Devansh Saxena, Anna Kawakami, Tonya Nguyen, Asbjorn Ammitzbell Fliigge, Motahhare Eslami,
Naja Holten Moller, Min Kyung Lee, Shion Guha, Kenneth Holstein, and Haiyi Zhu. 2022. Who Has an Interest in
“Public Interest Technology”?: Critical Questions for Working with Local Governments & Impacted Communities.
In Companion Publication of the 2022 Conference on Computer Supported Cooperative Work and Social Computing
(CSCW’22 Companion). Association for Computing Machinery, New York, NY, USA, 282-286. https://doi.org/10.
1145/3500868.3560484

Michael Andrea Strebel, Daniel Kiibler, and Frank Marcinkowski. 2019. The importance of input and output legitimacy
in democratic governance: Evidence from a population-based survey experiment in four West European countries.
European Journal of Political Research 58, 2 (2019), 488-513. _https://doi.org/10.1111/1475-6765.12293 _ eprint:
https://onlinelibrary.wiley.com/doi/pdf/10.1111/1475-6765.12293.

Daniel Susser. 2019. Invisible Influence: Artificial Intelligence and the Ethics of Adaptive Choice Architectures.
In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society (AIES 19). Association for Computing
Machinery, New York, NY, USA, 403-408. https://doi.org/10.1145/3306618.3314286

, Vol. 1, No. 1, Article . Publication date: October 2024.


Thoughtful Adoption of NLP for Civic Participation 27

[120

[121

[122

[123

[124
[125

[126

[127

[128

[129

[130

[131

[132

[133

[134

[135

[136

a

@ystein Sebg, Leif Skiftenes Flak, and Maung K. Sein. 2011. Understanding the dynamics in e-Participation initiatives:
Looking through the genre and stakeholder lenses. Government Information Quarterly 28, 3 (July 2011), 416-425.
https://doi.org/10.1016/j.giq.2010.10.005

Reem Talhouk, Ebtisam Alabdulqader, Cat Kutay, Kagonya Awori, Marisol Wong-Villacres, Neha Kumar, Tariq Zaman,
Volker Wulf, Zainab Almeraj, and Shaimaa Lazem. 2023. Re-articulating North-South Collaborations in HCI. In
Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems (CHI EA ’23). Association for
Computing Machinery, New York, NY, USA, 1-4. https://doi.org/10.1145/3544549.3583752

Luca Tangi, Colin van Noordt, and A. Paula Rodriguez Miller. 2023. The challenges of AI implementation in
the public sector. An in-depth case studies analysis. In Proceedings of the 24th Annual International Conference
on Digital Government Research (DGO ’23). Association for Computing Machinery, New York, NY, USA, 414-422.
https://doi.org/10.1145/3598469.3598516

Peter Tolmie, James Pycock, Tim Diggins, Allan MacLean, and Alain Karsenty. 2002. Unremarkable computing. In
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ’02). Association for Computing
Machinery, New York, NY, USA, 399-406. https://doi.org/10.1145/503376.503448

UNESCO. 2023. Chile: artificial intelligence readiness assessment report - UNESCO Biblioteca Digital. Technical Report.
UNESCO, Paris. https://unesdoc.unesco.org/ark:/48223/pf0000387216

Economist Intelligence Unit. 2024. Democracy Index 2023 - Age of Conflict. Technical Report. Economist Intelligence
Unit.

Briana Vecchione, Karen Levy, and Solon Barocas. 2021. Algorithmic Auditing and Social Justice: Lessons from the
History of Audit Studies. In Proceedings of the 1st ACM Conference on Equity and Access in Algorithms, Mechanisms,
and Optimization (EAAMO ’21). Association for Computing Machinery, New York, NY, USA, 1-9. https://doi.org/10.
1145/3465416.3483294

Constantin von Brackel-Schmidt, Emir Kuéevi¢, Stephan Leible, Dejan Simic, Gian-Luca Giictik, and Felix N. Schmidt.
2024. Equipping Participation Formats with Generative AI: A Case Study Predicting the Future of a Metropolitan
City in the Year 2040. In HCI in Business, Government and Organizations, Fiona Fui-Hoon Nah and Keng Leng Siau
(Eds.). Springer Nature Switzerland, Cham, 270-285. https://doi.org/10.1007/978-3-031-61315-9_19

Danding Wang, Qian Yang, Ashraf Abdul, and Brian Y. Lim. 2019. Designing Theory-Driven User-Centric Explainable
AL In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI ’19). Association for
Computing Machinery, New York, NY, USA, 1-15. https://doi-org/10.1145/3290605.3300831

Laura Weidinger, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang, John Mellor, Amelia Glaese, Myra
Cheng, Borja Balle, Atoosa Kasirzadeh, Courtney Biles, Sasha Brown, Zac Kenton, Will Hawkins, Tom Stepleton,
Abeba Birhane, Lisa Anne Hendricks, Laura Rimell, William Isaac, Julia Haas, Sean Legassick, Geoffrey Irving, and
Iason Gabriel. 2022. Taxonomy of Risks posed by Language Models. In Proceedings of the 2022 ACM Conference on
Fairness, Accountability, and Transparency (FAccT ’22). Association for Computing Machinery, New York, NY, USA,
214-229. https://doi.org/10.1145/3531146.3533088

Min-Hsien Weng, Shaoqun Wu, and Mark Dyer. 2021. AI Augmented Approach to Identify Shared Ideas from Large
Format Public Consultation. Sustainability 13, 16 (Jan. 2021), 9310. https://doi.org/10.3390/su13169310 Number: 16
Publisher: Multidisciplinary Digital Publishing Institute.

Bernd W. Wirtz, Jan C. Weyerer, and Carolin Geyer. 2019. Artificial Intelligence and the Public Sector—Applications
and Challenges. International Journal of Public Administration 42, 7 (May 2019), 596-615. https://doi.org/10.1080/
01900692.2018.1498103 Publisher: Routledge _ eprint: https://doi.org/10.1080/01900692.2018.1498103.

Richmond Y. Wong. 2021. Tactics of Soft Resistance in User Experience Professionals’ Values Work. Proceedings of
the ACM Human-Computer Interaction 5, CSCW2 (Oct. 2021). https://doi.org/10.1145/3479499

Richmond Y. Wong, Michael A. Madaio, and Nick Merrill. 2023. Seeing Like a Toolkit: How Toolkits Envision
the Work of AI Ethics. Proceedings of the ACM on Human-Computer Interaction 7, CSCW1 (2023), 145:1-145:27.
https://doi.org/10.1145/3579621

Marisol Wong-Villacres, Adriana Alvarado Garcia, Karla Badillo-Urquiola, Mayra Donaji Barrera Machuca, Mari-
anela Ciolfi Felice, Laura S. Gaytan-Lugo, Oscar A. Lemus, Pedro Reynolds-Cuéllar, and Monica Perusquia-Hernandez.
2021. Lessons from Latin America: embracing horizontality to reconstruct HCI as a pluriverse. Interactions 28, 2
(March 2021), 56-63. https://doi.org/10.1145/3447794

Qian Yang, Justin Cranshaw, Saleema Amershi, Shamsi T. Iqbal, and Jaime Teevan. 2019. Sketching NLP: A Case
Study of Exploring the Right Things To Design with Language Intelligence. In Proceedings of the 2019 CHI Conference
on Human Factors in Computing Systems (CHI ’19). Association for Computing Machinery, New York, NY, USA, 1-12.
https://doi.org/10.1145/3290605.3300415

Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-examining Whether, Why, and How
Human-Al Interaction Is Uniquely Difficult to Design. In Proceedings of the 2020 CHI Conference on Human Factors in
Computing Systems (CHI ’20). Association for Computing Machinery, New York, NY, USA, 1-13. https://doi.org/10.

, Vol. 1, No. 1, Article . Publication date: October 2024.


28

[137

[138

[139

[140

=

[141

ao

Jose A. Guridi, Cristobal Cheyre, and Qian Yang

1145/3313831.3376301

Qian Yang, Aaron Steinfeld, and John Zimmerman. 2019. Unremarkable AI: Fitting Intelligent Decision Support
into Critical, Clinical Decision-Making Processes. In Proceedings of the 2019 CHI Conference on Human Factors in
Computing Systems (CHI ’19). Association for Computing Machinery, New York, NY, USA, 1-11. https://doi.org/10.
1145/3290605.3300468

Qian Yang, Richmond Wong, Thomas Gilbert, Margaret Hagan, Steven Jackson, Sabine Junginger, and John Zim-
merman. 2023. Designing Technology and Policy Simultaneously: Towards A Research Agenda and New Practice.
https://doi.org/10.1145/3544549.3573827

Qian Yang, Richmond Y. Wong, Steven Jackson, Sabine Junginger, Margaret D. Hagan, Thomas Gilbert, and John
Zimmerman. 2024. The Future of HCI-Policy Collaboration. In Proceedings of the 2024 CHI Conference on Human
Factors in Computing Systems (Honolulu, HI, USA) (CHI ’24). Association for Computing Machinery, New York, NY,
USA, Article 820, 15 pages. https://doi.org/10.1145/3613904.3642771

Nur Yildirim, Alex Kass, Teresa Tung, Connor Upton, Donnacha Costello, Robert Giusti, Sinem Lacin, Sara Lovic,
James M O’Neill, Rudi O’Reilly Meehan, Eoin O Loideain, Azzurra Pini, Medb Corcoran, Jeremiah Hayes, Diarmuid J
Cahalane, Gaurav Shivhare, Luigi Castoro, Giovanni Caruso, Changhoon Oh, James McCann, Jodi Forlizzi, and John
Zimmerman. 2022. How Experienced Designers of Enterprise Applications Engage AI as a Design Material. In CHI
Conference on Human Factors in Computing Systems. ACM, New Orleans LA USA, 1-13. https://doi-org/10.1145/
3491102.3517491

Ivania Yovanovic, Ifaki Gofi, and Constanza Miranda. 2021. Remote Usability Assessment of Topic Visualization
Interfaces with Public Participation Data: A Case Study. JeDEM - eJournal of eDemocracy and Open Government 13, 1
(Aug. 2021), 101-126. https://doi.org/10.29379/jedem.v13i1.640 Number: 1.

Received 15 January 2024; revised 16 July 2024; accepted

, Vol.

1, No. 1, Article . Publication date: October 2024.
