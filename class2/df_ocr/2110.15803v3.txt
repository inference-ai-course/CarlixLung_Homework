2110.15803v3 [cs.CL] 26 Sep 2022

arXiv

IEEE REVIEWS IN BIOMEDICAL ENGINEERING

Natural Language Processing for Smart Healthcare

Binggui Zhou, Guanghua Yang™, Zheng Shi, and Shaodan Ma“

Abstract—Smart healthcare has achieved significant progress
in recent years. Emerging artificial intelligence (AI) technologies
enable various smart applications across various healthcare
scenarios. As an essential technology powered by AI, natural
language processing (NLP) plays a key role in smart healthcare
due to its capability of analysing and understanding human
language. In this work, we review existing studies that concern
NLP for smart healthcare from the perspectives of technique and
application. We first elaborate on different NLP approaches and
the NLP pipeline for smart healthcare from the technical point
of view. Then, in the context of smart healthcare applications
employing NLP techniques, we introduce representative smart
healthcare scenarios, including clinical practice, hospital man-
agement, personal care, public health, and drug development. We
further discuss two specific medical issues, i.e., the coronavirus
disease 2019 (COVID-19) pandemic and mental health, in which
NLP-driven smart healthcare plays an important role. Finally,
we discuss the limitations of current works and identify the
directions for future works.

Index Terms—Natural Language Processing, Smart Health-
care, Artificial Intelligence, NLP Techniques, Healthcare Appli-
cations

I. INTRODUCTION

MART healthcare is a healthcare system that exploits
emerging technologies, such as artificial intelligence (AD,
blockchain, big data, cloud/edge computing, and the internet
of things (IOT), for realizing various intelligent systems to
connect healthcare participants and promote the quality of
healthcare [1]. Major participants in smart healthcare can
be classified into three categories, i.e., the public, health-
care service providers, and third-party healthcare participants.
Related to the participants, representative smart healthcare
scenarios include smart homes, smart hospitals, intelligent
research and development for life science, health management,
public health, rehabilitation therapy, and etc. Fig. [I] shows the
major participants, emerging technologies, and representative
scenarios of smart healthcare.
Natural language processing (NLP) is a subfield of com-
puter science and artificial intelligence that is concerned with

Binggui Zhou is with the School of Intelligent Systems Science and
Engineering, Jinan University, Zhuhai 519070, China; and also with the State
Key Laboratory of Internet of Things for Smart City and the Department of
Electrical and Computer Engineering, University of Macau, Macao 999078,
China.

Guanghua Yang is with the School of Intelligent Systems Science and
Engineering, Jinan University, Zhuhai 519070, China.

Zheng Shi is with the School of Intelligent Systems Science and Engineer-
ing, Jinan University, Zhuhai 519070, China; and also with the State Key
Laboratory of Internet of Things for Smart City, University of Macau, Macao
999078, China.

Shaodan Ma is with the State Key Laboratory of Internet of Things for
Smart City and the Department of Electrical and Computer Engineering,
University of Macau, Macao 999078, China.

Corresponding authors: Guanghua Yang (ghyang@jnu.edu.cn), Shaodan
Ma (shaodanma@um.edu.mo).

the automatic analysis, representation and understanding of
human language (2). NLP has become a hot research area
and has attracted widespread attention from many research
communities in the past several years. As human language
is a general form of data entry for intelligent systems, NLP
enables machines to understand human language and interact
with humans, making it essential to smart healthcare.

The main manifestations of natural language are text and
speech, where text encompasses text records, articles, book
chapters, dictionaries, and so forth, while speech occurs in
human-human and human-machine dialogues. NLP has been
developed for several decades following the early origin of
artificial intelligence in the 1950s. Approaches to conduct
NLP are generally divided into three categories: rule-based
approaches, statistical approaches, and deep learning-based
approaches. From the 1950s to 1980s, NLP research mainly
focused on rule-based approaches, which required expertise in
both computer science and linguistics to design rules that fit
human language. However, even well-designed rules are quite
limited for covering human language due to its flexibility and
complex patterns. Since the 1980s, statistical NLP systems
have been designed by extracting features from corpora using
statistical and machine learning algorithms and have gradually
replaced rule-based NLP systems due to their superiority in
performance and robustness. With the early application of
the neural probabilistic language model and the rapid
development of deep learning since 2013, neural NLP, by
using neural networks and large corpora for automated feature
learning, has dominated current research and achieved SOTA
performance of many NLP tasks.

In smart healthcare, NLP is applied to process text data and
is associated with human-machine/human-human communica-
tion. The text data can be classified into 2 categories: clinical
text and other text data. Clinical text comes from all clinical
scenarios and mainly comprises of unstructured text records
from electronic health record (EHR) systems, including med-
ical notes, diagnostic reports, electronic prescriptions, and
etc. Other text data include all text that appears within other
healthcare scenarios, e.g., surveys in population screening and
articles for evidence-based reference. Communication is com-
mon in all smart healthcare scenarios, such as patient-provider
communication in clinical inquiry and human-robot interaction
in rehabilitation therapy, accompanied by applications such
as machine translations and user interfaces for rehabilitation
robots.

As well recognized, research on and applications of NLP
for smart healthcare have received intensive attention in recent
years. However, no study has offered a well-organized sum-
mary of existing works in a systematic way. In this paper, we
first provide a systematic review of NLP for smart healthcare

© 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media,
including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers
or lists, or reuse of any copyrighted component of this work in other works.


2
healthcare life science
institutions companies
Service Providers
Smart
Healthcare
healthy people _ patients
Public
a Major Participants
Fig. 1.

IEEE REVIEWS IN BIOMEDICAL ENGINEERING

@ @ a

i OQ

government medical insurance

Third Parties

ME computing

blockchain
b a Technologies

f

intelligent R&D
for life science

public health
promotion

smart hospitals

c Representative Scenarios

health monitoring

Smart healthcare. a, major participants in smart healthcare include the public, healthcare service providers, and third-party healthcare participants.

b, example emerging technologies enable smart healthcare applications include artificial intelligence, blockchain, cloud computing, the internet of things, and
etc. ¢, representative smart healthcare scenarios include intelligent research and development for life science, public health promotion, smart hospitals, health

monitoring, and etc.

from both technical and application perspectives. After that,
we discuss two specific medical issues, i.e., coronavirus dis-
ease 2019 (COVID-19) pandemic and mental health, in which
NLP-driven smart healthcare plays an important role. Finally
we discuss the limitations of existing works, identify the future
directions of applying NLP to smart healthcare, and close the
review with some conclusions.

II. NLP FOR SMART HEALTHCARE FROM TECHNICAL
PERSPECTIVE

NLP has been undergoing continuous development since the
1950s. Studies on NLP for smart healthcare have also been
conducted for decades and have attracted increased attention
in recent years with the advancement of artificial intelligence
and general NLP. To connect existing works from technical
perspective, in this section, we first introduce the three kinds of
NLP approaches and their representative algorithms, and then
introduce the NLP pipeline for smart healthcare to show how
NLP techniques are used in real smart healthcare applications.

A. Comparisons of different NLP approaches

The mainstream NLP approaches can be classified into three
categories, i.e., rule-based NLP, statistical NLP and neural
NLP, which have different characteristics. Below, we discuss
the advantage and disadvantages of the three categories and
introduce the representative algorithms of them.

Rule-based NLP approaches, e.g., pattern matching
and parsing [5], could be quite accurate in specific cases if
dedicated studies by experts are conducted. In addition, rule-
based NLP approaches are easy to interpret and understand.
However, rules are normally too limited to cover all cases
considering the flexibility and complex patterns of human lan-
guage. In addition, rule-based NLP requires expertise in both
computer science and linguistics to design appropriate rules to
fit human language, hindering it from large-scale applications.
Currently, rule-based approaches have been widely considered
obsolete by academia (6). and are occasionally used for better
preprocessing nowadays (7).

In general, statistical NLP is superior to rule-based NLP in
performance and robustness. However, it also requires domain
expertise to create handcrafted features, and is therefore lim-
ited to taking full advantage of available data and providing
enough accuracy in complex applications. Although statistical
NLP requires intensive feature engineering, it is this direct
feature design that makes it transparent and interpretable as
rule-based NLP. In addition, statistical NLP does not rely on
large-scale datasets or large amounts of computational power,
and thus is much more efficient than neural NLP. Furthermore,
representative statistical NLP models, such as bag-of-words
(8). TF-IDF [9}, [10], and n-gram [i1}+{13], have different
characteristics. Bag-of-words is easy to implement, but it
only considers the frequencies of words in a sentence, which
neglects the importance and sequential order of these words.


ZHOU et al.: NATURAL LANGUAGE PROCESSING FOR SMART HEALTHCARE

Through the inverse document frequency, TF-IDF improves
the measurement of a word’s importance, but still does not
take sequential order information into consideration. N-gram
considers n — 1 words before a word, which makes it more
accurate than bag-of-words but with higher computational
complexity (increases exponentially with n). It is worth men-
tioning that despite the dominance of deep learning in recent
years, statistical NLP is still active in many healthcare studies
and applications.

Recent years have witnessed the success of neural NLP, who
has shown better performance than both rule-based NLP and
statistical NLP in applications with abundant available data.
However, neural NLP is often blamed for low interpretability
and dependence on expensive computing platforms. It is
also worth noting that, compared with rule-based NLP and
statistical NLP, neural NLP usually fails to achieve satisfac-
tory performance if limited data is available. Among neural
NLP models, recurrent neural network (RNN)-based models,
especially long short-term memory (LSTM) [14]-[16]-based
models and gated recurrent unit (GRU)-based models (15),
(17). are more natural for processing sequential data such
as text and speech. They have the ability to remember his-
torical information of the inputs, but suffer from gradient
vanishing/explosion, training issues and short-term memories.
Convolutional neural networks (CNN)-based models [18],
[19], combining with word embeddings, also show good
performance in some tasks due to their ability in learning
local features and high computational efficiency which enables
deep network architectures. Recently, graph neural network
(GNN)-based models have been applied to NLP-driven smart
healthcare by incorporating knowledge from graph-structured
ontology/entities (20)-22}. When graphs are large in scale
or complex, GNN-based models are difficult and costly to
implement and train. Generally speaking, RNNs, CNNs, and
GNNs are all limited in tackling long-term dependencies in se-
quences. Through the self-attention mechanism, Transformer-
based models (23). are very efficient in processing
long sequences and support parallel training, but are lack
of ability in learning local features and position information.
We have witnessed many combinations of the aforementioned
models for better feature extraction performance, including
CNN-LSTM networks [25], RNN-Attention networks [26],
(27], memory networks (MM) [28], [29], graph convolutional
networks (GCN) [30], CNN-LSTM-Attention networks [31],
(32), graph convolutional attention networks (GCAN) (33),
(34), etc. In addition, to further leverage large unlabelled
corpora, pretraining, a very effective method, has been widely
exploited to obtain non-contextual or contextual embeddings
[35]. Word2vec [36]-[39], and GloVe (Global Vectors) [36],
(40), as representative algorithms of non-contextual embed-
dings, provide distributed dense vectors as word embeddings,
and outperform statistical algorithms such as bag-of-words and
n-gram. The non-contextual embedding for a word is static
and does not dynamically change as its context changes (35).
Based on the Transformer architecture, contextual embed-
dings, e.g., ELMo (Embeddings from Language Models) (41),
BERT (Bidirectional Encoder Representations from Trans-
formers) [42}-[45], and GPT (Generative Pre-Training) [46],

are developed to embed dynamic contextual information into
word embeddings, achieving outstanding performance than
other word embedding algorithms. It should be noted that these
models are typically huge and expensive to pre-train, which
somehow constraints their broad application in healthcare.

The comparisons of different NLP approaches and repre-
sentative algorithms are shown in Table

B. NLP pipeline for smart healthcare

As shown in Fig. |2] there are three parts in an NLP pipeline
for smart healthcare, i.e., preprocessing, feature extraction, and
modelling. An NLP pipeline takes text or speech as illustrated
before as the input. After that, preprocessing is conducted
considering various inputs and their qualities to facilitate
feature extraction and modelling. As the most important step,
feature extraction is essential to NLP, which undoubtedly
explains the attention it has received from researchers. Finally,
models for specific NLP tasks are built with the extracted
features to yield the outputs accordingly.

1) Preprocessing: Preprocessing, including the procedures
of tokenization, stemming, lemmatization, stopword removal,
and etc., makes natural language normalized, machine-
readable, and easy for postprocessing. Text preprocessing
mostly paves the way for feature extraction and modelling,
since many NLP tasks require normalized text input to guar-
antee accuracy and efficiency due to significant challenges
coming from the flexibility of natural languages and the
wide variety of morphological variants of medical terms in
medical text [47]-[49]. However, with the development of
neural NLP, some text preprocessing procedures have become
unnecessary and may even cause problems. For example,
removing stopwords may lead to the loss of informative
context information when using the BERT pre-trained model
(50). As the preprocessing of speech, such as denoising, is
typically regarded as a problem in signal processing, we do
not discuss it in detail here.

2) Feature extraction: Apart from the increase in accessible
digital data and the advances in computing platforms such
as graphics processing units, the development of NLP is
largely attributed to the improvement in feature design or
feature extraction methods. Both rule-based approaches and
statistical approaches require expertise for rule design (4).
[5] or feature engineering [8)-[13]. For neural NLP, auto-
mated feature extraction via varieties of neural networks [14]—
have greatly improved the efficiency of data utilization
and feature extraction. Automated feature engineering can be
conducted directly according to the downstream tasks using
supervised learning, unsupervised learning or reinforcement
learning. In addition, pretraining is also widely used in NLP
to automatically extract features from large unlabelled corpora
via self-supervised learning in a generative, contrastive or
generative-contrastive manner before the downstream
tasks begin. The extracted features, known as contextual or
non-contextual embeddings, may encompass features such as
lexical meanings, syntactic features, semantic features, and
even pragmatics, which contribute to downstream tasks (35).


TABLE I

IEEE REVIEWS IN BIOMEDICAL ENGINEERING

COMPARISONS OF DIFFERENT NLP APPROACHES AND REPRESENTATIVE ALGORITHMS.

NLP Approach

Feature Extrac-
tion Method

Advantages and Disadvantages

Representative Algorithms

Rule-based NLP

tule design

advantages:

- could be quite accurate in specific
cases;

- easy to interpret and understand

disadvantages:

- rules are too limited to cover all
cases considering the flexibility and
complex patterns of human language;
- require expertise in both computer
and linguistics to fit human language

pattern matching and parsing

Statistical NLP

hand-crafted fea-
ture engineering

advantages:

- superior to rule-based NLP in
performance and robustness;

- good interpretability

disadvantages:

- require domain expertise to create
handcrafted features;

- limited to taking full advantage of
available data and providing enough
accuracy in complex applications

bag-of-words (8):
- easy to implement;
- neglects the importance and sequential order of words

TF-IDF {9}, (10):
- improves the measurement of a word’s importance;
- does not take sequential order information into consideration

n-gram (1H{13)

- more {tg it an bag-of-words;
- high computational complexity Gree exponentially with n)

Neural NLP

automated
feature extraction

advantages:

- better performance than both
rule-based NLP and statistical NLP
in applications with abundant
available data

disadvantages:

- low interpretability;

- dependence on expensive computing}
platforms;

- usually fail to achieve satisfactory
performance if limited data is
available

T) RNN-based models (e.g., LSTM [14|-[16] and GRUs (5, (17):
- more natural for processing text and ae input;

- capable of remembering historical information of the inputs;

- suffer from gradient vanishing/explosion, training issues and
short-term memories

2) CNN-based models [18] (i3}, (19);
ures;

- able to learn local fea’
- high computational efficiency;
- limited in tackling long-term dependencies in sequences

3) GNN-based models
- efficient in incorporating knowledge from graph-structured

ontology/entities;

- limited in tackling long-term dependencies in sequences;

- difficult and costly to implement and train with large-scale
or very complex graphs

4) Transformer-based models {23}, 24):
- efficient in processing long sequences and parallel training;
- lack of ability in learning local features and position information

pe O81, PII. CNN-LSTM , RNN-Attention
Ae Bd Bo} ChE N= STM- Attention BTL | Bz

sid

6) non-contextual embedding-oriented pre-trained models

(word2vec [36] Bé}-69] (39), GloVe [36] (36), (40):

- outperform statistical algorithm

- the non-contextual embedding fe a word is static and will not
dynamically change as its context change

7) contextual embedding-oriented pre-trained models (ELMo 41),
BERT (42}-(45), GPT [46)):

- able to embed dynamic contextual information into word embeddings;
- outstanding performance than other word embedding algorithms;

- typically huge and expensive to pre-train



ZHOU et al.: NATURAL LANGUAGE PROCESSING FOR SMART HEALTHCARE

Inputs

a! Preprocessing —

Feature Extraction

Modelling

¢ Text Classification

¢ Information Extraction

* Machine Translation

¢ Text Generation

¢ Information Retrieval

* Question Answering and Dialogue
* Knowledge Engineering

* Natural Language Understanding
* Causal Inference

* Speech Recognition

* Speech Synthesis

Outputs
— Ss

Fig. 2. The NLP pipeline for smart healthcare. There are three parts in an NLP pipeline for smart healthcare, i.e., preprocessing, feature extraction, and
modelling. NLP takes text or speech as the input, followed by preprocessing to facilitate feature extraction and modelling. Features can be extracted with
various methods and models. Models for specific NLP tasks are finally built with the extracted features to yield the outputs.

3) Modelling: For various smart healthcare applications,
different models should be built to accomplish various NLP
tasks, such as text classification, information extraction, and
natural language understanding. The extracted feature can be
directly processed by classifiers and regressors to yield outputs
for simple tasks, e.g., medical text classification [18], 52},
while further steps are required to complete complex tasks. In
the following subsections, we first introduce several text input-
based NLP tasks according to their complexity. At the end of
this section, we will introduce two speech-specific tasks, 1.e.,
speech recognition and speech synthesis.

Information extraction. Information extraction (IE), a.k.a.
text mining, enables harvesting information from text inputs,
and plays an important role in text analysis. Works related to
information extraction in smart healthcare focus on the ex-
traction of diseases, drugs, events (mainly including temporal
expressions, spatial expressions and participant information)
through name entity waaeion BT, [54], relation extraction
(54)-(56], and event extraction [57] from medical text, includ-
ing unstructured text in EHRs, articles, etc.

Machine translation. Machine translation (MT) aims to
automatically translate text from one language to another
(58). Currently, healthcare resources in various languages are
becoming easily accessible as technologies evolve, and they
are all of great value in modern medical practice. Machine
translation therefore has drawn growing attention for building
better (multilingual) translation systems and further leveraging
multilingual healthcare resources for other applications, either
to provide more accurate translations (59). or to require
less time than human translations.

Text generation. Text generation (TG) automatically gener-
ates text with given inputs while pursuing the goal of appearing
indistinguishable from human-written text. Specifically, there
are 3 kinds of inputs and corresponding subtasks in smart
healthcare: text inputs (e.g., routine reports) associated with
text summarization Cea ana generation [64]-(66],
dialogue generation [67]-[69], and etc.; data inputs (e.g.,
neonatal intensive care data) connected with data-to-text (70);
and image inputs (e.g., medical images) related to image cap-
tioning [71], [72], visual question answering (VQA) [73]-[75}.
and etc. Note that for data-to-text and image-to-text generation,
a combination of NLP with data analysis or computer vision
is generally required, respectively.

Information retrieval. Information retrieval (IR) obtains
materials that meet the query requirements from numerous
documents, and is a core of search engines for all applications.
To ease the retrieval process |/76], [77], improve the relevance
and diversity of the veatona ICES or reduce the query
time (81). current works aim to develop fast and efficient
information retrieval methods to obtain useful retrieval from a
large collection of data sources, ranging from internal health
information system (HIS) systems and other digital documents
to online resources.

Question answering and dialogue systems. Question an-
swering (QA) involves automatically providing answers to
questions raised by humans in a natural language. Question
answering requires the machine to understand natural language
and infer the answers, making it highly dependent on natural
language understanding and information retrieval. To date,
QA systems for healthcare have developed from information
retrieval based QA systems (82)-('85| and knowledge-based
QA systems [86]-[89] to hybrid QA systems {90}, [91].
Compared to question answering, dialogue is also presented
in an interactive manner between humans and machines.
Common dialogue systems in smart healthcare include task-
oriented dialogue systems (92 |-[94], and non-task-oriented
(a.k.a. chat-oriented) dialogue systems, which assume
different functions in various applications.

Knowledge engineering. Knowledge engineering (KE) is
a field within artificial intelligence that tries to construct and
use knowledge-based systems (96). It does not refer to a pure
NLP technique, but receives much attention in NLP for smart
healthcare since medical text is one of the major sources
for knowledge engineering. Within knowledge engineering,
knowledge acquisition and knowledge representation are cou-
pling with information extraction, aiming at the acquisition
and representation of medical knowledge in a certain way,
e.g., knowledge graphs (97)-(99}. Besides, knowledge engi-
neering also concerns building knowledge-based systems to
exploit existing knowledge, such as knowledge-based ques-
tion answering (KBQA) systems [86] -[89}, knowledge-based
information retrieval systems [100], text generation systems
[65], 101}, etc.

Natural language understanding. Natural language un-
derstanding (NLU) focuses on machines’ comprehension of
human language in the form of unstructured text or speech.


Many of the aforementioned tasks, e.g., question answering,
information retrieval, require NLU to fully understand the in-
put queries. The difficulties of natural language understanding
come from the diversity, ambiguity, and potential dependence
of natural language, making slow progress in natural language
understanding compared with other NLP techniques. After
years of development in both general areas and smart health-
care, the mainstream route of NLU is still to use various meth-
ods to conduct slot filling and intent detection (102)-(704].
NLU is the core of multiple intelligent agents, assuming a
role in understanding human intentions during human-machine
interactions [102], (105), [106], medical queries [103], [104],
etc.

Causal inference. Generally, causal inference is a discipline
concerning the determination of actual effects of specific
things, events or phenomena. Causal inference in NLP has
long received insufficient attention since the goal of classical
NLP applications is simply to make accurate predictions with
all available statistical correlations regardless of the underlying
causal relationship (107). Recently, with growing concerns
about uninterpretable black box models, the importance of
causal inference has gradually been recognized by NLP re-
searchers, especially in the area of healthcare. Specifically, re-
cent advances of causal inference in NLP for smart healthcare
have been made in uncovering causality from medical text
[108)-{110] and realizing reliable NLP-driven applications
with discovered causal effects [108|-[110}.

Speech recognition and speech synthesis. Speech recogni-
tion (SR) aims to convert human speech into text information.
Contrary to speech recognition, speech synthesis, a.k.a. text-to-
speech (TTS), is concerned with representing text information
with speech. Basically, SR-oriented and SS-oriented studies
attempt to build automatic computer systems for interconver-
sion between speech and text in the area of smart healthcare,
making human-machine interaction as natural and flexible as
human-human interaction (ii). For speech recognition, these
efforts encompass the improvement in acoustic modelling
(112), [113], language modelling [114], and the whole system
pipeline [115], to enhance recognition accuracy. For
speech synthesis, recent advancements have been made in
investigating and making synthesized speech natural [117],

[118], intelligible [}119|-[123] and expressive [124]-[126],

which will help stimulate the enthusiasm of human-machine

interaction [127].

III. APPLICATIONS OF NLP FOR SMART HEALTHCARE

NLP has been widely applied in smart healthcare and
has brought dramatic improvements in many applications. As
shown in Fig. B] a typical NLP-driven application is composed
of two parts: user interface (UI) and backend. The user
provides text or speech input to the backend through the UI,
and then, the backend processes these inputs with the NLP
models and feeds the results back to the user by providing
specific services through the UI. Knowledge bases are also
required at the backend for applications that essentially rely on
knowledge, for example, the aforementioned KBQA systems.
The NLP techniques described in the previous section play a
key role in both UI and backend.

IEEE REVIEWS IN BIOMEDICAL ENGINEERING

User

User Interfaces

Backend

Fig. 3. Basic architecture of NLP-driven applications. A typical NLP-
driven application is composed of user interface and backend, where the UI
takes inputs from the user and feedback the results to the user, and the backend
processes these inputs with the NLP models with or without the knowledge
bases according to the specific task type.

The UI enables information exchange between users and
intelligent systems through speech, text, etc. Easily accessible
Uls are critical for enhancing the experience of using intelli-
gent systems and realizing smart healthcare. Such user inter-
faces can be implemented by using NLP techniques, especially
speech recognition and natural language understanding.

According to their application scenarios, smart healthcare
applications employing NLP techniques can be classified into
5 major categories, i.e., clinical practice, hospital manage-
ment, personal care, public health, and drug development. A
summary of the applications and related NLP techniques is
presented in Table |II} Below we introduce the five categories
in detail.

A. Clinical practice

Clinical communication and data collection. Clinical
data, including but not limited to demographics, medical
history, comorbidities, medical notes, physical examination
notes, electronic recordings from medical devices, and clinical
laboratory testing data and medical images (128), are the most
important data for diagnosis, treatment and even further retro-
spection. Patient-provider communication is an important way
to obtain first-hand clinical data. When necessary, machine
translation may assist doctors in communicating with patients
who speak different languages or have low literacy and limited
levels of health education [129], [130]. Meanwhile, free text
notes can be taken through speech recognition (131]-(133},
which can significantly reduce medical staff’s time on labour-
intensive clinical documentation.


ZHOU et al.: NATURAL LANGUAGE PROCESSING FOR SMART HEALTHCARE

Clinical decision support. Clinical decision support (CDS)
systems can provide physicians with diagnosis and treatment
suggestions, which play an increasingly important role in
clinical medicine with the surge of clinical cases and growing
concerns regarding public healthcare. With the development of
question answering systems, clinical decision support based
on question answering [84], [134], has emerged and
become common, as it is closer to traditional patient-provider
communication. NLP techniques have shown great ability to
build clinical decision support systems by extracting various
useful information for making diagnosis and therapeutic de-
cisions, such as family history information (136), entities and
relations [137], [138], treatment and prognosis data [139],
clinical data concepts and features (140), and even causal
relations [109], [110J. In addition, to ensure quality control
and future quality improvement, NLP can also contribute to
the assessment of clinical procedures [141], [142], warning
of potentially harmful adverse drug events (ADEs) {143},
disease symptoms [144], [145], and outcome-related causal
effects [146]. Finally, NLP is also powerful in enhancing
the interpretability and reliability of clinical decision support
systems for practical deployment, by providing supporting
evidence for diagnosis or treatment decisions in an evidence-

based fashion [108], |147]-[150].

B. Hospital management

Medical resource allocation. Due to limited medical re-
sources, including hospital spaces, personnel, and materi-
als, efficient resource allocation is critical in hospitals and
other medical facilities. By building patient triage systems,
medical resources can attend to critical cases with priority
and enhance medical resource sstants (33 3}. (133), ho and
efficiency (151), (152). seh fish serene 155}, hospital
automation systems [156], | and aa. robots
(158), with voice 4 can further reduce the burden
on medical staff, thereby improving hospital management
efficiency. There are also some interesting works that have
explored the prediction of patient readmission to rearrange
rate FTE 7 aeaeeomanae and reduce the readmission
rate [160)-{162]. In addition, by leveraging text generation
wohelanee part of text writing in healthcare, especially routine
reports, can be taken over by machines, freeing medical staff
from many administrative duties and making them available
for direct patient care [70], (163).

Data management. To manage large volumes of medical
documentation, text classification, information extraction and
text summarization can be used to generate category labels,
informative keywords and simplified summaries (18), (52),
(62), (63). for management, while information retrieval
systems, especially those systems based on semantic search
(76). and question answering [77], can be used in
healthcare information systems to ease the retrieval process.

Service quality control. Sentiment analysis with patient
experience feedback will help hospitals improve their service
quality and patient experience. Such analysis required sub-
stantial personnel resources in the past, while NLP makes this
work easier and greatly improves the efficiency of sentiment

analysis [}166|—[168].

C. Personal care

Personal health assistants. Personal health assistants en-
able people to easily access useful medical information and
healthcare services without visiting the healthcare institutions.
Personal health assistants may incorporate several subsystems,
such as medical information access systems and remote
healthcare systems [170], for various purposes.

Assisting elderly individuals and disabled individuals.
NLP techniques can help elderly individuals and disabled
individuals to greatly enhance their quality of life and so-
cial integration. Voice-controlled home automation systems
and robots may assist the elderly and the disabled in their
daily lives (171), while robots (especially androids and other
robots that communicate with people) can even encourage and
accompany them through social interactions (172), (173). In
addition, NLP techniques are also of great value for providing
essential aids a et ve TTR bea oso é; Th speech

impairments [122! ‘pean joss , dyslexia
/180], or newoiotiou a eNien —(121}.

D. Public health

Health knowledge popularization and medical educa-
tion. Health knowledge popularization and medical education
are essential public health interventions since they can im-
prove people’s health literacy and help them develop healthy
living habits. Through knowledge engineering, accurate and
complete medical knowledge bases can be established to
promote the popularization of medical knowledge among the
population [86}-[89], (97|-[100], [181]. Specifically, people
can easily access medical knowledge through question an-
swering systems [182], [183], information retrieval systems
79], [81], and machine translation systems [I], [130], [184],
185], facilitating the popularization and education of medical
knowledge. In addition, text generation techniques, such as
question generation and text summarization, can also be used
in medical education to generate medical case-based questions
| 186) and construct simplified summaries (61).

Population screening. In addition to the health knowledge
popularization, population screening, which refers to the pro-
cess of assessing the prevalence of a disease or condition in
a population or subgroup, is also an important intervention
for delivering public health. The population screening starts
with identifying target populations, followed by the screening
test. After that, further actions such as further tests, advice, or
treatment can be taken considering the screening results (187).
NLP can play two main roles in population screening. First,
NLP helps identify populations with higher health risk factors,
which may improve the efficiency of population screening
(188). Second, NLP can also assist in the analysis of healthcare
questionnaires and surveys (189), especially for open-ended
questions.

E. Drug development

Drug discovery. NLP helps construct textual representa-
tions of biochemical entities for mapping the interactions


between diseases, drugs/chemical compounds, and biomacro-
molecules (e.g., genes, proteins); predicting molecular prop-
erties; and designing novel molecules. Readers are referred to
the comprehensive review by Oztiirk et al [190] for a deeper
understanding of NLP methodologies for drug discovery.

Preclinical research. NLP techniques, especially informa-
tion extraction, are also able to identify the relations between
chemical structures and biological activity and further
help researchers search for potentially effective chemical com-
pounds, i.e., virtual screening {192}, [193], in a huge chemical
space. In addition, they are also applied in the prediction
of adverse drug reactions, including side effect prediction
[194], toxicity prediction [195], [196], and etc., in preclinical
research.

Clinical research. Across the clinical research stage, NLP

may enable efficient clinical trial design [110], patient recruit-
200)

ment [197|-[199], clinical trial analytics [200], and etc.
Drug review and safety monitoring. Recently, the FDA

and other institutions have reported being interested in using
NLP for adverse drug event discovery and drug safety moni-

toring |201]-[203], showing the full range of NLP’s key role
in drug development.

IV. NLP-DRIVEN SMART HEALTHCARE FOR SPECIFIC
MEDICAL ISSUES

NLP-driven smart healthcare plays an important role in
many medical issues. In this section, we discuss how NLP-
driven smart healthcare works in medical issues by taking two
specific medical issues, i.e., COVID-19 pandemic and mental
health, as examples.

A. COVID-19 pandemic

Worldwide outbreak of COVID-19 has triggered an unprece-
dented global health crisis and has attracted much attention
from researchers [204]. No wonder, the COVID-19 pandemic
has become one of the most influential medical issues over
the past few years. In the COVID-19 pandemic, NLP-driven
smart healthcare can be utilized for pandemic prevention,
diagnosing, and drug development.

Early forecasts of COVID-19 cases and pandemic knowl-
edge popularization are crucial to the prevention of the
COVID-19 pandemic. In [205], an NLP module is embedded
into an improved susceptible—-infected model to build the
proposed hybrid AI model for COVID-19 prediction, showing
that the forecasting accuracy of COVID-19 cases can be im-
proved by incorporating text inputs and with NLP techniques.
In [206], the authors conclude that NLP techniques, e.g.,
NLP-aided information retrieval, literature-based discovery,
question answering and etc., can be applied to address the
information/knowledge needs of both researchers and the
public in the COVID-19 pandemic.

In clinical practice, NLP can be utilized to identify posi-
tively diagnosed COVID19 patients from free text narratives
[207], assess thoracic CT imaging reports [208], and identify
individuals with the greatest risk of severe complications due
to COVID-19 (209), and provide COVID-19 testing advice
210]. Such applications would be very useful to accelerate

IEEE REVIEWS IN BIOMEDICAL ENGINEERING

the diagnosis of COVID-19, mitigate its worst effects, and
also reduce costs for combating the COVID-19 pandemic.

NLP has also been applied to drug development confronting
COVID-19. In [211], the authors developed an NLP method
to automatically recognize the associations among potential
targeted host organ systems, associated clinical manifestations
and pathways, and suggest potential drug candidates. NLP
models have also made great impacts in COVID-19 vaccine
discovery through protein interaction prediction, molecular
reaction modelling (212). In addition, great opportunities
for NLP can also be found in clinical design, regulatory
decision-making, and pharmacovigilance (213). These appli-
cations would significantly reduce the time and cost of drug
development for COVID-19.

B. Mental health

The mental health issues have received widespread and
continuously increasing attention for many years. Specially,
the World Health Organization (WHO) claimed that the pan-
demic and the resulting lockdowns, economic security, fear
and uncertainty would further cause devastating impacts on
people’s mental health the world over in the past several
years (214). NLP-driven smart healthcare has great value in
predicting/diagnosing and treating mental health conditions.

NLP techniques have been applied to early predict or
identify/screen various mental disorders, such as psychiatric
illness (215), late-life depression [216], severe mental illness
(schizophrenia, schizoaffective disorder and bipolar disorder)
(217). In addition, some works have shown that NLP tech-
niques can predict risk-taking behaviours (e.g., suicide) with
good discrimination [218], so that early interventions
can be taken to save lives. The data collected for such
analysis may include text data such as social media posts,
screening surveys, EHRs [220], and also speech data come
from narrative interviews etc.

NLP techniques could also (automatically) provide effective
psychotherapeutic interventions through web-based psycho-
educational interventions, online counseling, etc., to augment
therapist-based mental health interventions, showing potential
future opportunities for their integration into online men-
tal health tools [222]. For example, the insights of
could help improve counselor training and generate real-time
counseling quality monitoring and answer suggestion support
tools. In addition, several mental health related areas that may
benefit from NLP techniques, including characterizing and
understanding mental disorders, measuring health outcomes,
studying of social and occupational functioning, etc, were
shown in [219]. Specifically, [224] showed that the older
would respond better to digital assistants employing a socially-
oriented interaction style rather than the one with a task-
oriented style, which is promising to promote mental health
in older adults by providing social interaction and company.

V. LIMITATIONS AND OUTLOOK

Although recent advancements in deep learning and neural
NLP have brought extraordinary enhancement to smart health-
care, there are still some limitations that current methods have
yet to overcome.


ZHOU et al.: NATURAL LANGUAGE PROCESSING FOR SMART HEALTHCARE

TABLE II
APPLICATIONS DRIVEN BY NLP IN ALL SMART HEALTHCARE SCENARIOS.

Category Sub-Category

Representative Applications

Related Techniques

clinical communication

patient-provider communication

machine translation

and data collection clinical documentation

speech recognition

Clinical Practice

information extraction

clinical decision support

build QA-based clinical decision support systems
build clinical decision support systems with extract
history information [136], entities and relations

Ts,
[ information: family

, treatment and

question answering

prognosis data 139}, clinical data concepts and features 140], causal relations
[09 , (110

ealthcare quality control: assess clinical procedures [141], [142], warning of
ADE {143}, disease symptoms [144], [145],

information extraction, causal in-

and outcome-related causal effects | ference

[7-30

provide supporting evidence for decisions under evidence-based fashion 108),

information retrieval, causal infer-
ence

information extraction

patient triage (sty,

medical resource allocation

assistants

Hospital Management rative robots

enable users to communicate and control intelligent systems through virtual

155], hospital automation systems [156], and collabo-

speech recognition, natural Jan-
guage understanding

predict and reduce readmission rate

information extraction

free medical staff from routine text writing

information extraction

data management

manage clinical documents fs}

text generation

(2 2}. sh

answering

ease the HIS retrieval process based on semantic searc!

, and question

text classification, text summariza-
tion, information extraction

service quality control

improve service quality and patient experience

information retrieval, question an-
swering

access online medical information [169]

information retrieval

personal health assistants

enable remote healthcare

speech recognition

Personal Care daily assistance

assisting the elderly and
the disabled

speech recognition, natural lan-
guage understanding

social interaction and company (r72},

speech recognition, speech synthe-
sis

assist people with speech impairments |122], 178], hearing loss (179),
dyslexia

0}, or neurological disorders 119] sis

speech recognition, speech synthe-

health knowledge

knowledge engineering

popularization and

Public Health medical education

acquisition and representation of medical knowledge (s6F-(89]. 10
(rn

ease the access of medical knowledge

PY Te

question answering, information
retrieval, machine translation

generate medical case-based questions

question generation

construct simplified summaries

text summarization

oy

identify target populations

information extraction

population screening

analyse of healthcare questionnaire and surveys

information extraction

drug discovery

map the interactions between diseases, chemical compounds, and biomacro-
molecules, predict molecular properties, and design novel molecules

information extraction, information
retrieval, knowledge engineering

Lini@Al FERSRESH drug screening ead 3) information extraction
Drug Development Preclinical researc predict adverse drug reactions: side effect prediction (194), and toxicity | information extraction
prediction (133),
clinical trial design | 110] information extraction, causal in-
clinical research ference
patient recruitment information extraction

clinical trial analytic

information extraction

drug review and _ safety
monitoring

adverse drug events discovery and drug safety monitoring

information extraction

Understanding human language. Although substantial
efforts have been made to enable natural language understand-
ing, the flexibility of human language still makes full under-
standing difficult, especially when ambiguity in biomedical
texts is encountered. Misunderstanding could lead to inaccu-
rate actions taken by robots, useless information returned by
engines, and even wrong decisions made by decision support
systems, leading to economic loss, time wasting, and even
more serious consequences.

Interpretability. Although applications that rely on neural
NLP to extract features and make decisions show excellent
performance in real tasks, they are usually challenged by
users due to their weakness in interpretability. Interpretability
is essential for smart healthcare applications, especially in
clinical scenarios that require quality assurance in cases of
low confidence. One of the major interpretability issues is
that the learned features are usually not understood by hu-
mans. In addition, when tuning pre-trained language models
to downstream tasks, no enough intuitions on data for fine-

tuning or types of applications can be given to guarantee good
performance. Although efforts have been made to achieve
interpretable NLP-driven applications, existing theories and
methodologies are still not convincing and acceptable for
many healthcare researchers and institutions. Before the inter-
pretability issue is fully explored, the role of decision support
systems in clinical practice can only be auxiliary from the
perspectives of medical ethics and practical application.

Implementation. There are still many issues concerning the
implementation of NLP-driven applications in smart health-
care. With the development of neural NLP, large deep neu-
ral networks (e.g., pre-trained language models) have been
quickly migrated to smart healthcare. What followed are the
increased requirements in computing power and training cost,
and the concerns about the reliability of neural NLP systems.
Patient privacy also prevents these models from achieving
more prominent effects in smart healthcare for further practice.
The consideration of medical ethics when applying such
systems makes practical implementation more difficult.


In addition to tackling the aforementioned limitations, there
are some other directions to enhance existing NLP systems for
smart healthcare.

Combining multiple NLP techniques. One direction to
enhance existing NLP systems can be the combination of
multiple NLP techniques. For example, text generation can
work as a data augmentation method for achieving comparable
results in many applications with limited original data, such
as training QA systems (65), and other clinically relevant
tasks [225], [226]. Through automatic question generation,
questionnaires and surveys for population screening can be
generated from EHRs, which may outperform handcrafted
ones. Machine translation has also proven beneficial for var-
ious text-based tasks by increasing the availability of mul-
tilingual healthcare information (227|-(229], implying the
possibility of improving the performance of current CDS
systems. In addition, exploration of general knowledge and
domain knowledge in the field of NLP for smart healthcare
deserves further attention and verification.

End-to-end applications. Current NLP driven applications
for smart healthcare usually focus on dealing with tasks step
by step and do not fully explore the feature extraction capa-
bility of advanced neural NLP for complex smart healthcare
tasks. A deeper integration of NLP techniques and healthcare
applications in an end-to-end manner can map the inputs
and outputs directly, significantly simplify traditional pipelines
for complex applications, eliminate the biases of intermediate
components, and therefore achieve better performance. Taking
population screening as an example, although NLP has been
applied to identify populations and analyse screening test
results in traditional screening procedures, NLP techniques can
be further applied to build end-to-end population screening
systems, with which the correlations between populations
and optimal actions can be found to improve the screening
performance and the quality of healthcare. Another example
would be reducing the readmission rate. As mentioned before,
some works have revealed that NLP has the ability to predict
patient readmission, but further studies on providing appropri-
ate interventions to reduce the readmission rate are not fully
conducted. We look forward to studies that integrate the two
parts to reveal every possibility for readmission rate reducing.

Few-shot learning and incorporating domain knowledge.
By exploiting the learning capability of neural networks and
large available corpora, neural NLP has shown powerful ability
in learning language representations. However, for downstream
tasks or smart healthcare applications, there is still a long
way for NLP to go. Taking clinical decision support as an
example, there are a lot of rare diseases with only a small
number of observations available for training a clinical deci-
sion support system to distinguish rare diseases from common
diseases. This is a quite challenging task, especially when
there are similar outcomes among some rare diseases and
common diseases. In addition, high-quality labelled data are
undoubtedly essential to guarantee task accuracy in developing
practical applications for smart healthcare. However, quality-
controlled annotation not only requires a large amount of
cost, but is also challenging due to the bias of experts’ level
of expertise. Therefore, even with well-learned pre-trained

IEEE REVIEWS IN BIOMEDICAL ENGINEERING

language models, few-shot learning algorithms and domain
knowledge are expected to be applied so that the fine-tuned
models would be effective in learning from few rare disease
observations or limited high-quality labelled data.

Incorporating multimodal and longitudinal data. Finally,
we also anticipate future intelligent systems to utilize all avail-
able AI techniques, not only NLP, for practical applications
with high accuracy and reliability. The past few years have
witnessed the dominance of data-driven approaches in many
applications across various fields. NLP, computer vision, and
other machine learning algorithms can be applied to analyse
medical text, medical images, electronic recordings (e.g., heart
sound), sensors data, laboratory results, and even genetic
information. With multimodal learning, useful information
extracted from these modalities can be combined together to
perfectly fit the need for a complete and accurate analysis
of available healthcare data and patients’ health status. In
addition, all of these data and clinical events can be longi-
tudinal, where time series analysis can be applied to extract
long-term dependencies and improve health care delivery. By
combining these techniques to analyse multimodal and lon-
gitudinal data, future intelligent systems would become more
powerful and reliable for patients, physicians, and healthcare
institutions for applications such as 24/7 health monitoring,
chronic-condition management, healthy lifestyle promotion,
and precision medicine.

VI. CONCLUSION

In the context of smart healthcare, NLP takes text or speech
as the input in various scenarios involving humans and ma-
chines, and realizes the functions of analysing and understand-
ing human language. In this paper, we review existing studies
concerning NLP for smart healthcare from the perspectives
of technique and application. We elaborate on different NLP
approaches and the NLP pipeline for smart healthcare from the
technical point of view. Table I provides the comparisons of
different NLP approaches and their representative algorithms.
Various text-oriented and speech-oriented NLP tasks are elab-
orated to conclude existing methodologies for tackling such
tasks. By introducing smart healthcare applications employing
NLP techniques in various smart healthcare scenarios (in-
cluding clinical practice, hospital management, personal care,
public health, and drug development), we show the strength
and possibility of NLP for delivering smart healthcare. Table I
provides a detailed list of representative applications in smart
healthcare and their related NLP techniques. We further dis-
cuss two specific medical issues, i.e., COVID-19 pandemic and
mental health, in which NLP-driven smart healthcare plays an
important role. After that, we discuss the limitations of current
works across understanding human language, interpretability,
and implementation of NLP systems for smart healthcare.
Finally, we identify several directions for future works, notably
combining multiple NLP techniques, developing end-to-end
applications, few-shot learning, and incorporating multimodal
and longitudinal data.


ZHOU et al.: NATURAL LANGUAGE PROCESSING FOR SMART HEALTHCARE

[1]

[2]

[3]

[4]

[5]

[6]

[7]

[8]

[9]

[10]

(11)

[12]

[13]

[14]

[15]

[16]

[17]

[18]

[19]

[20]

REFERENCES

S. Tian, W. Yang, J. M. L. Grange, P. Wang, W. Huang, and Z. Ye,
“Smart healthcare: Making medical care more intelligent,’ Global
Health Journal, vol. 3, no. 3, pp. 62-65, Sep. 2019.

T. Young, D. Hazarika, S. Poria, and E. Cambria, “Recent trends in
deep learning based natural language processing,’ arXiv:1708.02709
[cs], Nov. 2018.

Y. Bengio, R. Ducharme, P. Vincent, and C. Jauvin, “A neural prob-
abilistic language model,’ Journal of Machine Learning Research,
vol. 3, no. Feb, pp. 1137-1155, 2003.

J. Crim, R. McDonald, and F. Pereira, “Automatically annotating
documents with normalized gene lists,’ BMC Bioinformatics, vol. 6,
no. 1, p. $13, May 2005.

J. Vilares, M. A. Alonso, and M. Vilares, “Extraction of complex
index terms in non-English IR: A shallow parsing based approach,”
Information Processing & Management, vol. 44, no. 4, pp. 1517-1537,
Jul. 2008.

L. Chiticariu, Y. Li, and F. R. Reiss, “Rule-based information extraction
is dead! Long live rule-based information extraction systems!” in
Proceedings of the 2013 Conference on Empirical Methods in Natural
Language Processing. Seattle, Washington, USA: Association for
Computational Linguistics, Oct. 2013, pp. 827-832.

N. Kang, B. Singh, Z. Afzal, E. M. van Mulligen, and J. Kors,
“Using rule-based natural language processing to improve disease
normalization in biomedical text,’ Journal of the American Medical
Informatics Association : JAMIA, vol. 20, Oct. 2012.

W.-H. Weng, K. B. Wagholikar, A. T. McCray, P. Szolovits, and H. C.
Chueh, “Medical subdomain classification of clinical notes using a
machine learning-based natural language processing approach,” BMC
Medical Informatics and Decision Making, vol. 17, p. 155, Dec. 2017.
D. Dessi, R. Helaoui, V. Kumar, D. R. Recupero, and D. Riboni, “TF-
IDF vs word embeddings for morbidity identification in clinical notes:
An initial study,” arXiv:2105.09632 [cs], Mar. 2020.

O. Ozyegen, D. Kabe, and M. Cevik, “Word-level text highlighting
of medical texts forTelehealth services,” arXiv:2105.10400 [cs], May
2021.

M. Rahimian, J. L. Warner, S. K. Jain, R. B. Davis, J. A. Zerillo, and
R. M. Joyce, “Significant and distinctive n-grams in oncology notes:
A text-mining method to analyze the effect of OpenNotes on clinical
documentation,” JCO Clinical Cancer Informatics, no. 3, pp. 1-9, Dec.
2019.

A. Yazdani, R. Safdari, A. Golkar, and S. Rostam Niakan Kalhori,
“Words prediction based on N-gram model for free-text entry in
electronic health records,” Health Information Science and Systems,
vol. 7, Feb. 2019.

V. Yip, M. Mete, U. Topaloglu, and S. Kockara, “Concept discovery for
pathology reports using an N-gram model,” Summit on Translational
Bioinformatics, vol. 2010, pp. 43-47, Mar. 2010.

M. Beeksma, S. Verberne, A. van den Bosch, E. Das, I. Hendrickx,
and S. Groenewoud, “Predicting life expectancy with a long short-term
memory recurrent neural network using electronic medical records,”
BMC Medical Informatics and Decision Making, vol. 19, no. 1, p. 36,
Feb. 2019.

A. N. Jagannatha and H. Yu, “Bidirectional RNN for medical event
detection in electronic health records,’ in Proceedings of the 2016
Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies. San
Diego, California: Association for Computational Linguistics, Jun.
2016, pp. 473-482.

C. Liu, H. Sun, N. Du, S. Tan, H. Fei, W. Fan, T. Yang, H. Wu, Y. Li,
and C. Zhang, “Augmented LSTM framework to construct medical
self-diagnosis android,” in 20/6 IEEE 16th International Conference
on Data Mining (ICDM), Dec. 2016, pp. 251-260.

Y.-S. Zhao, K.-L. Zhang, H.-C. Ma, and K. Li, “Leveraging text
skeleton for de-identification of electronic medical records,’ BMC
Medical Informatics and Decision Making, vol. 18, no. Suppl 1, p. 18,
Mar. 2018.

M. Hughes, I. Li, S. Kotoulas, and T. Suzumura, “Medical text
classification using convolutional neural networks,” Studies in Health
Technology and Informatics, vol. 235, pp. 246-250, 2017.

X. Li, H. Wang, H. He, J. Du, J. Chen, and J. Wu, “Intelligent diagnosis
with chinese electronic medical records based on convolutional neural
networks,” BMC Bioinformatics, vol. 20, no. 1, p. 62, Feb. 2019.

Y. Li, B. Qian, X. Zhang, and H. Liu, “Graph neural network-based
diagnosis prediction,” Big Data, vol. 8, no. 5, pp. 379-390, Oct. 2020.

[21]

[22]

[23]

[24]

[25]

[26]

[27]

[28]

[29]

[30]

[31]

[32]

[33]

[34]

[35]

[36]

[37]

[38]

[39]

[40]

Z. Sun, H. Yin, H. Chen, T. Chen, L. Cui, and F Yang, “Disease
prediction via graph neural networks,’ JEEE Journal of Biomedical
and Health Informatics, vol. 25, no. 3, pp. 818-826, Mar. 2021.

T. Wu, Y. Wang, Y. Wang, E. Zhao, and Y. Yuan, “Leveraging graph-
based hierarchical medical entity embedding for healthcare applica-
tions,” Scientific Reports, vol. 11, no. 1, p. 5858, Mar. 2021.

T. Mayer, E. Cabrio, and S. Villata, “Transformer-based argument
mining for healthcare applications,” in ECAI 2020 - 24th European
Conference on Artificial Intelligence, Santiago de Compostela / Online,
Spain, Aug. 2020.

D. Zhang, J. Thadajarassiri, C. Sen, and E. Rundensteiner, “Time-
aware transformer-based network for clinical notes series prediction,”
in Machine Learning for Healthcare Conference. PMLR, Sep. 2020,
pp. 566-588.

S. Tokala, V. Gambhir, and A. Mukherjee, “Deep learning for social
media health text classification,” in Proceedings of the 2018 EMNLP
Workshop SMM4H: The 3rd Social Media Mining for Health Applica-
tions Workshop & Shared Task. Brussels, Belgium: Association for
Computational Linguistics, Oct. 2018, pp. 61-64.

E. Choi, M. T. Bahadori, J. A. Kulas, A. Schuetz, W. F. Stewart, and
J. Sun, “RETAIN: An interpretable predictive model for healthcare
using reverse time attention mechanism,” arXiv:1608.05745 [cs], Feb.
2017.

J. Chu, W. Dong, K. He, H. Duan, and Z. Huang, “Using neural
attention networks to detect adverse medical events from electronic
health records,” Journal of Biomedical Informatics, vol. 87, pp. 118-
130, Nov. 2018.

P. Chakraborty, F. Wang, J. Hu, and D. Sow, “Explicit-blurred
memory network for analyzing patient electronic health records,”
arXiv:1911.06472 [cs, stat], Jul. 2020.

J. Song, Y. Wang, S. Tang, Y. Zhang, Z. Chen, Z. Zhang, T. Zhang,
and F. Wu, “Local—Global memory neural network for medication
prediction,’ IEEE Transactions on Neural Networks and Learning
Systems, vol. 32, no. 4, pp. 1723-1736, Apr. 2021.

H.-J. Yoon, J. Gounley, M. T. Young, and G. Tourassi, “Information ex-
traction from cancer pathology reports with graph convolution networks
for natural language texts,” in 2019 IEEE International Conference on
Big Data (Big Data), Dec. 2019, pp. 4561-4564.

R. Cai, B. Zhu, L. Ji, T. Hao, J. Yan, and W. Liu, “An CNN-LSTM
attention approach to understanding user query intent from online
health communities,” in 2017 IEEE International Conference on Data
Mining Workshops (ICDMW), Nov. 2017, pp. 430-437.

B. Tang, X. Wang, J. Yan, and Q. Chen, “Entity recognition in chinese
clinical text using attention-based CNN-LSTM-CRF,” BMC Medical
Informatics and Decision Making, vol. 19, no. 3, p. 74, Apr. 2019.
E. Choi, Z. Xu, Y. Li, M. W. Dusenberry, G. Flores, Y. Xue, and A. M.
Dai, “Learning the graphical structure of electronic health records with
graph convolutional transformer,’ arXiv: 1906.04716 [cs, stat], Jan.
2020.

J. Wang, X. Chen, Y. Zhang, Y. Zhang, J. Wen, H. Lin, Z. Yang, and
X. Wang, “Document-level biomedical relation extraction using graph
convolutional network and multihead attention: Algorithm development
and validation,’ JMIR Medical Informatics, vol. 8, no. 7, p. ¢17638,
Jul. 2020.

X. Qiu, T. Sun, Y. Xu, Y. Shao, N. Dai, and X. Huang, “Pre-trained
models for natural language processing: A survey,” arXiv:2003.08271
[cs], Apr. 2020.

A. L. Beam, B. Kompa, A. Schmaltz, I. Fried, G. Weber, N. P. Palmer,
X. Shi, T. Cai, and I. S. Kohane, “Clinical concept embeddings learned
from massive sources of multimodal medical data,” arXiv: 1804.01486
[cs, stat], Aug. 2019.

X. Cai, J. Gao, K. Y. Ngiam, B. C. Ooi, Y. Zhang, and X. Yuan, “Med-
ical concept embedding with time-aware attention,” in Proceedings of
the 27th International Joint Conference on Artificial Intelligence, ser.
IJCAT'18. Stockholm, Sweden: AAAI Press, Jul. 2018, pp. 3984—
3990.

M. Kholghi, L. De Vine, L. Sitbon, G. Zuccon, and A. Nguyen, “The
benefits of word embeddings features for active learning in clinical
information extraction,” in Proceedings of the Australasian Language
Technology Association Workshop 2016, Melbourne, Australia, Dec.
2016, pp. 25-34.

Y. Zhang, Q. Chen, Z. Yang, H. Lin, and Z. Lu, “BioWordVec,
improving biomedical word embeddings with subword information and
MeSH,” Scientific Data, vol. 6, no. 1, p. 52, May 2019.

S. Dubois, N. Romano, D. C. Kale, N. Shah, and K. Jung, “Effective
representations of clinical notes,’ arXiv:1705.07025 [cs, stat], Aug.
2018.


[41]

[42]

[43]

[44]

[45]

[46]

[47]

[48]

[49]

[50]

[51]

[52]

[53]

[54]

[55]

[56]

[57]

[58]

[59]

[60]

[61]

Q. Jin, B. Dhingra, W. W. Cohen, and X. Lu, “Probing biomedical
embeddings from language models,” arXiv: 1904.02181 [cs], Apr. 2019.
J. Lee, W. Yoon, S. Kim, D. Kim, S. Kim, C. H. So, and J. Kang,
“BioBERT: A pre-trained biomedical language representation model
for biomedical text mining,” Bioinformatics, vol. 36, no. 4, pp. 1234—
1240, Feb. 2020.

K. Huang, J. Altosaar, and R. Ranganath, “ClinicalBERT: Modeling
clinical notes and predicting hospital readmission,” arXiv: 1904.05342
[cs], Nov. 2020.

L. Rasmy, Y. Xiang, Z. Xie, C. Tao, and D. Zhi, “Med-BERT: Pre-
trained contextualized embeddings on large-scale structured electronic
health records for disease prediction,’ npj Digital Medicine, vol. 4,
no. 1, pp. 1-13, May 2021.

Y. Li, S. Rao, J. R. A. Solares, A. Hassaine, R. Ramakrishnan,
D. Canoy, Y. Zhu, K. Rahimi, and G. Salimi-Khorshidi, “BEHRT:
Transformer for electronic health records,” Scientific Reports, vol. 10,
no. 1, p. 7155, Apr. 2020.

E. T. R. Schneider, J. V. A. de Souza, Y. B. Gumiel, C. Moro, and E. C.
Paraiso, “A GPT-2 language model for biomedical texts in portuguese,”
in 2021 IEEE 34th International Symposium on Computer-Based
Medical Systems (CBMS), Jun. 2021, pp. 474-479.

A. Akkasi, E. Varoglu, and N. Dimililer, “ChemTok: A new rule based
tokenizer for chemical named entity recognition,’ BioMed Research
International, vol. 2016, 2016.

H.-J. Dai, P.-T. Lai, Y.-C. Chang, and R. T.-H. Tsai, “Enhancing of
chemical compound and drug name recognition using representative
tag scheme and fine-grained tokenization,” Journal of Cheminformatics,
vol. 7, no. Suppl 1 Text mining for chemistry and the CHEMDNER
track, p. $14, 2015.

H. Liu, T. Christiansen, W. A. Baumgartner, and K. Verspoor, “Bi-
oLemmatizer: A lemmatization tool for morphological processing of
biomedical text,’ Journal of Biomedical Semantics, vol. 3, p. 3, Apr.
2012.

Y. Qiao, C. Xiong, Z. Liu, and Z. Liu, “Understanding the Behaviors
of BERT in Ranking,” arXiv: 1904.07531 [cs], Apr. 2019.

X. Liu, F. Zhang, Z. Hou, Z. Wang, L. Mian, J. Zhang, and J. Tang,
“Self-supervised learning: Generative or contrastive,” IEEE Transac-
tions on Knowledge and Data Engineering, pp. 1-1, 2021.

Y. Wang, S. Sohn, S. Liu, F. Shen, L. Wang, E. J. Atkinson, S. Amin,
and H. Liu, “A clinical text classification paradigm using weak supervi-
sion and deep representation,’ BMC Medical Informatics and Decision
Making, vol. 19, no. 1, p. 1, Jan. 2019.

S. Hassanpour and C. P. Langlotz, “Information extraction from multi-
institutional radiology reports,” Artificial intelligence in medicine,
vol. 66, pp. 29-39, Jan. 2016.

N. Perera, M. Dehmer, and F. Emmert-Streib, “Named entity recog-
nition and relation detection for biomedical information extraction,”
Frontiers in Cell and Developmental Biology, vol. 8, p. 673, Aug.
2020.

A. Thillaisundaram and T. Togia, “Biomedical relation extraction
with pre-trained language representations and minimal task-specific
architecture,” in Proceedings of The 5th Workshop on BioNLP Open
Shared Tasks. Hong Kong, China: Association for Computational
Linguistics, Nov. 2019, pp. 84-89.

S. Zitnik, M. Zitnik, B. Zupan, and M. Bajec, “Sieve-based relation
extraction of gene regulatory networks from biological literature,” BMC
Bioinformatics, vol. 16, no. Suppl 16, p. S1, Oct. 2015.

P. Jindal and D. Roth, “Extraction of events and temporal expressions
from clinical narratives,’ Journal of Biomedical Informatics, vol. 46,
pp. S13-S19, Dec. 2013.

A. Garg and M. Agarwal, “Machine translation: A literature review,”
arXiv:1901.01122 [cs], Dec. 2018.

A. Bérard, Z. M. Kim, V. Nikoulina, E. L. Park, and M. Gallé, “A
multilingual neural machine translation model for biomedical data,” in
Proceedings of the Ist Workshop on NLP for COVID-19 (Part 2) at
EMNLP 2020. Online: Association for Computational Linguistics,
Dec. 2020.

K. Kirchhoff, A. M. Turner, A. Axelrod, and F. Saavedra, “Application
of statistical machine translation to public health information: A feasi-
bility study,” Journal of the American Medical Informatics Association
: JAMIA, vol. 18, no. 4, pp. 473-478, 2011.

M. Afzal, F Alam, K. M. Malik, and G. M. Malik, “Clinical Con-
text-Aware biomedical text summarization using deep neural network:
Model development and validation,’ Journal of Medical Internet Re-
search, vol. 22, no. 10, p. e19810, Oct. 2020.

[62]

[63]

[64]

[65]

[66]

[67]

[68]

[69]

[70]

[71]

[72]

[73]

[74]

[75]

[76]

[77]

[78]

[79]

[80]

IEEE REVIEWS IN BIOMEDICAL ENGINEERING

J. Lopez, “Automatic summarization of medical conversations, a
review,” in TALN-RECITAL 2019-PFIA 2019. Toulouse, France:
ATALA, Jul. 2019, pp. 487-498.

G. Manas, V. Aribandi, U. Kursuncu, A. Alambo, V. L. Shalin,
K. Thirunarayan, J. Beich, M. Narasimhan, and A. Sheth, “Knowledge-
infused abstractive summarization of clinical diagnostic interviews:
Framework development study,’ JMIR Mental Health, vol. 8, no. 5,
p. e20865, May 2021.

I. Pistol, D. Trandabat, and M. Raschip, “Medi-test: Generating tests
from medical reference texts,” Data, vol. 3, no. 4, p. 70, Dec. 2018.
S. Shen, Y. Li, N. Du, X. Wu, Y. Xie, S. Ge, T. Yang, K. Wang,
X. Liang, and W. Fan, “On the generation of medical question-answer
pairs,” arXiv:1811.00681 [cs], Dec. 2019.

W. Wang, T. Hao, and W. Liu, “Automatic question generation for
learning evaluation in medicine,” in Advances in Web Based Learning
— ICWL 2007, ser. Lecture Notes in Computer Science, H. Leung,
F. Li, R. Lau, and Q. Li, Eds. Berlin, Heidelberg: Springer, 2008, pp.
242-251.

D. Li, Z. Ren, P. Ren, Z. Chen, M. Fan, J. Ma, and M. de Rijke, “Semi-
supervised variational reasoning for medical dialogue generation,”
Proceedings of the 44th International ACM SIGIR Conference on
Research and Development in Information Retrieval, pp. 544-554, Jul.
2021.

S. Lin, P. Zhou, X. Liang, J. Tang, R. Zhao, Z. Chen, and L. Lin,
“Graph-evolving meta-learning for low-resource medical dialogue gen-
eration,” arXiv:2012.11988 [cs], Dec. 2020.

W. Yang, G. Zeng, B. Tan, Z. Ju, S. Chakravorty, X. He, S. Chen,
X. Yang, Q. Wu, Z. Yu, E. Xing, and P. Xie, “On the generation of
medical dialogues for COVID-19,” arXiv:2005.05442 [cs], Jun. 2020.
S. Pauws, A. Gatt, E. Krahmer, and E. Reiter, “Making effective use of
healthcare data using data-to-text technology,” arXiv: 1808.03507 [cs],
Aug. 2018.

V. Kougia, J. Pavlopoulos, and I. Androutsopoulos, “A survey on
biomedical image captioning,” arXiv: 1905.13302 [cs], May 2019.

Y. Xiong, B. Du, and P. Yan, “Reinforced transformer for medical
image captioning,” in Machine Learning in Medical Imaging, set.
Lecture Notes in Computer Science, H.-I. Suk, M. Liu, P. Yan, and
C. Lian, Eds. Cham: Springer International Publishing, 2019, pp.
673-680.

X. He, Z. Cai, W. Wei, Y. Zhang, L. Mou, E. Xing, and P. Xie,
“Towards visual question answering on pathology images,” in Proceed-
ings of the 59th Annual Meeting of the Association for Computational
Linguistics and the 11th International Joint Conference on Natural
Language Processing (Volume 2: Short Papers). Online: Association
for Computational Linguistics, Aug. 2021, pp. 708-718.

L.-M. Zhan, B. Liu, L. Fan, J. Chen, and X.-M. Wu, “Medical visual
question answering via conditional reasoning,” in Proceedings of the
28th ACM International Conference on Multimedia, ser. MM ’20. New
York, NY, USA: Association for Computing Machinery, Oct. 2020, pp.
2345-2354.

B. Afrae, D. Yousra, A. Imane, B. A. Mohamed, and A. B. Abdel-
hakim, “A new visual question answering system for medical images
characterization,” in Proceedings of the 4th International Conference
on Smart City Applications, ser. SCA °19. | New York, NY, USA:
Association for Computing Machinery, Oct. 2019, pp. 1-7.

H. Wu, G. Toti, K. I. Morley, Z. M. Ibrahim, A. Folarin, R. Jackson,
I. Kartoglu, A. Agrawal, C. Stringer, D. Gale, G. Gorrell, A. Roberts,
M. Broadbent, R. Stewart, and R. J. Dobson, “SemEHR: A general-
purpose semantic search system to surface semantic data from clinical
notes for tailored care, trial recruitment, and clinical research,” Journal
of the American Medical Informatics Association : JAMIA, vol. 25,
no. 5, pp. 530-537, Jan. 2018.

J. Gobeill, A. Gaudinat, E. Pasche, D. Vishnyakova, P. Gaudet,
A. Bairoch, and P. Ruch, “Deep question answering for protein anno-
tation,” Database: The Journal of Biological Databases and Curation,
vol. 2015, Sep. 2015.

A. Montazeralghaem, R. Rahimi, and J. Allan, “Relevance ranking
based on query-aware context analysis,’ Advances in Information
Retrieval, vol. 12035, pp. 446-460, Mar. 2020.

B. Xu, H. Lin, Y. Lin, Y. Ma, L. Yang, J. Wang, and Z. Yang,
“Improve biomedical information retrieval using modified learning to
rank methods,” IEEE/ACM Transactions on Computational Biology and
Bioinformatics, vol. 15, no. 6, pp. 1797-1809, Nov. 2018.

J. Urbain, O. Frieder, and N. Goharian, “Passage relevance models for
genomics search,’ BMC Bioinformatics, vol. 10, no. Suppl 3, p. $3,
Mar. 2009.


ZHOU et al.: NATURAL LANGUAGE PROCESSING FOR SMART HEALTHCARE

[81]

[82]

[83]

[84]

[85]

[86]

[87]

[88]

[89]

[90]

[91]

[92]

[93]

[94]

[95]

[96]

[97]

[98]

[99]

[100]

S. Mohan, N. Fiorini, S. Kim, and Z. Lu, “A fast deep learning
model for textual relevance in biomedical information retrieval,’ in
Proceedings of the 2018 World Wide Web Conference, ser. WWW °18.
Republic and Canton of Geneva, CHE: International World Wide Web
Conferences Steering Committee, Apr. 2018, pp. 77-86.

D. Hristovski, D. Dinevski, A. Kastrin, and T. C. Rindflesch, “Biomedi-
cal question answering using semantic relations,” BMC Bioinformatics,
vol. 16, no. 1, p. 6, Jan. 2015.

V. Vinod, S. Agrawal, V. Gaurav, P. R, and S. Choudhary, “Multilingual
medical question answering and information retrieval for rural health
intelligence access,” arXiv:2106.01251 [cs], Jun. 2021.

M. A. H. Zahid, A. Mittal, R. C. Joshi, and G. Atluri, “CLINIQA:
A machine intelligence based clinical question answering system,”
arXiv: 1805.05927 [cs], May 2018.

P. Wang, T. Shi, and C. K. Reddy, “Text-to-SQL generation for question
answering on electronic medical records,” in Proceedings of The Web
Conference 2020. Taipei Taiwan: ACM, Apr. 2020, pp. 350-361.

Z. Jiang, C. Chi, and Y. Zhan, “Research on medical question an-
swering system based on knowledge graph,” IEEE Access, vol. 9, pp.
21094-21101, 2021.

H. Liu, Q. Hu, Y. Zhang, C. Xing, and M. Sheng, “A knowledge-
based health question answering system,” in Smart Health, ser. Lecture
Notes in Computer Science, H. Chen, D. D. Zeng, E. Karahanna, and
I. Bardhan, Eds. Cham: Springer International Publishing, 2017, pp.
286-291.

D. Demner-Fushman and J. Lin, “Answering clinical questions with
knowledge-based and statistical techniques,’ Computational Linguis-
tics, vol. 33, no. 1, pp. 63-103, Mar. 2007.

R. M. Terol, P. Martinez-Barco, and M. Palomar, “A knowledge based
method for the medical question answering problem,’ Computers in
Biology and Medicine, vol. 37, no. 10, pp. 1511-1521, Oct. 2007.

Z. Liu, E. Peng, S. Yan, G. Li, and T. Hao, “T-know: A knowledge
graph-based question answering and infor-mation retrieval system for
traditional chinese medicine,” in Proceedings of the 27th International
Conference on Computational Linguistics: System Demonstrations.
Santa Fe, New Mexico: Association for Computational Linguistics,
Aug. 2018, pp. 15-19.

E. Mutabazi, J. Ni, G. Tang, and W. Cao, “A review on medical textual
question answering systems based on deep learning approaches,”
Applied Sciences, vol. 11, no. 12, p. 5456, Jan. 2021.

H. Shim, D. Lowet, S. Luca, and B. Vanrumste, “Building blocks
of a task-oriented dialogue system in the healthcare domain,” in
Proceedings of the Second Workshop on Natural Language Processing
for Medical Conversations. Online: Association for Computational
Linguistics, Jun. 2021, pp. 47-57.

Z. Wei, Q. Liu, B. Peng, H. Tou, T. Chen, X. Huang, K.-f. Wong,
and X. Dai, “Task-oriented dialogue system for automatic diagnosis,”
in Proceedings of the 56th Annual Meeting of the Association for
Computational Linguistics (Volume 2: Short Papers). Melbourne,
Australia: Association for Computational Linguistics, Jul. 2018, pp.
201-207.

L. Xu, Q. Zhou, K. Gong, X. Liang, J. Tang, and L. Lin, “End-to-end
knowledge-routed relational dialogue system for automatic diagnosis,”
arXiv: 1901.10623 [cs], Mar. 2019.

H. Kawata, K. Ookawara, M. Muta, S. Masuko, and J. Hoshino,
“Lifestyle agent: The chat-oriented dialogue system for lifestyle man-
agement,” in Entertainment Computing — ICEC 2017, ser. Lecture
Notes in Computer Science, N. Munekata, I. Kunita, and J. Hoshino,
Eds. Cham: Springer International Publishing, 2017, pp. 396-399.
R. Studer, V. R. Benjamins, and D. Fensel, “Knowledge engineering:
Principles and methods,’ Data & Knowledge Engineering, vol. 25,
no. 1, pp. 161-197, Mar. 1998.

T. Goodwin and S. M. Harabagiu, “Automatic generation of a qualified
medical knowledge graph and its usage for retrieving patient cohorts
from electronic medical records,” in 20/3 IEEE Seventh International
Conference on Semantic Computing, Sep. 2013, pp. 363-370.

A. Rossanez, J. C. dos Reis, R. d. S. Torres, and H. de Ribaupierre,
“KGen: A knowledge graph generator from biomedical scientific
literature,” BMC Medical Informatics and Decision Making, vol. 20,
no. 4, p. 314, Dec. 2020.

M. Rotmensch, Y. Halpern, A. Tlimat, S. Horng, and D. Sontag,
“Learning a health knowledge graph from electronic medical records,”
Scientific Reports, vol. 7, no. 1, p. 5994, Jul. 2017.

H. Wang, Q. Zhang, and J. Yuan, “Semantically enhanced medical
information retrieval system: A tensor factorization based approach,”
IEEE Access, vol. 5, pp. 7584-7593, 2017.

[101]

102]

103]

104]

105]

106]

[107]

108]

109]

110]

111]

[112]

113]

114]

115]

116]

(117]

[118]

[119]

Y. Pan, Q. Chen, W. Peng, X. Wang, B. Hu, X. Liu, J. Chen, and
W. Zhou, “MedWriter: Knowledge-aware medical text generation,” in
Proceedings of the 28th International Conference on Computational
Linguistics. Barcelona, Spain (Online): International Committee on
Computational Linguistics, Dec. 2020, pp. 2363-2368.

A. Stoica, T. Kadar, C. Lemnaru, R. Potolea, and M. Dinsoreanu,
“Intent detection and slot filling with capsule net architectures for a
romanian home assistant,” Sensors, vol. 21, no. 4, p. 1230, Jan. 2021.
A. Neuraz, L. C. Llanos, A. Burgun, and S. Rosset, “Natural language
understanding for task oriented dialog in the biomedical domain in a
low resources context,” arXiv:1811.09417 [cs], Nov. 2018.

C. Zhang, N. Du, W. Fan, Y. Li, C.-T. Lu, and P. S. Yu, “Bringing
semantic structures to user intent detection in online medical queries,”
in 2017 IEEE International Conference on Big Data (Big Data), Dec.
2017, pp. 1019-1026.

I. Giachos, E. C. Papakitsos, and G. Chorozoglou, “Exploring natural
language understanding in robotic interfaces,” International Journal of
Advances in Intelligent Informatics, vol. 3, no. 1, pp. 10-19, Mar. 2017.
J. Thomason, A. Padmakumar, J. Sinapov, N. Walker, Y. Jiang,
H. Yedidsion, J. Hart, P. Stone, and R. J. Mooney, “Improving grounded
natural language understanding through human-robot dialog,” 2019
International Conference on Robotics and Automation (ICRA), pp.
6934-6941, May 2019.

A. Feder, K. A. Keith, E. Manzoor, R. Pryzant, D. Sridhar, Z. Wood-
Doughty, J. Eisenstein, J. Grimmer, R. Reichart, M. E. Roberts, B. M.
Stewart, V. Veitch, and D. Yang, “Causal inference in natural lan-
guage processing: Estimation, prediction, interpretation and beyond,”
arXiv:2109.00725 [cs], Sep. 2021.

J. Zeng, M. F. Gensheimer, D. L. Rubin, S. Athey, and R. D. Shachter,
“Uncovering interpretable potential confounders in electronic medical
records,” medRxiv : the preprint server for health sciences, 2021.

S. Doan, E. W. Yang, S. S. Tilak, P. W. Li, D. S. Zisook, and M. Torii,
“Extracting health-related causality from twitter messages using natural
language processing,” BMC Medical Informatics and Decision Making,
vol. 19, no. 3, p. 79, Apr. 2019.

G. Nordon, G. Koren, V. Shalev, B. Kimelfeld, U. Shalit, and K. Radin-
sky, “Building causal graphs from medical literature and electronic
medical records,” Proceedings of the AAAI Conference on Artificial
Intelligence, vol. 33, no. 01, pp. 1102-1109, Jul. 2019.

R. Stiefelhagen, C. Fugen, R. Gieselmann, H. Holzapfel, K. Nickel,
and A. Waibel, “Natural human-robot interaction using speech, head
pose and gestures,” in 2004 IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),
vol. 3, Sep. 2004, pp. 2422-2427 vol.3.

G. P. Finley, E. Edwards, W. Salloum, A. Robinson, N. Sadoughi,
N. Axtmann, M. Korenevsky, M. Brenndoerfer, M. Miller, and
D. Suendermann-Oeft, “Semi-supervised acoustic model retraining
for medical ASR,” in Speech and Computer, ser. Lecture Notes in
Computer Science, A. Karpov, O. Jokisch, and R. Potapova, Eds.
Cham: Springer International Publishing, 2018, pp. 177-187.

J. Sas and T. Poreba, “Optimal acoustic model complexity selection in
polish medical speech recognition,” Journal of Medical Informatics &
Technologies, vol. Vol. 17, 2011.

J. M. Paulett and C. P. Langlotz, “Improving language models for
radiology speech recognition,” Journal of Biomedical Informatics,
vol. 42, no. 1, pp. 53-58, Feb. 2009.

C.-C. Chiu, A. Tripathi, K. Chou, C. Co, N. Jaitly, D. Jaunzeikare,
A. Kannan, P. Nguyen, H. Sak, A. Sankar, J. Tansuwan, N. Wan,
Y. Wu, and X. Zhang, “Speech recognition for medical conversations,”
arXiv:1711.07274 [cs, eess, stat], Jun. 2018.

E. Edwards, W. Salloum, G. P. Finley, J. Fone, G. Cardiff, M. Miller,
and D. Suendermann-Oeft, “Medical speech recognition: Reaching
parity with humans,” in Speech and Computer, ser. Lecture Notes
in Computer Science, A. Karpov, R. Potapova, and I. Mporas, Eds.
Cham: Springer International Publishing, 2017, pp. 512-524.

T. He, W. Zhao, and L. Xu, “DOP-tacotron: A fast chinese TTS system
with local-based attention,” in 2020 Chinese Control And Decision
Conference (CCDC), Aug. 2020, pp. 4345-4350.

K. Sugiura, Y. Shiga, H. Kawai, T. Misu, and C. Hori, “Non-monologue
HMM-based speech synthesis for service robots: A cloud robotics
approach,” in 20/4 IEEE International Conference on Robotics and
Automation (ICRA), May 2014, pp. 2237-2242.

H. Akbari, B. Khalighinejad, J. L. Herrero, A. D. Mehta, and N. Mes-
garani, “Towards reconstructing intelligible speech from the human
auditory cortex,” Scientific Reports, vol. 9, no. 1, p. 874, Jan. 2019.


[120]

[121]

[122]

[123]

[124]

[125]

[126]

[127]

[128]

[129]

[130]

[131]

[132]

[133]

[134]

[135]

[136]

[137]

G. K. Anumanchipalli, J. Chartier, and E. F. Chang, “Speech synthesis
from neural decoding of spoken sentences,” Nature, vol. 568, no. 7753,
pp. 493-498, Apr. 2019.

C. Herff, L. Diener, M. Angrick, E. Mugler, M. C. Tate, M. A. Goldrick,
D. J. Krusienski, M. W. Slutzky, and T. Schultz, “Generating natural,
intelligible speech from brain activity in motor, premotor, and inferior
frontal cortices,” Frontiers in Neuroscience, vol. 13, p. 1267, 2019.
C. Jreige, R. Patel, and H. T. Bunnell, “VocaliD: Personalizing text-
to-speech synthesis for individuals with severe speech impairment,” in
Proceedings of the 11th International ACM SIGACCESS Conference
on Computers and Accessibility, ser. Assets 09. New York, NY, USA:
Association for Computing Machinery, Oct. 2009, pp. 259-260.

M. Marge, C. Espy-Wilson, N. G. Ward, A. Alwan, Y. Artzi, M. Bansal,
G. Blankenship, J. Chai, H. Daumé, D. Dey, M. Harper, T. Howard,
C. Kennington, I. Kruijff-Korbayovaé, D. Manocha, C. Matuszek,
R. Mead, R. Mooney, R. K. Moore, M. Ostendorf, H. Pon-Barry, A. I.
Rudnicky, M. Scheutz, R. S. Amant, T. Sun, S. Tellex, D. Traum, and
Z. Yu, “Spoken language interaction with robots: Recommendations for
future research,’ Computer Speech & Language, vol. 71, p. 101255,
Jan. 2022.

J. James, B. T. Balamurali, C. I. Watson, and B. MacDonald, “Empa-
thetic speech synthesis and testing for healthcare robots,” International
Journal of Social Robotics, Sep. 2020.

X. Li, B. MacDonald, and C. I. Watson, “Expressive facial speech
synthesis on a robotic platform,” in Proceedings of the 2009 IEEE/RSJ
International Conference on Intelligent Robots and Systems, ser.
IROS’09. St. Louis, MO, USA: IEEE Press, Oct. 2009, pp. 5009-
5014.

S. Roehling, B. Macdonald, and C. Watson, “Towards expressive
speech synthesis in english on a robotic platform,” in In Proceedings
of the Australasian International Conference on Speech Science and
Technology, 2006, pp. 130-135.

K. Kiihne, M. H. Fischer, and Y. Zhou, “The human takes it all: Hu-
manlike synthesized voices are perceived as less eerie and more likable.
evidence from a subjective ratings study,” Frontiers in Neurorobotics,
vol. 14, p. 105, 2020.

F. Jiang, Y. Jiang, H. Zhi, Y. Dong, H. Li, S. Ma, Y. Wang, Q. Dong,
H. Shen, and Y. Wang, “Artificial intelligence in healthcare: Past,
present and future,” Stroke and Vascular Neurology, vol. 2, no. 4, Dec.
2017.

K. N. Dew, A. M. Turner, Y. K. Choi, A. Bosold, and K. Kirchhoff,
“Development of machine translation technology for assisting health
communication: A systematic review,” Journal of Biomedical Informat-
ics, vol. 85, pp. 56-67, Sep. 2018.

G. Randhawa, M. Ferreyra, R. Ahmed, O. Ezzat, and K. Pottie, “Using
machine translation in clinical practice,’ Canadian Family Physician,
vol. 59, no. 4, pp. 382-383, Apr. 2013.

F. Goss, S. Blackley, C. Ortega, L. Kowalski, A. Landman, C. Lin,
M. Meteer, S. Bakes, S. Gradwohl, D. Bates, and Z. Li, “A clinician
survey of using speech recognition for clinical documentation in the
electronic health record,” International Journal of Medical Informatics,
vol. 130, Jul. 2019.

K. Saxena, R. Diamond, R. F. Conant, T. H. Mitchell, i. G. Gallopyn,
and K. E. Yakimow, “Provider adoption of speech recognition and its
impact on satisfaction, documentation quality, efficiency, and cost in an
inpatient EHR,” AMJA Summits on Translational Science Proceedings,
vol. 2018, pp. 186-195, May 2018.

Y. Zhao, “Speech-recognition technology in health care and special-
needs assistance [life sciences],’ IEEE Signal Processing Magazine,
vol. 26, no. 3, pp. 87-90, May 2009.

T. R. Goodwin and S. M. Harabagiu, “Medical question answering for
clinical decision support,” Proceedings of the ... ACM International
Conference on Information & Knowledge Management. ACM Interna-
tional Conference on Information and Knowledge Management, vol.
2016, pp. 297-306, Oct. 2016.

G. Xu, W. Rong, Y. Wang, Y. Ouyang, and Z. Xiong, “External
features enriched model for biomedical question answering,’ BMC
Bioinformatics, vol. 22, no. 1, p. 272, May 2021.

X. Shi, D. Jiang, Y. Huang, X. Wang, Q. Chen, J. Yan, and B. Tang,
“Family history information extraction via deep joint learning,” BMC
Medical Informatics and Decision Making, vol. 19, no. Suppl 10, Dec.
2019.

A. Gupta, I. Banerjee, and D. L. Rubin, “Automatic information
extraction from unstructured mammography reports using distributed
semantics,” Journal of Biomedical Informatics, vol. 78, pp. 78-86, Feb.
2018.

[138]

[139]

[140]

[141]

[142]

[143]

[144]

[145]

[146]

[147]

148]

149]

150]

151]

152]

153]

154]

IEEE REVIEWS IN BIOMEDICAL ENGINEERING

J. Yang, Y. Liu, M. Qian, C. Guan, and X. Yuan, “Information
extraction from electronic medical records using multitask recurrent
neural network with contextual word embedding,” Applied Sciences,
vol. 9, no. 18, p. 3658, Jan. 2019.

S. Zheng, S. K. Jabbour, S. E. O’Reilly, J. J. Lu, L. Dong, L. Ding,
Y. Xiao, N. Yue, F. Wang, and W. Zou, “Automated information
extraction on treatment and prognosis for Non-Small cell lung can-
cer radiotherapy patients: Clinical study,’ JMIR Medical Informatics,
vol. 6, no. 1, p. e8, Feb. 2018.

H. Liang, B. Y. Tsui, H. Ni, C. C. S. Valentim, S. L. Baxter, G. Liu,
W. Cai, D. S. Kermany, X. Sun, J. Chen, L. He, J. Zhu, P. Tian, H. Shao,
L. Zheng, R. Hou, S. Hewett, G. Li, P. Liang, X. Zang, Z. Zhang,
L. Pan, H. Cai, R. Ling, S. Li, Y. Cui, S. Tang, H. Ye, X. Huang,
W. He, W. Liang, Q. Zhang, J. Jiang, W. Yu, J. Gao, W. Ou, Y. Deng,
Q. Hou, B. Wang, C. Yao, Y. Liang, S. Zhang, Y. Duan, R. Zhang,
S. Gibson, C. L. Zhang, O. Li, E. D. Zhang, G. Karin, N. Nguyen,
X. Wu, C. Wen, J. Xu, W. Xu, B. Wang, W. Wang, J. Li, B. Pizzato,
C. Bao, D. Xiang, W. He, S. He, Y. Zhou, W. Haw, M. Goldbaum,
A. Tremoulet, C.-N. Hsu, H. Carter, L. Zhu, K. Zhang, and H. Xia,
“Evaluation and accurate diagnoses of pediatric diseases using artificial
intelligence,” Nature Medicine, vol. 25, no. 3, pp. 433-438, Mar. 2019.
H. Harkema, W. W. Chapman, M. Saul, E. S. Dellon, R. E. Schoen, and
A. Mehrotra, “Developing a natural language processing application
for measuring the quality of colonoscopy procedures,” Journal of the
American Medical Informatics Association: JAMIA, vol. 18 Suppl 1,
pp. 1150-156, Dec. 2011.

A. Mehrotra, E. S. Dellon, R. E. Schoen, M. Saul, F. Bishehsari,
C. Farmer, and H. Harkema, “Applying a natural language processing
tool to electronic health records to assess performance on colonoscopy
quality measures,” Gastrointestinal Endoscopy, vol. 75, no. 6, pp.
1233-1239.e14, Jun. 2012.

S. Wunnava, X. Qin, T. Kakar, C. Sen, E. A. Rundensteiner, and
X. Kong, “Adverse drug event detection from electronic health records
using hierarchical recurrent neural networks with dual-level embed-
ding,” Drug Safety, vol. 42, no. 1, pp. 113-122, Jan. 2019.

R. G. Jackson, R. Patel, N. Jayatilleke, A. Kolliakou, M. Ball,
G. Gorrell, A. Roberts, R. J. Dobson, and R. Stewart, “Natural
language processing to extract symptoms of severe mental illness from
clinical text: The clinical record interactive search comprehensive data
extraction (CRIS-CODE) project,” BMJ Open, vol. 7, no. 1, p. e€012012,
Jan. 2017.

J. Luo, L. Lan, D. Yang, S. Huang, M. Li, J. Yin, J. Xiao, and X. Zhou,
“Early prediction of organ failures in patients with acute pancreatitis
using text mining,” Scientific Programming, vol. 2021, p. e6683942,
May 2021.

X. Wang, X. Xu, W. Tong, R. Roberts, and Z. Liu, “InferBERT: A
transformer-based causal inference framework for enhancing pharma-
covigilance,” Frontiers in Artificial Intelligence, vol. 4, p. 67, 2021.
S. V. Wang, O. V. Patterson, J. J. Gagne, J. S. Brown, R. Ball,
P. Jonsson, A. Wright, L. Zhou, W. Goettsch, and A. Bate, “Transparent
reporting on research using unstructured electronic health record data to
generate ‘real world’ evidence of comparative effectiveness and safety,”
Drug Safety, vol. 42, no. 11, pp. 1297-1309, Nov. 2019.

A. Lee, B. E. Alving, M. B. Horup, and L. Thrysoee, “Information
retrieval as a part of evidence-based practice: Retrieval skills, behavior
and needs among nurses at a large university hospital:,” Nordic Journal
of Nursing Research, Aug. 2019.

T. B. Patrick, G. Demiris, L. C. Folk, D. E. Moxley, J. A. Mitchell, and
D. Tao, “Evidence-based retrieval in evidence-based medicine,” Journal
of the Medical Library Association, vol. 92, no. 2, pp. 196-199, Apr.
2004.

N. Ford, D. Miller, A. Booth, A. O’rourke, J. Ralph, and E. Turnock,
“Information retrieval for evidence-based decision making,” JOURNAL
OF DOCUMENTATION, vol. 55, Oct. 1999.

N. W. Sterling, R. E. Patzer, M. Di, and J. D. Schrager, “Prediction
of emergency department patient disposition based on natural language
processing of triage notes,” International Journal of Medical Informat-
ics, vol. 129, pp. 184-188, Sep. 2019.

B. Tahayori, N. Chini-Foroush, and H. Akhlaghi, “Advanced natural
language processing technique to predict patient disposition based on
emergency triage notes,’ Emergency Medicine Australasia, vol. 33,
no. 3, pp. 480-484, 2021.

E. Sezgin, Y. Huang, U. Ramtekkar, and S. Lin, “Readiness for voice
assistants to support healthcare delivery during a health crisis and
pandemic,” npj Digital Medicine, vol. 3, no. 1, pp. 1-4, Sep. 2020.
S. Spanig, A. Emberger-Klein, J.-P. Sowa, A. Canbay, K. Menrad, and
D. Heider, “The virtual doctor: An interactive artificial intelligence


ZHOU et al.: NATURAL LANGUAGE PROCESSING FOR SMART HEALTHCARE

[155]

[156]

[157]

[158]

[159]

[160]

[161]

[162]

[163]

[164]

[165]

[166]

[167]

[168]

[169]

[170]

[171]

based on deep learning for non-invasive prediction of diabetes,” Arti-
ficial Intelligence in Medicine, vol. 100, p. 101706, Sep. 2019.

M. Gandhi, V. K. Singh, and V. Kumar, “IntelliDoctor - AI based
medical assistant,’ in 2019 Fifth International Conference on Science
Technology Engineering and Mathematics (ICONSTEM), vol. 1, Mar.
2019, pp. 162-168.

E. I. Agustin, R. T. Yunardi, and A. A. Firdaus, “Voice recognition
system for controlling electrical appliances in smart hospital room,”
TELKOMNIKA (Telecommunication Computing Electronics and Con-
trol), vol. 17, no. 2, pp. 965-972, Apr. 2019.

A. Ismail, S. Abdlerazek, and I. M. El-Henawy, “Development of smart
healthcare system based on speech recognition using support vector
machine and dynamic time warping,” Sustainability, vol. 12, no. 6, p.
2403, Jan. 2020.

L. Grasse, S. J. Boutros, and M. S. Tata, “Speech interaction to control a
hands-free delivery robot for high-risk health care scenarios,” Frontiers
in Robotics and AI, vol. 8, p. 40, 2021.

J. Holland, L. Kingston, C. McCarthy, E. Armstrong, P. O’Dwyer,
F. Merz, and M. McConnell, “Service robots in the healthcare sector,”
Robotics, vol. 10, no. 1, p. 47, Mar. 2021.

C. M. Lineback, R. Garg, E. Oh, A. M. Naidech, J. L. Holl, and
S. Prabhakaran, “Prediction of 30-day readmission after stroke using
machine learning and natural language processing,” Frontiers in Neu-
rology, vol. 12, p. 1069, 2021.

A. Rajkomar, E. Oren, K. Chen, A. M. Dai, N. Hajaj, M. Hardt, P. J.
Liu, X. Liu, J. Marcus, M. Sun, P. Sundberg, H. Yee, K. Zhang,
Y. Zhang, G. Flores, G. E. Duggan, J. Irvine, Q. Le, K. Litsch,
A. Mossin, J. Tansuwan, D. Wang, J. Wexler, J. Wilson, D. Ludwig,
S. L. Volchenboum, K. Chou, M. Pearson, S. Madabushi, N. H. Shah,
A. J. Butte, M. D. Howell, C. Cui, G. S. Corrado, and J. Dean,
“Scalable and accurate deep learning with electronic health records,”
npj Digital Medicine, vol. 1, no. 1, p. 18, Dec. 2018.

A. Rumshisky, M. Ghassemi, T. Naumann, P. Szolovits, V. M. Cas-
tro, T. H. McCoy, and R. H. Perlis, “Predicting early psychiatric
readmission with natural language processing of narrative discharge
summaries,” Translational Psychiatry, vol. 6, no. 10, p. e921, Oct.
2016.

O. Alfarghaly, R. Khaled, A. Elkorany, M. Helal, and A. Fahmy, “Au-
tomated radiology report generation using conditioned transformers,”
Informatics in Medicine Unlocked, vol. 24, p. 100557, Jan. 2021.

B. Chintagunta, N. Katariya, X. Amatriain, and A. Kannan, “Medically
aware GPT-3 as a data generator for medical dialogue summarization,”
in Proceedings of the Second Workshop on Natural Language Process-
ing for Medical Conversations. Online: Association for Computational
Linguistics, Jun. 2021, pp. 66-76.

A. M. Ibrahim, “Ontology-driven information retrieval for healthcare
information system : A case study,” International Journal of Network
Security & Its Applications, vol. 5, no. 1, pp. 61-69, Jan. 2013.

M. Khanbhai, P. Anyadi, J. Symons, K. Flott, A. Darzi, and E. Mayer,
“Applying natural language processing and machine learning tech-
niques to patient experience feedback: A systematic review,’ BMJ
Health & Care Informatics, vol. 28, no. 1, p. e100262, Mar. 2021.
K. Nawab, G. Ramsey, and R. Schreiber, “Natural language processing
to extract meaningful information from patient experience feedback,”
Applied Clinical Informatics, vol. 11, no. 2, pp. 242-252, Mar. 2020.
K. Doing-Harris, D. L. Mowery, C. Daniels, W. W. Chapman, and
M. Conway, “Understanding patient satisfaction with received health-
care services: A natural language processing approach,” AMIA Annual
Symposium Proceedings, vol. 2016, pp. 524-533, Feb. 2017.

D. Rodger, A. Skuse, M. Wilmore, S. Humphreys, J. Dalton,
M. Flabouris, V. L. Clifton, D. Rodger, A. Skuse, M. Wilmore,
S. Humphreys, J. Dalton, M. Flabouris, and V. L. Clifton, “Preg-
nant women’s use of information and communications technologies
to access pregnancy-related health information in South Australia,”
Australian Journal of Primary Health, vol. 19, no. 4, pp. 308-312,
Dec. 2013.

B. Zhou, K. Wu, P. Ly, J. Wang, G. Chen, B. Ji, and S. Liu, “A
new remote health-care system based on moving robot intended for
the elderly at home,” Journal of Healthcare Engineering, vol. 2018, p.
4949863, Feb. 2018.

P. J. Rani, J. Bakthakumar, B. P. Kumaar, U. P. Kumaar, and S. Kumar,
“Voice controlled home automation system using natural language
processing (NLP) and internet of things (IoT),” in 2017 Third Inter-
national Conference on Science Technology Engineering Management
(ICONSTEM), Mar. 2017, pp. 368-373.

[172]

[173]

[174]

175]

176]

177]

178]

179]

180]

181]

182]

183]

184]

185]

186]

187]

188]

189]

190]

191]

192]

A. Tapus, M. J. Mataric, and B. Scassellati, “Socially assistive
robotics,’ IEEE Robotics Automation Magazine, vol. 14, no. 1, pp.
35-42, Mar. 2007.

N. Mavridis, “A review of verbal and non-verbal human-—robot interac-
tive communication,” Robotics and Autonomous Systems, vol. 63, pp.
22-35, Jan. 2015.

J. R. Green, R. L. MacDonald, P.-P. Jiang, J. Cattiau, R. Heywood,
R. Cave, K. Seaver, M. A. Ladewig, J. Tobin, M. P. Brenner, P. C.
Nelson, and K. Tomanek, “Automatic speech recognition of disordered
speech: Personalized models outperforming human listeners on short
phrases,” in Interspeech 2021. ISCA, Aug. 2021, pp. 4778-4782.
K. Hux, K. Knollman-Porter, J. Brown, and S. E. Wallace, “Compre-
hension of synthetic speech and digitized natural speech by adults with
aphasia,” Journal of Communication Disorders, vol. 69, pp. 15—26, Sep.
2017.

K. Hux, J. A. Brown, S. Wallace, K. Knollman-Porter, A. Saylor, and
E. Lapp, “Effect of text-to-speech rate on reading comprehension by
adults with aphasia,” American Journal of Speech-Language Pathology,
vol. 29, no. 1, pp. 168-184, Jul. 2020.

S. Cassidy, B. Stenger, L. Van Dongen, K. Yanagisawa, R. Anderson,
V. Wan, S. Baron-Cohen, and R. Cipolla, “Expressive visual text-to-
speech as an assistive technology for individuals with autism spectrum
conditions,’ Computer Vision and Image Understanding, vol. 148, pp.
193-200, Jul. 2016.

B. Repova, M. Zabrodsky, J. Plzak, D. Kalfert, J. Matousek, and
J. Betka, “Text-to-speech synthesis as an alternative communication
means after total laryngectomy,” Biomedical Papers of the Medical
Faculty of the University Palacky, Olomouc, Czechoslovakia, Apr. 2020.
F.C. Lyall, P. J. Clamp, and D. Hajioff, “Smartphone speech-to-text
applications for communication with profoundly deaf patients,’ The
Journal of Laryngology and Otology, vol. 130, no. 1, pp. 104-106,
Jan. 2016.

S. Nittrouer, L. M. Krieg, and J. H. Lowenstein, “Speech recognition
in noise by children with and without dyslexia: How is it related to
reading?” Research in developmental disabilities, vol. 77, pp. 98-113,
Jun. 2018.

D. Riafio, M. Peleg, and A. ten Teije, “Ten years of knowledge repre-
sentation for health care (2009-2018): Topics, trends, and challenges,”
Artificial Intelligence in Medicine, vol. 100, p. 101713, Sep. 2019.

Q. Bao, L. Ni, and J. Liu, “HHH: An online medical chatbot system
based on knowledge graph and hierarchical bi-directional attention,”
Proceedings of the Australasian Computer Science Week Multiconfer-
ence, pp. 1-10, Feb. 2020.

W. Xie, R. Ding, J. Yan, and Y. Qu, “A mobile-based question-
answering and early warning system for assisting diabetes manage-
ment,” Wireless Communications and Mobile Computing, vol. 2018, p.
e9163160, Jun. 2018.

P. Peters, Y. Qian, and J. Ding, “Translating medical terminology and
bilingual terminography,” Lexicography: Journal of ASIALEX, vol. 3,
no. 2, pp. 99-113, 2016.

A. Renato, J. Castafio, M. d. P. A. Williams, H. Berinsky, M. L.
Gambarte, H. Park, D. Pérez-Rey, C. Otero, and D. Luna, “A machine
translation approach for medical terms,” in HEALTHINF, 2018.

J. Leo, G. Kurdi, N. Matentzoglu, B. Parsia, U. Sattler, S. Forge,
G. Donato, and W. Dowling, “Ontology-based generation of medical,
multi-term MCQs,” International Journal of Artificial Intelligence in
Education, vol. 29, no. 2, pp. 145-188, May 2019.

NHS, “Nhs population screening explained,” nhs population screening

explained, Feb 2013. [Online]. Available: |https://www.gov.uk/guidance/|
P. M, G. M, Newton-DameRemle, T. E, P. E, M. H, and G. N, “The
state of population health surveillance using electronic health records:
A narrative review,” Population Health Management, Jun. 2015.

D. Georgiou, A. MacFarlane, and T. Russell-Rose, “Extracting senti-
ment from healthcare survey data: An evaluation of sentiment analysis
tools,’ in 2015 Science and Information Conference (SAI), Jal. 2015,
pp. 352-361.

H. Oztiirk, A. Ozgiir, P. Schwaller, T. Laino, and E. Ozkirimli, “Explor-
ing chemical space using natural language processing methodologies
for drug discovery,” Drug Discovery Today, vol. 25, no. 4, pp. 689-705,
Apr. 2020.

F. Lake, “Artificial intelligence in drug discovery: What is new, and
what is next?” Future Drug Discovery, vol. 1, no. 2, p. FDD19, Oct.
2019.

T.-H. Pham, Y. Qiu, J. Zeng, L. Xie, and P. Zhang, “A deep learning
framework for high-throughput mechanism-driven phenotype com-


[193]

[194]

[195]

[196]

[197]

[198]

[199]

[200]

[201]

[202]

[203]

[204]

[205]

[206]

[207]

[208]

[209]

[210]

pound screening and its application to COVID-19 drug repurposing,”
Nature Machine Intelligence, vol. 3, no. 3, pp. 247-257, Mar. 2021.
J. Schwartz, M. Awale, and J.-L. Reymond, “SMIfp (SMILES finger-
print) chemical space for virtual screening and visualization of large
databases of organic molecules,” Journal of Chemical Information and
Modeling, vol. 53, no. 8, pp. 1979-1989, Aug. 2013.

F. Zhang, B. Sun, X. Diao, W. Zhao, and T. Shu, “Prediction of adverse
drug reactions based on knowledge graph embedding,’ BMC Medical
Informatics and Decision Making, vol. 21, no. 1, p. 38, Feb. 2021.
K. Bouhedjar, A. Boukelia, A. K. Nacereddine, A. Boucheham, A. Be-
laidi, and A. Djerourou, “A natural language processing approach
based on embedding deep learning from heterogeneous compounds
for quantitative structure—activity relationship modeling,’ Chemical
Biology & Drug Design, vol. 96, no. 3, pp. 961-972, 2020.

W. Jeon and D. Kim, “FP2VEC: A new molecular featurizer for
learning molecular properties,” Bioinformatics, vol. 35, no. 23, pp.
4979-4985, Dec. 2019.

L. Chen, Y. Gu, X. Ji, C. Lou, Z. Sun, H. Li, Y. Gao, and Y. Huang,
“Clinical trial cohort selection based on multi-level rule-based natural
language processing system,” Journal of the American Medical Infor-
matics Association : JAMIA, vol. 26, no. 11, pp. 1218-1226, Jul. 2019.
S. Harrer, P. Shah, B. Antony, and J. Hu, “Artificial intelligence for
clinical trial design,’ Trends in Pharmacological Sciences, vol. 40,
no. 8, pp. 577-591, Aug. 2019.

H. Tissot, F. Asselbergs, A. Shah, D. Brealey, S. Harris, R. Agbakoba,
A. Folarin, L. Romao, L. Roguski, and R. Dobson, “Natural language
processing for mimicking clinical trial recruitment in critical care:
A semi-automated simulation based on the LeoPARDS trial,’ IEEE
Journal of Biomedical and Health Informatics, vol. PP, pp. 1-1, Mar.
2020.

X. Chen, H. Xie, G. Cheng, L. K. M. Poon, M. Leng, and F. L. Wang,
“Trends and features of the applications of natural language processing
techniques for clinical trials text analysis,’ Applied Sciences, vol. 10,
no. 6, p. 2157, Jan. 2020.

C. L. Ventola, “Big data and pharmacovigilance: Data mining for
adverse drug events and interactions,’ Pharmacy and Therapeutics,
vol. 43, no. 6, pp. 340-351, Jun. 2018.

X. Wang, G. Hripcsak, M. Markatou, and C. Friedman, “Active
computerized pharmacovigilance using natural language processing,
statistics, and electronic health records: A feasibility study,’ Journal
of the American Medical Informatics Association : JAMIA, vol. 16,
no. 3, pp. 328-337, 2009.

F. Liu, A. Jagannatha, and H. Yu, “Towards drug safety surveillance
and pharmacovigilance: Current progress in detecting medication and
adverse drug events from electronic health records,’ Drug Safety,
vol. 42, no. 1, pp. 95-97, Jan. 2019.

B. Zhou, G. Yang, Z. Shi, and S. Ma, “Interpretable Temporal Attention
Network for COVID-19 forecasting,’ Applied Soft Computing, vol. 120,
p. 108691, May 2022.

N. Zheng, S. Du, J. Wang, H. Zhang, W. Cui, Z. Kang, T. Yang, B. Lou,
Y. Chi, H. Long, M. Ma, Q. Yuan, S. Zhang, D. Zhang, F. Ye, and
J. Xin, “Predicting COVID-19 in china using hybrid AI model,” IEEE
Transactions on Cybernetics, vol. 50, no. 7, pp. 2891-2904, Jul. 2020.
Q. Chen, R. Leaman, A. Allot, L. Luo, C.-H. Wei, S. Yan, and Z. Lu,
“Artificial intelligence in action: Addressing the COVID-19 pandemic
with natural language processing,’ Annual Review of Biomedical Data
Science, vol. 4, no. 1, pp. 313-339, 2021.

A. Chapman, K. Peterson, A. Turano, T. Box, K. Wallace, and
M. Jones, “A natural language processing system for national COVID-
19 surveillance in the US department of veterans affairs,” in Proceed-
ings of the 1st Workshop on NLP for COVID-19 at ACL 2020. Online:
Association for Computational Linguistics, 2020.

R. C. Cury, I. Megyeri, T. Lindsey, R. Macedo, J. Batlle, S. Kim,
B. Baker, R. Harris, and R. H. Clark, “Natural language processing
and machine learning for detection of respiratory illness by chest CT
imaging and tracking of COVID-19 pandemic in the united states,”
Radiology: Cardiothoracic Imaging, vol. 3, no. 1, p. e200596, Feb.
2021.

D. DeCaprio, J. Gartner, C. J. McCall, T. Burgess, K. Garcia,
S. Kothari, and S. Sayed, “Building a COVID-19 vulnerability index,”
Journal of Medical Artificial Intelligence, vol. 3, no. 0, Dec. 2020.

S. M. Meystre, P. M. Heider, Y. Kim, M. Davis, J. Obeid, J. Madory,
and A. V. Alekseyenko, “Natural language processing enabling
COVID-19 predictive analytics to support data-driven patient advising
and pooled testing,’ Journal of the American Medical Informatics
Association: JAMIA, vol. 29, no. 1, pp. 12-21, Dec. 2021.

[211]

[212]

213]

214]

215]

216]

217]

[218]

219]

220]

221]

222]

223]

224]

[225]

226]

227]

228]

229]

IEEE REVIEWS IN BIOMEDICAL ENGINEERING

L. Wang, L. Jiang, D. Pan, Q. Wang, Z. Yin, Z. Kang, H. Tian, X. Geng,
J. Shao, W. Pan, J. Yin, L. Fang, Y. Wang, W. Zhang, Z. Li, J. Zheng,
W. Hu, Y. Pan, D. Yu, S. Guo, W. Lu, Q. Li, Y. Zhou, and H. Xu, “Novel
approach by natural language processing for COVID-19 knowledge
discovery,” Biomedical Journal, Apr. 2022.

A. Keshavarzi Arshadi, J. Webb, M. Salem, E. Cruz, S. Calad-
Thomson, N. Ghadirian, J. Collins, E. Diez-Cecilia, B. Kelly,
H. Goodarzi, and J. S. Yuan, “Artificial Intelligence for COVID-19
Drug Discovery and Vaccine Development,’ Frontiers in Artificial
Intelligence, vol. 3, 2020.

Z. Liu, R. A. Roberts, M. Lal-Nag, X. Chen, R. Huang, and W. Tong,
“Al-based language models powering drug discovery and develop-
ment,” Drug Discovery Today, vol. 26, no. 11, pp. 2593-2607, Nov.
2021.

WHO, “10 global health issues to track in 2021,”
https://www.who.int/news-room/spotlight/10-global-health-issues-
to-track-in-2021, 2020.

H.-J. Dai, C.-H. Su, Y.-Q. Lee, Y.-C. Zhang, C.-K. Wang, C.-J. Kuo,
and C.-S. Wu, “Deep learning-based natural language processing for
screening psychiatric patients,” Frontiers in Psychiatry, vol. 11, 2021.
D. D. DeSouza, J. Robin, M. Gumus, and A. Yeung, “Natural language
processing as an emerging tool to detect late-life depression,” Frontiers
in Psychiatry, vol. 12, 2021.

R. G. Jackson, R. Patel, N. Jayatilleke, A. Kolliakou, M. Ball,
G. Gorrell, A. Roberts, R. J. Dobson, and R. Stewart, “Natural
language processing to extract symptoms of severe mental illness from
clinical text: The clinical record interactive search comprehensive data
extraction (CRIS-CODE) project,” BMJ Open, vol. 7, no. 1, p. e€012012,
Jan. 2017.

J. Cohen, J. Wright-Berryman, L. Rohlfs, D. Trocinski, L. Daniel, and
T. W. Klatt, “Integration and validation of a natural language processing
machine learning suicide risk prediction model based on open-ended
interview language in the emergency department,” Frontiers in Digital
Health, vol. 4, 2022.

D. Harvey, F. Lobban, P. Rayson, A. Warner, and S. Jones, “Natural
language processing methods and bipolar disorder: Scoping review,”
JMIR Mental Health, vol. 9, no. 4, p. e35928, Apr. 2022.

T. Zhang, A. M. Schoene, S. Ji, and S. Ananiadou, “Natural language
processing applied to mental illness detection: A narrative review,” npj
Digital Medicine, vol. 5, no. 1, pp. 1-13, Apr. 2022.

G. Bedi, F. Carrillo, G. A. Cecchi, D. F. Slezak, M. Sigman, N. B. Mota,
S. Ribeiro, D. C. Javitt, M. Copelli, and C. M. Corcoran, “Automated
analysis of free speech predicts psychosis onset in high-risk youths,”
npj Schizophrenia, vol. 1, no. 1, pp. 1-7, Aug. 2015.

R. A. Calvo, D. N. Milne, M. S. Hussain, and H. Christensen, “Natural
language processing in mental health applications using non-clinical
textst,’ Natural Language Engineering, vol. 23, no. 5, pp. 649-685,
Sep. 2017.

T. Althoff, K. Clark, and J. Leskovec, “Large-scale analysis of coun-
seling conversations: An application of natural language processing
to mental health,’ Transactions of the Association for Computational
Linguistics, vol. 4, pp. 463-476, 2016.

V. Chattaraman, W.-S. Kwon, J. E. Gilbert, and K. Ross, “Should AI-
Based, conversational digital assistants employ social- or task-oriented
interaction style? A task-competency and reciprocity perspective for
older adults?’ Computers in Human Behavior, vol. 90, pp. 315-330,
Jan. 2019.

A. Amin-Nejad, J. Ive, and S. Velupillai, “Exploring transformer text
generation for medical dataset augmentation,” in Proceedings of the
12th Language Resources and Evaluation Conference. Marseille,
France: European Language Resources Association, May 2020, pp.
4699-4708.

J. Ive, N. Viani, J. Kam, L. Yin, S. Verma, S. Puntis, R. N. Cardinal,
A. Roberts, R. Stewart, and S. Velupillai, “Generation and evaluation
of artificial mental health records for natural language processing,” npj
Digital Medicine, vol. 3, no. 1, pp. 1-9, May 2020.

X. Soto, O. Perez-de-Vifiaspre, G. Labaka, and M. Oronoz, “Neural
machine translation of clinical texts between long distance languages,”
Journal of the American Medical Informatics Association, vol. 26,
no. 12, pp. 1478-1487, Dec. 2019.

K. Wotk and K. Marasek, “Neural-based machine translation for
medical text domain. based on european medicines agency leaflet
texts,’ Procedia Computer Science, vol. 64, pp. 2-9, Jan. 2015.

K. Wolk and K. P. Marasek, “Translation of medical texts using neural
networks,” International Journal of Reliable and Quality E-Healthcare
(IJRQEH), vol. 5, no. 4, pp. 51-66, 2016.


ZHOU et al.: NATURAL LANGUAGE PROCESSING FOR SMART HEALTHCARE

Binggui Zhou received the B.Eng. degree from
Jinan University, Zhuhai, China, in 2018, and the
M.Sc. degree from the University of Macau, Macao,
China, in 2021, respectively. He is currently working
toward the Ph.D. degree in Electrical and Computer
Engineering with the University of Macau, Macao,
China. He also serves as a Research Assistant
with the School of Intelligent Systems Science and

Engineering, Jinan University, Zhuhai, China. His
TS research interests include Natural Language Process-

ing, Artificial Intelligence, and AI assisted Wireless

Communications.

Guanghua Yang received his Ph.D. degree in elec-
trical and electronic engineering from the University
of Hong Kong, Hong Kong, in 2006. From 2006
to 2013, he served as post-doctoral fellow, research
associate at the University of Hong Kong. Since
April 2017, he has been with Jinan University, where
he is currently a Full Professor in the School of
Intelligent Systems Science and Engineering. His
research interests are in the general areas of AI and
its applications.

Zheng Shi received his B.S. degree in communi-

cation engineering from Anhui Normal University,

China, in 2010 and his M.S. degree in communi-

cation and information system from Nanjing Uni-

versity of Posts and Telecommunications (NUPT),

China, in 2013. He obtained his Ph.D. degree in

Electrical and Computer Engineering from Univer-

aN sity of Macau, Macao, in 2017. He is currently an

f Associate Professor with the School of Intelligent

| ‘2 i Systems Science and Engineering, Jinan University,

Zhuhai, China. His current research interests include

hybrid automatic repeat request, non-orthogonal multiple access, machine
learning and Internet of Things.

Shaodan Ma received the double Bachelor’s degrees
in science and economics and the M.Eng. degree
in electronic engineering from Nankai University,
Tianjin, China, in 1999 and 2002, respectively, and
the Ph.D. degree in electrical and electronic engi-
neering from The University of Hong Kong, Hong
Kong, in 2006. From 2006 to 2011, she was a post-
doctoral fellow at The University of Hong Kong.
Since August 2011, she has been with the University
of Macau, where she is currently a Professor. Her
research interests include array signal processing,
machine learning, wireless sensing and mmwave communications.

17
