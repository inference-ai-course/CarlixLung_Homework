arXiv:2106.02192v1 [cs.CL] 4 Jun 2021

Grounding ‘Grounding’ in NLP

Khyathi Raghavi Chandu, Yonatan Bisk, Alan W Black
Language Technologies Institute
Carnegie Mellon University
{kchandu, ybisk, awb}@cs.cmu.edu

Abstract

The NLP community has seen substantial re-
cent interest in grounding to facilitate inter-
action between language technologies and the
world. However, as a community, we use the
term broadly to reference any linking of text to
data or non-textual modality. In contrast, Cog-
nitive Science more formally defines “ground-
ing” as the process of establishing what mu-
tual information is required for successful
communication between two interlocutors —
a definition which might implicitly capture the
NLP usage but differs in intent and scope.

We investigate the gap between these defini-
tions and seek answers to the following ques-
tions: (1) What aspects of grounding are miss-
ing from NLP tasks? Here we present the di-
mensions of coordination, purviews and con-
straints. (2) How is the term “grounding” used
in the current research? We study the trends in
datasets, domains, and tasks introduced in re-
cent NLP conferences. And finally, (3) How
to advance our current definition to bridge
the gap with Cognitive Science? We present
ways to both create new tasks or repurpose
existing ones to make advancements towards
achieving a more complete sense of grounding.
github.com/khyathiraghavi/Grounding-Grounding

1 Introduction

We as humans communicate and interact for a va-
riety of reasons with a goal. We use language to
seek and share information, clarify misunderstand-
ings that conflict with our prior knowledge and
contextualize based on the medium of interaction
to develop and maintain social relationships. How-
ever, language is only one of the enablers of this
communication reliant on several auxiliary signals
and sources such as documents, media, physical
context etc., This linking of concepts to context
is grounding and within NLP context is often a
knowledge base, images or discourse.

What is missing in
grounding?

¢ Dynamic grounding

° Expanding purviews

'° Satisfying more
media-based
constraints

Constraints of
grounding

Coordination in
grounding

Figure 1: Dimensions of grounding — required to bridge
the gap between current state of research and what is
missing from a more complete sense of grounding.

In contrast, research in cognitive science defines
grounding as the process of building a common
ground based on shared mutual information in or-
der to successfully communicate (Clark and Carl-
son, 1982; Krauss and Fussell, 1990; Clark and
Brennan, 1991; Lewis, 2008). We argue that this
definition subsumes NLP’s current working defi-
nition and provides concrete guidance on which
phenomena are missing to ensure the naturalness
and long term utility of our technologies.

In Section 2, we formalize 3 dimensions key
to grounding: Coordination, Purviews and Con-
straints, to systematize our analysis of limitations in
current work. Section 3 presents a comprehensive
review of the current progress in the field including
the interplay of different domains, modalities, and
techniques. This analysis includes understanding
when techniques have been specifically designed
for a single modality, task, or form of grounding.
Finally, Section 4 outlines strategies to repurpose
existing datasets and tasks to align with the new


richer definition from cognitive science literature.
These introspections, re-formulations, and concrete
steps situate NLP ‘grounding’ in larger scientific
discourse, to increase its relevance and promise.

2 Dimensions of grounding

Defining grounding loosely as linking or tethering
concepts is insufficient to achieve a more realistic
sense of grounding. Figure 1 presents the research
dimensions missing from most current work.

2.1 Dimension 1: Coordination in grounding

The first and the most important dimension that
bridges the gap between the two definitions of
grounding is the aspect of coordination — alterna-
tively viewed as the difference between static and
dynamic grounding (Fig 2).

Static grounding is the most common type and
assumes that the evidence for common ground or
the gold truth for grounding is given or attained
pseudo-automatically. This is demonstrated in Fig-
ure 2 (a). The sequence for this form of interaction
includes: (1) human querying the agent, (2) agent
querying the data or the knowledge it acquired, (3)
agent retrieving and framing a response and (4)
agent delivering it to the human. In this setting the
common ground is the ground truth KB/data. The
human and the agent have common ground by as-
suming its universality (i.e. no external references).
Therefore, successfully grounding the query in this
case relies solely on the agent being able to link the
query to the data. For instance, in a scenario where
a human wants to know the weather report, the ac-
curacy of the database itself is axiomatic and we
build a model for the agent to accurately retrieve
the queried information in natural language.

Most current research assumes static grounding
SO progress is measured by the ability of the agent
to link more concepts to more data. However, the
axiomatic common ground often does not exist and
needs to be established in real world scenarios.

Dynamic grounding _ posits that common ground
is built via interactions and clarifications. The mu-
tual information needed to communicate success-
fully is built via interactions including: Request-
ing and providing clarifications, Acknowledging or
confirming the clarifications, Enacting or demon-
strating to receive confirmations, and so forth. This
dynamically-established-grounding guides the rest
of the interaction by course-correcting any misun-

a) en |e Onn.
0 . o Bc:

f fog
eer @----.. 8

Yeon. ae ae | @--7" wes
OS vo ®

(a) Coordination sequence in static grounding | |(b) Coordination sequence in dynamic grounding

Figure 2: Coordination sequence in grounding

derstandings. The sequence of actions in dynamic
grounding is demonstrated in Figure 2 (b). The
steps for establishing grounding is a part of the
interaction that includes: (1) The human querying
the agent, (2) The agent requesting clarification or
acknowledging, (3) The human clarifying or con-
firming. These three steps loop until a common
ground is established. The remaining steps of (4)
querying the data, (5) retrieving or framing a re-
sponse, and (6) delivering the response, are same as
that of static grounding. The agent and the human
may not be on the same common ground but steps
2 and 3 loop as the conversation progresses to build
this common ground. The process of successfully
grounding the query not only relies on the ability of
the agent to Jink the query but also to construct the
common ground from the mutually shared informa-
tion with respect to the human. Although there are
efforts about clarification questioning (), the cover-
age of phenomena are still far from comprehensive
(Benotti and Blackburn, 2021b).

Cognitive sciences in the perspective of language
acquisition (Carpenter et al., 1998) present two
ways of dynamic grounding via joint attention (Kol-
eva et al., 2015; Tan et al., 2020): Dyadic joint
attention and Triadic joint attention. In our case,
dyadic attention describes the interaction between
the human and the agent and any clarification or
confirmation is done strictly between the both of
them. Triadic attention also includes a tangible
entity along with the human and the agent. The
human can provide clarifications by gazing or point-
ing to this additional piece in the triad.

Summary: The community should prioritize dy-
namic grounding as it is more general and more

accurately matches real experiences.

2.2 Dimension 2: Purviews of grounding

Next, we present the different stages behind reach-
ing a common ground, known as purviews. Most


of the current approaches and tasks address these
purviews individually and independently, while
they are often co-dependent in real world scenarios.

Stage 1: Localization: The first stage is the local-
ization of the concept either in the physical or men-
tal contexts. This step is idiosyncratic and relates to
the ability of the agent alone to localize the concept.
These concepts often are also linked in a compo-
sitional form. For instance, consider a scenario
in which the agent is to locate a ‘blue sweater’.
The agent needs to understand each of the con-
cepts of ‘blue’ and ‘sweater’ individually and then
locate the composition of the whole unit. Clark
and Krych (2004) from cognitive sciences demon-
strate how incremental grounding (Schlangen and
Skantze, 2009; DeVault and Traum, 2013; Eshghi
et al., 2015) is performed with these compositions
and show how recognition and interpretation of
fragments help in this by breaking down instruc-
tions into simpler ones. This localization occurs
at word, phrase and even sentence level in the lan-
guage modality and pixel, object and scene level in
the visual modality.

Stage 2: External Knowledge: After localizing
the concept, the next step is to ensure consistency
of the current context of the concept with existing
knowledge. Often times, the references of ground-
ing either match or contradict the references from
our prior knowledge and external knowledge. This
might lead to misunderstandings in the consequent
rounds of communication. Hence, in addition to
localizing the concept, it is also essential to make
the concept and its attributes consistent with the
available knowledge sources. Most of the current
research is focused on localizing with few efforts to-
wards extending it to maintain a consistency of the
grounded concept with other knowledge sources.

Stage 3: Common sense: After establishing con-
sistency of the concept, a human-like interaction
additionally calls for grounding the common sense
associated with the concept in that scenario. In
addition to the basic level of practical knowledge
that concerns with day to day scenarios Sap et al.
(2020), the concept should also be reasoned based
on that particular context. This contextual common
sense moves the idiosyncratic sense towards a sense
of collective understanding. For instance, if the hu-
man feels cold and asks the agent to get a blue coat,
the agent needs to understand that the coat in this
instance is a sweater coat and not a formal coat.
This implicit common sense minimizes the effort

in building a common ground reducing articulation
of meticulous details. Therefore it is essential to
incorporate this explicitly in our modeling as well.
Stage 4: Personalized consensus: As a part of
the evolving conversations, the references in the
language evolve as well. The grounded term might
have different meanings for the agent in the context
with access to the history as opposed to a fresh
agent without access to the history. This multi-
instance multi-turn process to achieve consensus
makes this collective or a shared stage continu-
ally adapting to personalization leading to better
engagement (Bohus and Horvitz, 2014). In such
settings, it is sufficient that the human and the
agent are in consensus with the truth value of the
grounded term, which need not be the same as the
ground truth. This shift in the truth value of the
meanings of the grounded terms often arise due to
developing short-cuts for ease of communication
and personalization, which is an acceptable shift as
long as the communication is successful.

Summary: Common ground requires expanding
to verticals of local, general, common-sense and

personalized contextual knowledge.

2.3. Dimension 3: Constraints of grounding

The medium and mode of communication con-
strain communicative goals in practical scenarios.
The number and availability of such media have
increased and facilitated ubiquitous communica-
tion around the world, presenting a diversity in
the mode of interaction. Motivated by this, we
resurface and adapt the constraints of grounding
with respect to media of interaction as defined by
Clark and Brennan (1991). Here are the definitions
of these constraints in the context of grounded lan-
guage processing and the corresponding categoriza-
tion of the majority of the representative domains
in grounding satisfying different constraints.

e Copresence: Agent and human share the same
physical environment of the data. Most of the cur-
rent research in the category of embodied agents
satisfy this constraint.

¢ Visibility: The data is visible to the agent and/or
human. The domains of images, images & speech,
videos, embodied agents satisfy this constraint.

e Audibility: Agent and human communicate by
speaking about the data. Domains like speech, spo-
ken image captions and videos satisfy this.

¢ Cotemporality: The agent/human receives at
roughly the same time as the human/agent pro-


duces. The lag in the domains like conversations
or interactive embodied agents is considered negli-
gible and satisfy this constraint.

e Simultaneity: The agent and the human can send
and receive at once simultaneously. Most media
are cotemporal but do not engage in simultaneous
interaction. This often disrupts the understanding
of the current utterance and the participant may
have to repeat it to avoid misunderstandings, which
is commonly observed in real world scenarios.

e Sequentiality: The turn order of the agent and
the human cannot get out of sequence. Face-to-face
conversations usually follow this constraint but an
email thread with active participants and the com-
ments sections in online portals (such as Youtube,
Twitch etc.,) do not necessarily follow a sequence.
In such cases a reply to the message may be sepa-
rated by arbitrary number of irrelevant messages.
These categories are usually understudied but are
commonly observed online.

e Reviewability: The agent reviews the common
ground to the human to adapt to imperfect human
memories. For instance, we reiterate full references
instead of adapting to short cut references when
the conversation resurfaces after a while. This is
to develop a personalized adaptation between the
interlocutors based on the media to enable ease of
communication.

¢ Revisability: The interaction between the agent
and the human indexes to a specific utterance in
the conversation sequence and revise it, therefore
changing the course of the interaction henceforth.
Human errors are only natural in a conversation and
the agent needs to be ready to rectify the previously
grounded understanding.

There has been a good and continual effort in
formulating tasks and datasets that satisfy the con-
straints of visibility, audibility and cotemporality.
Contemporary efforts also see an increased inter-
est in addressing copresence in grounded contexts.
Very recently, (Benotti and Blackburn, 202 1a) high-
lights the importance of recovering from mistakes
while establishing the collabrative nature of ground-
ing, contributing to the ability of revisability.

Summary: Key to progress is to focus on largely
a blind spot in grounding: simultaneity, sequen-

tiality & revisability to revive from mistakes.

3 Grounding ‘Grounding’

Having covered a more formal definition of ground-
ing adapted to NLP, we turn our attention to cat-

aloging the precise usage of ‘grounding’ in our
research community. We present an analysis on the
various domains and techniques NLP has explored.

3.1 Data and Annotations

To this end, since our aim is to investigate how the
community understands the loosely defined term
‘grounding’, we subselected all the papers that men-
tion terms for ‘grounding’ in the title or abstract
from the S2ORC data (Lo et al., 2020) between
the years 1980-2020. In this way, we grounded
the term ‘grounding’ in literature ! to collect the
relevant papers. We acknowledge that the papers
analyzed here are not exhaustive with respect to
concept of ‘grounding’.

Each of the paper is annotated with answers to
the following questions: (i) is it introducing a new
task? (ii) is it introducing a new dataset? (iii) what
is the world scope (iv) is it working on multiple
languages? (v) what are the grounding domains?
(vi) what is the grounding task? (vii) what is the
grounding technique?

3.2 Domains of grounding

Real world contexts we interact with are diverse
and can be derived from different modalities such
as textual or non-textual, each of which comprises
of domains. Our categorization of these is inspired
from the constraints of grounding as described in
§2.3. Based on this, the modality based categoriza-
tion include the following domains:

e Textual modality comprising plain text, entities &
events, knowledge bases and knowledge graphs.

e Non-textual modality comprising images, speech,
images & speech and videos.

Numerous other domains including numbers and
equations, colors, programs, tables, brain activity
signals etc., are studied in the context of grounding
at relatively lower scale in comparison to the afore-
mentioned ones. Each of these can further be inter-
acted with along the variation in the coordination
dimension of grounding from §2.1, that give rise
to the following settings including conversations,
embodied agents and face-to-face interactions.

3.3 Approaches to grounding

This section presents a list of approaches tailored
to grounding. The obvious solution is to expand
the datasets to promote a research platform. The

'Please note that this is not an exhaustive list of papers

working on grounding as there are several others that do men-
tion this term and still work on some form of grounding.


Grounding
Approaches

Incorporating in >)
objective )

Multitasking &
Joint modeling

—= se )

Manipulating
annotations

representations

(Fusion |

{now datasets datasets

4 eet) Novel Loss
—(_ Projection) :
4 eet) Function
Hein —(_ Atonent Adversarial
Hein

Figure 3: Categorical approaches to grounding

second is to manipulate different representations
to link and bring them together. Finally the learn-
ing objective can leverage grounding. The sub-
categories within each are presented in Figure 3.

1. Expanding datasets / annotations: The first
step towards building an ecosystem for research in
grounding is to curate the necessary datasets which
is accomplished with expensive human efforts, aug-
menting existing annotations and automatically de-
riving annotations with weak supervision.

la) New datasets: There has been an increase in
efforts for curating new datasets with task specific

annotations. These are briefly overlaid in Table 1
along with their modalities, domains and tasks.
1b) Augment annotations: These curated datasets
can also be used subsequently to augment with task
specific annotations instead of collecting the data
from scratch, which might be more expensive.

e Non-textual Modality: Static grounding here in-
cludes using adversarial references to ground visual
referring expressions (Akula et al., 2020), narration
(Chandu et al., 2019b, 2020a), language learning
(Suglia et al., 2020; Jin et al., 2020) etc.,

e Textual Modality: Static grounding includes
entity slot filling (Bisk et al., 2016).

e Interactive: Though not fully dynamic ground-
ing, some efforts here are amongst tasks like under-
standing spatial expressions (Udagawa et al., 2020),
collaborative drawing (Kim et al., 2019) etc.,
1c) Weak supervision: While the above two are
based on human efforts, we can also perform weak
supervision to use a model trained to derive auto-
matic soft annotations required for the task.

e Non-Textual Modality: In the visual modal-
ity, weak supervision is used in the contexts of
automatic object proposals for different tasks like
spoken image captioning (Srinivasan et al., 2020),
visual semantic role labeling (Silberer and Pinkal,
2018), phrase grounding (Chen et al., 2019), loose

Modality Domain Task

Work

caption relevance
multimodal MT
sports commentaries
semantic role labeling
instruction following

(Suhr et al., 2019)

(Zhou et al., 2018c)
(Koncel-Kedziorski et al., 2014)
(Silberer and Pinkal, 2018)
(Han and Schlangen, 2017)

_ images navigation (Andreas and Klein, 2014)
g causality (Gao et al., 2016)
x spatial expressions (Kelleher et al., 2006)
E spoken image captioning (Alishahi et al., 2017)
Z entailment (Vu et al., 2018)
image search (Kiros et al., 2018)
scene generation (Chang et al., 2015)
action segmentation (Regneri et al., 2013)
s semantic parsin; (Ross et al., 2018)
ideas mend faIlGRABE (Liu et al., 2016)
question answering (Lei et al., 2020)
content transfer (Prabhumoye et al., 2019)
_ commonsense inference (Zellers et al., 2018)
g Text reference resolution (Kennington and Schlangen, 2015)
é on symbol grounding (Kameko et al., 2015)
bilingual lexicon extraction (Laws et al., 2010)
POS tagging (Cardenas et al., 2019)
negotiations (Cadilhac et al., 2013)
Text documents (Zhou et al., 2018b)
improvisation (Cho and May, 2020)
2 referring expressions aber eval, 201)
9 (Takmaz et al., 2020)
8 . emotions and styles (Shuster et al., 2020)
I Visual . : .
a media interviews (Majumder et al., 2020)

(Jaénner et al., 2018)
(Ku et al., 2020)
(Li and Boyer, 2015)

spatial reasoning
navigation
problem solving

Other

Table 1: Example datasets introduced for grounding.

temporal alignments between utterances and a set
of events (Koncel-Kedziorski et al., 2014) etc.,

e Textual Modality: In the contexts of text,
Tsai and Roth (2016a) work towards disambiguat-
ing concept mentions appearing in documents and
grounding them in multiple KBs which is a step
towards Stage 3 in §2.2. Poon (2013) perform ques-
tion answering with a single database and (Parikh
et al., 2015) with symbols.

Summary: While augmentation and weak super-
vision can be leveraged for dimensions of coordi-
nation and purviews, curating new datasets is the

need of the hour to explore various constraints.

2. Manipulating representations: Grounding
concepts often involves multiple modalities or rep-
resentations that are linked. Three major methods
to approach this are detailed here.

2a) Fusion and concatenation: Fusion is a very
common technique in scenarios involving multiple
modalities. In scenarios with a single modality,
representations are often concatenated.

¢ Non-textual modality: Fusion is applied with im-
ages for tasks like referring expressions (Roy et al.,
2019), SRL (Yang et al., 2016) etc., For videos,
some tasks are grounding action descriptions (Reg-
neri et al., 2013), spatio-temporal QA (Lei et al.,


2020), concept similarity (Kiela and Clark, 2015),
mapping events (Fleischman and Roy, 2008) etc.,
e Textual Modality: With text, this is similar to
concatenating context (Prabhumoye et al. (2019)
perform content transfer by augmenting context).

e Interactive: Ina conversational setting, work
is explored in reference resolution (Takmaz et al.,
2020; Haber et al., 2019), generating engaging re-
sponse (Shuster et al., 2020), document grounded
response generation Zhou et al. (2018b), etc.,

¢ Others: Nakano et al. (2003) study face-to-face
grounding in instruction giving for agents.
2b) Alignment: An alternative to combining rep-
resentations is aligning them with one another.

e Non-textual modality: Wang et al. (2020) per-
form phrase localization in images and Hessel et al.
(2020) study temporal alignment in videos.

e Interactive: Han and Schlangen (2017) align
GUI actions to sub-utterances in conversations and
Janner et al. (2018) align local neighborhoods to
the corresponding verbalizations.
2c) Projecting into a common space: A widely
used approach is to also bring the different repre-
sentations on to a joint common space.

e Non-textual modality: Projection to a joint se-
mantic space is used in spoken image captioning
(Chrupala et al., 2017; Alishahi et al., 2017; Havard
et al., 2019), bicoding for learning image attributes
(Silberer and Lapata, 2014), representation learn-
ing of images (Zarrie and Schlangen, 2017) and
speech (Vijayakumar et al., 2017).

e Textual modality: Tsai and Roth (2016b) demon-
strate cross-lingual NER and mention grounding
model by activating corresponding language fea-
tures. Yang et al. (2019) perform imputation of em-
beddings for rare and unseen words by projecting
a graph to the pre-trained embeddings space.

Summary: Modeling different representations ef-
fectively aid in improving both consistency across

purviews and media based constraints.

3. Learning Objective: Grounding is often per-
formed to support a more defined end purpose task.
We identified 3 ways that are broadly adopted to
incorporate grounding in objective functions.

3a) Multitasking and Joint Modeling: The Jink-
ing formulation of grounding is often used as an
auxiliary or dependent to model another task.

e Non-textual Modality: Multitasking with im-
ages is used to perform spoken image captioning
(Chrupala, 2019) and grammar induction (Zhao

and Titov, 2020). Joint modeling was used in multi-
resolution language grounding Koncel-Kedziorski
et al. (2014), identifying referring expressions Roy
et al. (2019), multimodal MT (Zhou et al., 2018c),
video parsing Ross et al. (2018), learning latent
semantic annotations (Qin et al., 2018) etc.,

e Interactive: In a conversational setting, mul-
titasking is used to compute concept similarity
judgements (Silberer and Lapata, 2014), know!l-
edge grounded response generation (Majumder
et al., 2020), grounding language instructions Hu
et al. (2019). Joint modeling is used by Li and
Boyer (2015) to address dialog for complex prob-
lem solving in computer programs.
3b) Loss Function: It is crucial to utilize appro-
priate loss designed for the specific grounding task.
The main difference between multitasking and a
loss function adaptation is that while multitasking
reweights combinations of existing loss functions,
novel loss functions are informed by the data/task
at hand, adapting to a novel use case.

e Non-textual Modality: Grujicic et al. (2020) de-
sign soft organ distance loss to model inter and intra
organ interactions for relative grounding. [lharco
et al. (2019) improve diversity in spoken captions
with a masked margin softmax loss.
3c) Adversarial: Leveraging deceptive grounded
inputs in an attempt to fool the model is capable of
making it robust to certain errors.

e Non-textual Modality: Chen et al. (2018); Akula
et al. (2020) present an algorithm to craft visually-
similar adversarial examples.

e Textual Modality: Zellers et al. (2018) perform
adversarial filtering and constructs a de-biased
dataset by iteratively training stylistic classifiers.

Summary: Manipulating learning objective is a
modeling capability aiding as an additional com-
ponent in bringing grounding adjunct to several

other end tasks across all the dimensions.

3.4 Analysis of trends

Based on the categories of approaches and different
datasets from §3.3, we presented a representative
set of analyses that highlight the major avenues
that addressing the key missing pieces of work on
grounding to advance future research.

Figure 4 presents the trends in the develop-
ment of grounding over the past decade includ-
ing: specific approaches (a,b) that presents new
tasks/challenges; world scopes (Bisk et al., 2020)
(c) contributing to grounding language in different


® New Datasets ™® Augment Annotations

4

2

0

® Fusion @ Alignment ® Projection

ed

2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020

a) Trends in curating new datasets and augmenting annotations

@ WSS @ WS4 @WS3 BWS2 B WS1
30

0
2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020

(c) Trends in world scopes

2013-2014 2015-2016 2017-2018 2019-2020

(b) Trends in manipulation of representations

® Single language ®™ Multiple languages
30

o_eallg il

2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020

(c) Trends in multilingual datasets and tasks

Figure 4: Analysis on the trends in grounding

data types; and multilinguality (d) contributing to
a part of linguistic diversity. We also present hi-
erarchical pie charts in Figure 5 and in Appendix
to analyze the compositions of modalities and do-
mains for these approaches. While we believe our
analysis targets several of the most critical dimen-
sions paving way for future research directions, it is
not exhaustive and welcome suggestions from the
community for additional analysis. For example, it
is also interesting to study domain diversity, task
formulation/usefulness, etc., in future.

Trends in datasets expansion: The introduction
of new datasets has seen a rapid increase over the
years, while there is also a subtle increasing trend in
augmenting annotations to the existing datasets, as
observed in Figure 4 (a). As we can see from Figure
5 (a), across all the domains, gathering new datasets
seem to be prominent than augmenting them with
additional annotations to repurpose the data for a
new task. There seems to be a higher emphasis of
expansion of datasets in the non-textual modalities,
particularly in the domain of images. A similar
rise is not observed in interactive settings including
conversational data and interaction with embodied
agents; which is the propitious way to bridge the
gap towards real sense of grounding. It is indeed
encouraging to see an increasing trend in the efforts
for expanding datasets but the need of the hour is to
redirect some of these resources to address dynamic
grounding in the coordination dimension which is
scarcely studied in existing datatsets.

Trends in manipulating representations: From

Figure 4 (b), we note that the fusion technique has
and is increasingly becoming popular in ground-
ing through manipulating representations in com-
parison to alignment and projection. This is also
observed in Figure 5 (b) with the dominance of non-
textual modality. In the context of textual modality,
this technique is equivalent to concatenation of the
context or history in a conversation. Projecting
onto a common space is the next popular technique
in comparison to alignment. Similarly, we observe
that the non-textual modality overwhelmingly occu-
pies the space of manipulating representations with
exceeding prominence of fusion. Fusion and pro-
jecting onto common space currently are exceed-
ingly used methodologies to ground within a single
purview. They demonstrate a promising direction to
manipulate representations across different stages
to maintain consistency along the purviews.

Trends in World Scopes: We also study the de-
velopment of the field based on the definitions of
the world scopes presented by Bisk et al. (2020).
Based on this, last decade has seen an increasing
dominance in research on world scope 3 (world
of sights and sounds). However, this is limited to
this scope and the same trend is not clear in world
scope 4 (world of embodiment and action). An
encouraging observation is the focus of the field in
world scope 5 (social world) which is closer to real
interactions in the last year. We need to accelerate
development of datasets and tasks in world scopes
4 and 5. It is highly recommended to take dynamic
grounding scenario into account in the efforts for


(a) Expanding datasets/annotations

(b) Manipulating Representations

Figure 5: Analysis of Domains and Techniques

curating datasets in these scopes.

Inclusivity of multiple languages: Figure 4 (c)
shows that research into grounding in multiple lan-
guages is still incredibly rare. As noted by Ben-
der (2011), improvements in one language do not
necessarily mandate comparable performances in
other languages. The norm for benchmarking
large scale tasks still remains anglo-centric and
we need serious efforts to drift this trend to identify
challenges in grounding across languages. As a
first step, a relatively less expensive way to navi-
gate this dearth is to augment the annotations of
existing datasets with other languages.

4 Path Ahead: Towards New Tasks and
Repurposing Existing Datasets

We presented the dimensions of grounding that re-
quire serious attention to bridge the gap between
the definitions in cognitive sciences and language
processing communities in §2. Based on this, we
analyzed the language processing research to under-
stand where we stand and where we fall short with
the ongoing efforts in trends in grounding in §3.
While we strongly advocate for efforts in building
new datasets and tasks considering progress along
these dimensions, we believe in a smoother transi-
tion towards this goal. Hence we present strategies
to repurpose existing resources to maximum utility
as we stride towards achieving grounding in real
sense. In this section, we focus on concrete sugges-
tions to improve along each of the dimensions.
Coordination: This is based on simulating inter-
action for dynamic grounding. As establishing a
common ground is not integrated within datasets,
we propose an iterative paradigm to explicitly settle
on a common ground based on our priors.

The first family of methods to perform this is
human-in-the-loop interactions. The traditional
methods of data collection do not cater to human
feedback or generation. Some recent approaches to
incorporate human feedback are during data collec-
tion (Wallace et al., 2019), training (Stiennon et al.,
2020), inference (Hancock et al., 2019). While
the feedback in a human in the loop setting can
be via scores, we argue for natural language feed-
back (Wallace et al., 2019) loop, which resembles
human-human grounding via communication.

The second family of methods are inspired from
the theory of mind (Gopnik and Wellman, 1992)
to iteratively or progressively ask and clarify to
establish a common ground (Roman et al., 2020).
de Vries et al. (2017); Suglia et al. (2020) disam-
biguate or clarify the referenced object through a
series of questions in a guessing game. This itera-
tive paradigm can be related to work by Shwartz
et al. (2020) that generates clarification questions
and answers to incorporate in the task of question
answering. This loop of semi-automatic genera-
tion of clarifications establishes a common ground.
This is also in spirit similar to generating an ex-
planation or a hypothesis for question answering
(Latcinnik and Berant, 2020). The process of gen-
erating an acceptable explanation to human before
acts as establishing a common ground.

We believe that datasets and tasks along the
following three directions encourage dynamic
grounding: (1) conversational language learning
(Chevalier-Boisvert et al., 2019) or acquisition, and
(2) clarification questioning and ambiguity resolu-
tion (Shwartz et al., 2020) (3) mixed initiative for
grounding in conversations (Morbini et al., 2012).

The need of the hour that can revolutionize this


paradigm is the development of evaluation strate-
gies to monitor evolution of the common ground.
This dynamic grounding data helps improve per-
formance/robustness and encourages human’s trust
while using these interactive systems.

Purviews: This is based on establishing consis-
tency across stages of grounding with an incre-
mental paradigm. A simple solution is a modular
approach where the purviews flow into the next
stage after reasonably satisfying the previous stage.
The current benchmarking approaches are mostly
lateral i.e., our current strategies collate multiple
datasets of a single task to benchmark. This ap-
proach implicitly establishes boundaries between
the purviews. In contrast, we advocate for a longi-
tudinal approach for benchmarking i.e in addition
to collating different datasets for a task, we also
extend the purviews of the task such that the out-
put from the previous purview flows into the next
purview. An example of establishing a longitudinal
benchmark for visual dialog. The tasks flow from
object detection (stage 1: localization) to knowIl-
edge graphs (stage 2: external knowledge) to com-
mon sense understanding (stage 3: common sense)
to empathetic dialogue (stage 4: personalization)
for the same dataset. This helps us dissect which
aspect of grounding is the model good and bad at
to understand the weak areas.

Constraints: With media imposed constraints,
there is a need for paradigm shift in the way these
datasets are curated. The optimal way to navigate
this problem is curating new datasets to specifically
focus on the less studied constraints of simultane-
ity, sequentiality and revisability. At the heart of
revisability in a collaborative dialog is clarification
questioning and resolving ambiguities (Boni and
Manandhar, 2003; Rao and III, 2018; Braslavski
et al., 2017; Kumar and Black, 2020; Aliannejadi
et al., 2020; Benotti and Blackburn, 2021b) How-
ever, they are rarely explored and are not systemat-
ically standardized across modalities. Transferring
knowledge for shared constraints across tasks is a
promising way to leverage the existing datasets.

Augment with multilingual annotations: Dif-
ferent languages also bring novel challenges to
each of these issues (e.g. pronoun drop dialogue
in Japanese, morphological alignments, etc). How-
ever, as observed in §3.4, the increase in expanding
datasets is not proportionally reflected to include
multiple languages. We recommend a relatively
less expensive process of translating the datasets

for grounding into other languages to kick start
this inclusion. The research community has al-
ready seen such efforts in image captioning with
human annotated German captions in Multi30k (El-
liott et al., 2016) extended from Flick30k (Plum-
mer et al., 2015) and Japanese captions in STAIR
(Yoshikawa et al., 2017) based on MS-COCO im-
ages (Lin et al., 2014). Instead of using human an-
notations, some efforts have also been made to use
automatic translations such as the work by Thap-
liyal and Soricut (2020) and denoising (Chandu
et al., 2020b) extending from (Sharma et al., 2018).
Not just augmentation, but there are also ongoing
efforts in gathering datasets in multiple languages
(Ku et al., 2020) extending (Anderson et al., 2018).

5 Conclusions

We discussed the missing pieces and dimensions
that bridge the gap between the definitions of
grounding in Cognitive Sciences and NLP commu-
nities. Thereby, we chart out executable actions in
steering existing resources to bridge this gap along
these dimensions to achieve a more realistic sense
of grounding. Specifically: (1) Static grounding
still remains the central tenet for existing tasks and
datasets. However, dynamic grounding is key mov-
ing forward. (2) Current benchmarking strategies
evaluate model generalization. In tandem, we also
need to steer towards longitudinal benchmarking to
naturally proliferate across purviews of grounding
that is closer to natural human interactions. (3) Con-
straints imposed by the medium of communication
present nuanced categories of communicative goals.
While discerning learning from shared constraints,
we also urge the community to invest resources
on revisability as a way to recover from contex-
tually mistaken groundings. While ruminating on
the above phenomena, the challenge of expanding
them to multiple languages and domains still per-
sists. We also recommend systematic evaluation
of grounding along these dimensions in addition to
the existing linking capabilities.

Ethical Considerations

The analytical and ontological discussion here fo-
cuses exclusively on the question of grounding and
common ground and does not address the harm-
ful biases inherent in these datasets. Further, the
common ground for which we are advocating is
culturally specific and future work that introduces
tasks and data for these purposes must be explicit


about who they serve (culturally and linguistically).

References

Arjun R. Akula, Spandana Gella, Yaser Al-Onaizan,
Song-Chun Zhu, and Siva Reddy. 2020. Words
aren’t enough, their order matters: On the robust-
ness of grounding visual referring expressions. In
Proceedings of the 58th Annual Meeting of the As-
sociation for Computational Linguistics, ACL 2020,
Online, July 5-10, 2020, pages 6555-6565. Associa-
tion for Computational Linguistics.

Mohammad Aliannejadi, Julia Kiseleva, Aleksandr
Chuklin, Jeff Dalton, and Mikhail S. Burtsev.
2020. Convai3: Generating clarifying questions
for open-domain dialogue systems (clariq). CoRR,
abs/2009.11352.

Afra Alishahi, Marie Barking, and Grzegorz Chrupala.
2017. Encoding of phonology in a recurrent neu-
ral model of grounded speech. In Proceedings of
the 21st Conference on Computational Natural Lan-
guage Learning (CoNLL 2017), Vancouver, Canada,
August 3-4, 2017, pages 368-378. Association for
Computational Linguistics.

Peter Anderson, Qi Wu, Damien Teney, Jake Bruce,
Mark Johnson, Niko Stinderhauf, Ian D. Reid,
Stephen Gould, and Anton van den Hengel.
2018. Vision-and-language navigation: Interpreting
visually-grounded navigation instructions in real en-
vironments. In 2018 IEEE Conference on Computer
Vision and Pattern Recognition, CVPR 2018, Salt
Lake City, UT, USA, June 18-22, 2018, pages 3674—
3683. IEEE Computer Society.

Jacob Andreas and Dan Klein. 2014. Grounding lan-
guage with points and paths in continuous spaces.
In Proceedings of the Eighteenth Conference on
Computational Natural Language Learning, CoNLL
2014, Baltimore, Maryland, USA, June 26-27, 2014,
pages 58-67. ACL.

Leonor Becerra-Bonache, Henning Christiansen, and
M Dolores Jiménez-Lépez. 2018. A gold stan-
dard to measure relative linguistic complexity with
a grounded language learning model. In Proceed-
ings of the Workshop on Linguistic Complexity and
Natural Language Processing, pages 1-9.

Emily M Bender. 2011. On achieving and evaluating
language-independence in nlp. Linguistic Issues in
Language Technology, 6(3):1—26.

Luciana Benotti and Patrick Blackburn. 2021a.
Grounding as a collaborative process. In Pro-
ceedings of the 16th Conference of the European
Chapter of the Association for Computational
Linguistics: Main Volume, EACL 2021, Online,
April 19 - 23, 2021, pages 515-531. Association for
Computational Linguistics.

Luciana Benotti and Patrick Blackburn. 2021b. A
recipe for annotating grounded clarifications. CoRR,
abs/2104.08964.

Yonatan Bisk, Ari Holtzman, Jesse Thomason, Ja-
cob Andreas, Yoshua Bengio, Joyce Chai, Mirella
Lapata, Angeliki Lazaridou, Jonathan May, Alek-
sandr Nisnevich, Nicolas Pinto, and Joseph P. Turian.
2020. Experience grounds language. In Proceed-
ings of the 2020 Conference on Empirical Methods
in Natural Language Processing, EMNLP 2020, On-
line, November 16-20, 2020, pages 8718-8735. As-
sociation for Computational Linguistics.

Yonatan Bisk, Siva Reddy, John Blitzer, Julia Hock-
enmaier, and Mark Steedman. 2016. Evaluating
induced CCG parsers on grounded semantic pars-
ing. In Proceedings of the 2016 Conference on
Empirical Methods in Natural Language Processing,
EMNLP 2016, Austin, Texas, USA, November 1-4,
2016, pages 2022-2027. The Association for Com-
putational Linguistics.

Dan Bohus and Eric Horvitz. 2014. Managing human-
robot engagement with forecasts and... wm... hesita-
tions. In Proceedings of the 16th International Con-
ference on Multimodal Interaction, ICMI 2014, Is-
tanbul, Turkey, November 12-16, 2014, pages 2-9.
ACM.

Marco De Boni and Suresh Manandhar. 2003. An anal-
ysis of clarification dialogue for question answering.
In Human Language Technology Conference of the
North American Chapter of the Association for Com-
putational Linguistics, HLT-NAACL 2003, Edmon-
ton, Canada, May 27 - June 1, 2003. The Associa-
tion for Computational Linguistics.

Benjamin Borschinger, Bevan K. Jones, and Mark
Johnson. 2011. Reducing grounded learning tasks to
grammatical inference. In Proceedings of the 2011
Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP 2011, 27-31 July 2011,
John McIntyre Conference Centre, Edinburgh, UK,
A meeting of SIGDAT, a Special Interest Group of
the ACL, pages 1416-1425. ACL.

Pavel Braslavski, Denis Savenkov, Eugene Agichtein,
and Alina Dubatovka. 2017. What do you mean
exactly?: Analyzing clarification questions in CQA.
In Proceedings of the 2017 Conference on Confer-
ence Human Information Interaction and Retrieval,
CHIIR 2017, Oslo, Norway, March 7-11, 2017,
pages 345-348. ACM.

Anais Cadilhac, Nicholas Asher, Farah Benamara, and
Alex Lascarides. 2013. Grounding strategic con-
versation: Using negotiation dialogues to predict
trades in a win-lose game. In Proceedings of the
2013 Conference on Empirical Methods in Natural
Language Processing, EMNLP 2013, 18-21 Octo-
ber 2013, Grand Hyatt Seattle, Seattle, Washington,
USA, A meeting of SIGDAT, a Special Interest Group
of the ACL, pages 357-368. ACL.


Ronald Cardenas, Ying Lin, Heng Ji, and Jonathan
May. 2019. A grounded unsupervised universal part-
of-speech tagger for low-resource languages. In
Proceedings of the 2019 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
NAACL-HLT 2019, Minneapolis, MN, USA, June 2-
7, 2019, Volume I (Long and Short Papers), pages
2428-2439. Association for Computational Linguis-
tics.

Malinda Carpenter, Katherine Nagell, Michael
Tomasello, George Butterworth, and Chris Moore.
1998. Social cognition, joint attention, and commu-
nicative competence from 9 to 15 months of age.
Monographs of the society for research in child
development, pages i-174.

Khyathi Chandu, Shrimai Prabhumoye, Ruslan
Salakhutdinov, and Alan W Black. 2019a. “my way
of telling a story”: Persona based grounded story
generation. In Proceedings of the Second Workshop
on Storytelling, pages 11-21.

Khyathi Raghavi Chandu and Alan W. Black. 2020.
Style variation as a vantage point for code-switching.
In Interspeech 2020, 21st Annual Conference of
the International Speech Communication Associa-
tion, Virtual Event, Shanghai, China, 25-29 October
2020, pages 4761-4765. ISCA.

Khyathi Raghavi Chandu, Ruo-Ping Dong, and Alan W.
Black. 2020a. Reading between the lines: Explor-
ing infilling in visual narratives. In Proceedings of
the 2020 Conference on Empirical Methods in Nat-
ural Language Processing, EMNLP 2020, Online,
November 16-20, 2020, pages 1220-1229. Associ-
ation for Computational Linguistics.

Khyathi Raghavi Chandu, Eric Nyberg, and Alan W.
Black. 2019b. Storyboarding of recipes: Grounded
contextual generation. In Proceedings of the 57th
Conference of the Association for Computational
Linguistics, ACL 2019, Florence, Italy, July 28- Au-
gust 2, 2019, Volume 1: Long Papers, pages 6040—
6046. Association for Computational Linguistics.

Khyathi Raghavi Chandu, Piyush Sharma, Soravit
Changpinyo, Ashish Thapliyal, and Radu Sori-
cut. 2020b. Weakly supervised content selection
for improved image captioning. arXiv preprint
arXiv:2009.05175.

Angel X. Chang, Will Monroe, Manolis Savva, Christo-
pher Potts, and Christopher D. Manning. 2015. Text
to 3d scene generation with rich lexical grounding.
In Proceedings of the 53rd Annual Meeting of the
Association for Computational Linguistics and the
7th International Joint Conference on Natural Lan-
guage Processing of the Asian Federation of Natural
Language Processing, ACL 2015, July 26-31, 2015,
Beijing, China, Volume 1: Long Papers, pages 53-
62. The Association for Computer Linguistics.

David L. Chen. 2012. Fast online lexicon learning for
grounded language acquisition. In The 50th Annual

Meeting of the Association for Computational Lin-
guistics, Proceedings of the Conference, July 8-14,
2012, Jeju Island, Korea - Volume 1: Long Papers,
pages 430-439. The Association for Computer Lin-
guistics.

Hongge Chen, Huan Zhang, Pin-Yu Chen, Jinfeng Yi,
and Cho-Jui Hsieh. 2018. Attacking visual language
grounding with adversarial examples: A case study
on neural image captioning. In Proceedings of the
56th Annual Meeting of the Association for Com-
putational Linguistics, ACL 2018, Melbourne, Aus-
tralia, July 15-20, 2018, Volume I: Long Papers,
pages 2587-2597. Association for Computational
Linguistics.

Zhenfang Chen, Lin Ma, Wenhan Luo, and Kwan-
Yee Kenneth Wong. 2019. Weakly-supervised
spatio-temporally grounding natural sentence in
video. In Proceedings of the 57th Conference of
the Association for Computational Linguistics, ACL
2019, Florence, Italy, July 28- August 2, 2019, Vol-
ume 1: Long Papers, pages 1884—1894. Association
for Computational Linguistics.

Maxime Chevalier-Boisvert, Dzmitry Bahdanau,
Salem Lahlou, Lucas Willems, Chitwan Saharia,
Thien Huu Nguyen, and Yoshua Bengio. 2019.
Babyai: A platform to study the sample efficiency
of grounded language learning. In 7th International
Conference on Learning Representations, ICLR
2019, New Orleans, LA, USA, May 6-9, 2019.
OpenReview.net.

Hyundong Cho and Jonathan May. 2020. Grounding
conversations with improvised dialogues. In Pro-
ceedings of the 58th Annual Meeting of the Associ-
ation for Computational Linguistics, ACL 2020, On-
line, July 5-10, 2020, pages 2398-2413. Association
for Computational Linguistics.

Grzegorz Chrupala. 2019. Symbolic inductive bias
for visually grounded learning of spoken language.
In Proceedings of the 57th Conference of the As-
sociation for Computational Linguistics, ACL 2019,
Florence, Italy, July 28- August 2, 2019, Volume
1: Long Papers, pages 6452-6462. Association for
Computational Linguistics.

Grzegorz Chrupala, Lieke Gelderloos, and Afra AlI-
ishahi. 2017. Representations of language in a
model of visually grounded speech signal. In Pro-
ceedings of the 55th Annual Meeting of the Associa-
tion for Computational Linguistics, ACL 2017, Van-
couver, Canada, July 30 - August 4, Volume 1: Long
Papers, pages 613-622. Association for Computa-
tional Linguistics.

Chenhui Chu, Mayu Otani, and Yuta Nakashima. 2018.
iparaphrasing: Extracting visually grounded para-
phrases via an image. In Proceedings of the 27th
International Conference on Computational Linguis-
tics, COLING 2018, Santa Fe, New Mexico, USA,
August 20-26, 2018, pages 3479-3492. Association
for Computational Linguistics.


Herbert H. Clark and Susan E. Brennan. 1991. Ground-
ing in communication. In Lauren B. Resnick,
John M. Levine, and Stephanie D. Teasley, editors,
Perspectives on socially shared cognition, pages
127-149. American Psychological Association.

Herbert H Clark and Thomas B Carlson. 1982. Hearers
and speech acts. Language, pages 332-373.

Herbert H Clark and Meredyth A Krych. 2004. Speak-
ing while monitoring addressees for understanding.
Journal of memory and language, 50(1):62-8 1.

David DeVault and David R. Traum. 2013. A method
for the approximation of incremental understanding
of explicit utterance meaning using predictive mod-
els in finite domains. In Human Language Technolo-
gies: Conference of the North American Chapter of
the Association of Computational Linguistics, Pro-
ceedings, June 9-14, 2013, Westin Peachtree Plaza
Hotel, Atlanta, Georgia, USA, pages 1092-1099.
The Association for Computational Linguistics.

Ruo-Ping Dong, Khyathi Raghavi Chandu, and Alan W.
Black. 2019. Induction and reference of entities in a
visual story. CoRR, abs/1909.09699.

Gabriel Doyle and Michael C. Frank. 2015. Shared
common ground influences information density in
microblog texts. In NAACL HLT 2015, The 2015
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, Denver, Colorado, USA,
May 31 - June 5, 2015, pages 1587-1596. The As-
sociation for Computational Linguistics.

Judith Eckle-Kohler. 2016. Verbs taking clausal and
non-finite arguments as signals of modality - revisit-
ing the issue of meaning grounded in syntax. In Pro-
ceedings of the 54th Annual Meeting of the Associ-
ation for Computational Linguistics, ACL 2016, Au-
gust 7-12, 2016, Berlin, Germany, Volume 1: Long
Papers. The Association for Computer Linguistics.

Desmond Elliott, Stella Frank, Khalil Sima’an, and Lu-
cia Specia. 2016. Multi30k: Multilingual english-
german image descriptions. In Proceedings of the
Sth Workshop on Vision and Language, hosted by
the 54th Annual Meeting of the Association for Com-
putational Linguistics, VL@ACL 2016, August 12,
Berlin, Germany. The Association for Computer
Linguistics.

Arash Eshghi, Christine Howes, Eleni Gre-
goromichelaki, Julian Hough, and Matthew
Purver. 2015. Feedback in conversation as incre-
mental semantic update. In Proceedings of the 11th
International Conference on Computational Seman-
tics, IWCS 2015, 15-17 April, 2015, Queen Mary
University of London, London, UK, pages 261-271.
The Association for Computer Linguistics.

Zhihao Fan, Zhongyu Wei, Siyuan Wang, and Xuanjing
Huang. 2019. Bridging by word: Image grounded
vocabulary construction for visual captioning. In

Proceedings of the 57th Conference of the Asso-
ciation for Computational Linguistics, ACL 2019,
Florence, Italy, July 28- August 2, 2019, Volume
1: Long Papers, pages 6514-6524. Association for
Computational Linguistics.

Michael Fleischman and Deb Roy. 2008. Grounded
language modeling for automatic speech recognition
of sports video. In ACL 2008, Proceedings of the
46th Annual Meeting of the Association for Com-
putational Linguistics, June 15-20, 2008, Colum-
bus, Ohio, USA, pages 121-129. The Association for
Computer Linguistics.

Akira Fukui, Dong Huk Park, Daylen Yang, Anna
Rohrbach, Trevor Darrell, and Marcus Rohrbach.
2016. Multimodal compact bilinear pooling for vi-
sual question answering and visual grounding. In
Proceedings of the 2016 Conference on Empirical
Methods in Natural Language Processing, EMNLP
2016, Austin, Texas, USA, November 1-4, 2016,
pages 457-468. The Association for Computational
Linguistics.

Qiaozi Gao, Malcolm Doering, Shaohua Yang, and
Joyce Yue Chai. 2016. Physical causality of action
verbs in grounded language understanding. In Pro-
ceedings of the 54th Annual Meeting of the Associ-
ation for Computational Linguistics, ACL 2016, Au-
gust 7-12, 2016, Berlin, Germany, Volume 1: Long
Papers. The Association for Computer Linguistics.

Alison Gopnik and Henry M Wellman. 1992. Why the
child’s theory of mind really is a theory.

Dusan Grujicic, Gorjan Radevski, Tinne Tuytelaars,
and Matthew B. Blaschko. 2020. Learning to
ground medical text in a 3d human atlas. In Pro-
ceedings of the 24th Conference on Computational
Natural Language Learning, CoNLL 2020, Online,
November 19-20, 2020, pages 302-312. Association
for Computational Linguistics.

Janosch Haber, Tim Baumgartner, Ece Takmaz, Lieke
Gelderloos, Elia Bruni, and Raquel Fernandez. 2019.
The photobook dataset: Building common ground
through visually-grounded dialogue. In Proceedings
of the 57th Conference of the Association for Compu-
tational Linguistics, ACL 2019, Florence, Italy, July
28- August 2, 2019, Volume I: Long Papers, pages
1895-1910. Association for Computational Linguis-
tics.

Ting Han and David Schlangen. 2017. Grounding lan-
guage by continuous observation of instruction fol-
lowing. In Proceedings of the 15th Conference of
the European Chapter of the Association for Com-
putational Linguistics, EACL 2017, Valencia, Spain,
April 3-7, 2017, Volume 2: Short Papers, pages 49 1-
496. Association for Computational Linguistics.

Braden Hancock, Antoine Bordes, Pierre-Emmanuel
Mazaré, and Jason Weston. 2019. Learning from
dialogue after deployment: Feed yourself, chatbot!
In Proceedings of the 57th Conference of the As-
sociation for Computational Linguistics, ACL 2019,


Florence, Italy, July 28- August 2, 2019, Volume
1: Long Papers, pages 3667-3684. Association for
Computational Linguistics.

William Havard, Laurent Besacier, and Jean-Pierre
Chevrot. 2020. Catplayinginthesnow: Impact of
prior segmentation on a model of visually grounded
speech. In Proceedings of the 24th Conference on
Computational Natural Language Learning, CoNLL
2020, Online, November 19-20, 2020, pages 291-—
301. Association for Computational Linguistics.

William N. Havard, Jean-Pierre Chevrot, and Laurent
Besacier. 2019. Word recognition, competition, and
activation in a model of visually grounded speech.
In Proceedings of the 23rd Conference on Compu-
tational Natural Language Learning, CoNLL 2019,
Hong Kong, China, November 3-4, 2019, pages 339-
348. Association for Computational Linguistics.

Jack Hessel, Zhenhai Zhu, Bo Pang, and Radu Sori-
cut. 2020. Beyond instructional videos: Probing for
more diverse visual-textual grounding on youtube.
In Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing, EMNLP
2020, Online, November 16-20, 2020, pages 8812-—
8822. Association for Computational Linguistics.

Ronghang Hu, Daniel Fried, Anna Rohrbach, Dan
Klein, Trevor Darrell, and Kate Saenko. 2019. Are
you looking? grounding to multiple modalities in
vision-and-language navigation. In Proceedings of
the 57th Conference of the Association for Compu-
tational Linguistics, ACL 2019, Florence, Italy, July
28- August 2, 2019, Volume I: Long Papers, pages
6551-6557. Association for Computational Linguis-
tics.

Pingping Huang, Jianhui Huang, Yuqing Guo, Min
Qiao, and Yong Zhu. 2019. Multi-grained attention
with object-level grounding for visual question an-
swering. In Proceedings of the 57th Conference of
the Association for Computational Linguistics, ACL
2019, Florence, Italy, July 28- August 2, 2019, Vol-
ume 1: Long Papers, pages 3595-3600. Association
for Computational Linguistics.

Gabriel Iharco, Yuan Zhang, and Jason Baldridge.
2019. Large-scale representation learning from vi-
sually grounded untranscribed speech. In Proceed-
ings of the 23rd Conference on Computational Nat-
ural Language Learning, CoNLL 2019, Hong Kong,
China, November 3-4, 2019, pages 55-65. Associa-
tion for Computational Linguistics.

Michaela Janner, Karthik Narasimhan, and Regina
Barzilay. 2018. Representation learning for
grounded spatial reasoning. Trans. Assoc. Comput.
Linguistics, 6:49-61.

Sujay Kumar Jauhar, Chris Dyer, and Eduard H. Hovy.
2015. Ontologically grounded multi-sense repre-
sentation learning for semantic vector space models.
In NAACL HLT 2015, The 2015 Conference of the

North American Chapter of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, Denver, Colorado, USA, May 31 - June 5, 2015,
pages 683-693. The Association for Computational
Linguistics.

Xisen Jin, Junyi Du, Arka Sadhu, Ram Nevatia, and Xi-
ang Ren. 2020. Visually grounded continual learn-
ing of compositional phrases. In Proceedings of
the 2020 Conference on Empirical Methods in Nat-
ural Language Processing, EMNLP 2020, Online,
November 16-20, 2020, pages 2018-2029. Associ-
ation for Computational Linguistics.

Mark Johnson, Katherine Demuth, and Michael C.
Frank. 2012. Exploiting social information in
grounded language learning via grammatical reduc-
tion. In The 50th Annual Meeting of the Associa-
tion for Computational Linguistics, Proceedings of
the Conference, July 8-14, 2012, Jeju Island, Korea
- Volume 1: Long Papers, pages 883-891. The Asso-
ciation for Computer Linguistics.

Hirotaka Kameko, Shinsuke Mori, and Yoshimasa Tsu-
ruoka. 2015. Can symbol grounding improve low-
level nlp? word segmentation as a case study. In
Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing, EMNLP
2015, Lisbon, Portugal, September 17-21, 2015,
pages 2298-2303. The Association for Computa-
tional Linguistics.

Kazuya Kawakami, Chris Dyer, and Phil Blunsom.
2019. Learning to discover, ground and use words
with segmental neural language models. In Pro-
ceedings of the 57th Conference of the Association
for Computational Linguistics, ACL 2019, Florence,
Italy, July 28- August 2, 2019, Volume 1: Long Pa-
pers, pages 6429-6441. Association for Computa-
tional Linguistics.

John D. Kelleher, Geert-Jan M. Kruijff, and Fintan J.
Costello. 2006. Proximity in context: An empir-
ically grounded computational model of proximity
for processing topological spatial expressions. In
ACL 2006, 21st International Conference on Compu-
tational Linguistics and 44th Annual Meeting of the
Association for Computational Linguistics, Proceed-
ings of the Conference, Sydney, Australia, 17-21 July
2006. The Association for Computer Linguistics.

Casey Kennington and David Schlangen. 2015. Simple
learning and compositional application of perceptu-
ally grounded word meanings for incremental refer-
ence resolution. In Proceedings of the 53rd Annual
Meeting of the Association for Computational Lin-
guistics and the 7th International Joint Conference
on Natural Language Processing of the Asian Fed-
eration of Natural Language Processing, ACL 2015,
July 26-31, 2015, Beijing, China, Volume 1: Long
Papers, pages 292-301. The Association for Com-
puter Linguistics.

Douwe Kiela, Luana Bulat, and Stephen Clark. 2015.
Grounding semantics in olfactory perception. In


Proceedings of the 53rd Annual Meeting of the Asso-
ciation for Computational Linguistics and the 7th In-
ternational Joint Conference on Natural Language
Processing of the Asian Federation of Natural Lan-
guage Processing, ACL 2015, July 26-31, 2015, Bei-
jing, China, Volume 2: Short Papers, pages 231-236.
The Association for Computer Linguistics.

Douwe Kiela and Stephen Clark. 2015. Multi- and
cross-modal semantics beyond vision: Grounding
in auditory perception. In Proceedings of the 2015
Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP 2015, Lisbon, Portugal,
September 17-21, 2015, pages 2461-2470. The As-
sociation for Computational Linguistics.

Jin-Hwa Kim, Nikita Kitaev, Xinlei Chen, Marcus
Rohrbach, Byoung-Tak Zhang, Yuandong Tian,
Dhruv Batra, and Devi Parikh. 2019. Codraw: Col-
laborative drawing as a testbed for grounded goal-
driven communication. In Proceedings of the 57th
Conference of the Association for Computational
Linguistics, ACL 2019, Florence, Italy, July 28- Au-
gust 2, 2019, Volume 1: Long Papers, pages 6495—
6513. Association for Computational Linguistics.

Jamie Ryan Kiros, William Chan, and Geoffrey E.
Hinton. 2018. Illustrative language understanding:
Large-scale visual grounding with image search. In
Proceedings of the 56th Annual Meeting of the As-
sociation for Computational Linguistics, ACL 2018,
Melbourne, Australia, July 15-20, 2018, Volume 1:
Long Papers, pages 922-933. Association for Com-
putational Linguistics.

Nikolina Koleva, Martin Villalba, Maria Staudte, and
Alexander Koller. 2015. The impact of listener gaze
on predicting reference resolution. In Proceedings
of the 53rd Annual Meeting of the Association for
Computational Linguistics and the 7th International
Joint Conference on Natural Language Processing
of the Asian Federation of Natural Language Pro-
cessing, ACL 2015, July 26-31, 2015, Beijing, China,
Volume 2: Short Papers, pages 812-817. The Asso-
ciation for Computer Linguistics.

Rik Koncel-Kedziorski, Hannaneh Hajishirzi, and Ali
Farhadi. 2014. Multi-resolution language ground-
ing with weak supervision. In Proceedings of the
2014 Conference on Empirical Methods in Natural
Language Processing, EMNLP 2014, October 25-29,
2014, Doha, Qatar, A meeting of SIGDAT, a Special
Interest Group of the ACL, pages 386-396. ACL.

Robert M Krauss and Susan R Fussell. 1990. Mutual
knowledge and communicative effectiveness. Intel-
lectual teamwork: Social and technological founda-
tions of cooperative work, pages 111-146.

Alexander Ku, Peter Anderson, Roma Patel, Eugene
Ie, and Jason Baldridge. 2020. Room-across-room:
Multilingual vision-and-language navigation with
dense spatiotemporal grounding. In Proceedings of
the 2020 Conference on Empirical Methods in Nat-
ural Language Processing, EMNLP 2020, Online,

November 16-20, 2020, pages 4392-4412. Associ-
ation for Computational Linguistics.

Vaibhav Kumar and Alan W. Black. 2020. Clarq: A
large-scale and diverse dataset for clarification ques-
tion generation. In Proceedings of the 58th Annual
Meeting of the Association for Computational Lin-
guistics, ACL 2020, Online, July 5-10, 2020, pages
7296-7301. Association for Computational Linguis-
tics.

Veronica Latcinnik and Jonathan Berant. 2020. Ex-
plaining question answering models through text
generation. CoRR, abs/2004.05569.

Florian Laws, Lukas Michelbacher, Beate Dorow,
Christian Scheible, Ulrich Heid, and Hinrich
Schiitze. 2010. A linguistically grounded graph
model for bilingual lexicon extraction. In COL-
ING 2010, 23rd International Conference on Com-
putational Linguistics, Posters Volume, 23-27 Au-
gust 2010, Beijing, China, pages 614-622. Chinese
Information Processing Society of China.

Jie Lei, Licheng Yu, Tamara L. Berg, and Mohit
Bansal. 2020. TVQA+: spatio-temporal grounding
for video question answering. In Proceedings of the
58th Annual Meeting of the Association for Compu-
tational Linguistics, ACL 2020, Online, July 5-10,
2020, pages 8211-8225. Association for Computa-
tional Linguistics.

David Lewis. 2008. Convention: A philosophical study.
John Wiley & Sons.

Xiaolong Li and Kristy Boyer. 2015. Semantic ground-
ing in dialogue for complex problem solving. In
NAACL HLT 2015, The 2015 Conference of the
North American Chapter of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, Denver, Colorado, USA, May 31 - June 5, 2015,
pages 841-850. The Association for Computational
Linguistics.

Zekang Li, Cheng Niu, Fandong Meng, Yang Feng,
Qian Li, and Jie Zhou. 2019. Incremental trans-
former with deliberation decoder for document
grounded conversations. In Proceedings of the 57th
Conference of the Association for Computational
Linguistics, ACL 2019, Florence, Italy, July 28- Au-
gust 2, 2019, Volume I: Long Papers, pages 12-21.
Association for Computational Linguistics.

Tsung- Yi Lin, Michael Maire, Serge J. Belongie, James
Hays, Pietro Perona, Deva Ramanan, Piotr Dollar,
and C. Lawrence Zitnick. 2014. Microsoft COCO:
common objects in context. In Computer Vision
- ECCV 2014 - 13th European Conference, Zurich,
Switzerland, September 6-12, 2014, Proceedings,
Part V, volume 8693 of Lecture Notes in Computer
Science, pages 740-755. Springer.

Changsong Liu, Lanbo She, Rui Fang, and Joyce Y.
Chai. 2014. Probabilistic labeling for efficient ref-
erential grounding based on collaborative discourse.


In Proceedings of the 52nd Annual Meeting of
the Association for Computational Linguistics, ACL
2014, June 22-27, 2014, Baltimore, MD, USA, Vol-
ume 2: Short Papers, pages 13-18. The Association
for Computer Linguistics.

Changsong Liu, Shaohua Yang, Sari Saba-Sadiya, Nis-
hant Shukla, Yunzhong He, Song-Chun Zhu, and
Joyce Yue Chai. 2016. Jointly learning grounded
task structures from language instruction and vi-
sual demonstration. In Proceedings of the 2016
Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP 2016, Austin, Texas,
USA, November 1-4, 2016, pages 1482-1492. The
Association for Computational Linguistics.

Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kin-
ney, and Daniel Weld. 2020. S2ORC: The semantic
scholar open research corpus. In Proceedings of the
58th Annual Meeting of the Association for Compu-
tational Linguistics, pages 4969-4983, Online. As-
sociation for Computational Linguistics.

Minh-Thang Luong, Michael C. Frank, and Mark John-
son. 2013. Parsing entire discourses as very long
strings: Capturing topic continuity in grounded lan-
guage learning. Trans. Assoc. Comput. Linguistics,
1:315-326.

Bodhisattwa Prasad Majumder, Shuyang Li, Jianmo
Ni, and Julian J. McAuley. 2020. Interview: Large-
scale modeling of media dialog with discourse pat-
terns and knowledge grounding. In Proceedings of
the 2020 Conference on Empirical Methods in Nat-
ural Language Processing, EMNLP 2020, Online,
November 16-20, 2020, pages 8129-8141. Associ-
ation for Computational Linguistics.

Alexandre Blondin Massé, Guillaume Chicoisne, Yas-
sine Gargouri, Stevan Harnad, Odile Marcotte, and
Olivier Picard. 2008. How is meaning grounded
in dictionary definitions? In Coling 2008: Pro-
ceedings of the 3rd Textgraphs workshop on Graph-
based Algorithms for Natural Language Processing,
pages 17-24.

Brian McMahan and Matthew Stone. 2015. A bayesian
model of grounded color semantics. Trans. Assoc.
Comput. Linguistics, 3:103-115.

Will Monroe, Robert X. D. Hawkins, Noah D. Good-
man, and Christopher Potts. 2017. Colors in context:
A pragmatic neural model for grounded language

understanding. Trans. Assoc. Comput. Linguistics,
5:325-338.

Fabrizio Morbini, Eric Forbell, David DeVault, Kenji
Sagae, David R. Traum, and Albert A. Rizzo. 2012.
A mixed-initiative conversational dialogue system
for healthcare. In Proceedings of the SIGDIAL 2012
Conference, The 13th Annual Meeting of the Special
Interest Group on Discourse and Dialogue, 5-6 July
2012, Seoul National University, Seoul, South Ko-
rea, pages 137-139. The Association for Computer
Linguistics.

Yukiko I. Nakano, Gabe Reinstein, Tom Stocky, and
Justine Cassell. 2003. Towards a model of face-to-
face grounding. In Proceedings of the 41st Annual
Meeting of the Association for Computational Lin-
guistics, 7-12 July 2003, Sapporo Convention Center,
Sapporo, Japan, pages 553-561. ACL.

Sushobhan Nayak and Amitabha Mukerjee. 2012.
Grounded language acquisition: A minimal com-
mitment approach. In COLING 2012, 24th Inter-
national Conference on Computational Linguistics,
Proceedings of the Conference: Technical Papers,
8-15 December 2012, Mumbai, India, pages 2059-
2076. Indian Institute of Technology Bombay.

Joel Nothman, Matthew Honnibal, Ben Hachey, and
James R. Curran. 2012. Event linking: Grounding
event reference in a news archive. In The 50th An-
nual Meeting of the Association for Computational
Linguistics, Proceedings of the Conference, July 8-
14, 2012, Jeju Island, Korea - Volume 2: Short Pa-
pers, pages 228-232. The Association for Computer
Linguistics.

Tim Oates. 2003. Grounding word meanings in sen-
sor data: Dealing with referential uncertainty. In
Proceedings of the HLT-NAACL 2003 workshop on
Learning word meaning from non-linguistic data,

pages 62-69.

Brian E. Pangburn, S. Sitharama Iyengar, Robert C.
Mathews, and Jonathan P. Ayo. 2003. EBLA: A per-
ceptually grounded model of language acquisition.
In Proceedings of the HLT-NAACL 2003 Workshop
on Learning Word Meaning from Non-Linguistic
Data, pages 46-53.

Nikolaos Pappas, Phoebe Mulcaire, and Noah A. Smith.
2020. Grounded compositional outputs for adaptive
language modeling. In Proceedings of the 2020 Con-
ference on Empirical Methods in Natural Language
Processing, EMNLP 2020, Online, November 16-20,
2020, pages 1252-1267. Association for Computa-
tional Linguistics.

Ankur P. Parikh, Hoifung Poon, and Kristina
Toutanova. 2015. Grounded semantic parsing for
complex knowledge extraction. In NAACL HLT
2015, The 2015 Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies, Denver,
Colorado, USA, May 31 - June 5, 2015, pages 756—
766. The Association for Computational Linguistics.

Bryan A. Plummer, Liwei Wang, Chris M. Cervantes,
Juan C. Caicedo, Julia Hockenmaier, and Svetlana
Lazebnik. 2015. Flickr30k entities: Collecting
region-to-phrase correspondences for richer image-
to-sentence models. In 2015 IEEE International
Conference on Computer Vision, ICCV 2015, Santi-
ago, Chile, December 7-13, 2015, pages 2641-2649.
IEEE Computer Society.

Hoifung Poon. 2013. Grounded unsupervised seman-
tic parsing. In Proceedings of the 51st Annual Meet-
ing of the Association for Computational Linguistics,


ACL 2013, 4-9 August 2013, Sofia, Bulgaria, Volume
1: Long Papers, pages 933-943. The Association for
Computer Linguistics.

Shrimai Prabhumoye, Chris Quirk, and Michel Galley.
2019. Towards content transfer through grounded
text generation. In Proceedings of the 2019 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, NAACL-HLT 2019, Minneapo-
lis, MN, USA, June 2-7, 2019, Volume I (Long and
Short Papers), pages 2622-2632. Association for
Computational Linguistics.

Guanghui Qin, Jin-Ge Yao, Xuening Wang, Jinpeng
Wang, and Chin-Yew Lin. 2018. Learning latent se-
mantic annotations for grounding natural language
to structured data. In Proceedings of the 2018 Con-
ference on Empirical Methods in Natural Language
Processing, Brussels, Belgium, October 31 - Novem-
ber 4, 2018, pages 3761-3771. Association for Com-
putational Linguistics.

Sudha Rao and Hal Daumé III. 2018. Learning to ask
good questions: Ranking clarification questions us-
ing neural expected value of perfect information. In
Proceedings of the 56th Annual Meeting of the As-
sociation for Computational Linguistics, ACL 2018,
Melbourne, Australia, July 15-20, 2018, Volume
1: Long Papers, pages 2737-2746. Association for
Computational Linguistics.

Michaela Regneri, Marcus Rohrbach, Dominikus Wet-
zel, Stefan Thater, Bernt Schiele, and Manfred
Pinkal. 2013. Grounding action descriptions in
videos. Trans. Assoc. Comput. Linguistics, 1:25—36.

Homero Roman Roman, Yonatan Bisk, Jesse Thoma-
son, Asli Celikyilmaz, and Jianfeng Gao. 2020.
Rmm: A recursive mental model for dialog navi-
gation. In Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Processing:
Findings, pages 1732-1745.

Candace Ross, Andrei Barbu, Yevgeni Berzak, Bat-
tushig Myanganbayar, and Boris Katz. 2018.
Grounding language acquisition by training seman-
tic parsers using captioned videos. In Proceedings
of the 2018 Conference on Empirical Methods in
Natural Language Processing, Brussels, Belgium,
October 31 - November 4, 2018, pages 2647-2656.
Association for Computational Linguistics.

Deb Roy, Kai-Yuh Hsiao, and Nikolaos Mavridis. 2003.
Conversational robots: building blocks for ground-
ing word meaning. In Proceedings of the HLT-
NAACL 2003 workshop on Learning word meaning
from non-linguistic data, pages 70-77.

Subhro Roy, Michael Noseworthy, Rohan Paul, Dae-
hyung Park, and Nicholas Roy. 2019. Leveraging
past references for robust language grounding. In
Proceedings of the 23rd Conference on Computa-
tional Natural Language Learning, CoNLL 2019,
Hong Kong, China, November 3-4, 2019, pages 430-
440. Association for Computational Linguistics.

Subhro Roy, Shyam Upadhyay, and Dan Roth. 2016.
Equation parsing : Mapping sentences to grounded
equations. In Proceedings of the 2016 Conference
on Empirical Methods in Natural Language Process-
ing, EMNLP 2016, Austin, Texas, USA, November
1-4, 2016, pages 1088-1097. The Association for
Computational Linguistics.

Maarten Sap, Vered Shwartz, Antoine Bosselut, Yejin
Choi, and Dan Roth. 2020. Commonsense reason-
ing for natural language processing. In Proceedings
of the 58th Annual Meeting of the Association for
Computational Linguistics: Tutorial Abstracts, ACL
2020, Online, July 5, 2020, pages 27-33. Associa-
tion for Computational Linguistics.

David Schlangen and Gabriel Skantze. 2009. A gen-
eral, abstract model of incremental dialogue process-
ing. In EACL 2009, 12th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics, Proceedings of the Conference, Athens,
Greece, March 30 - April 3, 2009, pages 710-718.
The Association for Computer Linguistics.

Piyush Sharma, Nan Ding, Sebastian Goodman, and
Radu Soricut. 2018. Conceptual captions: A
cleaned, hypernymed, image alt-text dataset for au-
tomatic image captioning. In Proceedings of the
56th Annual Meeting of the Association for Com-
putational Linguistics, ACL 2018, Melbourne, Aus-
tralia, July 15-20, 2018, Volume I: Long Papers,
pages 2556-2565. Association for Computational
Linguistics.

Haoyue Shi, Jiayuan Mao, Kevin Gimpel, and Karen
Livescu. 2019. Visually grounded neural syntax ac-
quisition. In Proceedings of the 57th Conference of
the Association for Computational Linguistics, ACL
2019, Florence, Italy, July 28- August 2, 2019, Vol-
ume 1: Long Papers, pages 1842-1861. Association
for Computational Linguistics.

Robik Shrestha, Kushal Kafle, and Christopher Kanan.
2020. A negative case analysis of visual grounding
methods for VQA. In Proceedings of the 58th An-
nual Meeting of the Association for Computational
Linguistics, ACL 2020, Online, July 5-10, 2020,
pages 8172-8181. Association for Computational
Linguistics.

Kurt Shuster, Samuel Humeau, Antoine Bordes, and Ja-
son Weston. 2020. Image-chat: Engaging grounded
conversations. In Proceedings of the 58th Annual
Meeting of the Association for Computational Lin-
guistics, ACL 2020, Online, July 5-10, 2020, pages
2414-2429. Association for Computational Linguis-
tics.

Ekaterina Shutova, Niket Tandon, and Gerard de Melo.
2015.  Perceptually grounded selectional prefer-
ences. In Proceedings of the 53rd Annual Meet-
ing of the Association for Computational Linguistics
and the 7th International Joint Conference on Natu-
ral Language Processing of the Asian Federation of


Natural Language Processing, ACL 2015, July 26-
31, 2015, Beijing, China, Volume 1: Long Papers,
pages 950-960. The Association for Computer Lin-
guistics.

Vered Shwartz, Peter West, Ronan Le Bras, Chandra
Bhagavatula, and Yejin Choi. 2020. Unsupervised
commonsense question answering with self-talk. In
Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing, EMNLP
2020, Online, November 16-20, 2020, pages 4615—
4629. Association for Computational Linguistics.

Carina Silberer and Mirella Lapata. 2014. Learn-
ing grounded meaning representations with autoen-
coders. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguistics,
ACL 2014, June 22-27, 2014, Baltimore, MD, USA,
Volume 1: Long Papers, pages 721-732. The Asso-
ciation for Computer Linguistics.

Carina Silberer and Manfred Pinkal. 2018. Ground-
ing semantic roles in images. In Proceedings of the
2018 Conference on Empirical Methods in Natural
Language Processing, Brussels, Belgium, October
31 - November 4, 2018, pages 2616-2626. Associ-
ation for Computational Linguistics.

Georgios P. Spithourakis, Isabelle Augenstein, and Se-
bastian Riedel. 2016. Numerically grounded lan-
guage models for semantic error correction. In Pro-
ceedings of the 2016 Conference on Empirical Meth-
ods in Natural Language Processing, EMNLP 2016,
Austin, Texas, USA, November 1-4, 2016, pages 987—
992. The Association for Computational Linguistics.

Tejas Srinivasan, Ramon Sanabria, Florian Metze, and
Desmond Elliott. 2020. Fine-grained grounding for
multimodal speech recognition. In Proceedings of
the 2020 Conference on Empirical Methods in Nat-
ural Language Processing: Findings, EMNLP 2020,
Online Event, 16-20 November 2020, pages 2667—
2677. Association for Computational Linguistics.

Luc Steels. 2004. Constructivist development of
grounded construction grammar. In Proceedings of
the 42nd Annual Meeting of the Association for Com-
putational Linguistics, 21-26 July, 2004, Barcelona,
Spain, pages 9-16. ACL.

Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M.
Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford,
Dario Amodei, and Paul F. Christiano. 2020. Learn-
ing to summarize from human feedback. CoRR,
abs/2009.01325.

Michael Strube and Udo Hahn. 1999. Functional cen-
tering - grounding referential coherence in informa-
tion structure. Comput. Linguistics, 25(3):309-344.

Alessandro Suglia, Ioannis Konstas, Andrea Vanzo,
Emanuele Bastianelli, Desmond Elliott, Stella
Frank, and Oliver Lemon. 2020. Compguesswhat?!:
A multi-task evaluation framework for grounded lan-
guage learning. In Proceedings of the 58th Annual

Meeting of the Association for Computational Lin-
guistics, ACL 2020, Online, July 5-10, 2020, pages
7625-7641. Association for Computational Linguis-
tics.

Alane Suhr, Stephanie Zhou, Ally Zhang, Iris Zhang,
Huajun Bai, and Yoav Artzi. 2019. A corpus for
reasoning about natural language grounded in pho-
tographs. In Proceedings of the 57th Conference of
the Association for Computational Linguistics, ACL
2019, Florence, Italy, July 28- August 2, 2019, Vol-
ume 1: Long Papers, pages 6418-6428. Association
for Computational Linguistics.

Ece Takmaz, Mario Giulianelli, Sandro Pezzelle, Ara-
bella Sinclair, and Raquel Fernandez. 2020. Re-
fer, reuse, reduce: Grounding subsequent references
in visual and conversational contexts. In Proceed-
ings of the 2020 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages
4350-4368.

Xiang Zhi Tan, Sean Andrist, Dan Bohus, and Eric
Horvitz. 2020. Now, over here: Leveraging ex-
tended attentional capabilities in human-robot in-
teraction. In Companion of the 2020 ACM/IEEE
International Conference on Human-Robot Interac-
tion, HRI 2020, Cambridge, UK, March 23-26, 2020,
pages 468-470. ACM.

Ashish V. Thapliyal and Radu Soricut. 2020. Cross-
modal language generation using pivot stabilization
for web-scale language coverage. In Proceedings
of the 58th Annual Meeting of the Association for
Computational Linguistics, ACL 2020, Online, July
5-10, 2020, pages 160-170. Association for Compu-
tational Linguistics.

Chen-Tse Tsai and Dan Roth. 2016a. Concept ground-
ing to multiple knowledge bases via indirect supervi-
sion. Trans. Assoc. Comput. Linguistics, 4:141—154.

Chen-Tse Tsai and Dan Roth. 2016b. Illinois cross-
lingual wikifier: Grounding entities in many lan-
guages to the english wikipedia. In COLING
2016, 26th International Conference on Computa-
tional Linguistics, Proceedings of the Conference
System Demonstrations, December 11-16, 2016, Os-
aka, Japan, pages 146-150. ACL.

Takuma Udagawa, Takato Yamazaki, and Akiko
Aizawa. 2020. A linguistic analysis of visually
grounded dialogues based on spatial expressions. In
Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing: Findings,
EMNLP 2020, Online Event, 16-20 November 2020,
pages 750-765. Association for Computational Lin-
guistics.

Ashwin K. Vijayakumar, Ramakrishna Vedantam, and
Devi Parikh. 2017. Sound-word2vec: Learning
word representations grounded in sounds. In Pro-
ceedings of the 2017 Conference on Empirical Meth-
ods in Natural Language Processing, EMNLP 2017,
Copenhagen, Denmark, September 9-11, 2017,


pages 920-925. Association for Computational Lin-
guistics.

Harm de Vries, Florian Strub, Sarath Chandar, Olivier
Pietquin, Hugo Larochelle, and Aaron C. Courville.
2017. Guesswhat?! visual object discovery through
multi-modal dialogue. In 2017 IEEE Conference
on Computer Vision and Pattern Recognition, CVPR
2017, Honolulu, HI, USA, July 21-26, 2017, pages
4466-4475. IEEE Computer Society.

Hoa Trong Vu, Claudio Greco, Aliia Erofeeva, So-
mayeh Jafaritazehjan, Guido Linders, Marc Tanti,
Alberto Testoni, Raffaella Bernardi, and Albert Gatt.
2018. Grounded textual entailment. In Proceedings
of the 27th International Conference on Computa-
tional Linguistics, COLING 2018, Santa Fe, New
Mexico, USA, August 20-26, 2018, pages 2354—
2368. Association for Computational Linguistics.

Eric Wallace, Pedro Rodriguez, Shi Feng, Ikuya Ya-
mada, and Jordan Boyd-Graber. 2019. Trick me
if you can: Human-in-the-loop generation of adver-
sarial examples for question answering. Transac-
tions of the Association for Computational Linguis-
tics, 7:387-401.

Qinxin Wang, Hao Tan, Sheng Shen, Michael W. Ma-
honey, and Zhewei Yao. 2020. MAF: multimodal
alignment framework for weakly-supervised phrase
grounding. In Proceedings of the 2020 Conference
on Empirical Methods in Natural Language Process-
ing, EMNLP 2020, Online, November 16-20, 2020,
pages 2030-2038. Association for Computational
Linguistics.

Jun Xu, Haifeng Wang, Zheng- Yu Niu, Hua Wu, Wanx-
iang Che, and Ting Liu. 2020. Conversational graph
grounded policy learning for open-domain conversa-
tion generation. In Proceedings of the 58th Annual
Meeting of the Association for Computational Lin-
guistics, ACL 2020, Online, July 5-10, 2020, pages
1835-1845. Association for Computational Linguis-
tics.

Shaohua Yang, Qiaozi Gao, Changsong Liu, Caiming
Xiong, Song-Chun Zhu, and Joyce Y. Chai. 2016.
Grounded semantic role labeling. In NAACL HLT
2016, The 2016 Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies, San Diego
California, USA, June 12-17, 2016, pages 149-159.
The Association for Computational Linguistics.

Tsung-Yen Yang, Andrew S. Lan, and Karthik
Narasimhan. 2020. Robust and interpretable ground-
ing of spatial references with relation networks. In
Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing: Findings,
EMNLP 2020, Online Event, 16-20 November 2020,
pages 1908-1923. Association for Computational
Linguistics.

Ziyi Yang, Chenguang Zhu, Vin Sachidananda, and
Eric Darve. 2019. Embedding imputation with

grounded language information. In Proceedings of
the 57th Conference of the Association for Compu-
tational Linguistics, ACL 2019, Florence, Italy, July
28- August 2, 2019, Volume I: Long Papers, pages
3356-3361. Association for Computational Linguis-
tics.

Yuya Yoshikawa, Yutaro Shigeto, and Akikazu
Takeuchi. 2017. STAIR captions: Constructing a
large-scale japanese image caption dataset. In Pro-
ceedings of the 55th Annual Meeting of the Associa-
tion for Computational Linguistics, ACL 2017, Van-
couver, Canada, July 30 - August 4, Volume 2: Short
Papers, pages 417-421. Association for Computa-
tional Linguistics.

Sina ZarrieB and David Schlangen. 2017. Deriv-
ing continous grounded meaning representations
from referentially structured multimodal contexts.
In Proceedings of the 2017 Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP 2017, Copenhagen, Denmark, September 9-
11, 2017, pages 959-965. Association for Computa-
tional Linguistics.

Rowan Zellers, Yonatan Bisk, Roy Schwartz, and
Yejin Choi. 2018. SWAG: A large-scale adversar-
ial dataset for grounded commonsense inference. In
Proceedings of the 2018 Conference on Empirical
Methods in Natural Language Processing, Brussels,
Belgium, October 31 - November 4, 2018, pages 93-
104. Association for Computational Linguistics.

Houyu Zhang, Zhenghao Liu, Chenyan Xiong, and
Zhiyuan Liu. 2020. Grounded conversation gener-
ation as guided traverses in commonsense knowl-
edge graphs. In Proceedings of the 58th Annual
Meeting of the Association for Computational Lin-
guistics, ACL 2020, Online, July 5-10, 2020, pages
2031-2043. Association for Computational Linguis-
tics.

Yanpeng Zhao and Ivan Titov. 2020. Visually
grounded compound pcfgs. In Proceedings of the
2020 Conference on Empirical Methods in Natu-
ral Language Processing, EMNLP 2020, Online,
November 16-20, 2020, pages 4369-4379. Associ-
ation for Computational Linguistics.

Victor Zhong, Mike Lewis, Sida I. Wang, and Luke
Zettlemoyer. 2020. Grounded adaptation for zero-
shot executable semantic parsing. In Proceedings of
the 2020 Conference on Empirical Methods in Nat-
ural Language Processing, EMNLP 2020, Online,
November 16-20, 2020, pages 6869-6882. Associ-
ation for Computational Linguistics.

Ben Zhou, Daniel Khashabi, Chen-Tse Tsai, and Dan
Roth. 2018a. Zero-shot open entity typing as type-
compatible grounding. In Proceedings of the 2018
Conference on Empirical Methods in Natural Lan-
guage Processing, Brussels, Belgium, October 31 -
November 4, 2018, pages 2065-2076. Association
for Computational Linguistics.


Kangyan Zhou, Shrimai Prabhumoye, and Alan W.
Black. 2018b. A dataset for document grounded
conversations. In Proceedings of the 2018 Confer-
ence on Empirical Methods in Natural Language
Processing, Brussels, Belgium, October 31 - Novem-
ber 4, 2018, pages 708-713. Association for Com-
putational Linguistics.

Mingyang Zhou, Runxiang Cheng, Yong Jae Lee, and
Zhou Yu. 2018c. A visual attention grounding neu-
ral model for multimodal machine translation. In
Proceedings of the 2018 Conference on Empirical
Methods in Natural Language Processing, Brussels,
Belgium, October 31 - November 4, 2018, pages
3643-3653. Association for Computational Linguis-
tics.


A Examples for dimensions of grounding

Static Grounding: In static grounding, when
you ask an agent “Can you place the dragon fruit
on the rack” ?, the agent links the entities and places
the dragon fruit on the rack. The challenge here is
mainly the linking part which is crucial to ensure it
accurately understood the instruction.

Dynamic Grounding: The same is not true for
dynamic grounding. There are primarily 2 ways
to materialize this. First, with respect to language
learning: What if the agent does not know dragon
fruit? The agent needs to first ask “What is a
dragon fruit?” , and the human provides an answer.
Lets say the human responded by describing the
physical attributes such as reddish pink fruit and/or
a spatial reference by refering to it as the fruit on
the bottom left. The important aspect here is that
the agent asks and learns what a dragon fruit is and
use this knowledge later.

The second is ambiguity resolution. Consider
a scenario where there are multiple racks. It is
very natural for a human to ask the agent which
rack to resolve ambiguity.We expect the same from
the agent to ask a clarifying question to resolve
ambiguity and then place it on the second rack.

Purviews - Localization: Consider this example
of a conversation between an agent and a human.

Once we localized Tony Stark, asking additional
information like whether he is the head of SHIELD
is natural in conversations; However, access to re-
quired external knowledge is rarely present in the
datasets as well as evaluated. Here, we need to
refer to external sources spanning from movies to
comics to conclude that he has been the acting head
in the comics but was never in the movies.

Purviews - Common sense: One of the
branches of natural progression to this context can
extend to the following turns:

Human: How long was the contract between Tony
Stark and Marvel?

Agent: Tony Stark is the name of the character in
Marvel. Would you like to know the contract length
for Robert Downey Jr who played the role?

Here, the agent needs to understand that Tony
Stark is not a real person, but is a character in
Marvel. Hence, any contract is with the actor but
not the character who played the role. The agent
needs to have the common sense to understand this
and clarify the question.

Purviews - Personalization: Upon a continous
exchange regarding this topic (and perhaps a few
other times earlier), the agent needs to adapt and
personalize to the interacting human over time.

Human: What is the name of the role Robert
Downey Jr played in Avengers?

Agent: He played the role of Tony Stark, and some-
times is also referred to as Iron Man.

The agent begins by localizing and linking
Robert Downey Jr to Tony Stark and Iron Man
to provide the appropriate answer to the query.

Purviews - External Knowledge: However, nat-
ural conversations also extend beyond the purview
of localization to discuss a broadened scope involv-
ing external knowledge of the context including
entities, actions etc., For example, consider this
conversation which seems to be a natural continua-
tion to the earlier one.

Human: Is he the head of SHIELD?

Agent: Tony Stark has never been the head of
SHIELD in the movies but has been the acting head
upon Maria Hill’s suggestion in the Comics.

Human: Can you give me any movie suggestions ?
Agent: Yes, since you like Disney movies and seem
interested in Robert Downey Jr, would you like to
watch “Dolittle” ?

Having discussed about Robert Downey Jr in
prior contexts and retaining from the prior interac-
tions that the human likes Disney movies, when the
human asks about a movie recommendation, the
agent continually learns and contextually suggests
Robert Downey Jr’s Disney movie “Dolittle” as a
recommendation.

Constraints - Copresence: Modality is an im-
portant medium that affects communicative goals
and the nature of interaction. Here is an example
in a copresent environment.

Human: I want to play with my cat. Can you get
me the ball on your right?

In the above example, the human and the agent


Modality Cue
Copresence Visibility Audibility | Cotemporality Simultaneity Sequentiality Reviewability Revisabiility

Face-to-face ov Y V v
Telephone v v v v
Video Teleconference v v v v Vv
Terminal Teleconference v v v
Answering Machines v v
E-mail v Vv
Letters v Vv

Table 2: Constraints of grounding along with their medium of communication (Clark and Brennan, 1991)

are copresent in the same environment. The above
utterance for instance, includes executable actions
in the environment along with references being
either person-centric or agent-centric.

Constraints - Visibility: Certain communica-
tions like in the cases of visual question answering
or visual dialog only presents a visible medium to
interact about. The interaction requires information
from an image or a video, but does not necessar-
ily include executable actions or cater to external
knowledge of the information. For example, with
an access to an image a human can ask a question
like the following:

Human: How many peaks are there in those moun-
tain ranges?

Constraints - Audibility: This modality con-
strains the information scope to be within speech
signals that are only heard and do not contain any
visual or copresent information.

Table 2 presents the constrainst of grounding.

B_ Further survey and categories

Here is a brief elaboration of the datasets presented
in Table 1.

New datasets: The first solution to curate the
entire dataset with annotations designed for the
task.

e Non-textual Modality: For images, new datasets
are curated for a variety of tasks including cap-
tion relevance (Suhr et al., 2019), multimodal MT
(Zhou et al., 2018c), soccer commentaries (Koncel-
Kedziorski et al., 2014) semantic role labeling (Sil-
berer and Pinkal, 2018), instruction following (Han
and Schlangen, 2017), navigation (Andreas and
Klein, 2014), understanding physical causality of
actions (Gao et al., 2016), understanding topologi-
cal spatial expressions (Kelleher et al., 2006), spo-
ken image captioning (Alishahi et al., 2017), entail-

ment (Vu et al., 2018), image search (Kiros et al.,
2018), scene generation (Chang et al., 2015), etc.,
Coming to videos, datasets have become popular
for several tasks like identifying action segments
(Regneri et al., 2013), sematic parsing (Ross et al.,
2018), instruction following from visual demon-
stration (Liu et al., 2016), spatio-temporal question
answering (Lei et al., 2020), etc.,

e Textual Modality: Within text, there are sev-
eral datasets for tasks like content transfer (Prabhu-
moye et al., 2019), commonsense inference (Zellers
et al., 2018), reference resolution (Kennington and
Schlangen, 2015), symbol grounding (Kameko
et al., 2015), studying linguistic and non-linguistic
contexts in microblogs (Doyle and Frank, 2015),
bilingual lexicon extraction (Laws et al., 2010),
universal part-of-speech tagging for low resource
languages (Cardenas et al., 2019), entity linking
and reference (Nothman et al., 2012) etc.,

e Other: More static grounding datasets corre-
spond to tasks like identifying phrases representing
variables (Roy et al., 2016), conceptual similarity
in olfactory data (Kiela et al., 2015), identifying
colors from descriptions (Monroe et al., 2017), cor-
recting numbers (Spithourakis et al., 2016) etc.,

e Interactive: Coming to an interactive setting,
the datasets span tasks like conversations based
on negotiations (Cadilhac et al., 2013), referring
expressions from images (Haber et al., 2019; Tak-
maz et al., 2020), emotions and styles (Shuster
et al., 2020), media interviews (Majumder et al.,
2020), documents (Zhou et al., 2018b), improvi-
sation (Cho and May, 2020), problem solving (Li
and Boyer, 2015), spatial reasoning in a simulated
environment (Janner et al., 2018), navigation (Ku
et al., 2020) etc.,

In addition, there are several other techniques
used to ground phenomenon in real world contexts.

In addition to the techniques dicscussed in the
paper, we also studied the categorization based on
stratification, which is explained here.


25

20

@ Images & Speech

® Images

@ Videos

@ Speech

@ Text

@ Entities & Events

™ KBs & KGs

© Numbers/Colors/Programs/Tables
@ Conversations

@® Embodiment

Figure 6: Comprehensive trends of papers using differnt techniques in various modalities to address grounding

Stratification: The stratification technique char-
acterizes the input or the model to explicitly cater
to the compositionality property. This can be done
by either breaking down the input to meaningful
compositions or building the model to compose
the representations. Utilizing grammatical rules
need not necessarily lead to compositions, although
there is an overlap between these two techniques.

A common strategy when language is involved
is leveraging syntax and parsing. In the domain
of images, Udagawa et al. (2020) design an annota-
tion protocol to capture important linguistic struc-
tures based on predicate-argument structure, modi-
fication and ellipsis to utilize linguistic structures
based on spatial expressions. Becerra-Bonache
et al. (2018) study linguistic complexity from a de-
velopmental point of view by using syntactic rules
to provide data to a learner, that identifies the under-
lying language from this data. Shi et al. (2019) use
image-caption pairs to extract constituents from
text, based on the assumption that similar spans
should be matched to similar visual objects and
these concrete spans form constituents. Kelleher
et al. (2006) use combinatory categorial grammar
(CCG) to build a psycholinguistic based model to
predict absolute proximity ratings to identify spa-
tial proximity between objects in a natural scene.
Ross et al. (2018) employ CCG-based parsing to
a fixed set of unary and binary derivation rules to

generate semantic parses for videos.

e Textual Modality: Johnson et al. (2012) study the

modeling the task of inferring the referred objects
using social cues and grammatical reduction strate-
gies in language acquisition. Eckle-Kohler (2016)
attempt to understand meaning in syntax by a multi-
perspective semantic characterization of the in-
ferred classes in multiple lexicons. Chen (2012) de-
velop a context-free grammar to understand formal
navigation instructions that correspond better with
words or phrases in natural language. Borschinger
et al. (2011) study the probabilistic context-free
grammar learning task using the inside-out algo-
rithm in game commentaries. CCG parsers are also
used to perform entity slot filling task (Bisk et al.,
2016). When applied to question answering over a
database, dependency rules are used to model the
edge states as well as transitions such as the work
done by using a tteeHMM (Poon, 2013).

¢ Other: Roy et al. (2016) perform equation pars-

ing that identifies noun phrases in a given sentence
representing variables using high precision mathe-
matical lexicon to generate the correct relations in
the equations. Parikh et al. (2015) perform proto-
type driven learning to learn a semantic parser in
tables of nested events and unannotated text.

e Interactive: Luong et al. (2013) use parsing
and grammar induction to produce a parser capable
of representing full discourses and dialogs. Steels


(2004) study games and embodied agents by mod-
eling a constructivist approach based on invention,
abduction and induction to language development.

Another frequently used technique when lan-
guage is involved is by leveraging the principle
of compositionality. This implies that the mean-
ing of a complex expression is determined by the
meanings of its constituents and how they interact
with one another.

e Non-textual Modality: In the domain of images,
Suhr et al. (2019) present a new dataset to under-
stand challenges in language grounding including
compositionality, semantic diversity and visual rea-
soning. Shi et al. (2019), discussed earlier also
use grammar rules to compose the inputs. Koncel-
Kedziorski et al. (2014) leverage the compositional
nature of language to understand professional soc-
cer commentaries. In the domain of videos, Nayak
and Mukerjee (2012) study language acquisition
by segmenting the world to obtain a meaning space
and combining them to get a linguistic pattern.

e Textual Modality: With ontologies, Pappas
et al. (2020) perform adaptive language modeling
to other domains to get a fully compositional out-
put embedding layer which is further grounded in
information from a structured lexicon.

e Interactive: Roy et al. (2003) work on grounding
word meanings for robots by composing perceptual,
procedural, and affordance representations.

Hierarchical modeling is also applied to show
effect of introducing phone, syllable, or word
boundaries in spoken captions (Havard et al., 2020)
and with a compact bilinear pooling in visual ques-
tion answering (Fukui et al., 2016).

There is some work that presents a bayesian proba-
bilistic formulation to learn referential grounding
in dialog (Liu et al., 2014), user preferences (Cadil-
hac et al., 2013), color descriptions (McMahan and
Stone, 2015; Andreas and Klein, 2014).

A huge chunk of work also focus on leveraging at-
tention mechanism for grounding multimodal phe-
nomenon in images (Srinivasan et al., 2020; Chu
et al., 2018; Huang et al., 2019; Fan et al., 2019;
Vu et al., 2018; Kawakami et al., 2019; Dong et al.,
2019), videos (Lei et al., 2020; Chen et al., 2019)
and navigation of embodied agents (Yang et al.,
2020), etc.,

Some approach this using data structures such as
graphs in the domains of grounding images (Chang
et al., 2015; Liu et al., 2014), videos (Liu et al.,
2016), text (Laws et al., 2010; Chen, 2012; Massé

et al., 2008), entities (Zhou et al., 2018a), knowl-
edge graphs and ontologies (Jauhar et al., 2015;
Zhang et al., 2020) and interactive settings Jauhar
et al. (2015); Xu et al. (2020).

Here is the technique wise representation of
these categories of models in the literature.

Figure 7: Papers addressing stratification in grounding

C_ Prevelance of modailties and
constraints

Here is the distribution of the papers studying vari-
ous tasks based on the constraints imposed by the
medium.

@ Copresence © Visibility @ Audibility @ Co-temporality © Sequentiality

Figure 8: Papers addressing different constraints of
grounding

As we can see, a major concentration of these
efforts lie in grounding visual and textual media,
while a few cater to audibility i.e speech signals. Pa-
pers studying dialog are the main representatives of
the constraints for sequentiality and co-temporality.

D_ Objective function for grounding

Figure 9 systeamtically presents the trends in the
usage of the objective function for grounding as


discussed in Section 3.3. While manipulating loss
function is a stable trend, recent approaches are fo-
cusing on adversarial objectives to perform ground-
ing.

Objective

satial

pave

Figure 9:
grounding

Objective functions in papers studying

E Nuanced modeling variations for
grounding

Here is a more nuanced and finer grained catego-
rization of the various modeling techniques used in
literature for grounding. Figure 10 presents these
categories in depth.

Modeling variations

Figure 10: Modeling variations in papers studying
grounding

As discussed in the paper, most of the literature
is focused on grounding in static visual modality.
Attention based methods dominate the rest of the
methods in both textual and non-textual modali-
ties closely followed by graph based methods as

observed in these trends.

This is not an exhaustive study of all the tech-
niques that present grounding, but are some of the
representative categories. Here are more studies
that perform grounding with various techniques
such as clustering (Shutova et al., 2015; Cardenas
et al., 2019) regularization (Shrestha et al., 2020),
CRFs (Gao et al., 2016), classification (Pangburn
et al., 2003; Monroe et al., 2017), linguistic theo-
ries (Strube and Hahn, 1999), iterative refinement
(Li et al., 2019; Chandu and Black, 2020), language
modeling (Spithourakis et al., 2016; Cho and May,
2020), nearest neighbors (Kiela et al., 2015), con-
textual fusion (Chandu et al., 2019a), mutual in-
formation (Oates, 2003), cycle consistency (Zhong
et al., 2020) etc.,
