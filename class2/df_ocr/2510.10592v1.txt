2510.10592v1 [cs.AI] 12 Oct 2025

arXiv

JOURNAL OF I4TgX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

A Layered Intuition—Method Model with Scope
Extension for LLM Reasoning

Hong Su

Abstract—Kxisting studies have introduced method-based rea-
soning and scope extension as approaches to enhance Large
Language Model (LLM) performance beyond direct matrix
mappings. Building on these foundations, this paper summarizes
and integrates these ideas into a unified Intuition—Method Layered
Model with Scope Extension, designed to address indirected
(unseen) issues more systematically. In this framework, intuition-
based thinking provides rapid first-reaction answers, while
method-based thinking decouples questions and solutions into
transferable reasoning units. Scope extension is then applied
to broaden applicability, including vertical (cause analysis),
horizontal (parallel and generalized issues), and for the first time,
temporal and spatial extensions, which expand reasoning across
time and contextual dimensions.

These extensions are organized into systematic knowledge trees
that interconnect into a knowledge network, thereby increasing
adaptability. To quantitatively evaluate this process, we propose
the entropy of method extension, which measures the indepen-
dence and diversity of extensions as an indicator of the system’s
capacity to solve unseen questions. By logically connecting exist-
ing approaches with new extensions and introducing an entropy-
based evaluation framework, this work advances toward a more
robust and extensible reasoning paradigm for LLMs in real-world
problem-solving.

Index Terms—Large Language Models (LLMs), Method-Based
Reasoning, Scope Extension, Entropy of Method Extension

I. INTRODUCTION

Large Language Models (LLMs) have achieved remarkable
performance across a wide range of natural language process-
ing tasks [1]. Their success largely stems from the transformer
architecture and massive pre-training, which enable strong
mappings from input queries to output responses [2]. While
this intuition-like mechanism allows LLMs to answer many
direct questions, it remains inherently limited when confronted
with indirected or unseen issues that lack explicit coverage in
the pre-trained distribution. Such limitations restrict the ability
of LLMs to adapt to complex real-world scenarios.

To address this gap, researchers have explored strategies
such as method-based reasoning (3), which decouples ques-
tions and solutions into reusable methods [4], and scope exten-
sion [5], which broadens the problem context to increase the
chance of correct resolution. These approaches have demon-
strated that reasoning can be extended beyond static matrix
mappings [6]. However, existing studies treat these ideas in
isolation and do not provide a unified logical framework to

H. Su is with the School of Computer Science, Chengdu University of
Information Technology, Chengdu, China.
E-mail: suguest @ 126.com.

connect them. Moreover, prior work has not systematically
addressed how such extensions can be organized, nor has it
provided quantitative measures of their effectiveness.

In this paper, we propose the Intuition—Method Layered
Model with Scope Extension, which integrates intuition-based
reasoning, method-based reasoning, and multiple forms of
scope extension into a unified framework. Intuition-based
reasoning captures the direct, reflex-like outputs of LLMs,
while method-based reasoning enables systematic reuse of
question-solution pairs. Scope extension further improves
adaptability by incorporating vertical (cause analysis) and
horizontal (parallel and generalization) reasoning, as shown
in Figure |1] Building on these foundations, this work makes
the following key contributions:

e We introduce the method-layer architecture with scope
extension. While method-based reasoning and scope ex-
tension have been studied separately in prior work, we
unify them into a single framework designed to address
a broader range of indirected questions.

« We propose systematic knowledge trees, which organize
extensions into structured hierarchies and interconnect
them into larger knowledge networks, enabling more
systematic reasoning.

e We define the entropy of method extension, a novel
metric that quantifies the independence and diversity of
extensions, providing a principled measure of an AI
system’s capacity to solve unseen questions.

form

Tree or network of
method reasoning *

Fig. 1. Intuition—Method Layered Model with Scope Extension for Forming
Method (knowledge) Trees and Networks

By logically integrating existing techniques with these new
contributions, our model extends the reasoning capacity of
LLMs beyond pre-trained mappings. The framework enables
more robust and systematic handling of indirected issues,


JOURNAL OF I4TgX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

moving toward an extensible reasoning paradigm that better
supports real-world problem-solving.

The remainder of this paper is organized as follows. Sec-
tion [I|reviews related work on method-based reasoning, scope
extension, difference-based reasoning, knowledge organiza-
tion, and evaluation methods. Section presents the pro-
posed Intuition—Method Layered Model with Scope Extension,
which integrates intuition-based and method-based reasoning
into a unified framework. Section further elaborates on
scope extension strategies, including vertical, horizontal, tem-
poral, and spatial dimensions, and their role in addressing
unseen or indirected issues. Section [V] introduces the entropy
of method extension as a quantitative framework for measuring
reasoning diversity and adaptability. Finally, we conclude with
a discussion of implications and future directions.

II. RELATED WORK

The proposed model builds upon several strands of prior
research that explore how Large Language Models (LLMs)
can move beyond direct matrix-based mappings to handle
more complex reasoning tasks. In particular, three areas are
closely related to this study: (1) method-based reasoning,
which focuses on decoupling and reusing question—solution
pairs; (2) scope extension approaches, which expand the
reasoning context to improve adaptability; and (3) difference-
based reasoning, which emphasizes recognizing temporal or
spatial changes to guide decision-making.

In addition, two complementary areas are also relevant:
(4) knowledge organization in AI systems, including knowl-
edge graphs, memory architectures, and hierarchical reasoning
structures; and (5) evaluation of reasoning diversity, which
highlights the limitations of existing benchmarks in measuring
adaptability to unseen or indirected issues.

This section reviews related works, identifies their limita-
tions, and motivates the need for a unified framework that
integrates method-based reasoning with scope extension. The
novelty of this paper lies in unifying these approaches into
a single framework capable of addressing a broader range
of indirected questions, introducing systematic knowledge
trees for dynamic organization, and proposing entropy-based
evaluation to quantify reasoning diversity.

A. Method-Based Reasoning in LLMs

Traditional LLMs generate answers by relying on pre-
trained transformer mappings between input and output tokens.
While this mechanism works well for direct questions, it often
fails to generalize when the question has not been explicitly
seen during training. To address this limitation, researchers
have proposed method-based reasoning, which treats reason-
ing as the reuse of previously learned methods rather than as
a one-time mapping.

A method is typically defined as a pair consisting of a
question and its corresponding solution. By decoupling this
pair, the method can be abstracted from its original context and
reused for new but related questions. This approach enables
LLMs to move beyond surface-level similarity and leverage
transferable reasoning strategies [3]. Furthermore, recent work

extends this idea by exploring how solutions can be applied
to less similar questions within a method-based framework.

However, existing studies typically examine method reuse in
isolation, without integrating it into a broader reasoning frame-
work. Furthermore, they lack mechanisms for systematically
extending methods to unseen issues, limiting their applicability
to real-world problem-solving. In this paper, we build upon
the idea of method-based reasoning and connect it with
scope extension strategies, systematic knowledge structures,
and entropy-based evaluation to form a more comprehensive
model.

B. Scope Extension Approaches

Another line of research relevant to this work is scope
extension, which aims to broaden the reasoning context of
LLMs when direct answers are insufficient. Instead of relying
solely on the original input, scope extension incorporates
additional information or perspectives to improve problem-
solving ability.

1) Vertical Extension: Error Analysis and Causal Reason-
ing: Vertical extension refers to identifying and incorporating
causal factors related to a given problem. Prior studies have
explored prompting LLMs to analyze their own errors or to
incorporate explanatory reasoning [5]. By including causal
chains, models can correct earlier mistakes or provide more
accurate answers. However, such approaches are often task-
specific and lack a generalizable structure.

2) Horizontal Extension: Parallel Reasoning and General-
ization: Horizontal extension focuses on exploring parallel
or related issues. For example, when a direct solution fails,
reasoning about related subproblems or generalizing from
specific instances to broader categories can provide more
robust answers [5]. This technique improves adaptability but
may also introduce noise, as not all parallel issues contribute
useful context.

3) Limitations of Existing Scope Extension Methods: A\-
though vertical and horizontal extensions have been proposed,
prior work typically applies them in isolation. There is no
unified framework that organizes different types of extensions
or connects them systematically with method-based reasoning.
Moreover, existing approaches rarely consider other dimen-
sions of extension, such as temporal changes or spatial context,
which are particularly important for handling dynamic real-
world issues. These gaps motivate our proposal of temporal
and spatial extensions, as well as the integration of all exten-
sions into structured knowledge trees.

C. Difference-Based Reasoning and Contextual Awareness

In addition to method-based reasoning and scope extension,
another important direction in LLM research is difference-
based reasoning, which emphasizes recognizing and respond-
ing to changes in context. Unlike static input-output mappings
[6], this approach enables models to focus on what has
changed across time or space, thereby improving their ability
to handle evolving or indirected problems.


JOURNAL OF I4TgX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

1) Temporal Difference Reasoning: Several works have
highlighted the importance of incorporating temporal dif-
ferences into reasoning [8]. For instance, monitoring how
an environment or input sequence evolves over time allows
models to identify critical changes that influence decision-
making. Temporal reasoning has been applied in areas such
as dialogue systems, forecasting, and process tracking, where
historical context is essential.

2) Spatial Reasoning and Attention Mechanisms: Spatial
difference reasoning focuses on identifying changes or salient
features within visual or structured spatial data. Techniques
such as attention mechanisms and region-based analysis
have been developed to allow models to prioritize relevant
parts of an input image or scene. These methods have im-
proved performance in tasks like object detection and scene
understanding by enabling localized reasoning.

3) Remaining Challenges in Handling Indirected Ques-
tions: While temporal and spatial difference reasoning has
been partially explored, existing approaches are typically
designed for specific applications (e.g., vision or sequence
modeling) rather than as general reasoning strategies. More-
over, they are rarely integrated with method-based or scope-
extended reasoning frameworks. As a result, prior methods
lack the systematic capability to generalize across unseen or
indirected questions. In this paper, we extend these ideas by
formalizing temporal and spatial extensions within a unified
layered framework, enabling broader adaptability in real-world
scenarios.

D. Knowledge Organization in AI Systems

A related area of research focuses on how knowledge
can be organized, represented, and retrieved in AI systems.
Since LLMs are limited by the implicit structure of their
pre-training data, explicit forms of knowledge organization
have been proposed to improve reasoning, interpretability, and
adaptability.

1) Knowledge Graphs and Structured Memory Approaches:
Knowledge graphs provide explicit representations of entities
and their relationships, enabling structured reasoning across
domains [9]. Similarly, structured memory architectures
allow models to store, update, and retrieve knowledge during
interaction. These approaches improve factual consistency and
enable systematic retrieval of related information. However,
they are often static and require extensive manual or external
construction.

2) Hierarchical Reasoning Networks: Another stream of
work investigates hierarchical reasoning structures, where
knowledge is organized into layered or tree-like forms to
support abstraction and decomposition [II]. These systems
mimic aspects of human cognition by enabling reasoning
at different levels of granularity. While effective in narrow
domains, such frameworks are typically handcrafted and lack
general adaptability to unseen problems.

3) Limitations Compared to Systematic Knowledge Trees:
Although knowledge graphs, memory modules, and _hierar-
chical reasoning networks provide structured representations,
they differ fundamentally from the systematic knowledge trees

proposed in this paper. Existing approaches generally represent
static knowledge or domain-specific reasoning, while sys-
tematic knowledge trees are constructed dynamically through
extensions (vertical, horizontal, temporal, and spatial). More-
over, knowledge trees in our framework interconnect to form
a broader systematic knowledge network, which increases
reasoning diversity and adaptability. This distinction marks a
key novelty of our work, as it introduces a dynamic, extension-
driven organization of knowledge rather than relying on fixed
structures.

E. Evaluation of Reasoning Diversity

Evaluating the reasoning ability of LLMs remains a signif-
icant challenge. Most existing benchmarks and metrics focus
on task-specific accuracy or output quality, such as exact
match, BLEU scores, or human evaluation [12]. While these
metrics are useful for measuring correctness in direct question
answering, they do not capture the diversity or adaptability of
reasoning strategies required for indirected or unseen prob-
lems.

1) Existing Performance Metrics: Previous studies have
introduced evaluation methods tailored to specific reasoning
tasks, such as logical consistency checks [13], factual verifica-
tion benchmarks [14], or chain-of-thought quality assessments
{15}. These approaches measure reasoning within narrowly
defined settings, but they fail to account for how effectively a
system can extend its reasoning to new contexts.

2) Lack of Metrics for Extension Independence and Diver-
sity: A critical limitation of current evaluation methods is
the absence of a metric for measuring the independence and
diversity of reasoning extensions. For example, two extensions
that are tightly coupled add little new problem-solving ca-
pacity, while independent extensions significantly expand the
system’s adaptability. Without a measure of this independence,
it is difficult to quantify how well a model can generalize to
indirected questions.

3) Motivation for Entropy of Method Extension: To address
this gap, we introduce the concept of entropy of method
extension. Unlike prior metrics, entropy provides a principled
way to evaluate the diversity of reasoning strategies by quan-
tifying the independence among extensions. Higher entropy
corresponds to greater adaptability, reflecting the ability of
the system to explore multiple perspectives and solve unseen
problems. This contribution distinguishes our work from exist-
ing evaluation methods, as it shifts the focus from correctness
alone to the extensibility and robustness of reasoning.

III. INTUITION METHOD LAYERED MODEL WITH SCOPE
EXTENSION TO SOLVE INDIRECTED ISSUES

A. Overview and Motivation

Large Language Models (LLMs) primarily rely on the pre-
trained transformer architecture to generate responses. While
this matrix-based mapping is effective for many direct ques-
tions, it remains relatively fixed and limited when addressing
unseen or indirected issues. To overcome these limitations,
we propose the Intuition Method Layered Model with Scope
Extension.


JOURNAL OF I4TgX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

The central motivation of this model is to maximize the
reuse of learned methods rather than relying solely on static
parameter mappings. Instead of treating each question as an
isolated case, questions are decomposed into two components:
the question and its corresponding solution |B]. This decou-
pling enables methods to be systematically applied to a broader
range of problems, even those not directly covered by the pre-
trained model.

Our ultimate goal is to construct a structured system of
reusable methods, analogous to how scientific disciplines (e.g.,
chemistry) organize knowledge into coherent frameworks. By
forming such a systematic method network, an LLM can
generalize beyond its training distribution, extend its reasoning
scope, and solve a wider variety of real-world problems.

B. Intuition and Method-Based Thinking Model

Questions can be categorized into two types: direct and
indirected. Direct questions are those for which an LLM
can provide an immediate answer by relying on its pre-
trained matrix. This process, which we call the intuition-based
approach, represents a first reaction to external input. Intuition
arises from repeated training and functions as a natural reflex,
but it is often limited in scope and rarely adaptable to new or
complex situations.

In contrast, indirected questions lack a direct mapping in
the pre-trained model. To address such cases, we employ a
method-based approach. A method is formally defined as a
pair consisting of a question and its corresponding solution. By
decoupling this pair, the method becomes a transferable unit
of reasoning that can be applied to related questions beyond
its original context [3].

This distinction leads to the formulation of the Intuition
and Method-Based Thinking Model. In this model, intuition
serves as a fast but narrow mechanism for solving well-
covered problems, while method-based reasoning provides a
more systematic and extensible process. By combining the
two, the model not only simulates human-like first reactions
but also incorporates deliberate reasoning, thereby enhancing
the ability to resolve indirected and unseen issues.

1) Timely Active Method-Based Thinking: In addition to
intuition and static method reuse, an effective AI system
should engage in continuous and proactive reasoning, similar
to human goal-directed thinking. We define this process as
timely active method-based thinking.

In this approach, the system continuously monitors its cur-
rent state and aligns its reasoning with a defined goal. The goal
may be user-specified (e.g., through task input) or derived from
the LLM’s output. For example, in autonomous driving, the
overarching objective is safe driving, which remains constant
while the environment dynamically changes.

To achieve this, the AI system actively collects contextual
information and constructs prompts that integrate both the
current state and the goal. The LLM is then queried for
solutions that account for these factors. However, if the system
directly queries without emphasizing recent or significant
changes, the LLM may overlook critical details. To mitigate
this, a difference-based prompting strategy is proposed in[8}:

first prompting the LLM to identify key changes in temporal or
spatial dimensions, and then requesting a solution that focuses
on these changes.

This mechanism simulates human-like active thinking,
where attention is directed toward evolving aspects of the envi-
ronment, thereby enabling more adaptive and timely decision-
making.

2) Method Improvement: Beyond applying existing meth-
ods, an AI system should be capable of evaluating and refining
them. This process, termed method improvement, ensures that
reasoning strategies remain effective and adaptable across
diverse scenarios.

After a method has been applied, the system can assess
whether it achieved the intended outcome and whether alter-
native strategies might perform better. One direct approach is
to prompt the LLM to critique the method as a whole, asking
whether it can be improved.

Another approach is to decompose the method into distinct
stages and evaluate each step individually. By examining
stages separately, the system can identify weaknesses, sub-
stitute improved steps, or revert unsuitable ones. This process
is referred to as a step-change strategy.

Step-change strategies can be classified according to the
degree of modification:

(1) Minimal change: Only one step of the method is altered.

(2) Partial change: A subset of steps is randomly or selec-
tively modified.

(3) Complete change: All steps are replaced, effectively
generating a new method.

To measure the impact of these changes, two approaches
are possible: (1) empirical validation in real-world or simulated
environments, and (2) predictive evaluation by the LLM itself,
particularly in high-risk contexts where direct testing is unsafe
(e.g., highway driving scenarios).

Through iterative refinement, method improvement enables
continuous evolution of reasoning strategies, ensuring both ro-
bustness and adaptability in dynamic real-world environments.

IV. SCOPE EXTENSION: ADDRESSING UNSEEN OR
INDIRECTED ISSUES

While the method-based approach enables reasoning beyond
direct mappings, certain questions may still remain unsolved
or may yield incorrect answers. To broaden coverage, we in-
troduce scope extension, which expands the contextual bound-
aries of reasoning. Scope extension incorporates additional in-
formation, perspectives, and related issues, thereby enhancing
the likelihood of producing correct or more complete answers
|S].

The major categories of scope extension include vertical,
horizontal, temporal, and spatial dimensions. Together, these
strategies enable systematic augmentation of the reasoning
process.

A. Vertical Extension (Cause Analysis) and Horizontal Exten-
sion (Parallel Issues and Generalization)

Vertical extension focuses on identifying underlying
reasons or causal factors. Errors in output can often be


JOURNAL OF I4TgX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

corrected by prompting the LLM to analyze the reasons behind
its mistakes or by incorporating user-provided explanations.
Formally, let g denote the question and y the predicted answer.
A vertical extension introduces a cause variable c such that:

Piylq) — ply!4¢.c),

where c represents causal or explanatory information. By
conditioning on c, the system reduces uncertainty in y and
improves problem resolution.

Horizontal extension explores parallel or related issues
that share contextual similarities. Let M(q) denote the set
of neighboring or parallel questions related to g. Horizontal
extension augments the reasoning context by:

Piylq) — pivl4.N(q)).

This expansion increases the chance of retrieving relevant
knowledge while mitigating misleading factors.

A special case of horizontal extension is generalization,
where a mapping g(q) transforms a specific question g into a
more general representation gg = g(q). If M(qg) denotes the
set of methods applicable to gg, then M(q) C M(qg). Thus,
the generalized method offers broader transferability across
multiple related problems.

B. Temporal and Spatial Extension

In addition to reasoning extensions on the LLM side, the
input data itself can also be extended. For instance, if an
input image X does not provide sufficient information, a larger
region X’ can be included to support better judgment. This
process is referred to as spatial extension, defined as:

xX’ = Espatial (X), XC X's

where Spatial expands the spatial coverage of the input.

Similarly, if knowledge of the history H of an issue or
predictions F' about its future evolution help to resolve it, we
call this temporal extension. In this case, the input sequence
is extended from X to:

xX’ =XUHUF,

where H = {x;_1,X;-2,...} represents historical states and
F = {x¢41,%742,-..} represents future predictions.

Consider the case of asking why a bridge lacks a connection.
As illustrated in Fig. 2] an LLM may generate several possible
reasons, many of which are incorrect. However, by extending
the temporal or spatial scope—looking at a broader view of
the bridge or considering its structural evolution—we may
observe, as shown in Fig. that the bridge branches out
but does not connect to the main road. This demonstrates
how temporal and spatial extensions can reduce error by
incorporating additional context.

Another form of temporal and spatial extension is the scatter
method [16]. In this approach, an optimization identified at one
stage or in one location is examined for applicability to other
stages or locations. Formally, if an optimization o is valid for
stage s;, the scatter method tests whether:

o(s;) = o(s;), VWs; €S,

Fig. 2. Initial reasoning on why the bridge lacks a connection, as indicated
by the red circle

Fig. 3. Extended reasoning with additional spatial context reveals the correct
explanation: the road diverges at a fork to reduce one connection and minimize
resonance.

where S is the set of alternative stages or locations. By
transferring optimizations across time or space, the scatter
method broadens the generalizability of solutions and en-
hances systematic reasoning.

C. Completion of Scope Extension and Relation to LLM
Output

The extensions described above represent common and
important strategies, but new forms of extension can be
dynamically added. For instance, when interpreting a narrative,
the emotional state of the author may serve as an additional
dimension of scope. Thus, we maintain two lists: a common
extension list of standard strategies, and a dynamic extension
list for context-specific additions. Over time, frequently used
dynamic extensions can be promoted into the common list.

It is worth noting that LLM output itself can be seen as an
implicit form of extension, since pre-trained models expand
input text using vast background knowledge. Explicit scope
extension, however, provides a rational and structured process
for systematically broadening the reasoning context.

Formally, let X denote the original input and Y the output.
Implicit extension occurs when the LLM internally augments
X with latent background knowledge Z drawn from its pre-
training corpus:

poll 1X) = f pol¥ | XZ) qalZ | X)azZ,

where qg(Z | X) is the model’s implicit posterior over latent
extensions.

Explicit extension instead applies a controlled operator
exp that enriches X with structured external information
S = {e1,€2,...,€@m}:

X’ = Exp(X; 58) = Xe De,

ees

Y = argmax po(y | X’).
y


JOURNAL OF I4TgX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

The difference between implicit and explicit extension can
be evaluated through measures such as KL-divergence:

IG(S | X) = KL(po(- | X’) || po(- | X)),

which quantifies the additional information contributed by
explicit extensions beyond what is already encoded implicitly.

D. Application of Methods to Dissimilar Questions

Methods can naturally be reused for similar issues or
through rational scope extension, where the relationship be-
tween questions is explicit. However, in many cases, a current
question may lack direct similarity to any previously solved
case. In such situations, it becomes necessary to borrow
methods from dissimilar questions.

To enable this, we define a notion of distance between
questions. Let g; and g; denote two questions represented in
an embedding space. Their similarity can be measured using
cosine similarity:

F Gi Wj
sim(qi,q;) = ——— >
ey" Ngillllaill

and the corresponding distance is defined as:

d(qi,qj) = 1-sim(qi,q;)-

A smaller distance d(q;,qj;) indicates higher similarity and
thus a greater likelihood that a borrowed method from qj;
will be effective for g;. Conversely, larger distances may still
provide alternative perspectives when no closer methods are
available. In practice, multiple candidate methods may be
borrowed simultaneously to increase coverage.

This approach is referred to as distance-based method
reuse. Importantly, similarity need not be computed solely
on the original question. By first applying scope extension
to expand the problem context, similarity can be measured
on the extended representation q; instead of q;. This often
reveals meaningful connections between otherwise unrelated
problems.

Thus, when no direct method exists for a given question,
the system proceeds in two steps: (1) apply scope extension
to broaden the problem context, and (2) identify candidate
methods to borrow based on distance to the extended question.
In this way, distance-based reuse ensures that even dissimilar
questions can be addressed by leveraging transferable reason-
ing strategies from other domains.

E. Systematic Knowledge Formation

The different forms of scope extension described above
can be organized into structured representations of knowledge.
Rather than treating each extension in isolation, we propose
forming systematic knowledge trees, which capture hierarchi-
cal and relational structures among questions, methods, and
their extensions. When multiple trees are interconnected, they
form a systematic knowledge network.

1) Knowledge Trees from Extensions: Each type of exten-
sion can be represented as a rooted tree T = (V, E), where V
is the set of nodes (questions, methods, or contexts) and E is
the set of directed edges (extension relations). The structure
of each tree depends on the type of extension:

¢ Horizontal extension: siblings in V represent paral-
lel or related issues, while parent nodes correspond to
generalized questions or methods. Formally, if g is a
specific question and g(q) is its generalization, then
(g(q),q) € E.

¢ Vertical extension: parent nodes capture causal factors,
and child nodes represent their consequences. If c is a
cause and e an effect, then (c,e) € E.

¢ Temporal extension: parent nodes represent histori-
cal states, and child nodes represent predicted or fu-
ture states. For a sequence {x+-1,X;,X++1}, we have
(X1-1, Xr), (%1, X41) € E.

« Spatial extension: nodes correspond to contexts of differ-
ent granularity. For example, a local region rjgca is con-
nected to its global context rglobal by (global, local) € E.

Each tree is anchored to an original question or method,
which serves as the root node vg € V. These trees provide
structured pathways for reasoning across multiple dimensions,
systematically organizing strategies that would otherwise re-
main implicit.

2) Knowledge Networks and Entropy of Extension: When
multiple knowledge trees share common nodes, they can be
merged into a knowledge network G = (V,E), which is a
directed acyclic graph (DAG). The union of trees increases
coverage by connecting extensions across dimensions. For
example, a parallel issue may also have a causal chain and
a temporal trajectory, creating cross-tree links.

Formally, if 7; = (Vi, £1) and T = (V2, E2) are two trees
with shared nodes V; MN V2 # 0, the combined network is:

G = (Vi UV2, E U Ep).

This network-based organization enables the system to reach
novel and previously unseen nodes, thereby increasing adapt-
ability to indirected and real-world questions. By leveraging
multiple independent extensions across interconnected trees,
the model approaches the robustness and systematic reasoning
typical of human knowledge.

V. MEASUREMENT OF METHOD EXTENSION (ENTROPY
FRAMEWORK)

To evaluate the effectiveness of the proposed model, we
introduce a quantitative framework based on the entropy of
method extension. The central idea is that an AI system’s
reasoning capacity can be measured by the independence and
diversity of its extensions. The more independent extensions
the system can generate and apply, the greater its entropy
and, consequently, its ability to handle unseen or indirected
questions.

Formally, let E = {e1,e2,...,@n} represent the set of
extensions applied to a question. Each extension e; contributes


JOURNAL OF I4TgX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

to the system’s reasoning space. The entropy of extension can
then be defined as:

H(E) =~ ) pei) log p(ei),
i=l

where p(e;) denotes the normalized contribution of extension
e; to solving the question.

Two key properties emerge:

¢ Coupled extensions: If two extensions are strongly de-
pendent, their joint contribution increases coverage only
marginally, resulting in lower entropy gain.

« Independent extensions: If two extensions address or-
thogonal aspects of a problem (e.g., temporal vs. causal
reasoning), they contribute significant additional entropy.
Analysis of Method-Based Reasoning.: Method-based

reasoning also benefits from the entropy view. A single method
m reused across highly similar questions contributes relatively
little entropy, as its scope of application is narrow. Formally,
if Q denotes the set of questions solvable by m, then

H(Qm)=— >) p(q\m)log p(q | m),
qeQm

remains low when Q,, contains only closely related ques-
tions. However, when methods are decoupled from their
original contexts and extended through independent transfor-
mations—such as generalization or distance-based reuse—the
support of Q,, expands, yielding higher entropy.

The entropy gain of adding a new transformed method m’
can be expressed as:

AH = H(OmU Om) — H(Om),

where Q,, covers a distinct set of questions. If Q,, is largely
independent of Q,,,, then AZ is significant, reflecting improved
adaptability. Conversely, overlapping Q,, and Q,, contribute
little to overall entropy.

In practice, the entropy measure thus distinguishes between
systems that reuse a few tightly coupled methods (low entropy)
and those that systematically apply diverse and independent
methods (high entropy), with the latter reflecting stronger
adaptability to unseen problems.

Analysis of Scope Extension.: Different forms of scope
extension naturally map to this entropy framework. Vertical
extensions often introduce causal variables c that overlap
with existing information, and thus add limited entropy when
strongly correlated with the question gq, i.e.,

I(q,¢) ~ H(c),

indicating redundancy. In contrast, horizontal extensions ex-
pand the space of related or parallel issues N(q), contributing
greater entropy when the distribution p(N(q)) is diverse.

Temporal and spatial extensions are typically orthogonal to
vertical and horizontal ones. If two extensions e; and e; are
independent, their joint contribution satisfies:

H(e;,e;) = H(e;) + H(e;),

thus yielding larger entropy gains by introducing new, non-
overlapping dimensions of reasoning. This explains why com-
bining multiple independent extensions leads to a more robust
and adaptable problem-solving capacity.

Knowledge Networks and Entropy.: When extensions are
organized into systematic knowledge trees and further inter-
connected into a knowledge network, the entropy of reasoning
increases. Let E,, Ex,..., E, represent the extension sets from
k different trees. The entropy of the combined network is

k
H LJ E;| > max H(E;).
i=l ’
If the extension sets are largely independent, then

k k
A\|_ zi] ~ >) ACE),
i=l i=l
indicating that the network contributes substantially more en-
tropy than any single tree. By contrast, overlapping extensions
provide limited additional entropy. Thus, the knowledge net-
work systematically increases the system’s reasoning diversity,
allowing it to handle a wider range of unseen problems.
Entropy thus provides a principled measure of how ef-
fectively an AI system broadens its reasoning scope. Higher
entropy indicates that the system can solve a wider range of
problems through diverse and independent extensions. This
framework also provides a foundation for comparing different
extension strategies, optimizing the balance between depth
(improving methods) and breadth (extending scope).

VI. CONCLUSION

This paper presented the Intuition—Method Layered Model
with Scope Extension, designed to enhance the reasoning
capacity of Large Language Models (LLMs) when addressing
indirected or unseen problems. We reviewed prior work on
method-based reasoning and scope extension, and integrated
them into a unified and logical framework. Building on
these foundations, this work makes three main contributions.
First, we propose the method-layer architecture with scope
extension, which unifies method-based reasoning and scope
extension into a single framework capable of addressing
a broader range of indirected questions. Second, we intro-
duce systematic knowledge trees, which organize extensions
into hierarchical structures and interconnect them into larger
knowledge networks. Third, we define the entropy of method
extension, a novel metric that quantitatively measures the in-
dependence, diversity, and adaptability of reasoning strategies.
Together, these contributions move LLMs beyond static matrix
mappings toward a more systematic and extensible reasoning
paradigm, thereby improving robustness in real-world problem
solving.

Future work will focus on further formalizing the mathe-
matical foundations of the entropy framework and empirically
validating its effectiveness across multiple benchmarks. In par-
ticular, we aim to quantify how different extensions (vertical,
horizontal, temporal, and spatial) influence entropy and rea-
soning accuracy. Another promising direction is the automated
construction of dynamic extension lists, enabling systems
to evolve their repertoire of extensions over time. Finally,
exploring efficient algorithms for building and traversing large-
scale knowledge networks may facilitate practical deployment
of the proposed framework in domains such as scientific
discovery, autonomous systems, and complex decision support.


JOURNAL OF I4TgX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

REFERENCES

[1] Y. Chang, X. Wang, J. Wang, Y. Wu, L. Yang, K. Zhu,
H. Chen, X. Yi, C. Wang, Y. Wang ef al., “A survey on
evaluation of large language models,’ ACM transactions
on intelligent systems and technology, vol. 15, no. 3, pp.
1-45, 2024.

[2] W. Du, T. Luo, Z. Qiu, Z. Huang, Y. Shen, R. Cheng,
Y. Guo, and J. Fu, “Stacking your transformers: A closer
look at model growth for efficient Ilm pre-training,”
Advances in Neural Information Processing Systems,
vol. 37, pp. 10491-10540, 2024.

[3] H. Su, “Method-based reasoning for large language
models: Extraction, reuse, and continuous improvement,”
arXiv preprint arXiv:2508.04289, 2025.

[4] C. Zhang, Y. Dong, Y. Wang, Y. Han, G. Shan, and
B. Tang, “Auragenome: An Ilm-powered framework for
on-the-fly reusable and scalable circular genome visu-
alizations,’ IEEE Computer Graphics and Applications,
2025.

[5] H. Su, “Improving Ilm accuracy in checkable scenarios
via scope expansion,” Authorea Preprints, 2025.

[6] Y. Zhao, Z. Li, and H. Zhao, “Iam: Efficient inference
through attention mapping between different-scale Ilms,”
arXiv preprint arXiv:2507.11953, 2025.

[7] H. Su, “Cross-question method reuse in large language
models: From word-level prediction to rational logical-
layer reasoning,” arXiv preprint arXiv:2509.05660, 2025.

[8] H. Su, “Difference-guided reasoning: A temporal-spatial
framework for large language models,” arXiv preprint
arXiv:2509.20713, 2025.

[9] Q. Wang, Z. Mao, B. Wang, and L. Guo, “Knowl-
edge graph embedding: A survey of approaches and
applications,” IEEE transactions on knowledge and data
engineering, vol. 29, no. 12, pp. 2724-2743, 2017.

[10] D. Yogatama, Y. Miao, G. Melis, W. Ling, A. Kuncoro,

C. Dyer, and P. Blunsom, “Memory architectures in

recurrent neural network language models,” in Interna-

tional Conference on Learning Representations, 2018.

Z. Zhang, Z. Zhang, Y. Zhang, and W. Zhao, “A hi-

erarchical reasoning framework for complex question

answering over knowledge graph with reinforcement
learning,’ in ICASSP 2025-2025 IEEE International

Conference on Acoustics, Speech and Signal Processing

(ICASSP). TEEE, 2025, pp. 1-5.

A. Celikyilmaz, E. Clark, and J. Gao, “Evaluation of text

generation: A survey,” arXiv preprint arXiv:2006.14799,

2020.

[13] P. Clark, O. Tafjord, and K. Richardson, “Transform-
ers as soft reasoners over language,’ arXiv preprint
arXiv:2002.05867, 2020.

[14] Z. Guo, M. Schlichtkrull, and A. Vlachos, “A survey on
automated fact-checking,” Transactions of the associa-
tion for computational linguistics, vol. 10, pp. 178-206,
2022.

[15] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia,
E. Chi, Q. V. Le, D. Zhou et al., “Chain-of-thought
prompting elicits reasoning in large language models,”

(11

ey

[12

roan

Advances in neural information processing systems,
vol. 35, pp. 24 824-24 837, 2022.

[16] H. Su, “Scatter-based innovation propagation in large
language models for multi-stage process adaptation,”
arXiv preprint arXiv:2506.17949, 2025.

Hong Su received the MS and PhD degrees, in
2006 and 2022, respectively, from Sichuan Univer-
sity, Chengdu, China. He is currently a researcher
of Chengdu University of Information Technol-

PLACE ogy Chengdu, China. His research interests include
PHOTO blockchain, cross-chain and smart contract.
HERE

