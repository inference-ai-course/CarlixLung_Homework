2204.04282v1 [cs.CL] 8 Apr 2022

arXiv

Classification of Natural Language Processing
Techniques for Requirements Engineering

Liping Zhao, Waad Alhoshan, Alessio Ferrari, Keletso J. Letsholo

Abstract—Research in applying natural language processing
(NLP) techniques to requirements engineering (RE) tasks spans
more than 40 years, from initial efforts carried out in the
1980s to more recent attempts with machine learning (ML)
and deep learning (DL) techniques. However, in spite of the
progress, our recent survey shows that there is still a lack of
systematic understanding and organization of commonly used
NLP techniques in RE. We believe one hurdle facing the industry
is lack of shared knowledge of NLP techniques and their usage
in RE tasks. In this paper, we present our effort to synthesize
and organize 57 most frequently used NLP techniques in RE.
We classify these NLP techniques in two ways: first, by their
NLP tasks in typical pipelines and second, by their linguist
analysis levels. We believe these two ways of classification are
complementary, contributing to a better understanding of the
NLP techniques in RE and such understanding is crucial to the
development of better NLP tools for RE.

Index Terms—Requirements Engineering (RE), Natural Lan-
guage Processing (NLP), NLP Tasks, NLP Techniques

I. INTRODUCTION

Research in developing natural language processing (NLP)
support for requirements engineering (RE), or NLP4RE for
short, dates back to the early 1980s and has seen a continuous
flow of contributions in the past 40 years (1}-14). However, in
spite of huge improvements and advances in NLP in the last
20 years (5). (6). and great progress in NLP4RE research in
the last 10 years, the uptake of NLP technologies in RE, and
their industrial penetration, is still limited and fragmented (7).
(8). Thus large gaps remain between NLP4RE research and
its practical application (8).

A recent survey cites insufficient industrial evaluation
of NLP4RE research, the lack of shared RE-specific language
resources, and the lack of technology know-how in NLP
among the reasons for these gaps. As a first step to close
these gaps, this paper aims to classify the NLP techniques
commonly used in RE so that they are easy to understand. We
believe that a better understanding of the NLP techniques in
RE is not only crucial to the development of better NLP tools
for RE, but also to their industrial adoption. In particular, the
paper lays foundations for establishing a common terminology
and vocabulary of the NLP techniques through the following
contributions:

L. Zhao is with the University of Manchester, Manchester, UK

W. Alhoshan is with Al-Imam Mohammed ibn Saud Islamic University,
Riyadh, Saudi Arabia

A. Ferrari is with Consiglio Nazionale delle Ricerche, CNR-ISTI, Pisa,
Italy

K.J. Letsholo is with Higher Colleges of Technology, Abu Dhabi, UAE

e We extract and synthesize 57 commonly used NLP tech-
niques in RE for NLP4RE research and practice.

e We systematically classify these techniques in two ways:
by their tasks typically performed in NLP pipelines and
then by their linguistic analysis capability.

The paper is organized as follows. Sect. [Il] provides a brief
history of NLP for RE, as the background and motivation for
this paper. Sect. [II] describes how we extract and synthesize
the common set of NLP techniques for RE. Sect. and
Sect. [V]present our classification of these techniques. Sect.
concludes the paper.

II. BACKGROUND: 40 YEARS OF NLP4RE

As a background to this paper, we provide a brief history of
NLP4RE. We first point to some notable contributions in RE
that use traditional NLP techniques, and then outline the recent
application of machine learning (ML) and deep learning (DL)
in RE. However, the focus of this paper is on NLP techniques,
not ML and DL techniques.

A. Traditional NLP for RE

The relationship between NLP and RE is well established
and widely discussed, with supporters and detractors (1). (7|,
(9). [70]. Pioneering researchers in the field are Chen
and Abbott (i2}, who, in the early 1980s, proposed using
syntactic features of English sentences for database modeling
and program design. Abbott’s approach was subsequently
adapted to a program design tool by Berry et al. (13). These
works were mostly based on extracting relevant entities from
the requirements text through simple syntactic rules, assuming
that NL requirements were expressed in some constrained,
predictable format, which, however, is rarely the case in
practice [14].

After these pioneering works, the beginning of 1990s saw
some serious attempts to develop NLP4RE tools, introducing
techniques to account for the complexity and variety of NL.
Two well-known NLP tools, findphrases by Aguilera and
Berry and OICSI by Rolland and Proix [16], were the
results of these efforts. Both tools were still oriented to the
extraction task (8), also referred as abstraction (10), and used
lexical affinity and semantic cases, respectively, two tech-
niques that are far more sophisticated than those previously
used.

For the remaining 1990s right up to the beginning of 2000s,
a succession of NL tools had been proposed, among which
were AbstFinder by Goldin and Berry [17], NL-OOPS by
Mich (18), Circe by Ambriola and Gore} CM-Builder


by Harmain and Gaizauskas (20). These works normally use
traditional rule-based NLP techniques, and are oriented to term
extraction and model generation. Other tools, such as QUARS
by Fabbrini et al. (21), and ARM by Wilson et al. [22},
focus on defect detection and mostly use dictionary-based
techniques.

The early 2000s appeared to be a period of experimentation
of new NLP techniques and new ideas addressing other tasks
and phases of the RE process. Information retrieval (IR)
techniques were used to improve requirements tracing (23).
statistical NLP techniques were applied to identify “shallow
knowledge” from requirements text (2). and to tracing rela-
tionships between requirements (24).

Since the late 2000s, NLP4RE has become a full-fledged
research area, attracting researchers from the wider RE com-
munity. A large number of tools have since been developed,
among which are SREE (Tjong and Berry (25)) for ambiguity
detection and aToucan (Yue et al. (26)) for model generation.
Further developments include tools detection of defects (27),
smells and equivalent requirements [29].

Given the increasing need to make software systems trust-
worthy, accountable, legally compliant, as well as security-
and privacy-aware, NLP has been largely applied also to legal
documents and privacy policies [31], in the field of
RE and Law. Finally, to support agile software development,
requirements expressed in the form of user stories have been
identified as an interesting area of application for NLP (32).

B. Machine Learning and Deep Learning for RE

Following the development of successful statistical NLP
methods based on ML in the 1990s [5], [33], ML techniques
have become increasingly important to NLP. The advantages of
the ML-based approaches over the traditional, rule-based NLP
approaches are effectiveness, considerable savings in terms of
expert manpower, and straightforward portability to different
domains [34].

In RE, the earliest adoption of ML to NLP can be traced
to a study by Cleland-Huang et al. (35), published in 2007,
in which the authors presented an approach for automati-
cally detecting and classifying non-functional requirements
(NFRs) from requirements documents. The approach uses a
set of weighted indicator terms to classify requirements; a
probability value of each indicator term is computed by a
probability function similar to Naive Bayes (36), to estimate
the likelihood of an input requirement being classified into a
certain NFR category. The development of this approach thus
marked the beginning of the work on ML-based approaches
for RE and, as a seminal work in this area, this approach has
been frequently used as the baseline to assess the performance
of new techniques [7], [37].

With the recent widespread availability of NL content
relevant to RE, such as feedback from users in app stores and
social media, and developers’ comments in discussion forums
and bug tracking systems, we have observed a rising interest
in using ML techniques to support data-driven RE and
crowd-based RE (39). These areas aim to leverage information

available from stakeholders’ implicit and explicit feedback,
including diverse sources as app reviews [40], issue tracking
systems (41), Twitter or user fora as improve RE
activities such as requirements elicitation and prioritization.
Most of the works use ML techniques, as these can be effec-
tively exploited when the task can be reduced to a classification
problem, and a large amount of data is available. The analysis
of different forms of feedback can be regarded as the main
trend of the last years in NLP4RE research (8).

However, several other RE tasks have profited from ML and
even DL techniques, for example: glossary extraction, with the
usage of unsupervised learning and convolutional neural
networks (45); requirements classification with the early works
from Casamayor et al. and developments from Kurtanovic
and Maalej [37]; requirements tracing (47). (48). which can be
regarded as the field where ML/DL have been more widely
experimented for traditional requirements, especially due to
the inherent nature of the problem, which entails finding
relevant relationship (i.e., trace links) within a large amount
of potential ones.

With the advent of DL and transfer learning in particular,
initial experiments have been carried out in RE with promising
results. In particular, DL-based approaches have been proposed
to classify software requirements into FR or NFR [49], to
discovery requirements from open source issue reports
and to extract and classify requirements from software project
contracts (51). We predict that research in developing DL-
based approaches for RE tasks will grow rapidly in the coming
years, overtaking the work on ML-based approaches.

III. METHOD

The main source of the literature used for our data collection
is the set of 404 NLP4RE studies identified in our systematic
review which covers the studies up to 2019. We then
performed a complementary targeted review to identify recent
publications, to find more recent techniques emerging in the
last 2 years. This complementary review focused on the major
RE and software engineering conferences (i.e., RE, REFSQ
and ICSE) and journals (i.e., REJ, JSS, ASE, DKE, IST,
and TSE). Based on this updated literature, we extract NLP
techniques.

To help us identify and extract NLP techniques from
each paper, we followed this definition: *An NLP technique
is a practical method, approach, process, or procedure for
performing a particular NLP task, such as POS tagging,
parsing or tokenizing (3).” Our data extraction resulted in a
large collection of diverse terms and phrases. To synthesize
different terms and phrases into a coherent set of standard
terms, we consulted many books written by NLP experts (e.g.,
(52)-(54)). This process gave rise to a total of 57 different
NLP techniques. Table |I| and Table |II] summarize these 57
techniques.

'The references of these papers are made available by Zhao ef al. at:
https://github.com/waadalhoshan/NLP4RE.


TABLE I
LIST OF NLP TECHNIQUES (PART 1)

ID Name Explanation

1 Part-of-Speech (POS) Tagging POS Tagging (or Tagging) processes a sequence of words, and attaches a POS tag to each word.
Parts of speech are also known as word classes or lexical categories.

2 Term Extraction The process of extracting the most relevant words and expressions from text. Related terms:
Keyword Extraction, Word Extraction

3 Keyword Searching The technique of finding strings that match a pattern. Related terms: Term Matching, Word
Matching

4 Chunking Chunking (or text chunking) is a type of shallow parsing that analyses a sentence by first
identifying its constituent parts (nouns, verbs, adjectives, etc.) and then links them to higher
order units that have discrete grammatical meanings (noun groups or phrases, verb groups, etc.).
Related term: Shallow Parsing.

5 Named Entity Recognition (NER) Subtask of information extraction that is based to find and classify named entities in a certain
text into pre-defined categories or class such as the names of persons, organizations, locations,
etc. Related terms: Entity Identification, Concept Extraction.

6 Semantic Role Labelling (SRL) The process of detecting the semantic arguments linked with the predicate or verb of a sentence
and their classification into their specific roles. Related Term: Semantic parsing, semantic trees,
shallow parsing, and shallow semantic analysis.

7 Temporal Tagging The task of finding phrases with temporal meaning within the context of a larger document.

8 Dependency Parsing Dependency parsing is the process of analyzing the grammatical structure of a sentence based on
the dependencies between the words in a sentence. Related terms: Syntactic Patterns, Syntactic
Structure

9 Constituency Parsing The process of analyzing the sentences by breaking down it into sub-phrases also known as
constituents. These sub-phrases belong to a specific category of grammar like NP (noun phrase)
and VP(verb phrase). Related terms: Phrase Parsing, Phrase Detection, Phrasal Verb Extraction

10 Link Grammar Builds relations between pairs of words, rather than constructing constituents in a phrase structure
hierarchy.

11 Semantic Parsing The task of converting a natural language utterance to a logical form: a machine-understandable
representation of its meaning.

12 Sentiment Analysis The process of computationally identifying and categorizing opinions expressed in a piece of
text

13 Text Annotation The practice and the result of adding a note or gloss to a text, which may include highlights or
underlining, comments, footnotes, tags, and links.

14 Semantic Annotation The process of attaching to a text document or other unstructured content, metadata about
concepts (e.g., people, places, organizations, products or topics) relevant to it.

15 Topic Modelling A type of statistical model for discovering the abstract ’topics” that occur in a collection of
documents

16 Summarization The practice of breaking down long publications into manageable paragraphs or sentences.
The procedure extracts important information while also ensuring that the paragraph’s sense
is preserved.

17 Latent Dirichlet Allocation (LDA) | The process of analysing relationships between a set of documents and the terms they contain
by producing a set of concepts related to the documents and terms.

18 Latent Semantic Indexing (LSD A mathematical practice that helps classify and retrieve information on particular key terms and
concepts using singular value decomposition (SVD). Related Term: Latent Semantic Analysis
(LSA)

19 Semantic Patterns Semantic patterns are generated based on common matching concepts. The top matching concepts
of each word are considered. One semantic pattern can relate to several concepts and a single
semantic clique can contain several semantic patterns.

20 Case Grammar A system of linguistic analysis, focusing on the link between the valence, or number of subjects,
objects, etc., of a verb and the grammatical context it requires.

21 Semantic Frames A coherent structure of concepts that are related such that without knowledge of all of them,
one does not have complete knowledge of one of the either.

22 Knowledge Graph A way of storing data that resulted from an information extraction task.

23 Bag-of-Words (BOW) A representation that turns arbitrary text into fixed-length vectors by counting how many times
each word appears. This process is often referred to as vectorization.

24 Word Frequency How often a word appears in a document, divided by how many words there are. Related Terms:
Term Frequency, Domain Term Frequency

25 Term Frequency-Inverse Document | A statistical measure that evaluates how relevant a word is to a document in a collection of

Frequency (TF-IDF) documents.

26 Co-location Analysis A Co-location is an expression consisting of two or more words that correspond to some
conventional way of saying things.

27 Term-Document Matrix A mathematical matrix that describes the frequency of terms that occur in a collection of
documents.

28 Character Counting Counts the number of characters in a line of text, page or group of text.

29 Concordance An alphabetical list of the words (especially the important ones) present in a text, usually with
citations of the passages in which they are found.

30 Cosine Similarity A metric used to measure how similar the documents are irrespective of their size.



TABLE II
LIST OF NLP TECHNIQUES (PART 2)

ID Name Explanation

31 Lexical Affinity Assigns to arbitrary words a probabilistic ’affinity’ for a particular category.

32 Similarity Distance Determines the minimum number of single character edits required to change one word to
another.

33 Document Similarity Computing the similarity between two text documents by transforming the input documents into
real-valued vectors.

34 Lexical Similarity Provides a measure of the similarity of two texts based on the intersection of the word sets of
same or different languages.

35 Regular Expression A special series of strings for describing a a text pattern for the purpose of searching or replacing
the described items.

36 Lexical Patterns Words or chuck of text that occurs in language with high frequency and the meaning of the
parts are sometime different than the meaning of the whole.

37 Generation Rules Generation rules to produce meaningful sentences in Natural Language.

38 Stemming A crude heuristic process that chops off the ends of words in the hope of achieving this goal
correctly most of the time, and often includes the removal of derivational affixes.

39 Lemmatization Use a vocabulary and morphological analysis of words, normally aiming to remove inflectional
endings only and to return the base or dictionary form of a word, which is known as the lemma.

40 Stop-Word Removal Words which are filtered out before or after processing of natural language data (text).

41 Noise Removal Removing characters digits and pieces of text that can interfere with your text analysis.

42 Punctuation Removal Removing puncuatations marks.

43 Lowercasing Converting all your data to lowercase helps in the process of preprocessing and in later stages
in the NLP application, when you are doing parsing.

44 Camel Case Splitting Split CamelCase string to individual strings.

45 Tokenization The process of breaking a stream of text into words, phrases, symbols, or other meaningful
tokens. Related terms: Word Segmentation

46 Sentence Segmentation Split a document into sentences, each containing a list of tokens. Related terms: Sentence
Splitting

47 n-gram A representation of a text using a sequence of N words or N characters (character n-gram),
where N can be any number. Thus we can have 1-gram (unigram), 2-gram (bigram), 3-gram
(trigram), etc.

48 Word Embedding One of the most popular technique to learn word embeddings using shallow neural network.
Word embeddings are vector representations of a particular word. Related terms: Word2Vec

49 Contextualized word embedding A neural model that learns a generic embedding function for variable length contexts of target
words. Related terms: Context2Vec

50 Sentence and document Embed- | A generalized word2vec method, for representing documents as a vector. Related term: Doc2Vec

ding

51 GloVe An alternative to word2vec for the representation of the distributed words.

52 FastText An alternative to word2vec, FastText represents each word as a bag of character n-gram.

53 Textual Entailment Recognition Deciding, given two text fragments, whether the meaning of one text is entailed (can be inferred)
from another text.

54 Homonym Detection Detecting the words that are pronounced the same as each other (e.g., ’maid” and ”made’’) or
have the same spelling (e.g., "lead weight” and to lead”).

55 Synonym Detection Finding a a word or phrase that means exactly or nearly the same as another word or phrase in
a text.

56 Coreference Resolution Finding all expressions that refer to the same entity in a discourse.

57 Anaphora Resolution Resolving what a pronoun, or a noun phrase refers to in a discourse.

IV. CLASSIFYING NLP TECHNIQUES BY TASKS e Syntactic Analysis: To analyze the syntactic structure

We first classify the NLP techniques based on their text pro-
cessing tasks. Figure [1] depicts the relationship between NLP
techniques, NLP tasks, NLP resources, and tools. We define a

NLP task as a piece of text processing work that can be done ‘

by means of one or more NLP techniques, supported by some
NLP tools and resources. A list of frequently performed NLP
tasks in RE are desribed below:

e Part-of-Speech (POS) Tagging: To associate words

with part-of-speech (POS) tags to distinguish between :

nouns, verbs, adjectives, adverbs, etc. The input unit is a
sentence, as context words (i.e., neighbouring ones) are

normally used to infer the POS of a word. °

e Semantic Tagging: To extract useful bits of information
(words, terms, relations, etc.) from the text.

of a sentence to represent the relationship between its
components. Different representation structures can be
used, such as the parse tree, or the dependency parsing
graph.

Semantic Analysis: To identify and label semantically
relevant components and relations in the text. These
entails identifying the meaning of a certain word or
phrase in a context and the relationship between words
or terms.

Frequency Analysis: To analyze the frequencies of
words or terms in a certain context and to produce
probabilistic data.

Similarity Analysis: To calculate the numerical estimates
of similarity between text elements, for example to iden-
tify semantic relatedness, synonyms, or to support topic


_ NLP Techniques
f \
/ \
/ use \
perform
NLP Tools NLP Tasks

— NLP Resources }«—

Fig. 1. Relationship between NLP techniques and NLP Tasks.

modelling.

e Rule-Based Analysis: To use grammar rules, semantic
rules or patterns to analyse the syntax of a text.

e Text Normalization: To convert the words into their orig-
inal form and remove unnecessary words or characters
from the text.

e Text Segmentation: To break down a text into a sequence
of individual sentences or words.

e Text Normalization: To reduce the words to a stan-
dardised format, with the removal of stop words, and
reduction of typographical forms (e.g., upper case, camel
case) to a unique form.

Table [Il] presents the classification results of the NLP
techniques for RE based on these tasks.

V. CLASSIFYING NLP TECHNIQUES BY LINGUISTIC
ANALYSIS LEVELS

Here, we classify the NLP techniques by levels of linguistic
analysis. According to Liddy (55). linguistic analysis can be
performed at the following seven levels:

Phonology. This level deals with the interpretation of
speech sounds within and across words.

Morphology. This is the lowest level of text analysis. At
this level, a NLP technique analyzes the smallest parts of
words that carry meaning, which are composed of morphemes,
including prefixes, roots and suffixes of words.

Lexical. A NLP technique at this level can interpret the
meaning of individual words to gain word-level understanding
(55). Lexical analysis may require a lexicon or dictionary,
which may be quite simple, with only the words and their POS
tags, or may be increasingly complex and contain information
on the semantic class of the word, its arguments etc. [55}.

Syntactic. A NLP technique at this level focuses on an-
alyzing the words in a sentence through the grammatical
structure of the sentence. This requires both a grammar
and a parser (55). There are two general types of parser:
dependency and constituency (52). The dependency parser
produces a syntactic representation of a sentence based on the
dependencies between the words in the sentence, whereas the
constituency parser represents a sentence as a parse tree of

related constituents (i.e., sub-phrases). These representations
(i.e., syntax) carry meaning in most languages, because the the
arrangement of words or sub-phrases in a sentence contributes
to meaning [55].

Semantic. A NLP technique at this level may focus on
the meanings of individual words (e.g., dictionary definitions
of words and word-sense disambiguation), or compositional
semantics, which looks at the interactions among word-level
meanings in sentences (e.g., semantic role labeling). Semantic
analysis thus can be divided into word-level semantic and
sentence-level semantic (groups of words or sentence-level).
Semantic role labelling and Case Grammar [57], are
among the examples of semantic analysis techniques.

Discourse. A NLP technique at this level focuses on the
properties of the text as a whole that convey meaning by
making connections between component sentences. Several
types of discourse processing can occur at this level, two of
the most common being anaphora resolution and coreference
resolution (55).

Pragmatic. This is the highest level of NLP. To reach this
level, NLP techniques need to be able to achieve human-like
language understanding, the ultimate goal of natural language
understanding (NLU). This entails inferring extra meaning
from texts that is not actually encoded in them [55] and
understanding narratives according to different contexts and
with respect to different actors and their intentions (33). This
requires NLP tools to have world knowledge and human
intelligence, and the ability to project semantics and sentics
dynamically (33). Pragmatic analysis appears to be the most
challenging NLP curve to jump (33).

It is assumed that humans normally produce or comprehend
language by utilizing all of these levels [59]. These levels thus
represent the competence of a NLP tool: The more levels of
analysis the tool supports, the stronger or more capable the
tool; the more higher-levels of analysis the tool supports, the
more advance the tool.

Table|[V]classifies the NLP techniques based on these levels.
As the table shows, we have not found any techniques for the
phonetic level analysis, as NLP techniques have been largely
use to deal with texts (including requirements documents [60],
app reviews, tweets, social media posts and usage ath
(9). (38), (61), (62), legal documents (30), and privacy poli-
cies [31]). In addition, we have not found any techniques for
pragmatic analysis either. This is because NLP4RE research
has so far focused on text processing of documents and has not
reached the level of natural language understanding (NLU).

VI. CONCLUSION

This paper presents 57 commonly used NLP techniques in
RE and organizes them in two different ways: by their NLP
tasks and by their analysis levels. The organization provides
a knowledge base for sharing these techniques. A user of this
knowledge base can query each NLP technique progressively:
Through Table [Ijand Table [I]| the user can ask: What technique
is it? Does it work at the word-level or sentence-level of
text processing? Based on Table [IT] the user can ask: Which


TABLE III

CLASSIFYING NLP TECHNIQUES BY TASKS.

NLP Tasks

Explanation

NLP Techniques

Part-of-Speech Tagging

Associate words with part-of-speech (POS) tags
to distinguish between nouns, verbs, adjectives,
adverbs, etc.

Part-of-Speech (POS) Tagging

Semantic Tagging

Extract useful bits of information (words, terms,
relations, etc.) from the text.

Term Extraction, Term Matching, Chunking, Concept Extrac-
tion, Named Entity Recognition (NER), Semantic Role Labelling
(SRL), Temporal Tagging

Syntactic Analysis

Construct a syntactic structure representing the
relationship between the logical components in
a stream of text, such as the parse tree, or the
dependency parsing graph.

Dependency Parsing, Constituency Parsing, Link Grammar

Semantic Analysis

Identify and label semantically relevant compo-
nents and relations in the text.

Semantic Parsing, Sentiment Analysis, Text Annotation, Semantic
Annotation, Topic Modelling, Summarization, Latent Dirichlet
Allocation (LDA), Latent Semantic Indexing (LSI), Semantic
Patterns, Case Grammar, Semantic Frames, Knowledge Graph,
Textual Entailment Recognition (TER), Homonym Detection,
Synonym Detection, Coreference Resolution, Anaphora Resolu-
tion

Frequency Analysis

Analyse the frequency of occurrence of lexical
elements (e.g., words and characters) and groups
of elements (e.g., phrases and multiwords) in a
given text.

Bag-of-Words (BOW), Word Frequency, Term Frequency (TF),
Term Frequency & Inverse Document Frequency (TF-IDF), Co-
location Analysis, Term-Document Matrix, Character Counting,
Concordance

Similarity Analysis

Calculate numerical values of the similarity be-
tween text elements, such as to identify semantic
relatedness.

Cosine Similarity, Lexical Affinity, Similarity Distance, Document
Similarity, Lexical Similarity

Rule-Based Analysis

Use rules or patterns to analyse the syntax or
semantics of a text or transform the text.

Regular Expression, Lexical Patterns, Generation Rules

Text Normalization

Convert the words into their original form and
remove unnecessary words or characters from
the text.

Stemming, Lemmatization, Stop-Word Removal, Noise Removal,
Punctuation Removal, Lowercasing, Camel Case Splitting

Text Segmentation

Break down a text into a sequence of individual
tokens (i.e., words or sentences).

Tokenization, Sentence Segmentation

Text Representation

Represent words, sentences or documents using

vectors of real numbers.

N-gram, Word2Vec, Context2Vec, Doc2Vec, GloVe, FastText

text processing task does this technique support? What are [3
the alternative techniques for the same task? From Table
the user can ask: What level of language analysis does this 14
technique provide? What are the techniques for performing
other levels of analysis? The answers to these questions can
help the user to decide if a specific technique is relevant to 15

the task at hand.

Our future work will improve this knowledge base as [6

follows:

[1]

quirements Engineering.

[7]
e To show the relationship between a given technique and
other techniques. For example, for text normalization, 8]
what techniques can I use together? in what order? For .
text representation, which technique is better for my case?
To provide information on the available NLP tools that 5]
support each technique. .
REFERENCES [10]
K. Ryan, “The role of natural language in requirements engineering,”
in [1993] Proceedings of the IEEE International Symposium on Re-
IEEE, 1993, pp. 240-242.
P. Sawyer, P. Rayson, and K. Cosh, “Shallow knowledge as an aid {11]

[2]

to deep understanding in early phase requirements engineering,” [EEE
Transactions on Software Engineering, vol. 31, no. 11, pp. 969-981,
2005.

V. Berzins, C. Martell, P. Adams et al., “Innovations in natural lan-
guage document processing for requirements engineering,” in Monterey
Workshop. Springer, 2007, pp. 125-146.

D. Berry, R. Gacitua, P. Sawyer, and S. F. Tjong, “The case for dumb re-
quirements engineering tools,” in International Working Conference on
Requirements Engineering: Foundation for Software Quality. Springer,
2012, pp. 211-217.

J. Hirschberg and C. D. Manning, “Advances in natural language
processing,” Science, vol. 349, no. 6245, pp. 261-266, 2015.

G. Goth, “Deep or shallow, nlp is breaking out,’ Communications of
the ACM, vol. 59, no. 3, pp. 13-16, 2016.

F. Dalpiaz, A. Ferrari, X. Franch, and C. Palomares, “Natural language
processing for requirements engineering: The best is yet to come,”
IEEE software, vol. 35, no. 5, pp. 115-119, 2018.

L. Zhao, W. Alhoshan, A. Ferrari, K. J. Letsholo, M. A. Ajagbe, E.-
V. Chioasca, and R. T. Batista-Navarro, “Natural language processing
(nlp) for requirements engineering (re): A systematic mapping study,”
ACM Computing Surveys, in press, 2021.

A. Ferrari, F. Dell’Orletta, A. Esuli, V. Gervasi, and S. Gnesi, ““Nat-
ural language requirements processing: a 4D vision,’ IEEE Software,
vol. 34, no. 06, pp. 28-35, 2017.

D. M. Berry, “Evaluation of tools for hairy requirements and software
engineering tasks,” in 2017 IEEE 25th International Requirements
Engineering Conference Workshops (REW). EEE, 2017, pp. 284—
291.

P. P-S. Chen, “English sentence structure and entity-relationship
diagrams,” Information Sciences, vol. 29, no. 2, pp. 127-149, 1983.

[Online]. Available: |https://www.sciencedirect.com/science/article/pii
0020025583900142


TABLE IV

CLASSIFYING NLP TECHNIQUES BY LEVELS OF ANALYSIS.

Analysis Level

Explanation

NLP Techniques

Morphology

This is the lowest level of text analysis, dealing with the smallest
parts of words that carry meaning. All the techniques used for
text normalization belong to this category.

Stemming, Lemmatization, Stop-Word Removal, Noise Re-
moval, Punctuation Removal, Lowercasing, Camel Case Split-
ting

Lexical

This is the word-level of text analysis, interpreting the meaning
of individual words to gain word-level understanding. All the
techniques used for frequency analysis belong to this category. In
addition, Tokenization and n-gram should also be in this category.

BOW, TF, TF-IDF, Co-location Analysis, Term-Document
Matrix, Character Counting, Concordance, n-gram

Syntactic

This level focuses on analyzing the words in a sentence through
the grammatical structure of the sentence. All the techniques used
for syntactic analysis belong to this category. In addition, the
techniques used for text segmentation and Regular Expression for
Rule-Based Analysis should also belong to this category.

POS Tagging, Dependency Parsing, Constituency Parsing,
Link Grammar, Regular Expression, Tokenization, Sentence
Segmentation

Semantic
(Word-Level)

We split the semantic level into word-level semantic and sentence-
level semantic. The word-level semantic focuses on the meanings
of individual words (e.g., dictionary definitions of words and
word-sense disambiguation). Most techniques used for semantic
tagging and similarly analysis belong to this level. In addition,
apart from n-gram, the techniques used for text representation
belong to this category.

Term Extraction, Keyword Searching, Chunking, NER, Tem-
poral Tagging, Lexical Patterns, Cosine Similarity, Lexical
Affinity, Similarity Distance, Document Similarity, Lexical
Similarity, Word2Vec, Context2Vec, Doc2Vec, GloVe, Fast-
Text

Semantic
(Sentence-Level)

This level deals with the compositional semantics, which looks
at the interactions among word-level meanings in sentences (e.g.,
semantic role labeling). Most techniques used for semantic analy-
sis belong to this category. In addition, SRL and most techniques
for disambiguation should also belong to this category.

Semantic Parsing, Sentiment Analysis, Text Annotation, Se-
mantic Annotation, Topic Modelling, SRL, Summarization,
LDA, LSI, Semantic Patterns, Case Grammar, Semantic
Frames, Knowledge Graph, TER, Homonym Detection, Syn-
onymy Detection

Discourse

This level focuses on the properties of the text as a whole
that convey meaning by making connections between component

Coreference Resolution, Anaphora Resolution, Generation
Rules

sentences. Only three techniques belong to this category.

[12] R. J. Abbott, “Program design by informal english descriptions,”

Communications of the ACM, vol. 26, no. 11, pp. 882-894, 1983.

D. M. Berry, N. Yavne, and M. Yavne, “Application of program
design language tools to abbott’s method of program design by
informal natural language descriptions,’ Journal of Systems and
Software, vol. 7, no. 3, pp. 221-247, 1987. [Online]. Available:
https://www.sciencedirect.com/science/article/pii/0 164 121287900446

(13)

[14] G. Booch, R. A. Maksimchuk, M. W. Engle, B. J. Young, J. Connallen,
and K. A. Houston, “Object-oriented analysis and design with applica-
tions,” ACM SIGSOFT software engineering notes, vol. 33, no. 5, pp.
29-29, 2008.

C. Aguilera and D. M. Berry, “The use of a repeated phrase
finder in requirements extraction,” Journal of Systems and Software,
vol. 13, no. 3, pp. 209-230, 1990. [Online]. Available:
//www.sciencedirect.com/science/article/pii/0164 121290900976

C. Rolland and C. Proix, “A natural language approach for requirements
engineering,” in International Conference on Advanced Information
Systems Engineering. Springer, 1992, pp. 257-277.

L. Goldin and D. M. Berry, “Abstfinder, a prototype natural language
text abstraction finder for use in requirements elicitation,’ Automated
Software Engineering, vol. 4, no. 4, pp. 375-412, 1997.

L. Mich, “Nl-oops: from natural language to object oriented require-
ments using the natural language processing system lolita,’ Natural
language engineering, vol. 2, no. 2, pp. 161-187, 1996.

V. Ambriola and V. Gervasi, “On the systematic analysis of natural
language requirements with Circe,’ Automated Software Engineering,
vol. 13, no. 1, pp. 107-167, 2006.

H. M. Harmain and R. Gaizauskas, ““Cm-builder: an automated nl-based
case tool,’ in Proceedings ASE 2000. Fifteenth IEEE International
Conference on Automated Software Engineering. _YEEE, 2000, pp.
45-53.

F. Fabbrini, M. Fusani, S. Gnesi, and G. Lami, “The linguistic approach
to the natural language requirements quality: benefit of the use of an
automatic tool,” in Proceedings 26th Annual NASA Goddard Software
Engineering Workshop. YEEE, 2001, pp. 97-105.

W. M. Wilson, L. H. Rosenberg, and L. E. Hyatt, “Automated analysis

{15]

[16]

[17]

[18]

[19]

[20]

[21]

[22]

[23]

[24]

[25]

[26]

[27]

[28]

[29]

[30]

[31]

[32]

of requirement specifications,” in Proceedings of the 19th international
conference on Software engineering, 1997, pp. 161-171.

J. H. Hayes, A. Dekhtyar, and J. Osborne, “Improving requirements
tracing via information retrieval,” in Proceedings. 11th IEEE Interna-
tional Requirements Engineering Conference, 2003. YEEE, 2003, pp.
138-147.

J. Cleland-Huang, B. Berenbach, S. Clark, R. Settimi, and E. Ro-
manova, “Best practices for automated traceability,’ Computer, vol. 40,
no. 6, pp. 27-35, 2007.

S. F. Tjong and D. M. Berry, “The design of sree—a prototype potential
ambiguity finder for requirements specifications and lessons learned,”
in International Working Conference on Requirements Engineering:
Foundation for Software Quality. Springer, 2013, pp. 80-95.

T. Yue, L. C. Briand, and Y. Labiche, “atoucan: an automated frame-
work to derive uml analysis models from use case models,’ ACM
Transactions on Software Engineering and Methodology (TOSEM),
vol. 24, no. 3, pp. 1-52, 2015.

A. Ferrari, G. Gori, B. Rosadini, I. Trotta, S. Bacherini, A. Fantechi,
and S. Gnesi, “Detecting requirements defects with nlp patterns:
an industrial experience in the railway domain,’ Empirical Software
Engineering, vol. 23, no. 6, pp. 3684-3733, 2018.

H. Femmer, D. M. Fernandez, S. Wagner, and S. Eder, “Rapid quality
assurance with requirements smells,” Journal of Systems and Software,
vol. 123, pp. 190-213, 2017.

D. Falessi, G. Cantone, and G. Canfora, “Empirical principles and an
industrial case study in retrieving equivalent requirements via natu-
ral language processing techniques,” IEEE Transactions on Software
Engineering, vol. 39, no. 1, pp. 18-44, 2011.

A. Sleimi, N. Sannier, M. Sabetzadeh, L. Briand, and J. Dann, “Au-
tomated extraction of semantic legal metadata using natural language
processing,” in 2018 IEEE 26th International Requirements Engineer-
ing Conference (RE). QEEE, 2018, pp. 124-135.

J. Bhatia, T. D. Breaux, and F. Schaub, “Mining privacy goals from
privacy policies using hybridized task recomposition,’ ACM Transac-
tions on Software Engineering and Methodology (TOSEM), vol. 25,
no. 3, pp. 1-24, 2016.

M. Robeer, G. Lucassen, J. M. E. Van Der Werf, F. Dalpiaz, and


[33]

[34]

[35]

[36]

[37]

[38]

[39]

[40]

[41]

[42]

[43]

[44]

[45]

[46]

[47]

[48]

[49]

[50]

[51]

[52]

[53]

S. Brinkkemper, “Automated extraction of conceptual models from
user stories via nlp,” in 2016 IEEE 24th international requirements
engineering conference (re). YEEE, 2016, pp. 196—205.

E. Cambria and B. White, “Jumping nlp curves: A review of natural
language processing research,” IEEE Computational intelligence mag-
azine, vol. 9, no. 2, pp. 48-57, 2014.

F. Sebastiani, “Machine learning in automated text categorization,”
ACM computing surveys (CSUR), vol. 34, no. 1, pp. 1-47, 2002.

J. Cleland-Huang, R. Settimi, X. Zou, and P. Solc, “Automated clas-
sification of non-functional requirements,” Requirements engineering,
vol. 12, no. 2, pp. 103-120, 2007.

D. D. Lewis, “Naive (bayes) at forty: The independence assumption in
information retrieval,’ in European conference on machine learning.
Springer, 1998, pp. 4-15.

Z. Kurtanovi¢é and W. Maalej, “Automatically classifying functional
and non-functional requirements using supervised machine learning,”
in 2017 IEEE 25th International Requirements Engineering Conference
(RE). Ieee, 2017, pp. 490-495.

W. Maalej, M. Nayebi, T. Johann, and G. Ruhe, “Toward data-driven
requirements engineering,” JEEE Software, vol. 33, no. 1, pp. 48-54,
2015.

E. C. Groen, N. Seyff, R. Ali, F. Dalpiaz, J. Doerr, E. Guzman, M. Hos-
seini, J. Marco, M. Oriol, A. Perini et al., “The crowd in requirements
engineering: The landscape and challenges,” JEEE software, vol. 34,
no. 2, pp. 44-52, 2017.

W. Maalej, Z. Kurtanovi¢, H. Nabil, and C. Stanik, “On the automatic
classification of app reviews,” Requirements Engineering, vol. 21, no. 3,
pp. 311-331, 2016.

T. Merten, M. Falis, P. Hiibner, T. Quirchmayr, S. Biirsner, and
B. Paech, “Software feature request detection in issue tracking sys-
tems,” in 2016 IEEE 24th International Requirements Engineering
Conference (RE). EEE, 2016, pp. 166-175.

E. Guzman, M. Ibrahim, and M. Glinz, “A little bird told me: Mining
tweets for requirements and software evolution,” in 2017 IEEE 25th
International Requirements Engineering Conference (RE). IEEE,
2017, pp. 11-20.

I. Morales-Ramirez, F. M. Kifetew, and A. Perini, “Speech-acts based
analysis for requirements discovery from online discussions,” Informa-
tion Systems, vol. 86, pp. 94-112, 2019.

C. Arora, M. Sabetzadeh, L. Briand, and F. Zimmer, “Automated
extraction and clustering of requirements glossary terms,’ IEEE Trans-
actions on Software Engineering, vol. 43, no. 10, pp. 918-945, 2016.
J. Winkler and A. Vogelsang, “Automatic classification of requirements
based on convolutional neural networks,’ in 2016 IEEE 24th In-
ternational Requirements Engineering Conference Workshops (REW).
IEEE, 2016, pp. 39-45.

A. Casamayor, D. Godoy, and M. Campo, “Identification of non-
functional requirements in textual specifications: A semi-supervised
learning approach,” Information and Software Technology, vol. 52,
no. 4, pp. 436-445, 2010.

J. Guo, J. Cheng, and J. Cleland-Huang, “Semantically enhanced soft-
ware traceability using deep learning techniques,” in 2017 IEEE/ACM
39th International Conference on Software Engineering (ICSE). TEEE,
2017, pp. 3-14.

H. Sultanov and J. H. Hayes, “Application of reinforcement learning
to requirements engineering: requirements tracing,” in 20/3 2/st IEEE
International Requirements Engineering Conference (RE). TEEE,
2013, pp. 52-61.

T. Hey, J. Keim, A. Koziolek, and W. F. Tichy, “NoRBERT: Transfer
learning for requirements classification,’ in 2020 IEEE 28th Interna-
tional Requirements Engineering Conference (RE). YEEE, 2020, pp.
169-179.

M. Li, L. Shi, Y. Yang, and Q. Wang, “A deep multitask learning
approach for requirements discovery and annotation from open forum,”
in 2020 35th IEEE/ACM International Conference on Automated
Software Engineering (ASE). EEE, 2020, pp. 336-348.

S. Gonzalez-Carvajal and E. C. Garrido-Merchan, “Comparing bert
against traditional machine learning text classification,” arXiv preprint
arXiv:2005.13012, 2020.

D. Jurafsky, Speech & language processing. Pearson Education India,
2000.

S. Bird, E. Klein, and E. Loper, Natural language processing with
Python: analyzing text with the natural language toolkit. ” O'Reilly
Media, Inc.”, 2009.

[54]
[55]

[56]

[57]

[58]

[59]

[60]

[61]

[62]

[63]

[64]

[65]

[66]

[67]

[68]

[69]

[70]

[71]

[72]

[73]

[74]

[75]

[76]

[77]

D. Sarkar, Text Analytics with python. Springer, 2016.

E. D. Liddy, “Natural language processing,” in Encyclopedia of Library
and Information Science. NY. Marcel Decker, Inc., 2001.

D. Gildea and D. Jurafsky, “Automatic labeling of semantic roles,”
Computational linguistics, vol. 28, no. 3, pp. 245-288, 2002.

C. J. Fillmore et al., “Frame semantics and the nature of language,”
in Annals of the New York Academy of Sciences: Conference on the
origin and development of language and speech, vol. 280, no. 1. New
York, 1976, pp. 20-32.

C. J. Fillmore, M. R. Petruck, J. Ruppenhofer, and A. Wright,
“Framenet in action: The case of attaching,” International journal of
lexicography, vol. 16, no. 3, pp. 297-332, 2003.

G. G. Chowdhury, “Natural language processing,’ Annual review of
information science and technology, vol. 37, no. 1, pp. 51-89, 2003.
A. Ferrari, G. O. Spagnolo, and S. Gnesi, “Pure: A dataset of public re-
quirements documents,” in 2017 IEEE 25th International Requirements
Engineering Conference (RE). YEEE, 2017, pp. 502-505.

A. Ferrari, L. Zhao, and W. Alhoshan, “‘NIp for requirements engineer-
ing: Tasks, techniques, tools, and technologies,” in Proceedings of the
43rd IEEE/ACM International Conference on Software Engineering.
IEEE, 2021.

W. Maalej, M. Nayebi, and G. Ruhe, “Data-driven requirements
engineering-an update,” in 20/9 IEEE/ACM 41st International Con-
ference on Software Engineering: Software Engineering in Practice
(ICSE-SEIP). YEEE, 2019, pp. 289-290.

I. Tenney, D. Das, and E. Pavlick, “Bert rediscovers the classical nlp
pipeline,” arXiv preprint arXiv:1905.05950, 2019.

M. Nayebi, “Eye of the mind: image processing for social coding,”
in Proceedings of the ACM/IEEE 42nd International Conference on
Software Engineering: New Ideas and Emerging Results, 2020, pp.
49-52.

A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.
Gomez, L. Kaiser, and I. Polosukhin, “Attention is all you need,” arXiv
preprint arXiv:1706.03762, 2017.

F. Movahedi, J. L. Coyle, and E. Sejdi¢, “Deep belief networks for
electroencephalography: A review of recent contributions and future
outlooks,” IEEE journal of biomedical and health informatics, vol. 22,
no. 3, pp. 642-652, 2017.

Y. Yu, M. Li, L. Liu, Y. Li, and J. Wang, “Clinical big data and
deep learning: Applications, challenges, and future outlooks,” Big Data
Mining and Analytics, vol. 2, no. 4, pp. 288-305, 2019.

S. Cornegruta, R. Bakewell, S. Withey, and G. Montana, “Modelling
radiological language with bidirectional long short-term memory net-
works,” arXiv preprint arXiv: 1609.08409, 2016.

Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” nature, vol. 521,
no. 7553, pp. 436-444, 2015.

X. Deng, Y. Li, J. Weng, and J. Zhang, “Feature selection for text
classification: A review,” Multimedia Tools and Applications, vol. 78,
no. 3, pp. 3797-3816, 2019.

A. K. Uysal and S. Gunal, “The impact of preprocessing on text
classification,’ Information Processing & Management, vol. 50, no. 1,
pp. 104-112, 2014.

Y. Wang, L. Shi, M. Li, Q. Wang, and Y. Yang, “A deep context-wise
method for coreference detection in natural language requirements,” in
2020 IEEE 28th International Requirements Engineering Conference
(RE). IEEE, 2020, pp. 180-191.

A. Sainani, P. R. Anish, V. Joshi, and S. Ghaisas, “Extracting and
classifying requirements from software engineering contracts,” in 2020
IEEE 28th International Requirements Engineering Conference (RE).
IEEE, 2020, pp. 147-157.

S. J. Pan and Q. Yang, “A survey on transfer learning,’ JEEE Transac-
tions on knowledge and data engineering, vol. 22, no. 10, pp. 1345-
1359, 2009.

C. C. Aggarwal and C. Zhai, “A survey of text classification algo-
rithms,” in Mining text data. Springer, 2012, pp. 163-222.

F. Pereira, T. Mitchell, and M. Botvinick, “Machine learning classifiers
and fmri: a tutorial overview,’ Neuroimage, vol. 45, no. 1, pp. S199-
$209, 2009.

R. Wagland, A. Recio-Saucedo, M. Simon, M. Bracher, K. Hunt,
C. Foster, A. Downing, A. Glaser, and J. Corner, “Development and
testing of a text-mining approach to analyse patients’ comments on
their experiences of colorectal cancer care,’ BMJ quality & safety,
vol. 25, no. 8, pp. 604-614, 2016.


[78]

[79]

[80]

[81]

[82]

[83]

[84]

[85]

[86]

[87]

[88]

[89]

[90]

[91]

[92]

[93]

[94]

[95]

[96]

[97]

K. Shameer, K. W. Johnson, B. S. Glicksberg, J. T. Dudley, and P. P.
Sengupta, “Machine learning in cardiovascular medicine: are we there
yet?” Heart, vol. 104, no. 14, pp. 1156-1164, 2018.

M. Li, Y. Yang, L. Shi, Q. Wang, J. Hu, X. Peng, W. Liao, and
G. Pi, “Automated extraction of requirement entities by leveraging
Istm-crf and transfer learning,” in 2020 IEEE International Conference
on Software Maintenance and Evolution (ICSME). EEE, 2020, pp.
208-219.

C. Palomares, C. Quer, and X. Franch, “Requirements reuse and
requirement patterns: a state of the practice survey,” Empirical Software
Engineering, vol. 22, no. 6, pp. 2719-2762, 2017.

C. Arora, M. Sabetzadeh, A. Goknil, L. C. Briand, and F. Zimmer,
“Change impact analysis for natural language requirements: An nlp
approach,” in 2015 IEEE 23rd International Requirements Engineering
Conference (RE). EEE, 2015, pp. 6-15.

S. Ezzini, S. Abualhaija, C. Arora, M. Sabetzadeh, and L. Briand,
“Using domain-specific corpora for improved handling of ambiguity in
requirements,” in In Proceedings of the 43rd International Conference
on Software Engineering (ICSE’21), Madrid 25-28 May 2021, 2021.

C. Boufaied, M. Jukss, D. Bianculli, L. C. Briand, and Y. I. Parache,
“Signal-based properties of cyber-physical systems: Taxonomy and
logic-based characterization,’ Journal of Systems and Software, vol.
174, p. 110881, 2021.

W. Martin, F. Sarro, Y. Jia, Y. Zhang, and M. Harman, “A survey of app
store analysis for software engineering,” [EEE transactions on software
engineering, vol. 43, no. 9, pp. 817-847, 2016.

E. Guzman, L. Oliveira, Y. Steiner, L. C. Wagner, and M. Glinz,
“User feedback in the app store: a cross-cultural study,’ in 20/8
IEEE/ACM 40th International Conference on Software Engineering:
Software Engineering in Society (ICSE-SEIS). TEEE, 2018, pp. 13-
22.

C. Stanik, M. Haering, and W. Maalej, “Classifying multilingual user
feedback using traditional machine learning and deep learning,” in
2019 IEEE 27th International Requirements Engineering Conference
Workshops (REW). YEEE, 2019, pp. 220-226.

G. Lucassen, M. Robeer, F. Dalpiaz, J. M. E. Van Der Werf, and
S. Brinkkemper, “Extracting conceptual models from user stories with
visual narrator,’ Requirements Engineering, vol. 22, no. 3, pp. 339-358,
2017.

A. Khan, B. Baharudin, L. H. Lee, and K. Khan, “A review of
machine learning algorithms for text-documents classification,” Journal
of advances in information technology, vol. 1, no. 1, pp. 4-20, 2010.
P. H. Swain and H. Hauska, “The decision tree classifier: Design and
potential,’ JEEE Transactions on Geoscience Electronics, vol. 15, no. 3,
pp. 142-147, 1977.

G. Forman et al., “An extensive empirical study of feature selection
metrics for text classification.” J. Mach. Learn. Res., vol. 3, no. Mar,
pp. 1289-1305, 2003.

C. Cortes and V. Vapnik, “Support-vector networks,” Machine learning,
vol. 20, no. 3, pp. 273-297, 1995.

J. Natt och Dag, B. Regnell, P. Carlshamre, M. Andersson, and
J. Karlsson, “A Feasibility Study of Automated Natural Language
Requirements Analysis in Market-Driven Development,” Requirements
Engineering, vol. 7, no. 1, pp. 20-33, Apr. 2002. [Online]. Available:

https://doi.org/10.1007/s007660200002

B. Gleich, O. Creighton, and L. Kof, “Ambiguity detection: Towards a
tool explaining ambiguity sources,” in International Working Confer-
ence on Requirements Engineering: Foundation for Software Quality.
Springer, 2010, pp. 218-232.

J. Brownlee, “Deep learning and time series forecasting:
Machine learning mastery,”
201
online; accessed 17 August 2020.

T. Hastie, R. Tibshirani, and J. Friedman, “Overview of supervised
learning,” in The elements of statistical learning. Springer, 2009, pp.
9-41.

F. Dalpiaz, D. Dell’Anna, F. B. Aydemir, and S. Cevikol, “Re-
quirements classification with interpretable machine learning and de-
pendency parsing,’ in 2019 IEEE 27th International Requirements
Engineering Conference (RE). YEEE, 2019, pp. 142-152.

B. Pang, L. Lee, and S. Vaithyanathan, “Thumbs up? sentiment classifi-
cation using machine learning techniques,” arXiv preprint cs/0205070,
2002.

[98] K. Dave, S. Lawrence, and D. M. Pennock, “Mining the peanut gallery:
Opinion extraction and semantic classification of product reviews,” in
Proceedings of the 12th international conference on World Wide Web,
2003, pp. 519-528.

N. K. Conroy, V. L. Rubin, and Y. Chen, “Automatic deception detec-
tion: Methods for finding fake news,” Proceedings of the Association
for Information Science and Technology, vol. 52, no. 1, pp. 1-4, 2015.
J. A. Sidey-Gibbons and C. J. Sidey-Gibbons, “Machine learning in
medicine: a practical introduction,’ BMC medical research methodol-
ogy, vol. 19, no. 1, pp. 1-18, 2019.

A. Agarwal, M. Mittal, A. Pathak, and L. M. Goyal, “Fake news
detection using a blend of neural networks: an application of deep
learning,’ SN Computer Science, vol. 1, no. 3, pp. 1-9, 2020.

W. Jin, H. H. Ho, and R. K. Srihari, “Opinionminer: a novel machine
learning system for web opinion mining and extraction,” in Proceedings
of the 15th ACM SIGKDD international conference on Knowledge
discovery and data mining, 2009, pp. 1195-1204.

J. Harding, Qualitative data analysis: From start to finish. Sage, 2018.
B. Kitchenham and S. Charters, “Guidelines for performing systematic
literature reviews in software engineering,” 2007.

F. Fabbrini, M. Fusani, S. Gnesi, and G. Lami, “An automatic quality
evaluation for natural language requirements,” in Proceedings of the
Seventh International Workshop on Requirements Engineering: Foun-
dation for Software Quality REFSQ, vol. 1, 2001, pp. 4-5.

S. Abualhaija, C. Arora, M. Sabetzadeh, L. C. Briand, and E. Vaz,
“A machine learning-based approach for demarcating requirements in
textual specifications,” in 20/9 IEEE 27th International Requirements
Engineering Conference (RE). YEEE, 2019, pp. 51-62.

N. H. Bakar, Z. M. Kasirun, and N. Salleh, “Feature extraction
approaches from natural language requirements for reuse in software
product lines: A systematic literature review,” Journal of Systems and
Software, vol. 106, pp. 132-149, 2015.

R. Santos, E. C. Groen, and K. Villela, “An overview of user feedback
classification approaches,” in Joint Proceedings of REFSQ-2019
Workshops, Doctoral Symposium, Live Studies Track, and Poster Track
co-located with the 25th International Conference on Requirements
Engineering: Foundation for Software Quality (REFSQ 2019), Essen,
Germany, March 18th, 2019, ser. CEUR Workshop Proceedings,
P. Spoletini, P. Mader, D. M. Berry, F. Dalpiaz, M. Daneva,
A. Ferrari, X. Franch, S. Gregory, E. C. Groen, A. Herrmann,
A. Hess, F. Houdek, O. Karras, A. Koziolek, K. Lauenroth,
C. Palomares, M. Sabetzadeh, N. Seyff, M. Trapp, A. Vogelsang, and
T. Weyer, Eds., vol. 2376. CEUR-WS.org, 2019. [Online]. Available:
C. EF. Baker, C. J. Fillmore, and J. B. Lowe, “The berkeley framenet
project,” in 36th Annual Meeting of the Association for Computational
Linguistics and 17th International Conference on Computational Lin-
guistics, Volume I, 1998, pp. 86-90.

C. J. Fillmore, C. R. Johnson, and M. R. Petruck, “Background to
framenet,” International journal of lexicography, vol. 16, no. 3, pp.
235-250, 2003.

N. Yu, M. Zhang, and G. Fu, “Transition-based neural rst parsing
with implicit syntax features,” in Proceedings of the 27th International
Conference on Computational Linguistics, 2018, pp. 559-570.

A. Ferrari, G. Lipari, S. Gnesi, and G. O. Spagnolo, “Pragmatic
ambiguity detection in natural language requirements,” in 20/4 IEEE
Ist International Workshop on Artificial Intelligence for Requirements
Engineering (AIRE). YEEE, 2014, pp. 1-8.

A. Ferrari and A. Esuli, “An nlp approach for cross-domain ambiguity
detection in requirements engineering,” Automated Software Engineer-
ing, vol. 26, no. 3, pp. 559-598, 2019.

C. D. Manning, M. Surdeanu, J. Bauer, J. R. Finkel, S. Bethard,
and D. McClosky, “The stanford corenlp natural language processing
toolkit,’ in Proceedings of 52nd annual meeting of the association for
computational linguistics: system demonstrations, 2014, pp. 55-60.
D. Jurafsky and J. Martin, Speech and Language Processing: An In-
troduction to Natural Language Processing, Computational Linguistics,
and Speech Recognition (Draft), 12 2020, vol. 3.

T. Sanders and W. Spooren, “Discourse and text structure,” Handbook
of cognitive linguistics, pp. 916-941, 2007.

E. D. Liddy, “Anaphora in natural language processing and information
retrieval,” Information processing & management, vol. 26, no. 1, pp.
39-52, 1990.

[99]

100]

101]

102]

103]
104]

105]

106]

107]

108]

109]

110]

111]

112]

113]

114]

115]

116]

117]


[118]

[119]

[120]

[121]

[122]

[123]

[124]

[125]

[126]

[127]

[128]

[129]

[130]

[131]

[132]

[133]

[134]

[135]

[136]

[137]

[138]

M. Binkhonain and L. Zhao, “A review of machine learning algorithms
for identification and classification of non-functional requirements,”
Expert Systems with Applications: X, vol. 1, p. 100001, 2019.

——.,, “Dealing with imbalanced class, short text and high dimension-
ality problems in machine learning-based requirements classification:
Method development and evaluation,’ Under review, 2021.

J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training
of deep bidirectional transformers for language understanding,” arXiv
preprint arXiv: 1810.04805, 2018.

T. Young, D. Hazarika, S. Poria, and E. Cambria, “Recent trends in
deep learning based natural language processing,” ieee Computational
intelligenCe magazine, vol. 13, no. 3, pp. 55-75, 2018.

V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G.
Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski
et al., “Human-level control through deep reinforcement learning,”
nature, vol. 518, no. 7540, pp. 529-533, 2015.

T. Mikolov, K. Chen, G. Corrado, and J. Dean, “Efficient estimation of
word representations in vector space,” arXiv preprint arXiv:1301.3781,
2013.

K. Kowsari, K. Jafari Meimandi, M. Heidarysafa, S. Mendu, L. Barnes,
and D. Brown, “Text classification algorithms: A survey,” Information,
vol. 10, no. 4, p. 150, 2019.

D. S. Cruzes and T. Dyba, “Recommended steps for thematic synthesis
in software engineering,” in 20// international symposium on empirical
software engineering and measurement. YEEE, 2011, pp. 275-284.
I. Hussain, L. Kosseim, and O. Ormandjieva, “Using linguistic knowl-
edge to classify non-functional requirements in srs documents,” in
International Conference on Application of Natural Language to In-
formation Systems. Springer, 2008, pp. 287-298.

H. Yang, A. De Roeck, V. Gervasi, A. Willis, and B. Nuseibeh,
“Analysing anaphoric ambiguity in natural language requirements,”
Requirements engineering, vol. 16, no. 3, p. 163, 2011.

E. Knauss, S. Houmb, K. Schneider, S. Islam, and J. Jiirjens, “Support-
ing requirements engineers in recognising security issues,” in Jnterna-
tional Working Conference on Requirements Engineering: Foundation
for Software Quality. Springer, 2011, pp. 4-18.

L. Yi, W. Zhang, H. Zhao, Z. Jin, and H. Mei, “Mining binary
constraints in the construction of feature models,” in 20/2 20th IEEE
International Requirements Engineering Conference (RE). IEEE,
2012, pp. 141-150.

M. Riaz, J. King, J. Slankas, and L. Williams, “Hidden in plain sight:
Automatically identifying security requirements from natural language
artifacts,’ in 20/4 IEEE 22nd international requirements engineering
conference (RE). YEEE, 2014, pp. 183-192.

E. Knauss and D. Ott, “(semi-) automatic categorization of natural
language requirements,” in International Working Conference on Re-
quirements Engineering: Foundation for Software Quality. Springer,
2014, pp. 39-54.

A. Mahmoud and G. Williams, “Detecting, classifying, and tracing non-
functional software requirements,” Requirements Engineering, vol. 21,
no. 3, pp. 357-381, 2016.

Z. S. H. Abad, O. Karras, P. Ghazi, M. Glinz, G. Ruhe, and K. Schnei-
der, “What works better? a study of classifying requirements,” in 2017
IEEE 25th International Requirements Engineering Conference (RE).
IEEE, 2017, pp. 496-501.

M. Lu and P. Liang, “Automatic classification of non-functional

requirements from augmented app user reviews,” in Proceedings of

the 21st International Conference on Evaluation and Assessment in
Software Engineering, 2017, pp. 344-353.
C. Li, L. Huang, J. Ge, B. Luo, and V. Ng, “Automatically classifying

user requests in crowdsourcing requirements engineering,” Journal of

Systems and Software, vol. 138, pp. 108-123, 2018.

Z. S. H. Abad, V. Gervasi, D. Zowghi, and B. H. Far, “Supporting
analysts by dynamic extraction and classification of requirements-
related knowledge,” in 2019 IEEE/ACM 41st International Conference
on Software Engineering (ICSE). YEEE, 2019, pp. 442-453.

J. A. Khan, Y. Xie, L. Liu, and L. Wen, “Analysis of requirements-
related arguments in user forums,” in 20/9 IEEE 27th International
Requirements Engineering Conference (RE). YEEE, 2019, pp. 63-74.
W. Zheng, H. Lu, Y. Zhou, J. Liang, H. Zheng, and Y. Deng, “ifeed-
back: exploiting user feedback for real-time issue detection in large-
scale online service systems,” in 2019 34th IEEE/ACM International
Conference on Automated Software Engineering (ASE). YEEE, 2019,
pp. 352-363.

139]

140]

141]

142]

143]

144]

145]

146]

147]

148]

149]

150]

151]

152]

153]

D. Martens and W. Maalej, “Towards understanding and detecting fake
reviews in app stores,” Empirical Software Engineering, vol. 24, no. 6,
pp. 3316-3355, 2019.

D. Falessi, J. Roll, J. L. Guo, and J. Cleland-Huang, “Leveraging his-
torical associations between requirements and source code to identify
impacted classes,” IEEE Transactions on Software Engineering, vol. 46,
no. 4, pp. 420-441, 2018.

J. Frattini, M. Junker, M. Unterkalmsteiner, and D. Mendez, “Automatic
extraction of cause-effect-relations from requirements artifacts,’ in
2020 35th IEEE/ACM International Conference on Automated Software
Engineering (ASE). YEEE, 2020, pp. 561-572.

J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “Imagenet:
A large-scale hierarchical image database,” in 2009 IEEE conference
on computer vision and pattern recognition. eee, 2009, pp. 248-255.
W. Yin, J. Hay, and D. Roth, “Benchmarking zero-shot text classifi-
cation: Datasets, evaluation and entailment approach,” arXiv preprint
arXiv:1909.00161, 2019.

E. Arisoy, T. N. Sainath, B. Kingsbury, and B. Ramabhadran, “Deep
neural network language models,” in Proceedings of the NAACL-HLT
2012 Workshop: Will We Ever Really Replace the N-gram Model? On
the Future of Language Modeling for HLT, 2012, pp. 20-28.

B. Chiu, A. Korhonen, and S. Pyysalo, “Intrinsic evaluation of word
vectors fails to predict extrinsic performance,” in Proceedings of the Ist
workshop on evaluating vector-space representations for NLP, 2016,
pp. 1-6.

Y. Shi, Y. Zheng, K. Guo, L. Zhu, and Y. Qu, “Intrinsic or extrinsic
evaluation: An overview of word embedding evaluation,” in 20/8
IEEE International Conference on Data Mining Workshops (ICDMW).
IEEE, 2018, pp. 1255-1262.

U. Kamath, J. Liu, and J. Whitaker, Deep learning for NLP and speech
recognition. Springer, 2019, vol. 84.

S. Landolt, T. Wambsganss, and M. Séllner, “A taxonomy for deep
learning in natural language processing.’ Hawaii International Con-
ference on System Sciences, 2021.

H. N. Mhaskar and T. Poggio, “Deep vs. shallow networks: An
approximation theory perspective,” Analysis and Applications, vol. 14,
no. 06, pp. 829-848, 2016.

I. Sutskever, O. Vinyals, and Q. V. Le, “Sequence to sequence learning
with neural networks,” arXiv preprint arXiv: 1409.3215, 2014.

M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee,
and L. Zettlemoyer, “Deep contextualized word representations,” arXiv
preprint arXiv: 1802.05365, 2018.

A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever, “Improving
language understanding by generative pre-training,” 2018.

J. Howard and S. Ruder, “Universal language model fine-tuning for
text classification,” arXiv preprint arXiv:1801.06146, 2018.
