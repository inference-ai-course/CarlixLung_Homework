2108.04674v2 [cs.CL] 13 Sep 2024

arXiv

Natural Language Processing with Commonsense
Knowledge: A Survey

Yubo Xie
College of Information Engineering
Shanghai Maritime University
yuboxie@hotmail.com

Fanyuan Meng
Alibaba Business School
Hangzhou Normal University
fanyuan.meng @hotmail.com

Zonghui Liu
Independent Researcher
zonghui.liu@hotmail.com

Yan Xiao
College of Information Engineering
Shanghai Maritime University
xiaoyan@ shmtu.edu.cn

Zongyang Ma
School of AI and Advanced Computing
Xi’an Jiaotong-Liverpool University
mzyone @ gmail.com

Fahui Miao
College of Information Engineering
Shanghai Maritime University
miaofahui@ 126.com

Pearl Pu
School of Computer and Communication Sciences
Ecole Polytechnique Fédérale de Lausanne
pearl.pu @epfi.ch

Abstract—Commonsense knowledge is essential for advancing
natural language processing (NLP) by enabling models to engage
in human-like reasoning, which requires a deeper understand-
ing of context and often involves making inferences based on
implicit external knowledge. This paper explores the integration
of commonsense knowledge into various NLP tasks. We begin
by reviewing prominent commonsense knowledge bases and
then discuss the benchmarks used to evaluate the commonsense
reasoning capabilities of NLP models, particularly language
models. Furthermore, we highlight key methodologies for incor-
porating commonsense knowledge and their applications across
different NLP tasks. The paper also examines the challenges and
emerging trends in enhancing NLP systems with commonsense
reasoning. All literature referenced in this survey can be accessed
via our GitHub repository: https://github.com/yuboxie/awesome-
commonsense.

Index Terms—Commonsense knowledge, natural language pro-
cessing, knowledge base, knowledge graph, language model.

I. INTRODUCTION

Natural language processing (NLP) is a field of artificial in-
telligence (AJ) that focuses on the interaction between comput-
ers and humans through natural language. The field of NLP has
a rich history, dating back to the 1950s with the development
of early machine translation systems [1], [2]. Over the decades,
NLP has evolved significantly, incorporating advancements
in computational linguistics, artificial intelligence, and deep
learning. These advancements have enabled the development
of sophisticated NLP applications, such as speech recognition,
sentiment analysis, and dialogue generation, which are now
integral to many technologies we use daily. NLP encompasses
a wide array of tasks, ranging from lexical and syntactical
activities such as tokenization and part-of-speech tagging, to
semantic and pragmatic challenges like reference resolution
and text generation. While lexical and syntactical tasks are

relatively straightforward and have largely been automated,
higher-level semantic and pragmatic tasks demand a deeper
understanding of natural language and remain challenging for
machines. These tasks often require machines to reason using
commonsense knowledge, which is universally accepted by
humans but usually implicitly stated. For instance, if a six-
foot-tall person is holding a two-foot-tall person and they are
identified as father and son, it is intuitive to infer that the
taller individual is the father [3]. This inference, obvious to
humans, is difficult for machines because it relies on external
commonsense knowledge that “normally, a father is taller than
a baby son.”

Since the 1960s, numerous efforts have been made to imbue
NLP systems with commonsense reasoning abilities. Bar-
Hillel [4] was among the first to emphasize the importance
of incorporating commonsense knowledge into NLP systems
in the context of machine translation. Subsequent research has
introduced various NLP tasks aimed at evaluating intelligent
systems’ commonsense reasoning capabilities. Broadly, these
tasks, known as benchmarks, address two main types of
commonsense knowledge: naive physics and intuitive psy-
chology. Naive physics involves understanding how physical
objects interact; for example, inferring that a glass of water
falling to the floor will likely result in the glass shattering
and the floor becoming wet. Intuitive psychology, on the
other hand, enables us to infer people’s behaviors, intents, or
emotions, such as understanding that a person who has lost
their job likely feels upset.

Commonsense knowledge is crucial for many real-world
applications of NLP. For instance, virtual assistants like Siri
and Alexa need to understand and respond appropriately to
a wide range of user queries, often relying on commonsense
reasoning. In online customer service, chatbots must handle di-


verse interactions, where they need to comprehend and address
user issues effectively, often by inferring implicit context [5],
[6]. In sentiment analysis, NLP systems use commonsense
knowledge to better understand the underlying emotions and
sentiments in text, which helps in accurately interpreting the
tone and context of user-generated content, such as reviews
and social media posts [7]-[10]. These applications demon-
strate the importance of integrating commonsense reasoning
to enhance the functionality and accuracy of NLP systems.

The most straightforward approach to enabling machines
to reason with commonsense knowledge is to manually cre-
ate comprehensive knowledge bases that encompass human
commonsense knowledge. However, this task is immensely
challenging due to the vastness and complexity of human
knowledge, and the difficulty in determining which knowledge
is considered common. Despite these challenges, significant
efforts have been made to develop commonsense knowledge
resources focused on specific domains, with the ultimate goal
of creating a complete repository of human commonsense
knowledge. One notable initiative in this area is the Open
Mind Common Sense (OMCS) [11] project, which aims to
crowdsource commonsense knowledge from volunteers around
the world. OMCS collects a wide range of commonsense facts
and assertions, which are then used to build machine-readable
knowledge bases such as ConceptNet [12]. These resources
provide a valuable foundation for enhancing the commonsense
reasoning capabilities of NLP systems.

Acquiring and utilizing commonsense knowledge in NLP is
fraught with challenges. One major difficulty lies in encoding
the implicit knowledge that humans take for granted. Addition-
ally, commonsense can vary widely across different cultures
and contexts, complicating the creation of universally appli-
cable systems. Moreover, creating dynamic systems that can
adapt to new information and contexts remains a significant
hurdle. Emerging trends in the field of commonsense reasoning
in NLP include the use of neural networks, deep learning, and
large language models (LLMs) such as the GPT series [13]-
[16]. These technologies have shown promise in capturing and
utilizing commonsense knowledge more effectively. Future
advancements may include more sophisticated models capable
of dynamic reasoning, integration of multimodal information,
and the development of more comprehensive and nuanced
commonsense knowledge bases.

This survey paper aims to provide an overview of the
current state of commonsense reasoning in NLP. We re-
view prominent commonsense knowledge bases and various
benchmarks used to assess machines’ commonsense reasoning
abilities. Additionally, we highlight methodological research
that leverages external commonsense knowledge resources to
enhance general NLP tasks. Finally, we discuss potential future
directions to further advance commonsense reasoning in NLP.

II. COMMONSENSE KNOWLEDGE BASES

In this section, we give an overview of well-known com-
monsense knowledge bases. Different from lexical knowledge
bases (such as WordNet [32]) and factual knowledge bases

(such as Wikidata [33]) widely used in natural language pro-
cessing tasks, commonsense knowledge bases encode knowl-
edge that is usually implicitly stated and considered obvious
to most humans. Many commonsense knowledge bases are
structured as knowledge graphs in the form of nodes and
edges, where nodes represent entities, and edges represent
relationships between entities. Others are in the form of a set
of facts/sentences, expressed in propositional logic (used for
symbolic inference) or natural language (used for language
model training). Table I gives an overview of well-known
commonsense knowledge bases. Here, we are going to briefly
introduce these knowledge bases one by one in their chrono-
logical order, denoting the year when its development began
and the year when its newest version was published:

e Cyc (1984-2012). Cyc [17] is an artificial intelligence
project aiming at integrating ontologies and common-
sense knowledge from all different domains into one
knowledge base, and based on that, achieving the ability
of knowledge inference like human beings. Concepts in
Cyc are called “constants” and categorized into individ-
uals, collections, truth functions, and functions. The Cyc
project also includes an inference engine, which is ca-
pable of performing general logical deduction. Currently
there are two releases of Cyc. OpenCyc 4.0 is the most
recent public version and contains 239,000 concepts and
2,039,000 facts. ResearchCyc is licensed for research
purposes and contains 500,000 concepts and 5,000,000
facts.

e ConceptNet (1999-2020). ConceptNet [12] is a semantic
network created by the Open Mind Common Sense
(OMCS) [11], an artificial intelligence project aiming
at building a large-scale commonsense knowledge base
from the contributions of online users. It is a directed
graph whose nodes are concepts, and the edges represent
assertions of commonsense about the concepts, e.g., “is
a’, “is used for’, “motivated by goal’, etc. The nodes
are natural language phrases, e.g., noun phrases, verb
phrases, or clauses. ConceptNet contains over 8 million
nodes and over 21 million links. The latest version of the
knowledge base is ConceptNet 5.8.

e SenticNet (2009-2024). As a knowledge base, Sentic-
Net [18], [34], [35] provides a set of semantics, sentics,
and polarity associated with 200,000 natural language
concepts. Specifically, semantics define the denotative
information associated with natural language phrases,
sentics define the emotion categorization values (ex-
pressed in terms of four affective dimensions) associated
with these concepts, and polarity is floating number be-
tween —1 and +1. The knowledge base is automatically
created from multiple other resources, e.g., WordNet-
Affect [36] and OMCS. SenticNet also functions as an
advanced AI framework comprising a suite of tools and
methodologies for sentiment analysis, integrating com-
monsense reasoning, semiotics, psychology, linguistics,
and machine learning. The latest iteration, SenticNet


TABLE I

OVERVIEW OF PROMINENT COMMONSENSE KNOWLEDGE BASES

Name Type Size Form Language Creation
‘ 5 239,000 concepts :
OpenCyc [17] Naive physics 2,039,000 facts Fact English Manual
Naive physics 8 million nodes wa ‘
ConceptNet [12] Intuitive psychology | 21 million links Graph Multilingual Crowdsourcing
SenticNet [18] Intuitive psychology | 200,000 concepts Concept Multilingual Automatic
WebChild [19] naive physics 2 million SODEEPIS Assertion English Automatic
ntuitive psychology | 18 million assertions
. . 690,000 events we .
EventKG [20] Naive physics 9% zillion xeladens Graph Multilingual Automatic
Naive physics 309,515 nodes . .
ATOMIC [21] Intuitive psychology | 877,108 triples Graph English Crowdsourcing
20 Naive physics ma : :
ATOMIC%9 [22] Intuitive psychology 1.33 million tuples Graph English Crowdsourcing
Naive physics 194,000,677 nodes , ‘
SER, [6 Intuitive psychology | 64,351,959 relations ong Engish URGTOR UE
GLUCOSE [24] naive piyales 670,000 annotations Annotation | English Crowdsourcing
ntuitive psychology
SOCIAL-CHEM-101 [25] || Intuitive psychology | 292,000 rules Rule English Crowdsourcing
Naive physics 2,160,968 nodes ; :
EPG [26] Intuitive psychology | 6,001,531 edges ape English IgG
MickeyCorpus [27] iti puysics 561,000 sentences Assertion Multilingual Automatic
ntuitive psychology
SOCIALDIAL [28] Intuitive psychology | 6,433 dialogues Dialogue Chinese Crowdsourcing
NORMDIAL [29] Intuitive psychology | 4,231 dialogues Dialogue Chinese & English | Crowdsourcing
MORAL EVENTS [30] Intuitive psychology | 5,494 annotations Annotation | English Crowdsourcing
ws 62,328 nodes . Automatic &
COKE 20 Infuitive Payehelogy 45,369 cognitive chains Graph English Crowdsourcing

8 [35], is a neurosymbolic AI framework that integrates
commonsense knowledge representation with hierarchical
attention networks. It surpasses traditional methods like
bag-of-words, word2vec [37], RoBERTa [38], and Chat-
GPT [39] in accuracy, and is distinguished by its full
interpretability, trustworthiness, and explainability.
WebChild (2014-2017). WebChild [19] is a large-scale
commonsense knowledge base that was automatically
extracted and disambiguated from Web contents, using
semi-supervised label propagation over graphs of noisy
candidate assertions. The knowledge base contains triples
that connect nouns with adjectives via fine-grained rela-
tions like “hasShape”, “hasTaste’”, “evokesEmotion’, etc.
The arguments of these assertions, nouns and adjectives,
are disambiguated by mapping them onto their proper
WordNet senses. The newest version WebChild 2.0 was
released in 2017 and contains over 2 million concepts
with 18 million assertions about them.

EventKG (2018). EventKG [20] is a multilingual,
event-centric temporal knowledge graph, that accen-

tuates the events and temporal relationships. It en-
capsulates over 690,000 historical and contemporary
events and in excess of 2.3 million temporal rela-
tions, structured through a canonical representation. The
graph innovatively introduces event KG-s: Relation,
a class that interlnks two sem:Core instances—
representing events or entities—to model temporal rela-
tionships between them, exemplified by relations such as
“Barack Obama’’-“participated in’-“Second Inauguration
of Barack Obama’, enriched with annotations like valid-
ity time and sem: RoleType for comprehensive relation
characterization.

ATOMIC (2019). ATOMIC [21] is a comprehensive com-
monsense knowledge graph comprising 877K textual
descriptions of inferential knowledge derived through
crowdsourcing. This knowledge graph emphasizes if-
then relationships between events and the possible in-
ferences that can be drawn from them. Specifically,
it includes three types of relations: “If-Event-Then-
Mental-State”, “If-Event-Then-Event”, and ‘“If-Event-


Then-Persona”. The base events are extracted from di-
verse corpora, including stories and books. Overall, the
ATOMIC knowledge graph encompasses 309,515 nodes
and 877,108 If-Event-Then-* triples, providing a robust
resource for understanding and modeling inferential rea-
soning.

ATOMIC3? (2020). ATOMIC3° [22] enhances the original
ATOMIC by expanding the knowledge graph’s scope
and scale, incorporating a broader range of events and
more complex relational structures. As a comprehen-
sive commonsense knowledge graph, ATOMIC3) com-
prises 1.33 million tuples spanning 23 commonsense
relations, encompassing social, physical, and eventive
aspects of everyday inferential knowledge. Studies have
shown that pre-trained language models (PLMs) retrained
on ATOMIC3) can articulate knowledge more precisely
than models trained solely on language data. Additionally,
ATOMIC3¢ serves as an effective training set for adapting
language models, improving their ability to capture and
express commonsense knowledge.

ASER (2020). ASER (activities, states, events, and their
relations) [23] is a large-scale eventuality knowledge
graph automatically extracted from more than 1 1-billion-
token unstructured textual data. It contains 15 relation
types belonging to five categories, 194 million unique
eventualities, and 64 million edges between them. The
eventualities were extracted from a wide range of cor-
pora from different sources, according to a selected set
of eventuality patterns. The eventuality relations were
also automatically extracted using a selected set of seed
connectives.

GLUCOSE (2020). The GLUCOSE [24] dataset com-
prises approximately 670,000 annotations that encode
causal explanations grounded in narrative contexts, focus-
ing on events, motivations, and emotional states. GLU-
COSE is structured into ten dimensions of causal expla-
nation, each providing a semi-structured format to cap-
ture both story-specific and generalized inference rules.
The dataset is collected through a robust crowdsourcing
platform, ensuring high-quality and diverse contributions
from non-expert annotators. Unlike existing resources
such as ConceptNet and ATomic, GLUCOSE offers
broader contextual coverage, enabling models to generate
nuanced and contextually appropriate commonsense in-
ferences. Empirical evaluations demonstrate that models
fine-tuned on GLUCOSE data significantly outperform
pre-trained models in generating commonsense explana-
tions. This dataset is poised to enhance AI applications
in natural language understanding by facilitating models
that more accurately mimic human-like reasoning across
a range of narrative-driven tasks.

SOCIAL-CHEM-101 (2020). SOCIAL-CHEM-101 [25]
is a large-scale corpus designed to enhance language
models’ comprehension of the intents and underlying
causes in human narratives. The corpus catalogs 292K
descriptive rules-of-thumb (RoTs) and each RoT is fur-

ther broken down with 12 different dimensions of peo-
ple’s judgments, including social judgments of good
and bad, moral foundations, expected cultural pressure,
and assumed legality, which together amount to over
4.5 million annotations of categorical labels and free-
text descriptions. Each RoT within this collection is a
descriptive cultural norm structured as the judgment of
an action.

CSKG (2021). The CommonSense Knowledge Graph
(CSKG) [26] integrates seven distinct sources of com-
monsense knowledge into a unified graph to enhance AI
systems’ reasoning capabilities. CSKG addresses chal-
lenges in combining diverse knowledge sources, such
as different modeling approaches and sparse overlap, by
following five principles: embracing node heterogeneity,
reusing edge types, leveraging external links, generating
high-quality probabilistic links, and ensuring easy ac-
cess to labels. It incorporates resources like ConceptNet,
ATOMIC, Visual Genome [40], and WordNet, creating a
hyper-relational graph structure that improves connectiv-
ity and reasoning capabilities. CSKG offers comprehen-
sive coverage with over 2.2 million nodes and 6 million
edges, significantly increasing the availability of evidence
for commonsense reasoning tasks. This integration allows
for improved commonsense question answering and lan-
guage model pre-training, offering substantial advance-
ments over existing resources by providing enriched,
interconnected commonsense knowledge.
MickeyCorpus (2021). The MickeyCorpus [27] is a
multilingual dataset created to evaluate and enhance the
performance of multilingual language models (ML-LMs)
in commonsense reasoning tasks. Comprising 561,000
sentences across 11 languages, the MickeyCorpus serves
as a resource for probing ML-LMs using the MICK-
EYPROBE task, which assesses the models’ ability to
rank sentences based on commonsense plausibility in a
zero-shot setting. This corpus addresses the limitations
of previous methods by providing a language-agnostic
framework that accommodates multi-token concepts and
ensures fair comparison across languages. Additionally,
MickeyCorpus is integral to the proposed multilingual
contrastive pre-training (MCP) strategy, which substan-
tially improves the sentence-level representation of ML-
LMs, leading to enhanced cross-lingual commonsense
reasoning performance. By offering a comprehensive and
diverse linguistic dataset, MickeyCorpus facilitates the
development of more robust and culturally adaptable ML-
LMs, advancing the field of natural language understand-
ing beyond English.

SOCIALDIAL (2023). SOCIALDIAL [28] is a dialogue
corpus designed to enhance the development of socially-
aware dialogue systems by incorporating Chinese social
norms. It addresses the gap in existing dialogue sys-
tems that lack the ability to understand and integrate
social norms. The dataset consists of 1,563 human-written
multi-turn dialogues and 4,870 synthetic dialogues gen-


erated by ChatGPT, annotated with fine-grained social
factors such as social relations, context, distance, and
norms. SOCIALDIAL also serves as a benchmark for
socially-aware dialogue systems. It includes an ontology-
based synthetic data generation framework, which en-
ables scalable and cost-effective creation of synthetic
dialogues. Evaluations using state-of-the-art models like
BERT [41] and RoBERTa demonstrate the dataset’s po-
tential to enhance the performance of dialogue systems
by incorporating social norms, thus providing a promising
avenue for advancing socially-aware NLP applications.

NORMDIAL (2023). NORMDIAL [29] is a synthetically
generated bilingual (Chinese and English) dyadic dia-
logue dataset designed to study social norm adherence
and violation within conversational contexts across Chi-
nese and American cultures. Developed using a human-
in-the-loop framework, the dataset consists of 4,231 dia-
logues with 29,550 conversational turns, each annotated
for adherence or violation of social norms. These norms
were initially defined by expert annotation and then
expanded using LLMs to reflect both cultural contexts.
The dialogues were evaluated and compared against
existing datasets and were found to be of high quality,
with strong naturalness and coherence ratings, although
the models struggled with accurately identifying norm
violations. The resource highlights the complexities of
cross-cultural communication and provides a foundation
for further research into developing systems capable of
understanding nuanced social interactions across cultures.
MORAL EVENTS (2024). MORAL EVENTS [30] is a
dataset that encompasses annotations of news articles
to analyze how different media ideologies report moral
events, which are defined as events with moral implica-
tions, rooted in Moral Foundations Theory (MFT) [42]-
[44], which includes polarities such as Care/Harm and
Fairness/Cheating. These events are characterized by their
moral evaluations, which arise when an agent with moral
agency affects a patient who can be helped or harmed by
the action. The dataset was curated using the moral event
extraction (MEE) framework, which identifies morality-
bearing event triggers, extracts participant entities, and
infers the underlying moralities within unstructured texts.
COKE (2024). COKE [31] is a COgnitive KnowledgE
graph that aims to empower AI systems with Theory
of Mind (ToM) [45] capabilities by formalizing ToM
as a comprehensive collection of over 45,000 manually
verified cognitive chains. These chains encapsulate hu-
man mental activities and their corresponding behavioral
and emotional responses within specific social contexts.
Composed of five node types—-situations, clues, thoughts,
actions, and emotions—COKE forms cognitive chains
labeled with either positive or negative polarity. To over-
come the limitation of addressing all real-world scenarios,
COKE integrates with the cognitive language model
COLM, which combines commonsense knowledge from
LLMs with ToM capabilities to infer cognitive chains for

novel situations. Experimental results demonstrate that
COLM significantly outperforms baseline models like
GPT-4 [16] in generating cognitive chains and enhancing
applications such as emotional support conversations,
highlighting the potential of integrating cognitive reason-
ing into AI systems.

III. BENCHMARKS

Advanced NLP tasks, such as machine reading comprehen-
sion and natural language inference, present significant chal-
lenges as they require systems to emulate human-like reason-
ing and draw inferences based on commonsense knowledge.
While the objectives of these tasks differ, successfully ad-
dressing them typically necessitates a degree of commonsense
reasoning within the systems. To evaluate the commonsense
reasoning capabilities of NLP models, particularly LLMs,
numerous benchmarks have been developed. In this section,
we review prominent benchmarks that demand commonsense
reasoning from models. We categorize these benchmarks into
several types, including multiple-choice questions, binary-
choice questions, classification tasks, cloze tasks, and gener-
ation tasks, as illustrated in Fig. 1. Additionally, we classify
these benchmarks based on the specific types of commonsense
knowledge they assess, as depicted in Fig. 2. The following
subsections provide a brief introduction to these benchmarks
according to their task type.

A. Multiple-Choice Questions

The majority of benchmarks are structured as multiple-
choice questions, where the evaluated model is presented with
several options and must select the correct one or more. In
one common scenario, referred to as question answering, the
benchmark poses a specific question, and the model is required
to identify the correct answer(s) from the given choices. Some
benchmarks also include supplementary text, often in the form
of a story or relevant facts, to provide context alongside the
question. Prominent benchmarks within this category include:

e OpenBookQA [46] is a benchmark dataset designed to
assess the ability of AI systems to combine core scientific
knowledge with broader commonsense reasoning in an-
swering elementary-level science questions. The dataset,
consisting of nearly 6,000 multiple-choice questions, re-
quires models to integrate provided science facts with
additional external knowledge to solve problems that
mimic the open-book exam setting. Unlike traditional
question-answering datasets, OpenBookQA emphasizes
the need for multi-hop reasoning and effective knowledge
retrieval, making it a more challenging task.

e COMMONSENSEQA [47] is a dataset designed to eval-
uate the capacity of natural language understanding sys-
tems to perform commonsense reasoning. Derived from
the ConceptNet knowledge graph, the dataset consists of
12,247 multiple-choice questions and requires reasoning
that extends beyond simple fact retrieval, often neces-
sitating the application of background knowledge. Each
question in CommonsenseQA is carefully constructed to


Multiple-Choice Questions

Question Answering

OpenBookQA
CommonsenseQA
MCTACO

Social IQa
Cosmos QA
PROST

Possible Stories
FeasibilityQA
TRAM

Completion

SWAG, HellaSwag
CODAH

TimeDial

Generation Tasks

Event2Mind
Defeasible NLI
TORQUE
CommonGen
TimeQA

OpenEQA

Commonsense
Reasoning
Benchmarks

Binary-Choice Questions

Question Answering

CommonsenseQA 2.0

FeasibilityQA

Natural Language Inference

ROCStories

Abductive NLI

Defeasible NLI

ReCoRD

NumerSense

Annotation Tasks

Story Commonsense
ETHICS
HeadlineCause

SocialDial

Fig. 1. Categorization of commonsense reasoning benchmarks by task type.

Naive Physics

OpenBookQA_ McTaco
PIQA NumerSense
TORQUE TimeQA
PROST HeadlineCause
TimeDial FeasibilityQA
OpenEQA TRAM

Both

Intuitive Psychology

Winograd Schema Challenge

COPA  TriangleeCOPA XCOPA

Story Commonsense

ROCStories SWAG HellaSwag

Event2Mind

ReCoRD CODAH Cosmos QA

Social |Qa

CommonsenseQA CommonGen

CommonsenseQA 2.0

Defeasible NLI

Possible Stories

ETHICS
BigToM

Abductive NLI

Fig. 2. Overview of commonsense reasoning benchmarks categorized by the types of commonsense knowledge they evaluate.

Winograd Schema Challenge

COPA, Triangle-COPA, XCOPA


present contextually complex scenarios, making it more
difficult for models to perform accurately.

McTACO (short for multiple choice temporal common-
sense) [48] is a dataset designed to evaluate tempo-
ral commonsense reasoning in natural language under-
standing. It systematically addresses five key tempo-
ral properties: duration, temporal ordering, typical time,
frequency, and stationarity. Created via crowdsourcing,
MCTACO provides a challenging test set for evaluating
the performance of NLP models, such as BERT [41] and
ESIM [49], on tasks requiring temporal reasoning.
SOCIAL IQA [50] is a large-scale benchmark for evalu-
ating and improving NLP models’ social and emotional
intelligence through commonsense reasoning about social
interactions. It includes 38,000 multiple-choice questions
designed to challenge models in understanding motiva-
tions, emotional reactions, and outcomes of everyday
scenarios. By using a crowdsourcing method that reduces
biases in incorrect answers, SOCIAL IQA offers a robust
dataset for training NLP models. Despite advancements,
models like BERT still fall short of human performance
on these tasks, but SOCIAL IQA has proven effective
for enhancing performance on related commonsense rea-
soning challenges such as the Winograd Schema Chal-
lenge [51] and COPA [52].

COSMOS QA [53] is a comprehensive machine reading
comprehension dataset designed to challenge models with
the need for contextual commonsense reasoning. The
dataset comprises 35,588 multiple-choice questions based
on a diverse range of everyday situations drawn from
personal narratives. Unlike traditional reading compre-
hension datasets, COSMOS QA emphasizes reasoning that
goes beyond the explicit text, requiring models to infer
causes, effects, and hypothetical scenarios.

PROST (Physical Reasoning about Objects through
Space and Time) [54] is a probing dataset designed to
evaluate the capability of language models to reason
about physical interactions in the real world. Compris-
ing 18,736 multiple-choice questions generated from 14
manually curated templates across 10 distinct physical
reasoning concepts, PROST challenges models in a zero-
shot setting, emphasizing the limitations of current state-
of-the-art pre-trained models. The results demonstrate
that these models often rely on spurious correlations,
such as the order of answer options, rather than a gen-
uine understanding of physical concepts like direction,
mass, and breakability. PROST highlights the signifi-
cant gap between human-like physical reasoning and the
performance of existing language models, underscoring
the necessity for multimodal training that incorporates
real-world experiences to enhance model capabilities in
understanding and reasoning about physical phenomena.
Possible Stories [55] provides a comprehensive eval-
uation framework for situated commonsense reasoning,
focusing on scenarios where multiple plausible outcomes
are possible. The benchmark consists of 4,533 multiple-

choice questions based on 1,313 story passages, each
designed to assess the ability of language models to
reason about potential outcomes in varied contexts. The
dataset includes diverse scenarios that require counter-
factual reasoning and an understanding of characters’
motivations, emotions, and fictional contexts.
FeasibilityQA [56] is a dataset designed to evaluate the
ability of NLP models to reason about the feasibility of
actions or their effects. This dataset includes binary clas-
sification (BCQ) and multi-choice multi-correct questions
(MCQ) that test models on commonsense reasoning about
feasibility, a fundamental yet underexplored aspect of nat-
ural language understanding. Despite the sophistication
of language models like GPT-3 [15], GPT-2 [14], and
T5 [57], they demonstrate significant struggles with these
tasks, achieving low accuracy rates (e.g., 19% and 62%
in MCQ and BCQ, respectively, in zero-shot settings).
TRAM (Temporal Reasoning for large [Anguage Mod-
els) [58] serves as a comprehensive benchmark designed
to evaluate the temporal reasoning capabilities of LLMs.
It comprises ten diverse tasks, ranging from foundational
temporal understanding (e.g., duration, frequency) to ad-
vanced temporal interpretations and computations (e.g.,
ambiguity resolution, arithmetic, causality). TRAM in-
cludes 526.7K questions across 38 subtasks, all formatted
as multiple-choice questions to ensure consistency and
ease of evaluation. The benchmark reveals that even the
most advanced models, such as GPT-4, significantly lag
behind human performance in temporal reasoning tasks.

In addition to the question-answering scenario, some bench-
marks employ a completion task, where the model is required
either to select the option that best continues the given context
or to choose the option that best fits into a blank space.
Prominent benchmarks in this category include:

SWAG (Situations With Adversarial Generations) [59]
provides 113K multiple-choice questions designed to pre-
dict the most plausible continuation of a given scenario.
To address annotation artifacts and biases common in ex-
isting datasets, SWAG employs a novel Adversarial Filter-
ing (AF) technique, which iteratively uses an ensemble of
classifiers to remove stylistic biases, thereby producing a
more challenging and robust dataset. HellaSwag (Harder
Endings, Longer contexts, and Low-shot Activities for
Situations With Adversarial Generations) [60] expands
on the SWAG benchmark by increasing the complexity
and diversity of context through sources like WikiHow
and ActivityNet, pushing the boundaries of what current
models can achieve. It includes 70K dataset examples in
total, with 25K best ActivityNet contexts (i.e., those with
the highest agreement among crowd workers) and 45K
best WikiHow contexts.

CODAH (COmmonsense Dataset Adversarially-authored
by Humans) [61] extends the SWAG dataset by introduc-
ing adversarially-constructed multiple-choice questions
that target the weaknesses of state-of-the-art models such


as BERT and GPT. Human annotators, incentivized to
generate questions that confound these models, con-
tributed to the creation of 2,801 questions. CODAH
includes various question types, such as idioms, negation,
and quantitative reasoning, and has proven to be a more
difficult benchmark than SWAG.

TIMEDIAL [62] addresses the challenge of temporal
commonsense reasoning in dialogues, focusing on the
ability of language models to understand and reason about
temporal concepts within multi-turn conversations. TI-
MEDIAL introduces a novel multiple-choice blank-filling
task with over 1,100 carefully curated dialogues requir-
ing models to infer correct temporal expressions based
on context, world knowledge, and arithmetic reasoning.
Empirical evaluations reveal that LLMs like TS and GPT-
3 struggle with this task, significantly underperforming
compared to human baselines. The analysis further shows
that these models often rely on shallow text patterns
rather than true contextual reasoning, highlighting the
need for more robust approaches to model temporal
commonsense in dialogues.

B. Binary-Choice Questions

Some benchmarks are designed as binary-choice questions,
where the model must select the correct answer from only
two options rather than multiple options, as is the case with
multiple-choice questions. Consequently, these tasks are inher-
ently easier due to the reduced number of choices. Similarly,
a common example of this type of task is question answering,
with several notable benchmarks falling into this category,
including:

e The Winograd Schema Challenge (WSC) [51] is pro-
posed as an alternative to the Turing Test [63], focusing
on a machine’s ability to resolve referential ambiguities
that are trivial for humans but challenging for AI. A
Winograd schema consists of a pair of sentences that
differ by only one or two words, leading to a referential
ambiguity that requires common sense reasoning and
world knowledge to resolve. The WSC avoids pitfalls
associated with statistical methods and simple linguistic
tricks, making it a more robust measure of machine
understanding. The challenge emphasizes the need for
NLP systems to engage in deep reasoning, distinguishing
it from other NLP tasks that rely heavily on statistical
approaches. As such, the WSC represents a significant
advancement in evaluating AI’s capacity for genuine
comprehension and intelligent behavior.

e COPA (Choice Of Plausible Alternatives) [52] is a bench-
mark that involves causal inference between events. The
dataset comprises 1,000 examples, each presenting an
event followed by a question asking the model to select
the correct cause or effect from two options. Triangle-
COPA [64] is a variation of COPA, containing 100 ex-
amples in the same format, but supplemented with videos
depicting interactions between a circle and a triangle. The
questions in Triangle-COPA focus more on emotions and

intentions. However, scalability remains a challenge for
both datasets when evaluating modern language models.
To advance NLP tools in languages other than English
and address the Anglocentric bias in commonsense rea-
soning models, XCOPA [65] was introduced. This mul-
tilingual dataset supports causal commonsense reasoning
across 11 languages and is typologically diverse.

PIQA (Physical Interaction: Question Answering) [66]
addresses the challenge of physical commonsense reason-
ing in natural language understanding. While humans find
physical reasoning intuitive, NLP models, such as BERT
and RoBERTa [38], struggle significantly with these
tasks. PIQA introduces a benchmark dataset focused on
physical interaction scenarios, requiring models to choose
the most sensible solution from a pair of options. This
benchmark aims to drive progress in developing models
that better capture physical commonsense knowledge.
COMMONSENSEQA 12.0 [67] introduces a gamified
framework for data creation. By engaging users in a game
where they generate challenging yes/no questions de-
signed to mislead AI, this approach ensures the collection
of diverse and difficult questions. The dataset, consisting
of 14,343 examples, is challenging for existing models,
with the best-performing model, UNICORN-11B [68],
achieving only 70.2% accuracy, far below the 94.1%
human accuracy.

BigToM [69] is a framework designed for evaluating
the social reasoning capabilities of LLMs by procedu-
rally generating Theory of Mind (ToM) evaluations. It
addresses limitations in previous methodologies, such
as ambiguous or insufficiently controlled test items, by
using causal templates to create a new social reasoning
benchmark consisting of 25 controls and 5,000 model-
generated evaluations. The benchmark, evaluated and
rated by human participants, was found to be superior
to crowd-sourced tests and comparable to expert-written
evaluations. BigToM’s results indicate that while GPT-4
demonstrates ToM capabilities that mirror human infer-
ence patterns, its performance remains less reliable com-
pared to humans, and other LLMs struggle significantly
more. This framework offers a scalable, cost-efficient
method for assessing and understanding the strengths
and weaknesses of LLMs in ToM reasoning, providing
valuable insights into the models’ ability to simulate
human-like social cognition.

In another scenario, the evaluated model performs a natural

language inference (NLI) task, where it must select the option
that is entailed by the given text. Some benchmarks in this
category include:

ROCStories [70], a corpus of 50,000 five-sentence com-
monsense stories, was developed to address the need for
a robust evaluation framework in the understanding of
causal and temporal relations in narratives. It is coupled
with an evaluation framework that challenges models to
select the correct ending for a four-sentence story from


two alternatives. Experimental results reveal that models
relying on shallow language understanding struggle with
this task, emphasizing the need for richer semantic rep-
resentations in story understanding and script learning.

e Abductive NLI [71] focuses on the task of identifying
the most plausible explanation for a given set of ob-
servations. It is supported by the ART dataset, which
includes over 20,000 commonsense narrative contexts
and 200,000 explanatory hypotheses. Despite achieving a
68.9% accuracy with the best model, there is a substantial
gap compared to human performance at 91.4%.

e Defeasible NLI [72] introduces a dataset and correspond-
ing tasks designed to explore the concept of defeasi-
ble inference within NLP. It extends existing inference
datasets to incorporate scenarios where an initial infer-
ence might be either strengthened or weakened by addi-
tional contextual information. Two tasks were formulated:
a classification task that determines whether a new piece
of information strengthens or weakens an inference, and
a generative task that requires creating such contextual
updates. While LLMs perform well on the classification
task, the generative task remains challenging.

C. Cloze Tasks

In a cloze task, the given context contains one or more
blanks, and the evaluated model must fill in these blanks
with appropriate words or phrases. Unlike in multiple-choice
completion tasks, the model is not provided with a set of
options but must predict the missing words based solely
on the context or its training vocabulary. Two well-known
benchmarks that utilize the cloze task are:

e ReCoRD (Reading Comprehension with Commonsense
Reasoning Dataset) [73] is a large-scale machine read-
ing comprehension (MRC) dataset designed to evaluate
systems’ abilities to perform commonsense reasoning.
Consisting of over 120,000 examples derived from news
articles, ReCoRD requires models to not only match pat-
terns in the text but also to engage in deep commonsense
reasoning to infer answers. Unlike other datasets, which
can often be addressed with surface-level text matching,
ReCoRD’s cloze-style queries demand an understanding
that spans multiple sentences and incorporates implicit
commonsense knowledge.

e NUMERSENSE [74] explores the limitations of LLMs
like BERT and RoBERTa in understanding and recall-
ing numerical commonsense knowledge. Despite their
success in various NLP tasks, these models perform
poorly when required to predict masked numerical values
in sentences, such as determining the number of legs
a bird typically has. NUMERSENSE introduces a diag-
nostic dataset of 13.6K examples, revealing that LLMs
struggle with consistency and accuracy in numerical
commonsense tasks, even after fine-tuning with distant
supervision.

D. Annotation Tasks

In an annotation task, the evaluated model is required to
label a given text using a predefined set of labels, often based
on commonsense knowledge. This process is essentially a text
classification task. Notable benchmarks are:

e Story Commonsense [75] is a large-scale dataset con-
taining detailed annotations that link commonsense story
events to the mental states of characters, even when
these states are not explicitly mentioned. It leverages
theories from psychology, including Maslow’s hierarchy
of needs [76], Reiss’s basic desires [77], and Plutchik’s
wheel of emotions [78], to categorize the motivations
and emotional reactions of characters. The dataset, which
covers over 15,000 stories and includes 300,000 low-
level annotations, serves as a foundation for new tasks
in natural language understanding, such as mental state
tracking and explanation generation.

e ETHICS [79] is a benchmark for evaluating language
models’ understanding of basic human ethical concepts
across diverse scenarios. The dataset covers five major ar-
eas of normative ethics: justice, deontology, virtue ethics,
utilitarianism, and commonsense morality. It challenges
models to make morally informed decisions by connect-
ing factual knowledge with value judgments in complex,
open-world contexts. Current models show some ability
to predict ethical judgments but are far from mastering
the nuanced understanding required for ethical AI.

e HeadlineCause [80] is a dataset designed to detect
implicit causal relations between pairs of news headlines,
addressing the challenges in existing datasets that focus
predominantly on either commonsense causal reason-
ing or explicit causal relations. Comprising over 5,000
headline pairs in English and 9,000 in Russian, this
dataset was annotated via crowdsourcing and includes a
variety of relationships, from unrelated headlines to those
involving causation and refutation. The dataset is partic-
ularly notable for its emphasis on implicit, inter-sentence
causal relations, which require models to leverage both
commonsense and world knowledge.

E. Generation Tasks

In a generation task, the evaluated model is expected to gen-
erate the answer independently, rather than selecting from a set
of predefined options. One approach to this is to reformulate
the problem as a classification task, determining which words
or n-grams should constitute the answer. A more common
approach, however, is to use an autoregressive decoder that
generates the answer token by token. Notable benchmarks in
this category include:

e Event2Mind [81] is a commonsense inference bench-
mark focusing on predicting the intents and reactions
of participants in everyday events. The model utilizes a
corpus of 25,000 event phrases, crowdsourced to include
a diverse range of scenarios. By encoding event phrases
and generating textual descriptions of intents and reac-


tions, Event2Mind aims to understand the mental states
associated with events.

TimeQA [82] is a dataset specifically designed to evalu-
ate the ability of NLP models to handle time-sensitive
queries that require temporal reasoning. The dataset
was constructed by mining time-evolving facts from
Wikidata [33], aligning these facts with corresponding
Wikipedia passages, and generating question-answer pairs
based on these annotated time-sensitive facts. TimeQA
presents significant challenges in both temporal under-
standing, where models must grasp the time scope of facts
scattered across long documents, and temporal reasoning,
where models need to infer and reason over temporal
relationships.

TORQUE [83] is a reading comprehension dataset specif-
ically designed to evaluate a model’s ability to understand
temporal relationships between events in text. Comprising
3.2K news snippets and over 21K human-generated ques-
tions, TORQUE addresses a critical gap in current MRC
benchmarks, which typically do not include questions that
assess temporal reasoning. The dataset challenges models
with complex queries about the sequence and timing of
events, such as identifying what happened before or after
a specific event, or what events occurred simultaneously.
CommonGen [84] introduces a constrained text gen-
eration task designed to assess and advance generative
commonsense reasoning in machines. The task requires
models to generate coherent sentences that describe ev-
eryday scenarios using a specified set of common con-
cepts, emphasizing the need for relational reasoning with
background commonsense knowledge and compositional
generalization to handle novel concept combinations. The
accompanying dataset includes 77K sentences across 35K
unique concept sets, offering a challenging benchmark for
state-of-the-art language models.

OpenEQA [85] is an open-vocabulary Embodied Ques-
tion Answering (EQA) [86] benchmark that supports
both episodic memory and active exploration scenarios.
It evaluates an AI agent’s ability to understand and
interact with real-world environments to answer com-
plex, natural language questions. OpenEQA includes over
1,600 human-generated questions based on 180 real-
world environments, testing various cognitive capabilities
such as spatial reasoning, object recognition, and world
knowledge. The benchmark incorporates a novel evalua-
tion protocol using LLMs to score responses, achieving
strong alignment with human judgments. Despite the so-
phistication of current foundation models, including GPT-
4V [87], performance on OpenEQA lags significantly
behind human-level accuracy, highlighting substantial
challenges in developing agents capable of robust, real-
world EQA.

F. Multi-Task Benchmarks

Some benchmarks consist of multiple tasks, and the perfor-
mance of evaluated systems is typically measured by averaging

10

their scores across these tasks. GLUE (General Language
Understanding Evaluation) [88] is a widely used comprehen-
sive benchmark for evaluating NLP systems, featuring tasks
that require commonsense reasoning, such as natural lan-
guage inference, textual entailment, and question answering.
SuperGLUE [89] builds upon GLUE by incorporating more
challenging natural language understanding tasks, designed to
meet the demands of increasingly advanced NLP systems in
recent years. CLUE [90] (Chinese Language Understanding
Evaluation) is a comprehensive benchmark developed to ad-
vance Chinese natural language processing. It addresses the
gap left by predominantly English-centric benchmarks like
GLUE and SuperGLUE by introducing a set of nine diverse
language understanding tasks. LOT (LOng Text) [91] is a
story-centric benchmark for evaluating the understanding and
generation of Chinese long texts. It includes two understanding
tasks and two generation tasks, all based on human-written
Chinese stories to test key abilities such as commonsense
reasoning, inter-sentence relations, and coherence. BIG-bench
(Beyond the Imitation Game benchmark) [92] is a large-scale,
diverse, and challenging benchmark designed to evaluate the
capabilities of current and future language models across a
wide range of tasks. It includes 204 tasks contributed by
over 450 authors from 132 institutions, covering topics from
linguistics to social biases and software development.

IV. METHODOLOGIES

This section explores and compares various methods for
enhancing commonsense knowledge in NLP models. By dis-
cussing these methods, we aim to provide a comprehensive
perspective on how different commonsense knowledge en-
hancement strategies are applied in NLP models, particularly
in language models. Given that commonsense knowledge is a
specialized form of knowledge, general knowledge enhance-
ment methods are also applicable. Therefore, we adopt the
methodology categorization proposed by Wang et al. [93],
with a focus on how commonsense knowledge is specifically
enhanced in recent papers.

A. External Memorization

Enhancing language models by incorporating commonsense
knowledge through external retrieval is a popular and ef-
fective method for boosting their understanding, as shown
in Fig. 3a. Under this category, commonsense knowledge
enhancement techniques can be broadly classified into static
knowledge retrieval and dynamic knowledge generation. Static
knowledge retrieval methods depend on pre-existing knowl-
edge bases and employ precise retrieval algorithms to extract
pertinent information, whereas dynamic knowledge gener-
ation methods utilize specialized models to generate real-
time commonsense reasoning that is relevant to the current
context. In open-domain conversational systems, integrating
commonsense knowledge is essential for generating responses
that align more closely with human reasoning and provide
deeper insights. Many recent studies have adopted the external


eS) Input/Prompt

User ———EESS
Retrieval Input
External ME EET
envy Zs —___——>
Retrieved Knowledge
Human

@ Preference Fine-tune

—— ———_—

oO

Pre-trained Model

Labeler Knowledge-Enhanced
Dataset
Editor e
Collect
Proping wes Cases Probing
Labeler Probing Dataset

(a)

(b)

(c)

Fuse and Output

+

——_____ ,
Model Knowledge-Enhanced
Output
eS)
—» —
© ap

User

Knowledge-Enhanced
Model

wel Knowledge Editing

apse

Pre-trained Model

User

eS)
<—
—

©

Knowledge-Enhanced
Model

Fig. 3. Three different ways for NLP models to incorporate and enhance commonsense knowledge: (a) External Memorization; (b) Global Optimization; (c)

Local Modification.

memorization approach for this purpose. Next, we will review
some of the key works in this area.

The commonsense knowledge aware conversational model
(CCM) introduced by Zhou et al. [94], represents an initiative
in integrating extensive commonsense knowledge into gener-
ating conversations in open domains. The model operates by
fetching pertinent knowledge graphs from a knowledge base
upon receiving a user prompt. Subsequently, it encodes these
graphs utilizing a static graph attention mechanism to enhance
the semantic content of the input, thereby aiding in better
comprehension. During the word generation phase, the model
carefully analyzes the retrieved knowledge graphs and the
knowledge triples contained within each graph to improve the
generation process via a dynamic graph attention mechanism.
By employing this dual graph attention approach, CCM effec-
tively captures and encodes more organized semantic details.
Wu et al. [95] found that previous commonsense knowledge-
enhanced dialogue systems (e.g., CCM) had a key limitation:
these systems usually retrieve knowledge facts without taking
into account the specific dialogue context, which can result
in the introduction of irrelevant knowledge facts (noises). To

11

address this issue, they proposed commonsense knowledge-
aware dialogue generation model (ConKADD, which consists
of: a knowledge retriever that extracts relevant commonsense
fact triples based on the query message, a context encoder that
summarizes utterances into contextual representations, and a
felicitous fact recognizer that calculates the probability distri-
bution of relevant facts over the retrieved set. This distribution
is then used to initialize the decoder and guide dialogue gener-
ation, employing a 0-1 indicator vector for supervised training.
Ling et al. [96] extended the retrieve-then-select approach to
more general open-ended dialogue systems. Recognizing that
open-domain commonsense reasoning often requires implicit
multi-hop reasoning, they proposed the external KnowlEdge-
Enhanced Prompting method (KEEP). This method constructs
the local knowledge graph based on the context and conceptual
knowledge graphs (e.g., ConceptNet [12]), and then incorpo-
rates the implicit knowledge in pre-trained language models
to prune irreverent path. Cai et al. [97] applied a similar
methodology to enhance empathetic dialogue generation.

The following methods dynamically generate relevant com-
monsense knowledge, which is different from the methods


mentioned above. Liu et al. [98] proposed a novel approach
that uses the COMET-BART model [22] to extract implicit
commonsense knowledge from the dialogue context. To im-
prove the language model’s understanding of the obtained
commonsense relations, they developed a method to express
the commonsense tuples using natural language templates.
These verbalized commonsense statements were then added to
the dialogue history as additional input text. Similarly, Finch
et al. [99] proposed a method that employs the T5-based
ConvoSenseGenerator [100] to produce inferences based on
the dialogue context and specified commonsense types. Sub-
sequently, GPT-3.5 is used to assess each inference, carefully
selecting the most useful, relevant, and interesting ones for the
next response. The final response generation step incorporates
the selected inferences and the dialogue context as input to
produce the next utterance. The dynamic heterogeneous-graph
reasoning method with language models and knowledge repre-
sentation learning (DHLK) [101] presents a novel approach to
integrating dynamic commonsense knowledge into language
models. It uses a two-stage pruning strategy that (1) filters
key entities based on the dictionary vocabulary to achieve the
first-stage pruning while incorporating the paraphrases in the
dictionary into the subgraph to construct the heterogeneous
knowledge graph (HKG), and (ii) encodes and fuses the
question answering context and HKG using a language model,
and dynamically removes irrelevant KG entities based on the
attention weights of the language model for the second-stage
pruning. Finally, DHLK performs answer reasoning on the
HKG by relation mask self-attention (RMSA).

B. Global Optimization

As shown in Fig. 3b, global optimization methods integrate
commonsense knowledge by first preparing a knowledge-
enhanced dataset and then fine-tuning a pre-trained model
(updating all of its parameters) to strengthen the model’s grasp
of the target knowledge. This fine-tuning process ensures the
model achieves desirable results regarding the target knowl-
edge, giving global optimization the advantages of precision
and generalization. However, this approach can struggle to
preserve the model’s original knowledge, and fine-tuning is
often time-consuming and prone to overfitting. Next, we
review recent works on commonsense reasoning that employ
the global optimization approach.

To enhance temporal commonsense reasoning, Kimura et
al. [102] proposed a language model created by multi-step
fine-tuning, continual pre-training, and multi-task learning,
using pre-trained models such as BERT [41], RoBERTa [38],
and ALBERT [103]. Their approach leverages masked lan-
guage modeling and the MCTACO dataset [48] to predict
temporal indicators, improving the performance on time-
related tasks. Notably, their experiments demonstrate that
ALBERT, when fine-tuned with auxiliary commonsense tasks,
yields the best results in temporal commonsense inference,
significantly outperforming standard fine-tuning techniques.
Huang et al. [104] presented an approach to enhancing event
causality identification, which distills commonsense meta-

12

graph from ConceptNet and then aggregates heterogeneous
information from the external meta-graph and the input text
through a commonsense-aware memory network. In the end,
they adopted continual pre-training and fine-tuning to further
fuse the input information, and make final predictions. Wang et
al. [105] proposed a framework called SinLG, which integrates
a pre-trained language model (PLM) with a graph neural
network (GNN) to enhance multi-turn response selection in
dialogue systems. The model leverages PLMs for capturing
word correlations and uses a GNN to incorporate common-
sense knowledge from external knowledge graphs. By fusing
the representations from the PLM and GNN through a Siamese
network architecture [106] and optimizing a similarity loss
function, the model transfers commonsense knowledge to
the PLM. This approach improves both the performance and
efficiency of the model, as only the PLM is required during
inference.

C. Local Modification

Local parameter editing represents an efficient and inter-
pretable method for knowledge editing, making it possible
to update open-source Transformer-based models without re-
training. As shown in Fig. 3c, it aims to identify and update
the specific parameters in LLMs related to targeted knowledge,
allowing for the incorporation of new, relevant information.
Previous applications of this technique have primarily focused
on editing factual knowledge with singular correct answers.
Gupta et al. [107] proposed MEMITcsx, which marks a
pioneering effort in extending this approach to the editing of
commonsense knowledge, typically accommodating multiple
correct answers. They initiated their study with a causal
analysis of GPT-2 Large and XL models [14], establishing
clear causal correlations between model predictions and local
parameters at the subject, verb, and object positions when
the models conduct commonsense plausibility tasks. Subse-
quently, they proposed Mass Editing Memory in a Transformer
for Commonsense Knowledge (MEMIT¢sx). This extension
encompasses editing diverse token positions (subject, verb,
object) and refining the layer selection strategy. Compared
to the vanilla MEMIT method [108], MEMITcsx improves
it for the commonsense domain by varying edit tokens and
improving the layer selection strategy.

V. APPLICATIONS

The application of commonsense knowledge in NLP has
opened new avenues for enhancing the performance and
versatility of various NLP tasks. This section explores how
incorporating commonsense knowledge enables more nuanced
and contextually aware language understanding, making it
possible to tackle complex tasks that require a deeper level of
reasoning and interpretation. We will discuss several key ap-
plications where commonsense knowledge plays a pivotal role,
including emotion detection, sarcasm detection and generation,
dialogue generation, question answering, machine translation,
and trustworthy AI. By examining these applications, we aim
to demonstrate the tangible benefits and the transformative


potential of integrating commonsense reasoning into NLP
models, paving the way for more sophisticated and human-
like interactions with machines.

A. Emotion Detection

Commonsense knowledge, particularly intuitive psychology,
enhances NLP models by providing a nuanced understanding
of social and cultural contexts. This capability allows for accu-
rate inference and prediction of contextual situations, evolving
emotional states, and intentions. As a result, it significantly
improves the models’ proficiency in detecting subtle and fine-
grained emotions. Zhong et al. [7] represented a pioneering
effort in integrating external commonsense knowledge for
emotion detection within textual dialogues. They proposed
a Knowledge Enriched Transformer (KET), where contextual
utterances are interpreted using hierarchical self-attention, and
external commonsense knowledge is dynamically leveraged
using a context-aware affective graph attention mechanism.
Based on that, Suresh and Ong [8] implemented more fine-
grained emotion recognition, without re-training language
models from scratch by augmenting the word-embedding.
Ghosal et al. [9] introduced the COSMIC framework, de-
signed to enhance utterance-level emotion recognition in con-
versations by incorporating commonsense knowledge. This
knowledge encompasses aspects like mental states, events,
and causal relationships, which are extracted from an external
commonsense knowledge graph. Nie et al. [10] employed the
classic commonsense knowledge atlas ATOMIC [21] to retrieve
prior knowledge for each utterance. This prior knowledge was
subsequently integrated as auxiliary information into an grow-
ing graph model, facilitating the enhancement of utterance
embeddings. Finally, they utilized a cross-attention module to
amalgamate previously extracted utterance features with latent
conversation topic information, which was derived through a
novel self-supervised learning approach.

B. Sarcasm Detection and Generation

Sarcasm detection and generation are challenging tasks in
NLP due to the subtle and often context-dependent nature
of sarcastic expressions. Sarcasm frequently involves saying
the opposite of what is meant, making it difficult for models
to accurately interpret or generate such language without a
deep understanding of context, tone, and intent. Commonsense
knowledge can play a crucial role in this process by providing
the model with the necessary background information to
recognize when a statement is intended sarcastically and to
generate sarcastic responses appropriately.

Basu Roy Chowdhury and Chaturvedi [109] explored the
use of commonsense knowledge in sarcasm detection, through
a graph convolutional network [110] integrating pre-trained
language model embeddings and COMET [111] (a GPT-2 [14]
model fine-tuned on ATOMIC [21]) commonsense sequences.
Despite applying it to multiple datasets, the commonsense-
augmented model performs similarly to a baseline model.
Through analysis, they found commonsense helps with sar-
casm involving polarity contrast but adds little value in non-

13

sarcastic contexts. Li et al. [112] presented a sarcasm detection
model that integrates commonsense knowledge via COMET.
Combining a BERT-based encoder with a commonsense rea-
soning module, the model improves sarcasm detection on
Twitter and Reddit datasets. Chen et al. [113] introduced a
sarcasm detection model using a heterogeneous graph attention
network that incorporates commonsense knowledge from Con-
ceptNet [12]. This approach captures implied sentiments often
missed by sentiment analysis alone, outperforming previous
methods on Reddit and Internet Argument Corpus datasets. Yu
et al. [114] presented a sarcasm detection model, Common-
sense Sentiment Dependency Graph Convolutional Network
(CSDGCN), which integrates commonsense knowledge with
syntactic structure. By constructing commonsense-augmented
sentiment and dependency graphs, the model captures contra-
dictions more effectively. Experiments show CSDGCN outper-
forms previous methods, highlighting the value of combining
commonsense and syntax for sarcasm detection.

Compared to sarcasm detection, fewer studies have focused
on sarcasm generation, as it is generally considered more
challenging and complex. Mishra et al. [115] presented a
framework for generating sarcastic sentences from literal,
negative opinions without the need for paired training data.
The system leverages a modular approach, consisting of
four stages: sentiment neutralization, positive sentiment in-
duction, negative situation retrieval, and sarcasm synthesis.
Chakrabarty et al. [116] presented an unsupervised sarcasm
generation framework with three modules: valence reversal,
commonsense retrieval, and semantic incongruity ranking.
The model enhances non-sarcastic inputs with commonsense
knowledge to generate creative, humorous sarcastic responses.
Human evaluations show it outperforms previous methods,
making it useful for conversational agents and content creation.

C. Dialogue Generation

Open-domain dialogue generation involves creating con-
versational agents capable of engaging in discussions across
a wide range of topics, without being limited to a specific
domain or subject area. For insights into how commonsense
knowledge can enhance open-domain dialogue generation, we
refer readers to Section IV-A, where we discuss recent works
in this area. Additionally, LLMs like GPT can be considered
open-domain dialogue agents due to their ability to converse
on diverse topics. Given the extensive research on LLMs, we
recommend readers consult survey papers focused on general
knowledge processing in these models [93], [117], [118]. Here,
we focus on a specific sub-domain of dialogue generation—
empathetic dialogue generation—where commonsense knowl-
edge plays a particularly crucial role.

Empathetic dialogue generation is a critical area of NLP
that focuses on creating responses that reflect understanding
and emotional sensitivity to the user’s situation or feelings.
Incorporating commonsense knowledge, particularly intuitive
psychology—the understanding of others’ emotions, inten-
tions, and mental states—plays a vital role in enhancing the
empathy of dialogue systems. By leveraging such knowl-


edge, models can better grasp the underlying emotional con-
text of a conversation and generate responses that are not
only contextually appropriate but also emotionally resonant.
Zhong et al. [119] proposed a model that integrates both
rationality, in the form of commonsense, and emotion into
conversational AI systems. The model constructs and in-
corporates latent concepts derived from an emotion-aware
commonsense knowledge graph to generate more accurate
and emotionally appropriate responses. Tu et al. [120] intro-
duced the MISC model that integrates fine-grained emotion
understanding with a mixed-strategy response model. The
model leverages COMET to enhance the understanding of
a user’s mental state and employs a strategy codebook for
generating empathetic and contextually appropriate responses.
Sabour et al. [121] also leveraged the COMET framework to
produce external commonsense knowledge (inferences about
the user’s situation and emotional state), and proposed the
CEM approach that incorporates both affective and cognitive
aspects of empathy, leading to more contextually appropriate
and empathetic responses. Li et al. [122] proposed the KEMP
model, which enhances empathetic dialogue generation by
constructing an emotional context graph from external knowl-
edge (ConceptNet and NRC VAD [123]) and employing an
emotional cross-attention mechanism to learn and utilize emo-
tional dependencies for generating more empathetic responses.
Cai et al. [97] proposed a method for empathetic dialogue
generation that dynamically selects and integrates the most
relevant commonsense knowledge using an adaptive module,
enhancing response consistency and emotional alignment with
the speaker’s context. Zhou et al. [124] introduced the CASE
model, which enhances empathetic response generation by
aligning coarse-to-fine cognition and affection through the in-
tegration of a commonsense cognition graph and an emotional
concept graph.

D. Textual Question Answering

Textual question answering aims at providing a precise
answer to the given question in natural language, by mining
from unstructured textual data. Depending on whether an
accompanied block of text is provided as context, textual
question answering is further divided into two sub-tasks:
machine reading comprehension (MRC) and open question
answering (OpenQA). In MRC, having access to external
commonsense knowledge allows inference over information
out of the context, even more so for OpenQA. Mihaylov and
Frank [125] developed a cloze-style reading comprehension
model that encodes relevant commonsense knowledge from
ConceptNet as a key-value memory. Other than performance
improvement over the baseline, the model could also provide
evidence about the background knowledge. Bauer et al. [126]
extracted relevant multi-hop knowledge reasoning paths from
ConceptNet that were subsequently used in the reasoning
cells to select helpful information for the NarrativeQA [127]
task. Zhong et al. [128] proposed to pre-train a commonsense
scoring function that exploits the graph structures in Concept-
Net to model direct and indirect relations between concepts,

14

which can be added to existing neural-based QA models.
Similarly, Chen et al. [129] adopted a graph-based module
to iteratively retrieve concepts and entities from multiple
knowledge sources, including ConceptNet. Bian et al. [130]
converted the commonsense QA task into an MRC task by
transforming the commonsense knowledge into a block of text
to serve as the accompanied context for the model to infer the
answer.

E. Machine Translation

It is believed that Bar-Hillel [4] was the first to mention the
importance of incorporating extra-linguistic knowledge into
machine translation programs, for the purpose of resolving
semantical ambiguities. Since then, many efforts have been put
into the task of knowledge-based machine translation [131].
With the advent of data-driven approaches and the creation of
commonsense knowledge resources, there has been some work
dedicated to the incorporation of commonsense knowledge
into machine translation systems. Caseli et al. [132] worked on
a project that aims at applying commonsense knowledge ex-
tracted from bilingual ConceptNets to the machine translation
task to generate more culturally contextualized translations.
To evaluate the commonsense reasoning capability of neural
machine translation, He et al. [133] created a test suite of 1,200
triplets covering lexical and syntactic ambiguities that require
commonsense reasoning to resolve. Liu et al. [134] improved
this evaluation method by considering the candidates as well
as the commonsense entities in the candidates, making the
results more aligned with human judgment. They also showed
that the incorporation of pre-trained knowledge leads to better
commonsense reasoning abilities.

F. Trustworthy AI

Trustworthy AI is an approach to AI development that
emphasizes safety and transparency for users. In the field
of NLP, one way to promote more trustworthy AI is by
mitigating hallucinations in large language models (LLMs).
Hallucination in LLMs refers to the generation of text that
is factually incorrect, nonsensical, or irrelevant to the given
context. This occurs when a model produces content that,
while seemingly coherent, is not grounded in reality or does
not align with the input data. Hallucinations can significantly
undermine the reliability and trustworthiness of language
models, particularly in critical applications such as healthcare
and finance, where LLMs like GPT-4 [16] are increasingly
integral. Consequently, mitigating hallucination is essential. In
anti-hallucination research, commonsense knowledge shares
characteristics with domain-specific knowledge. Due to this
similarity, a common approach to reducing hallucinations in
LLMs is to use general knowledge enhancement techniques
without strictly differentiating between domain-specific and
commonsense knowledge. This method’s strength lies in its
universality and flexibility, allowing it to address various
types of knowledge simultaneously. For methods using general
knowledge enhancement techniques to reduce hallucinations
in LLMs, we recommend referring to the survey paper by


Tonmoy et al. [135]. However, considering the unique role of
commonsense knowledge, this subsection will focus on papers
specifically addressing commonsense knowledge.

Toroghi et al. [136] proposed Right for Right Reasons
(R?), which leverages the intrinsic commonsense knowledge
in LLMs with external knowledge graphs to mitigate hal-
lucination. It begins by identifying query anchor entities in
the input and extracting related sub-graphs. It then elicits a
commonsense axiom from LLMs to guide reasoning within
each search tree branch. The algorithm iteratively evaluates
axiom satisfiability using available knowledge graph facts
at each tree level, making every reasoning step verifiable.
Similar to R°, the method proposed by Li et al. [137]
leverages external KGs and the LLMs’ intrinsic knowledge.
However, this approach first employs entity-guided knowledge
sub-graph retrieval, and then uses a probabilistic model for
step-by-step inference. Zhang et al. [138] proposed the Seif-
Alignment for Factuality approach, leveraging LLMs’ internal
knowledge to generate self-knowledge-guided training data
for fine-tuning, thereby enhancing commonsense reasoning
and mitigating hallucinations. This method comprises three
key steps: (i) sampling and verifying candidate answers for
factual correctness; (ii) constructing true/false training ex-
amples encompassing both correct and incorrect responses
while preserving the model’s prediction distribution across
diverse scenarios; and (iii) implementing Direct Preference
Optimization (DPO) [139] for fine-tuning.

It is believed that maintaining contextual semantic consis-
tency can effectively reduce hallucinations in LLMs [140].
Gao et al. [141] leveraged diffusion to learn to reconstruct
the implicit semantic connections between narrative contexts
and relevant commonsense knowledge by training Diffusion
Commonsense Transformer models. This approach avoids the
language models’ reasoning process from simply retrieving
discrete factual information from a commonsense knowledge
base. Instead, it converts the retrieved and contextually implied
commonsense knowledge into continuous vector representa-
tions, dynamically predicting and incorporating them into the
language models.

VI. DISCUSSION

In this discussion section, we delve into the unique contribu-
tions of this survey in comparison to existing literature, high-
lighting how our work differs in its comprehensive coverage
of commonsense knowledge in NLP. We will also explore the
challenges that remain unaddressed in the field, and propose
potential future research directions to advance the integration
of commonsense knowledge in NLP models. This discussion
aims to position our survey within the broader landscape of
research and provide insights for further developments in the
domain.

A. Comparison to Existing Literature

Davis and Marcus [3] explored the challenges and impor-
tance of commonsense reasoning and knowledge in artificial
intelligence, highlighting that despite advances in AI, progress

15

in this area has been slow. They discussed various approaches,
including logical analysis, handcrafted knowledge bases, web
mining, and crowdsourcing, but noted that no single method
has emerged as a comprehensive solution. Tandon et al. [142]
provided a comprehensive overview of the role of common-
sense knowledge in enhancing machine intelligence. They dis-
cussed the challenges in acquiring, representing, and applying
commonsense knowledge in various AI tasks, highlighting its
importance in NLP and smart computing applications. These
two works represent early surveys of commonsense knowledge
from a broader AI perspective, offering a general review of
commonsense knowledge in relation to machine intelligence.
In contrast, our work focuses specifically on the field of
NLP, providing a comprehensive introduction to commonsense
knowledge within this context and exploring its applications
in NLP models, including language models.

Some surveys have focused on specific aspects of com-
monsense knowledge. For example, Davis [143] provided a
comprehensive overview of over 100 benchmarks developed
to assess commonsense reasoning in AI systems, highlight-
ing significant flaws in many existing benchmarks. In the
context of NLP, some surveys have focused on certain tasks
or applications. For example, Storks et al. [144] provided
a comprehensive overview of recent developments in natu-
ral language inference (NLI), focusing on the creation of
benchmark datasets, the development of knowledge resources,
and the emergence of state-of-the-art learning and inference
models. They highlighted the critical role of these benchmarks
in advancing NLI research, addressing the complexities of
reasoning beyond the explicit content of text by incorporating
commonsense and world knowledge. Bhargava and Ng [145]
provided a survey of the use of pre-trained language models
(PLMs) for commonsense knowledge reasoning and genera-
tion, and discussed the strengths and limitations of current
PLMs in various tasks. Richardson and Heck [146] provided
a comprehensive survey on the integration of commonsense
reasoning in conversational AI, and Liu et al. [134] presented
a study on the integration of commonsense reasoning in
neural machine translation. While these surveys have different
focuses, our paper is more comprehensive, providing a holistic
and up-to-date overview that integrates various aspects of NLP
commonsense reasoning, including resources, benchmarks,
methodologies, and applications.

B. Future Research Directions

Commonsense reasoning continues to pose a major chal-
lenge in NLP due to the vast and varied nature of human
commonsense knowledge, which makes complete integration
difficult. Furthermore, commonsense knowledge differs sig-
nificantly across contexts, adding to the complexity. While
manually constructing a commonsense knowledge base or
using crowdsourcing is time-consuming and expensive, au-
tomatic extraction methods often face issues with accuracy.
Despite these obstacles, there are promising future directions
in commonsense reasoning research that hold the potential to
provide valuable insights for the NLP community.


1) Expression of commonsense knowledge: As shown in
Table I, early works on commonsense knowledge bases (prior
to 2020) typically adopted a structured graph format, where
concepts are represented as nodes and their relationships as
edges, such as in ConceptNet [12] and ATOMIC [21]. More
recent works, like MickeyCorpus [27] and Moral Events [30],
express commonsense knowledge directly in natural language,
ie., unstructured text, often with annotations. This shift is
likely due to the advent and development of LLMs, as the
most effective way to process commonsense knowledge with
LLMs is through natural language interaction. In fact, a study
by Bian et al. [147] demonstrated that LLMs retrieve com-
monsense knowledge more confidently and accurately from
unstructured stories than from structured rules. Additionally,
LLMs are more effective at leveraging stories than rules for
commonsense reasoning. Therefore, further investigation into
the optimal ways of expressing and utilizing different types of
commonsense knowledge for LLMs is warranted.

2) Knowledge priorities and conflicts in PLMs: The emer-
gence of pre-trained large language models, such as Chat-
GPT, has expanded the use cases of language models, re-
sulting in situations where models must handle various types
of knowledge (commonsense, domain-specific, and external
contextual knowledge) within the same reasoning task. This
convergence of knowledge types can potentially result in
knowledge conflicts, ultimately causing hallucinations during
the model’s reasoning process. While researchers like Jin et
al. [148], Wu et al. [149] and Zhang et al. [150] have astutely
identified and discussed this phenomenon, current literature
primarily focuses on detecting and resolving conflicts between
the model’s internal parametric knowledge and user-provided
external non-parametric knowledge. We advocate for a deeper
investigation into knowledge prioritization within language
models, as well as the detection and resolution of internal
parametric knowledge conflicts that arise after augmenting
the model with various types of knowledge. This research
direction could lead to more coherent and reliable reasoning
in LLMs, potentially mitigating hallucinations and improving
performance across diverse tasks that require the integration
of multiple knowledge types.

3) Commonsense reasoning benchmarks: As LLMs have
advanced significantly in recent years, numerous benchmarks
have been developed to assess their various capabilities.
However, a study by McIntosh et al. [151] analyzed 23
state-of-the-art benchmarks and highlighted significant limi-
tations, including biases, challenges in accurately measuring
reasoning abilities, and a lack of attention to cultural and
ideological diversity. Bhargava and Ng [145] further noted
that many LLMs have achieved near-human performance on
commonsense reasoning benchmarks, particularly in question
answering tasks. However, high scores on these benchmarks
do not necessarily indicate that the models possess near-
human commonsense reasoning abilities. A deeper analysis
of models’ true reasoning capabilities is needed, along with
the development of more comprehensive and standardized
benchmarks to keep pace with the evolving nature of LLMs.

16

4) Commonsense knowledge in multicultural contexts:
While naive physics commonsense knowledge is generally
universal across human societies, intuitive psychology com-
monsense can vary depending on linguistic or cultural back-
grounds, particularly regarding daily activities, social behav-
iors, and norms. Some existing studies have incorporated mul-
tilingual settings when developing commonsense knowledge
resources and benchmarks. For instance, XCOPA [65] is a
multilingual benchmark that translates and re-annotates the
English COPA [52] into 11 languages. Similarly, X-CSQA and
X-CODAH [27] are translations of the English CSQA [47] and
CODAH [61] benchmarks, with questions that might involve
cultural differences intentionally removed. However, simply
translating existing resources is insufficient for capturing the
nuances of multilingual commonsense knowledge, as noted by
Sakai et al. [152]. Instead of relying on translation, they built
on a multilingual commonsense knowledge base (ConceptNet)
and used LLMs to generate and validate questions, options,
and additional distractors. Despite these efforts, the differences
in social behaviors and norms across multicultural contexts
remain underexplored. Datasets like SOCIALDIAL [28], which
focuses on Chinese social culture, and NORMDIAL [29],
which studies social norms in both Chinese and American
cultures in conversational settings, are important steps forward.
Expanding commonsense knowledge resources and bench-
marks to encompass more diverse cultural backgrounds is
crucial, and this task will likely require collaboration with
experts in sociology and linguistics.

5) Commonsense knowledge in multimodal models: Re-
cent advancements in multimodal models have significantly
improved the integration of commonsense knowledge across
various modalities. Research on Commonsense-T2I [153]
demonstrates that enhancing commonsense knowledge in a
single modality is insufficient to ensure robust commonsense
reasoning capabilities in large multimodal models. Therefore,
enhancing, aligning and resolving conflicts between different
modalities remains challenging. We call upon the research
community to further investigate commonsense enhancement
methods for multimodal models, particularly focusing on
aligning commonsense knowledge across different modalities
to prevent internal knowledge conflicts. While there have been
initial forays into addressing this challenge, including the
proposal of a universal representation framework by Zhang
et al. [154], the field is still in the nascent stages of under-
standing how commonsense knowledge can be effectively rep-
resented and utilized within multimodal LLMs. Additionally,
due to modern (multimodal) language models’ deployment
constraints on resource-limited devices such as smartphones,
we advocate for distilling commonsense-enhanced multimodal
large language models into smaller multimodal or unimodal
models. We encourage the community to continue investi-
gating techniques to improve inference abilities in resource-
limited deployed models.


VII. CONCLUSION

In conclusion, this survey has provided a comprehensive
overview of the integration of commonsense knowledge in
natural language processing, covering key aspects such as
prominent knowledge bases, benchmarks for assessing com-
monsense reasoning, methodologies for incorporating this
knowledge into models, and real-world applications. By syn-
thesizing the current state of research, we have highlighted
the advancements and identified the gaps that still exist in the
field. As NLP continues to evolve, the role of commonsense
knowledge will become increasingly crucial, offering opportu-
nities for more intelligent and context-aware systems. Future
research should focus on addressing the identified challenges,
particularly in enhancing the scalability and generalization
of models, to further bridge the gap between human-like
understanding and machine learning.

[7]

[8]

[9]

[10]

(11)

[12]

{13]

[14]

REFERENCES

W. Weaver, “Translation,” in Proceedings of the Conference on Me-
chanical Translation, 1952.

W. J. Hutchins, “The Georgetown-IBM experiment demonstrated in
January 1954,” in Proceedings of AMTA 2004, Machine Translation:
From Real Users to Research, ser. Lecture Notes in Computer Science,
vol. 3265. Springer, 2004, pp. 102-114.

E. Davis and G. Marcus, ““Commonsense reasoning and commonsense
knowledge in artificial intelligence,’ Commun. ACM, vol. 58, no. 9,
pp. 92-103, 2015.

Y. Bar-Hillel, “The present status of automatic translation of lan-
guages,” Adv. Comput., vol. 1, pp. 91-163, 1960.

A. Ait-Mlouk and L. Jiang, “KBot: A knowledge graph based chatbot
for natural language understanding over linked data,’ IEEE Access,
vol. 8, pp. 149 220-149 230, 2020.

A. Augello, G. Pilato, G. Vassallo, and S. Gaglio, “Chatbots as
interface to ontologies,” in Advances onto the Internet of Things - How
Ontologies Make the Internet of Things Meaningful, ser. Advances in
Intelligent Systems and Computing. Springer, 2014, vol. 260, pp.
285-299.

P. Zhong, D. Wang, and C. Miao, “Knowledge-enriched Transformer
for emotion detection in textual conversations,” in Proceedings of
EMNLP-IJCNLP 2019. Association for Computational Linguistics,
2019, pp. 165-176.

V. Suresh and D. C. Ong, “Using knowledge-embedded attention
to augment pre-trained language models for fine-grained emotion
recognition,” in Proceedings of ACII 2021. JEEE, 2021, pp. 1-8.

D. Ghosal, N. Majumder, A. F. Gelbukh, R. Mihalcea, and S. Poria,
“COSMIC: COmmonSense knowledge for eMotion Identification in
Conversations,” in Findings of EMNLP 2020. Association for Com-
putational Linguistics, 2020, pp. 2470-2481.

W. Nie, Y. Bao, Y. Zhao, and A. Liu, “Long dialogue emotion
detection based on commonsense knowledge graph guidance,” [EEE
Transactions on Multimedia, 2023.

P. Singh, T. Lin, E. T. Mueller, G. Lim, T. Perkins, and W. L. Zhu,
“Open Mind Common Sense: Knowledge acquisition from the general
public,” in Proceedings of On the Move to Meaningful Internet Systems
2002: CoopIS, DOA, and ODBASE, ser. Lecture Notes in Computer
Science, vol. 2519. Springer, 2002, pp. 1223-1237.

R. Speer, J. Chin, and C. Havasi, “ConceptNet 5.5: An open multi-
lingual graph of general knowledge,” in Proceedings of AAAI 2017.
AAAI Press, 2017, pp. 4444-4451.

A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever, “Improving
language understanding by generative pre-training,’ OpenAl Blog,
2018.

A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever,
“Language models are unsupervised multitask learners,’ OpenAI Blog,
2019.

17

{15]

[16]
[17]

[18]

[19]

[20]

[21]

[22]

[23]

[24]

[25]

[26]

[27]

[28]

[29]

[30]

[31]

[32]

[33]

[34]

T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhari-
wal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal,
A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M.
Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin,
S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford,
I. Sutskever, and D. Amodei, “Language models are few-shot learners,”
in Proceedings of NeurIPS 2020, 2020.

OpenAI, “GPT-4 technical report,” CoRR, vol. abs/2303.08774, 2023.
D. B. Lenat and R. V. Guha, Building large knowledge-based systems:
Representation and inference in the Cyc project. Addison-Wesley
Longman Publishing Co., Inc., 1989.

E. Cambria, Y. Li, F. Z. Xing, S. Poria, and K. Kwok, “SenticNet 6:
Ensemble application of symbolic and subsymbolic AI for sentiment
analysis,” in Proceedings of CIKM 2020. ACM, 2020, pp. 105-114.
N. Tandon, G. de Melo, and G. Weikum, “WebChild 2.0: Fine-grained
commonsense knowledge distillation,’ in Proceedings of ACL 2017.
Association for Computational Linguistics, 2017, pp. 115-120.

S. Gottschalk and E. Demidova, “EventKG: A multilingual event-
centric temporal knowledge graph,” in Proceedings of ESWC 2018,
ser. Lecture Notes in Computer Science, vol. 10843. Springer, 2018,
pp. 272-287.

M. Sap, R. L. Bras, E. Allaway, C. Bhagavatula, N. Lourie, H. Rashkin,
B. Roof, N. A. Smith, and Y. Choi, “ATOMIC: An atlas of machine
commonsense for if-then reasoning,” in Proceedings of AAAI 2019.
AAAT Press, 2019, pp. 3027-3035.

J. D. Hwang, C. Bhagavatula, R. L. Bras, J. Da, K. Sakaguchi,
A. Bosselut, and Y. Choi, “(Comet-) Atomic 2020: On symbolic and
neural commonsense knowledge graphs,” in Proceedings of AAAI 2021.
AAAI Press, 2021, pp. 6384-6392.

H. Zhang, X. Liu, H. Pan, Y. Song, and C. W. Leung, “ASER: A large-
scale eventuality knowledge graph,” in Proceedings of WWW 2020.
ACM/IW3C2, 2020, pp. 201-211.

N. Mostafazadeh, A. Kalyanpur, L. Moon, D. W. Buchanan,
L. Berkowitz, O. Biran, and J. Chu-Carroll, “GLUCOSE: Generalized
and contextualized story explanations,’ in Proceedings of EMNLP
2020. Association for Computational Linguistics, 2020, pp. 4569-
4586.

M. Forbes, J. D. Hwang, V. Shwartz, M. Sap, and Y. Choi, “Social
Chemistry 101: Learning to reason about social and moral norms,”
in Proceedings of EMNLP 2020. Association for Computational
Linguistics, 2020, pp. 653-670.

F. Ilievski, P. A. Szekely, and B. Zhang, “CSKG: The commonsense
knowledge graph,” in Proceedings of ESWC 2021, ser. Lecture Notes
in Computer Science, vol. 12731. Springer, 2021, pp. 680-696.

B. Y. Lin, S. Lee, X. Qiao, and X. Ren, “Common sense beyond
English: Evaluating and improving multilingual language models for
commonsense reasoning,” in Proceedings of ACL/IJCNLP 2021. As-
sociation for Computational Linguistics, 2021, pp. 1274-1287.

H. Zhan, Z. Li, Y. Wang, L. Luo, T. Feng, X. Kang, Y. Hua, L. Qu,
L. Soon, S. Sharma, I. Zukerman, Z. Semnani-Azad, and G. Haffari,
“SocialDial: A benchmark for socially-aware dialogue systems,” in
Proceedings of SIGIR 2023. ACM, 2023, pp. 2712-2722.

O. Li, M. Subramanian, A. Saakyan, S. CH-Wang, and S. Muresan,
“NormDial: A comparable bilingual synthetic dialog dataset for mod-
eling social norm adherence and violation,” in Proceedings of EMNLP
2023. Association for Computational Linguistics, 2023, pp. 15 732-
15 744.

X. F Zhang, W. Wu, N. Beauchamp, and L. Wang, “MOKA: Moral
knowledge augmentation for moral event extraction,” in Proceedings of
NAACL-HLT 2024. Association for Computational Linguistics, 2024,
pp. 4481-4502.

J. Wu, Z. Chen, J. Deng, S. Sabour, H. Meng, and M. Huang,
“COKE: A cognitive knowledge graph for machine theory of mind,” in
Proceedings of ACL 2024. Association for Computational Linguistics,
2024.

G. A. Miller, “WordNet: A lexical database for English,’ Commun.
ACM, vol. 38, no. 11, pp. 39-41, 1995.

D. Vrandecic and M. Krotzsch, “Wikidata: A free collaborative knowl-
edgebase,’ Commun. ACM, vol. 57, no. 10, pp. 78-85, 2014.

E. Cambria, Q. Liu, S. Decherchi, F. Xing, and K. Kwok, “SenticNet
7: A commonsense-based neurosymbolic AI framework for explain-
able sentiment analysis,” in Proceedings of LREC 2022. European
Language Resources Association, 2022, pp. 3829-3839.


[35]

[36]

[37]

[38]

[39]

[40]

[41]

[42]

[43]

[44]

[45]

[46]

[47]

[48]

[49]

[50]

[51]

[52]

[53]

[54]

E. Cambria, X. Zhang, R. Mao, M. Chen, and K. Kwok, “SenticNet 8:
Fusing emotion AI and commonsense AI for interpretable, trustworthy,
and explainable affective computing,’ in Proceedings of HCII 2024,
2024.

C. Strapparava and A. Valitutti, “WordNet-Affect: An affective exten-
sion of WordNet,” in Proceedings of LREC 2004. European Language
Resources Association, 2004.

T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean,
“Distributed representations of words and phrases and their compo-
sitionality,” in Proceedings of NeurIPS 2013, 2013, pp. 3111-3119.
Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,
L. Zettlemoyer, and V. Stoyanov, “RoBERTa: A robustly optimized
BERT pretraining approach,” CoRR, vol. abs/1907.11692, 2019.

P. P. Ray, “ChatGPT: A comprehensive review on background, ap-
plications, key challenges, bias, ethics, limitations and future scope,”
Internet of Things and Cyber-Physical Systems, vol. 3, pp. 121-154,
2023.

R. Krishna, Y. Zhu, O. Groth, J. Johnson, K. Hata, J. Kravitz, S. Chen,
Y. Kalantidis, L. Li, D. A. Shamma, M. S. Bernstein, and L. Fei-Fei,
“Visual Genome: Connecting language and vision using crowdsourced
dense image annotations,” Int. J. Comput. Vis., vol. 123, no. 1, pp.
32-73, 2017.

J. Devlin, M. Chang, K. Lee, and K. Toutanova, “BERT: pre-training
of deep bidirectional transformers for language understanding,” in
Proceedings of NAACL-HLT 2019. Association for Computational
Linguistics, 2019, pp. 4171-4186.

J. Haidt and J. Graham, “When morality opposes justice: Conservatives
have moral intuitions that liberals may not recognize,” Social Justice
Research, vol. 20, no. 1, pp. 98-116, 2007.

J. Graham, J. Haidt, and B. A. Nosek, “Liberals and conservatives rely
on different sets of moral foundations,” Journal of Personality and
Social Psychology, vol. 96, no. 5, p. 1029, 2009.

J. Graham, J. Haidt, S. Koleva, M. Motyl, R. Iyer, S. P. Wojcik, and
P. H. Ditto, “Moral foundations theory: The pragmatic validity of moral
pluralism,” in Advances in Experimental Social Psychology. Elsevier,
2013, vol. 47, pp. 55-130.

D. Premack and G. Woodruff, “Does the chimpanzee have a theory
of mind?” Behavioral and Brain Sciences, vol. 1, no. 4, pp. 515-526,
1978.

T. Mihaylov, P. Clark, T. Khot, and A. Sabharwal, “Can a suit of armor
conduct electricity? A new dataset for open book question answering,”
in Proceedings of EMNLP 2018. Association for Computational
Linguistics, 2018, pp. 2381-2391.

A. Talmor, J. Herzig, N. Lourie, and J. Berant, “CommonsenseQA:
A question answering challenge targeting commonsense knowledge,”
in Proceedings of NAACL-HLT 2019. Association for Computational
Linguistics, 2019, pp. 4149-4158.

B. Zhou, D. Khashabi, Q. Ning, and D. Roth, “‘Going on a vacation’
takes longer than ‘going for a walk’: A study of temporal commonsense
understanding,” in Proceedings of EMNLP-IJCNLP 2019. Association
for Computational Linguistics, 2019, pp. 3361-3367.

Q. Chen, X. Zhu, Z. Ling, S. Wei, H. Jiang, and D. Inkpen, “Enhanced
LSTM for natural language inference,” in Proceedings of ACL. As-
sociation for Computational Linguistics, 2017, pp. 1657-1668.

M. Sap, H. Rashkin, D. Chen, R. L. Bras, and Y. Choi, “Social IQa:

Commonsense reasoning about social interactions,’ in Proceedings of

EMNLP-IJCNLP 2019.
2019, pp. 4462-4472.
H. J. Levesque, “The Winograd schema challenge,” in Logical For-
malizations of Commonsense Reasoning, Papers from the 2011 AAAI
Spring Symposium, Technical Report SS-11-06. AAAI, 2011.

M. Roemmele, C. A. Bejan, and A. S. Gordon, “Choice of plausible
alternatives: An evaluation of commonsense causal reasoning,” in
Logical Formalizations of Commonsense Reasoning, AAAI 2011 Spring
Symposium, Technical Report SS-11-06._AAAI Press, 2011.

L. Huang, R. L. Bras, C. Bhagavatula, and Y. Choi, “Cosmos QA:
Machine reading comprehension with contextual commonsense rea-
soning,” in Proceedings of EMNLP-IJCNLP 2019. Association for
Computational Linguistics, 2019, pp. 2391-2401.

S. Aroca-Ouellette, C. Paik, A. Roncone, and K. Kann, “PROST:
Physical reasoning about objects through space and time,” in Findings
of ACL-IJCNLP 2021. Association for Computational Linguistics,
2021, pp. 4597-4608.

Association for Computational Linguistics,

18

[55]

[56]

[57]

[58]

[59]

[60]

[61]

[62]

[63]
[64]

[65]

[66]

[67]

[68]

[69]

[70]

[71]

[72]

[73]

[74]

[75]

M. Ashida and S. Sugawara, “Possible Stories: Evaluating situated
commonsense reasoning under multiple possible scenarios,” in Pro-
ceedings of COLING 2022. International Committee on Computational
Linguistics, 2022, pp. 3606-3630.

H. Gupta, N. Varshney, S. Mishra, K. K. Pal, S. A. Sawant, K. Scaria,
S. Goyal, and C. Baral, “‘John is 50 years old, can his son be 65?’
Evaluating NLP models’ understanding of feasibility,’ in Proceedings
of EACL 2023. Association for Computational Linguistics, 2023, pp.
407-417.

C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena,
Y. Zhou, W. Li, and P. J. Liu, “Exploring the limits of transfer learning
with a unified text-to-text Transformer,’ J. Mach. Learn. Res., vol. 21,
pp. 140:1-140:67, 2020.

Y. Wang and Y. Zhao, “TRAM: Benchmarking temporal reasoning for
large language models,” in Findings of ACL 2024. Association for
Computational Linguistics, 2024, pp. 6389-6415.

R. Zellers, Y. Bisk, R. Schwartz, and Y. Choi, “SWAG: A large-scale
adversarial dataset for grounded commonsense inference,” in Proceed-
ings of EMNLP 2018. Association for Computational Linguistics,
2018, pp. 93-104.

R. Zellers, A. Holtzman, Y. Bisk, A. Farhadi, and Y. Choi, “HellaSwag:
Can a machine really finish your sentence?” in Proceedings of ACL
2019. Association for Computational Linguistics, 2019, pp. 4791-
4800.

M. Chen, M. D’Arcy, A. Liu, J. Fernandez, and D. Downey, “CODAH:
An adversarially authored question-answer dataset for common sense,”
CoRR, vol. abs/1904.04365, 2019.

L. Qin, A. Gupta, S. Upadhyay, L. He, Y. Choi, and M. Faruqui,
“TIMEDIAL: Temporal commonsense reasoning in dialog,” in Pro-
ceedings of ACL/AIJCNLP 2021. Association for Computational
Linguistics, 2021, pp. 7066-7076.

A. M. Turing, Computing machinery and intelligence. Springer, 2009.
A. S. Gordon, “Commonsense interpretation of triangle behavior,” in
Proceedings of AAAI 2016. AAAI Press, 2016, pp. 3719-3725.

E. M. Ponti, G. Glavas, O. Majewska, Q. Liu, I. Vulic, and A. Korho-
nen, “XCOPA: A multilingual dataset for causal commonsense reason-
ing,” in Proceedings of EMNLP 2020. Association for Computational
Linguistics, 2020, pp. 2362-2376.

Y. Bisk, R. Zellers, R. L. Bras, J. Gao, and Y. Choi, “PIQA: Reasoning
about physical commonsense in natural language,” in Proceedings of
AAAI 2020. AAAI Press, 2020, pp. 7432-7439.

A. Talmor, O. Yoran, R. L. Bras, C. Bhagavatula, Y. Goldberg,
Y. Choi, and J. Berant, “CommonsenseQA 2.0: Exposing the limits
of AI through gamification,” in Proceedings of NeurIPS Datasets and
Benchmarks 2021, 2021.

N. Lourie, R. L. Bras, C. Bhagavatula, and Y. Choi, “UNICORN on
RAINBOW: A universal commonsense reasoning model on a new
multitask benchmark,” in Proceedings of AAAI 2021. AAAI Press,
2021, pp. 13 480-13 488.

K. Gandhi, J. Franken, T. Gerstenberg, and N. D. Goodman, “Under-
standing social reasoning in language models with language models,”
in Proceedings of NeurIPS 2023, 2023.

N. Mostafazadeh, N. Chambers, X. He, D. Parikh, D. Batra, L. Van-
derwende, P. Kohli, and J. F Allen, “A corpus and cloze evaluation
for deeper understanding of commonsense stories,” in Proceedings of
NAACL-HLT 2016. The Association for Computational Linguistics,
2016, pp. 839-849.

C. Bhagavatula, R. L. Bras, C. Malaviya, K. Sakaguchi, A. Holtzman,
H. Rashkin, D. Downey, W. Yih, and Y. Choi, “Abductive common-
sense reasoning,” in Proceedings of ICLR 2020. OpenReview.net,
2020.

R. Rudinger, V. Shwartz, J. D. Hwang, C. Bhagavatula, M. Forbes,
R. L. Bras, N. A. Smith, and Y. Choi, “Thinking like a skeptic:
Defeasible inference in natural language,” in Findings of EMNLP 2020.
Association for Computational Linguistics, 2020, pp. 4661-4675.

S. Zhang, X. Liu, J. Liu, J. Gao, K. Duh, and B. V. Durme, “ReCoRD:
Bridging the gap between human and machine commonsense reading
comprehension,” CoRR, vol. abs/1810.12885, 2018.

B. Y. Lin, S. Lee, R. Khanna, and X. Ren, “Birds have four legs?! Nu-
merSense: Probing numerical commonsense knowledge of pre-trained
language models,” in Proceedings of EMNLP 2020. Association for
Computational Linguistics, 2020, pp. 6862-6868.

H. Rashkin, A. Bosselut, M. Sap, K. Knight, and Y. Choi, “Modeling
naive psychology of characters in simple commonsense stories,” in


[76]

[77]

[78]

[79]

[80]

[81]

[82]

[83]

[84]

[85]

[86]

[87]

[88]

[89]

[90]

[91]

[92]

[93]

[94]

[95]

Proceedings ACL 2018.
2018, pp. 2289-2299.
A. H. Maslow, “A theory of human motivation,” Psychological Review,
vol. 50, no. 4, p. 370, 1943.

S. Reiss, “Multifaceted nature of intrinsic motivation: The theory of
16 basic desires,” Review of General Psychology, vol. 8, no. 3, pp.
179-193, 2004.

R. Plutchik, “A general psychoevolutionary theory of emotion,” in
Theories of Emotion. Elsevier, 1980, pp. 3-33.

D. Hendrycks, C. Burns, S. Basart, A. Critch, J. Li, D. Song, and
J. Steinhardt, “Aligning AI with shared human values,” in Proceedings
of ICLR 2021. OpenReview.net, 2021.

I. Gusev and A. Tikhonov, “HeadlineCause: A dataset of news
headlines for detecting causalities,’ in Proceedings of LREC 2022.
European Language Resources Association, 2022, pp. 6153-6161.

H. Rashkin, M. Sap, E. Allaway, N. A. Smith, and Y. Choi,
“Event2Mind: Commonsense inference on events, intents, and reac-
tions,” in Proceedings ACL 2018. Association for Computational
Linguistics, 2018, pp. 463-473.

W. Chen, X. Wang, and W. Y. Wang, “A dataset for answering
time-sensitive questions,” in Proceedings of NeurIPS Datasets and
Benchmarks 2021, 2021.

Q. Ning, H. Wu, R. Han, N. Peng, M. Gardner, and D. Roth,
“TORQUE: A reading comprehension dataset of temporal ordering
questions,” in Proceedings of EMNLP 2020. Association for Compu-
tational Linguistics, 2020, pp. 1158-1172.

B. Y. Lin, M. Shen, W. Zhou, P. Zhou, C. Bhagavatula, Y. Choi, and
X. Ren, “CommonGen: A constrained text generation challenge for
generative commonsense reasoning,” in Proceedings of AKBC 2020,
2020.

A. Majumdar, A. Ajay, X. Zhang, P. Putta, S. Yenamandra, M. Henaff,
S. Silwal, P. Mcvay, O. Maksymets, S. Arnaud, K. Yadav, Q. Li,
B. Newman, M. Sharma, V. Berges, S. Zhang, P. Agrawal, Y. Bisk,
D. Batra, M. Kalakrishnan, F. Meier, C. Paxton, A. Sax, and A. Ra-
jeswaran, “OpenEQA: Embodied question answering in the era of
foundation models,” in Proceedings of CVPR 2024. Computer Vision
Foundation / IEEE Computer Society, 2024, pp. 16 488-16 498.

A. Das, S. Datta, G. Gkioxari, S. Lee, D. Parikh, and D. Batra, “Em-
bodied question answering,” in Proceedings of CVPR 2018. Computer
Vision Foundation / IEEE Computer Society, 2018, pp. 1-10.

Z. Yang, L. Li, K. Lin, J. Wang, C. Lin, Z. Liu, and L. Wang, “The
dawn of LMMs: Preliminary explorations with GPT-4V(ision),” CoRR,
vol. abs/2309.17421, 2023.

A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman,
“GLUE: A multi-task benchmark and analysis platform for natural lan-
guage understanding,” in Proceedings of ICLR 2019. OpenReview.net,
2019.

A. Wang, Y. Pruksachatkun, N. Nangia, A. Singh, J. Michael, F. Hill,
O. Levy, and S. R. Bowman, “SuperGLUE: A stickier benchmark for
general-purpose language understanding systems,” in Proceedings of
NeurIPS 2019, 2019, pp. 3261-3275.

L. Xu, H. Hu, X. Zhang, L. Li, C. Cao, Y. Li, Y. Ku, K. Sun,
D. Yu, C. Yu, Y. Tian, Q. Dong, W. Liu, B. Shi, Y. Cui, J. Li,
J. Zeng, R. Wang, W. Xie, Y. Li, Y. Patterson, Z. Tian, Y. Zhang,
H. Zhou, S. Liu, Z. Zhao, Q. Zhao, C. Yue, X. Zhang, Z. Yang,
K. Richardson, and Z. Lan, “CLUE: A Chinese language understanding
evaluation benchmark,” in Proceedings of COLING 2020. International
Committee on Computational Linguistics, 2020, pp. 4762-4772.

J. Guan, Z. Feng, Y. Chen, R. He, X. Mao, C. Fan, and M. Huang,
“LOT: A story-centric benchmark for evaluating Chinese long text
understanding and generation,” Trans. Assoc. Comput. Linguistics,
vol. 10, pp. 434-451, 2022.

A. Srivastava, A. Rastogi, A. Rao, A. A. M. Shoeb, A. Abid, A. Fisch,
A. R. Brown, A. Santoro, A. Gupta, A. Garriga-Alonso et al., “Beyond
the Imitation Game: Quantifying and extrapolating the capabilities of
language models,” Trans. Mach. Learn. Res., vol. 2023, 2023.

S. Wang, Y. Zhu, H. Liu, Z. Zheng, C. Chen, and J. Li, “Knowl-
edge editing for large language models: A survey,’ CoRR, vol.
abs/2310.16218, 2023.

H. Zhou, T. Young, M. Huang, H. Zhao, J. Xu, and X. Zhu, “Common-
sense knowledge aware conversation generation with graph attention,”
in Proceedings of IJCAI 2018.  ijcai.org, 2018, pp. 4623-4629.

S. Wu, Y. Li, D. Zhang, Y. Zhou, and Z. Wu, “Diverse and informative
dialogue generation with context-specific commonsense knowledge

Association for Computational Linguistics,

19

[96]

[97]

[98]

[99]

100]

101]

102]

103]

104]

105]

106]

107]

108]

109]

110]

111]

112]

113]

114]

115]

116]

awareness,” in Proceedings of ACL 2020.
tational Linguistics, 2020, pp. 5811-5820.
C. Ling, X. Zhang, X. Zhao, Y. Liu, W. Cheng, M. Oishi, T. Osaki,
K. Matsuda, H. Chen, and L. Zhao, “Open-ended commonsense
reasoning with unrestricted answer scope,” CoRR, vol. abs/2310.11672,
2023.

H. Cai, X. Shen, Q. Ku, W. Shen, X. Wang, W. Ge, X. Zheng, and
X. Xue, “Improving empathetic dialogue generation by dynamically
infusing commonsense knowledge,” in Findings of ACL 2023. Asso-
ciation for Computational Linguistics, 2023, pp. 7858-7873.

Y. Liu and H. Kilicoglu, “Commonsense-aware prompting for con-
trollable empathetic dialogue generation,” CoRR, vol. abs/2302.01441,
2023.

S. E. Finch and J. D. Choi, “Leveraging explicit reasoning for inference
integration in commonsense-augmented dialogue models,” CoRR, vol.
abs/2406.09138, 2024.

—., “ConvoSense: Overcoming monotonous commonsense infer-
ences for conversational AI,” Trans. Assoc. Comput. Linguistics,
vol. 12, pp. 467-483, 2024.

Y. Wang, H. Zhang, J. Liang, and R. Li, “Dynamic heterogeneous-
graph reasoning with language models and knowledge representation
learning for commonsense question answering,” in Proceedings of ACL
2023. Association for Computational Linguistics, 2023.

M. Kimura, L. K. Pereira, and I. Kobayashi, “Toward building a lan-
guage model for understanding temporal commonsense,” in Proceed-
ings of AACL/IJCNLP 2022, Student Research Workshop. Association
for Computational Linguistics, 2022, pp. 17-24.

Z. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, and R. Soricut,
“ALBERT: A lite BERT for self-supervised learning of language
representations,” in Proceedings of ICLR 2020. OpenReview.net, 2020.
P. Huang, X. Zhao, M. Hu, Z. Tan, and W. Xiao, “Distill, fuse, pre-train:
Towards effective event causality identification with commonsense-
aware pre-trained model,” in Proceedings of LREC/COLING 2024.
ELRA and ICCL, 2024, pp. 5029-5040.

Y. Wang, X. Ren, T. Chen, Y. Dong, N. Q. V. Hung, and J. Tang,
“Multi-turn response selection with commonsense-enhanced language
models,” CoRR, vol. abs/2407.18479, 2024.

X. Chen and K. He, “Exploring simple siamese representation learn-
ing,” in Proceedings of CVPR 2021. Computer Vision Foundation /
IEEE, 2021, pp. 15 750-15 758.

A. Gupta, D. Mondal, A. K. Sheshadri, W. Zhao, X. Li, S. Wiegreffe,
and N. Tandon, “Editing common sense in Transformers,” in Proceed-
ings of EMNLP 2023. Association for Computational Linguistics,
2023, pp. 8214-8232.

K. Meng, A. S. Sharma, A. J. Andonian, Y. Belinkov, and D. Bau,
“Mass-editing memory in a transformer,” in Proceedings of ICLR 2023.
OpenReview.net, 2023.

S. Basu Roy Chowdhury and S. Chaturvedi, “Does commonsense help
in detecting sarcasm?” in Proceedings of the Second Workshop on
Insights from Negative Results in NLP. Association for Computational
Linguistics, 2021, pp. 9-15.

T. N. Kipf and M. Welling, “Semi-supervised classification with graph
convolutional networks,” in Proceedings of ICLR 2017. | OpenRe-
view.net, 2017.

A. Bosselut, H. Rashkin, M. Sap, C. Malaviya, A. Celikyilmaz, and
Y. Choi, “COMET: Commonsense transformers for automatic knowl-
edge graph construction,” in Proceedings of ACL 2019. Association
for Computational Linguistics, 2019, pp. 4762-4779.

J. Li, H. Pan, Z. Lin, P. Fu, and W. Wang, “Sarcasm detection with
commonsense knowledge,” IEEE ACM Trans. Audio Speech Lang.
Process., vol. 29, pp. 3192-3201, 2021.

W. Chen, F. Lin, G. Li, X. Zhang, and B. Liu, “Commonsense-aware
sarcasm detection with heterogeneous graph attention network,” in
IEEE International Conference on Systems, Man, and Cybernetics,
SMC 2022. IEEE, 2022, pp. 2181-2188.

Z. Yu, D. Jin, X. Wang, Y. Li, L. Wang, and J. Dang, ““Commonsense
knowledge enhanced sentiment dependency graph for sarcasm detec-
tion,” in Proceedings of IJCAI 2023.  ijcai.org, 2023, pp. 2423-2431.
A. Mishra, T. Tater, and K. Sankaranarayanan, “A modular architecture
for unsupervised sarcasm generation,’ in Proceedings of EMNLP-
IJCNLP 2019. Association for Computational Linguistics, 2019, pp.
6143-6153.

T. Chakrabarty, D. Ghosh, S. Muresan, and N. Peng, “R3: Reverse,
retrieve, and rank for sarcasm generation with commonsense knowl-

Association for Compu-


[117]

[118]

[119]

[120]

[121]

[122]

[123]

[124]

[125]

[126]

[127]

[128]

[129]

[130]

[131]

[132]

[133]

[134]

[135]

edge,” in Proceedings of ACL 2020.
Linguistics, 2020, pp. 7976-7986.
S. Pan, L. Luo, Y. Wang, C. Chen, J. Wang, and X. Wu, “Unifying large
language models and knowledge graphs: A roadmap,” JEEE Trans.
Knowl. Data Eng., vol. 36, no. 7, pp. 3580-3599, 2024.

C. Wang, X. Liu, Y. Yue, X. Tang, T. Zhang, C. Jiayang, Y. Yao,
W. Gao, X. Hu, Z. Qi, Y. Wang, L. Yang, J. Wang, X. Xie, Z. Zhang,
and Y. Zhang, “Survey on factuality in large language models: Knowl-
edge, retrieval and domain-specificity,’ CoRR, vol. abs/2310.07521,
2023.

P. Zhong, D. Wang, P. Li, C. Zhang, H. Wang, and C. Miao, “CARE:
Commonsense-aware emotional response generation with latent con-
cepts,” in Proceedings of AAAI 2021. AAAI Press, 2021, pp. 14577-
14585.

Q. Tu, Y. Li, J. Cui, B. Wang, J. Wen, and R. Yan, “MISC: A
mixed strategy-aware model integrating COMET for emotional sup-
port conversation,” in Proceedings of ACL 2022. Association for
Computational Linguistics, 2022, pp. 308-319.

S. Sabour, C. Zheng, and M. Huang, “CEM: Commonsense-aware
empathetic response generation,” in Proceedings of AAAI 2022. AAAI
Press, 2022, pp. 11229-11237.

Q. Li, P. Li, Z. Ren, P. Ren, and Z. Chen, “Knowledge bridging for
empathetic dialogue generation,” in Proceedings of AAAI 2022. AAAI
Press, 2022, pp. 10993-11001.

S. M. Mohammad, “Obtaining reliable human ratings of valence,
arousal, and dominance for 20,000 English words,” in Proceedings
of ACL 2018. Association for Computational Linguistics, 2018, pp.
174-184.

J. Zhou, C. Zheng, B. Wang, Z. Zhang, and M. Huang, “CASE:
Aligning coarse-to-fine cognition and affection for empathetic response
generation,” in Proceedings of ACL 2023. Association for Computa-
tional Linguistics, 2023, pp. 8223-8237.

T. Mihaylov and A. Frank, “Knowledgeable Reader: Enhancing cloze-
style reading comprehension with external commonsense knowledge,”
in Proceedings of ACL 2018. Association for Computational Linguis-
tics, 2018, pp. 821-832.

L. Bauer, Y. Wang, and M. Bansal, ‘““Commonsense for generative
multi-hop question answering tasks,” in Proceedings of EMNLP 2018.
Association for Computational Linguistics, 2018, pp. 4220-4230.

T. Kocisky, J. Schwarz, P. Blunsom, C. Dyer, K. M. Hermann, G. Melis,
and E. Grefenstette, “The NarrativeQA reading comprehension chal-
lenge,” Trans. Assoc. Comput. Linguistics, vol. 6, pp. 317-328, 2018.
W. Zhong, D. Tang, N. Duan, M. Zhou, J. Wang, and J. Yin, “Im-
proving question answering by commonsense-based pre-training,” in
Proceedings of NLPCC 2019, ser. Lecture Notes in Computer Science,
vol. 11838. Springer, 2019, pp. 16-28.

Q. Chen, F. Ji, H. Chen, and Y. Zhang, “Improving commonsense
question answering by graph-based iterative retrieval over multiple
knowledge sources,” in Proceedings of COLING 2020. International
Committee on Computational Linguistics, 2020, pp. 2583-2594.

N. Bian, X. Han, B. Chen, and L. Sun, “Benchmarking knowledge-
enhanced commonsense question answering via knowledge-to-text
transformation,” in Proceedings of AAAI 2021. AAAI Press, 2021,
pp. 12574-12582.

S. Nirenburg, “Knowledge-based machine translation,’ Mach. Transl.,
vol. 4, no. 1, pp. 5-24, 1989.

H. Caseli, B. A. Sugiyama, and J. C. A. Silva, “Using common
sense to generate culturally contextualized machine translation,’ in
Proceedings of the NAACL HLT 2010 Young Investigators Workshop on
Computational Approaches to Languages of the Americas. Association
for Computational Linguistics, 2010, pp. 24-31.

J. He, T. Wang, D. Xiong, and Q. Liu, “The box is in the pen:
Evaluating commonsense reasoning in neural machine translation,” in
Findings of EMNLP 2020. Association for Computational Linguistics,
2020, pp. 3662-3672.

X. Liu, Y. Wang, D. F Wong, R. Zhan, L. Yu, and M. Zhang,
“Revisiting commonsense reasoning in machine translation: Training,
evaluation and challenge,” in Proceedings of ACL 2023. Association
for Computational Linguistics, 2023, pp. 15 536-15 550.

S. M. T. I. Tonmoy, S. M. M. Zaman, V. Jain, A. Rani, V. Rawte,
A. Chadha, and A. Das, “A comprehensive survey of hallucina-
tion mitigation techniques in large language models,’ CoRR, vol.
abs/2401.01313, 2024.

Association for Computational

20

136]

137]

138]

139]

140]

141]

142]
143]

144]

145]

146]

147]

148]

[149]

150]

151]

152]

153]

154]

A. Toroghi, W. Guo, M. M. A. Pour, and S. Sanner, “Right for right
reasons: Large language models for verifiable commonsense knowledge
graph question answering,” CoRR, vol. abs/2403.01390, 2024.

Y. Li, R. Zhang, J. Liu, and G. Liu, “An enhanced prompt-based
LLM reasoning scheme via knowledge graph-integrated collaboration,”
CoRR, vol. abs/2402.04978, 2024.

X. Zhang, B. Peng, Y. Tian, J. Zhou, L. Jin, L. Song, H. Mi, and
H. Meng, “Self-alignment for factuality: Mitigating hallucinations in
Ilms via self-evaluation,’ CoRR, vol. abs/2402.09267, 2024.

R. Rafailov, A. Sharma, E. Mitchell, C. D. Manning, S. Ermon, and
C. Finn, “Direct preference optimization: Your language model is
secretly a reward model,” in Proceedings of NeurIPS 2023, 2023.

S. Farquhar, J. Kossen, L. Kuhn, and Y. Gal, “Detecting hallucinations
in large language models using semantic entropy,” Nature, vol. 630,
no. 8017, pp. 625-630, 2024.

S. Gao, M. Ismayilzada, M. Zhao, H. Wakaki, Y. Mitsufuji, and
A. Bosselut, “DiffuCOMET: Contextual commonsense knowledge dif-
fusion,” CoRR, vol. abs/2402.17011, 2024.

N. Tandon, A. S. Varde, and G. de Melo, “Commonsense knowledge in
machine intelligence,’ SIGMOD Rec., vol. 46, no. 4, pp. 49-52, 2017.
E. Davis, “Benchmarks for automated commonsense reasoning: A
survey,’ ACM Comput. Surv., vol. 56, no. 4, pp. 81:1-81:41, 2024.

S. Storks, Q. Gao, and J. Y. Chai, “Recent advances in natural language
inference: A survey of benchmarks, resources, and approaches,” CoRR,
vol. abs/1904.01172, 2019.

P. Bhargava and V. Ng, “Commonsense knowledge reasoning and
generation with pre-trained language models: A survey,” in Proceedings
of AAAI 2022. AAAI Press, 2022, pp. 12317-12325.

C. Richardson and L. Heck, “Commonsense reasoning for conversa-
tional AI: A survey of the state of the art,’ CoRR, vol. abs/2302.07926,
2023.

N. Bian, X. Han, H. Lin, Y. Lu, B. He, and L. Sun, “Rule or story,
which is a better commonsense expression for talking with large
language models?” in Proceedings of ACL 2024. Association for
Computational Linguistics, 2024, pp. 4023-4043.

Z. Jin, P. Cao, H. Yuan, Y. Chen, J. Xu, H. Li, X. Jiang, K. Liu, and
J. Zhao, “Cutting off the head ends the conflict: A mechanism for
interpreting and mitigating knowledge conflicts in language models,”
in Findings of ACL 2024. Association for Computational Linguistics,
2024, pp. 1193-1215.

J. Wu, T. Yu, X. Chen, H. Wang, R. A. Rossi, S. Kim, A. B. Rao, and
J. J. McAuley, “DeCoT: Debiasing chain-of-thought for knowledge-
intensive tasks in large language models via causal intervention,” in
Proceedings of ACL 2024. Association for Computational Linguistics,
2024, pp. 14073-14087.

H. Zhang, Y. Zhang, X. Li, W. Shi, H. Xu, H. Liu, Y. Wang,
L. Shang, Q. Liu, Y. Liu, and R. Tang, “Evaluating the external and
parametric knowledge fusion of large language models,’ CoRR, vol.
abs/2405.19010, 2024.

T. R. McIntosh, T. Susnjak, T. Liu, P. A. Watters, and M. N. Halga-
muge, “Inadequacies of large language model benchmarks in the era
of generative artificial intelligence,’ CoRR, vol. abs/2402.09880, 2024.
Y. Sakai, H. Kamigaito, and T. Watanabe, “mCSQA: Multilingual
commonsense reasoning dataset with unified creation strategy by
language models and humans,” in Findings of ACL 2024. Association
for Computational Linguistics, 2024, pp. 14182-14214.

X. Fu, M. He, Y. Lu, W. Y. Wang, and D. Roth, “Commonsense-T2I
challenge: Can text-to-image generation models understand common-
sense?” CoRR, vol. abs/2406.07546, 2024.

Z. Zhang, K. Chen, R. Wang, M. Utiyama, E. Sumita, Z. Li, and
H. Zhao, “Universal multimodal representation for language under-
standing,” JEEE Trans. Pattern Anal. Mach. Intell., vol. 45, no. 7, pp.
9169-9185, 2023.
