arXiv:2510.10159v1 [cs.CL] 11 Oct 2025

BabyBabelLM:
A Multilingual Benchmark of Developmentally Plausible Training Data

Jaap Jumelet!, Abdellah Fourtassi”, Akari Haga*, Bastian Bunzeck*, Bhargav Shandilya®,
Diana Galvan-Sosa® ”, Faiz Ghifari Haznitrama’, Francesca Padovani!, Francois Meyer®,
Hai Hu’, Julen Etxaniz!’, Laurent Prévot?, Linyang He!!, Maria Grandury!’, Mila
Marcheva’*, Negar Foroutan!’, Nikitas Theodoropoulos!*, Pouya Sadeghi!>, Siyuan Song’,
Suchir Salhan®, Susana Zhou’, Yurii Paniv!’, Ziyin Zhang!®, Arianna Bisazza', Alex
Warstadt!’, Leshem Choshen””

‘University of Groningen, *Aix Marseille University, *Nara Institute of Science and Technology, Bielefeld University,
University of Colorado Boulder, ‘University of Cambridge, KAIST, *University of Cape Town, °City University of Hong
Kong, OHITZ, University of the Basque Country, "!Columbia University, 2 SomosNLP, EPFL, '4Tndependent Researcher,

6

'SUniversity of Tehran,

University of Texas at Austin, '’ Ukrainian Catholic University, '*Shanghai Jiao Tong University,

‘University of California San Diego, °°MIT, MIT-IBM Watson AI Lab

Correspondence to j.w.d. jumelet@rug.nl and leshem. choshen@mail.huji.ac.il*

Abstract

We present BabyBabelLM, a multilingual col-
lection of datasets modeling the language a per-
son observes from birth until they acquire a
native language. We curate developmentally
plausible pretraining data aiming to cover the
equivalent of 100M English words of content
in each of 45 languages. We compile evalu-
ation suites and train baseline models in each
language. BabyBabelLM aims to facilitate mul-
tilingual pretraining and cognitive modeling.!

1 Introduction

The prevailing trend in language modeling research
is to prioritize scaling, both in terms of model
size and training data volume (Kaplan et al., 2020;
Choshen et al., 2024). While this approach has
led to significant advances in model performance,
it neglects fundamental research questions about
the nature of language learning (Wilcox et al.,
2024). It disincentivizes work on data-efficient
modeling, which, from a practical perspective, of-
fers benefits in terms of efficiency and accessibil-
ity. From a theoretical perspective, it ignores the
growing mismatch between human language acqui-
sition and language model (LM) learning. From
infancy to maturity, English learners acquire lan-
guage through exposure to less than 100M words
(Gilkerson et al., 2017), several orders of mag-
nitude less than the massive pretraining corpora
required by contemporary LMs surpassing 10T
words (Bengio et al., 2025).

In response to the field’s focus on scale, the
BabyLM Challenge (Warstadt et al., 2023) was

“Author contributions provided in Appendix A.

‘All code and data available
babylm. github. io/babybabe11m.

through

created to redirect attention toward questions of
data efficiency and developmental plausibility in
language modeling. The shared task invites partici-
pants to propose data-efficient LMs pretrained on
a fixed, developmentally plausible English corpus
of child-directed speech (CDS), educational con-
tent, and other simplified texts. The top-performing
submissions (Charpentier and Samuel, 2023, 2024)
have significantly improved the state of the art for
models trained on the same limited data budget,
even surpassing LMs trained on much larger cor-
pora on various benchmarks.

The BabyLM Challenge has generated a new
line of research on data-efficient training and
cognitively-inspired modeling (Warstadt et al.,
2023; Hu et al., 2024), depending on the existence
of developmentally plausible datasets as training
corpora and supplying resources to ease and direct
such research. However, the majority of this work
has focused on English, largely due to the pub-
lic availability of the pretraining corpora released
for the BabyLM challenge, which is English-only.
There is a small but growing body of work that ex-
tends the BabyLM research project beyond English
(Salhan et al., 2024; Shen et al., 2024; Prévot et al.,
2024; Matzopoulos et al., 2025; Padovani et al.,
2025; Bunzeck et al., 2025). Such efforts are cru-
cial for developing an accurate understanding of the
relationship between human language acquisition
and LM learning. Any claim that a model is de-
velopmentally plausible can only be truly substan-
tiated by evaluations across typologically diverse
languages, as there is variation in acquisition tra-
jectories between languages, and human language
learning also frequently occurs in multilingual set-
tings (Grosjean, 1989; Slobin, 2014; Moran, 2016;


Stoll, 2020).

To facilitate this research, we create BabyBa-
belILM, a multilingual collection of developmen-
tally plausible training datasets. The collection
includes 45 languages, encompassing families pri-
marily rooted—though not exclusively spoken—
in Europe, Asia, and Africa. For each language,
we carefully select and compile publicly available
datasets while prioritizing developmentally plau-
sible data, as well as release new ones. This in-
cludes several categories of developmentally plau-
sible data, such as CDS, educational resources, and
other child-oriented content (e.g., books, news, and
wikis aimed towards children). We sort languages
into three tiers based on training set size, corre-
sponding to the equivalent of respectively 100M,
10M, or 1M English words, calibrated by language-
adjusted byte estimates (Arnett et al., 2024), to
ensure comparability of data budgets across lan-
guages with differing orthographic and morpholog-
ical characteristics.

To further facilitate research we also compile a
list of evaluations to test models created on those
domains. We provide a comprehensive list of exist-
ing datasets to facilitate any future questions and
to provide coverage. Specifically, we cover both
formal and functional competence across all lan-
guages, and include evaluation that fits the pretrain-
ing objective directly without adaptation (known as
zero-shot), as well as fine-tuning based evaluation
that relies on task-specific training datasets.

Overall, this effort releases:

¢ Developmentally plausible pretraining datasets
for 45 languages, collected with licenses permit-
ting research purposes (§3).

¢ A pipeline to allow for subsequent dataset expan-
sion with new resources and languages (§3.3).

¢ A survey of multilingual evaluation tasks (§4)
accompanied by an evaluation suite extendable
by the community.

¢ A collection of 45 monolingual pretrained mod-
els, 7 bilingual models and a multilingual model
that we analyze in §5.

2 Related Work

The first edition of the BabyLM challenge
(Warstadt et al., 2023) released two pretraining cor-
pora, respectively 1OM and 100M words, each con-
sisting of 39% developmentally plausible data and
a selection of high-quality corpora (e.g. Wikipedia).
The second edition (Hu et al., 2024) updated the

datasets to increase the proportion of child-oriented
data to 70%. Thus far, the BabyLM Challenge has
been limited to English for training and evalua-
tion. In both editions, BabyLM submissions were
evaluated on two types of language tasks: 1) zero-
shot minimal pair challenges (Warstadt et al., 2020;
Ivanova et al., 2024) benchmarking linguistic com-
petence, world knowledge or other capabilities by
testing if the model prefers a correct sentence over
an incorrect one with a minor but meaningful alter-
ation; and 2) fine-tuning based evaluations where
models are further trained on a novel dataset and
tested on their ability to learn the underlying task.

Beyond English, a growing body of work has
begun exploring BabyLM-style models and the
collection of developmentally plausible training
datasets for other languages. Salhan et al. (2024)
propose acquisition-inspired curriculum learning
strategies and train small-scale LMs on age-ordered
CDS for French, German, Japanese, and Chinese.
Prévot et al. (2024) investigate the value of sponta-
neous speech corpora for BabyLM evaluation with
experiments on English and French. Matzopou-
los et al. (2025) train BabyLMs for isiXhosa, a
low-resource South African language, highlight-
ing the limits of BabyLM research for languages
without publicly available developmentally plausi-
ble corpora. Capone et al. (2024) release a corpus
of Italian developmentally plausible training data.
Padovani et al. (2025) show that training on CDS
does not consistently improve grammatical learn-
ing across English, French, and German. Bunzeck
et al. (2025) train LMs on distributionally varied
subsets of a German BabyLM corpus, showing that
syntax learning benefits from complex construc-
tions while lexical learning benefits from fragmen-
tary constructions. Finally, Shen et al. (2024) inves-
tigate developmentally plausible L2 acquisition by
adapting an English BabyLM for Italian via a re-
ward signal from a parent Italian model. However,
these works are typically forced to compile novel
datasets in addition to their scientific contribution,
and they do not represent a coordinated effort to
compile such training data in comparable ways and
across diverse languages.

Some relevant multilingual resources do exist.
Notably, the Child Language Data Exchange Sys-
tem (CHILDES; MacWhinney, 2000) is a multi-
lingual database of transcribed child-adult interac-
tions, including data for over 40 languages, with
varying age ranges, interaction environments, and
corpus sizes. CHILDES serves as a starting point


for most of our languages. A previous effort to com-
pile developmentally plausible multilingual train-
ing corpora is MAO-CHILDES (Yadavalli et al.,
2023), an age-ordered dataset of CHILDES corpora
for five typologically diverse languages (German,
French, Polish, Indonesian, and Japanese), which
is used to study cross-lingual training and L2 learn-
ing. Salhan et al. (2024) and Goriely and Buttery
(2025) independently release MAO-CHILDES and
IPA-CHILDES for four languages (Japanese, Chi-
nese, French, German) and a phonemized corpus
based on CHILDES for 31 languages.

3 Dataset Creation and Overview

The BabyBabelLM dataset was created to support
research on developmentally plausible language
modeling across a wide range of languages. Our
aim is to approximate the kind of linguistic input
that humans are exposed to in early life, while pro-
viding clean, well-documented, high-quality data.

3.1. Data Collection Principles

The design of our datasets required various method-
ological choices regarding the types of data sources
to include, ensuring their developmental plausibil-
ity and long-term extensibility. In this section, we
describe the criteria guiding our choices, the orga-
nizational structure of our multilingual collection,
and the licensing considerations.

3.1.1 Developmental Plausibility Criteria

Our guiding principle in dataset construction is
that of developmental plausibility: the idea that
pretraining data should approximate the linguistic
input children encounter. To this end, we priori-
tized domains such as child-directed speech (CDS),
educational materials, children’s books, and tran-
scribed conversations. We deliberately excluded
synthetic corpora, like TinyStories (Eldan and Li,
2023) or TinyDialogues (Feng et al., 2024), despite
their developmental intention, as synthetic data has
been shown to feature a reduced long tail for many
linguistic measures (Ju et al., 2025), more unifor-
mity in syntactic constructions (Mufioz-Ortiz et al.,
2024; Striibbe et al., 2025), and less alignment with
human-like discursive patterns (Liu and Fourtassi,
2025). As such, it is unsuitable for our goal of
approximating the full complexity of a child’s lin-
guistic environment.

In addition to content filtering, we prioritized
data quality by removing noise, favoring conver-
sational data when applicable, and standardizing

the format of metadata (see Appendix B). This
preserved realism enables controlled cross-lingual
comparisons, which are essential for studying the
impact of linguistic variation on model learning.

3.1.2 Community-driven Data Leadership

To ensure dataset quality, data collection for most
languages was led by a researcher fluent in or famil-
iar with that language. These language leads were
responsible for sourcing appropriate corpora, veri-
fying developmental plausibility, and coordinating
with local experts in linguistics and acquisition.

The BabyBabelLM dataset is designed as a
“living resource”. As more developmentally plau-
sible data becomes available, we aim to expand
the collection both in breadth—by adding new
languages—and in depth—by enriching existing
ones. To support this, we provide an open-
source pipeline that enables researchers to add
entirely new languages and expand existing lan-
guage datasets. While our initial release covers
45 languages, 16 languages rely solely on general-
purpose multilingual data resources. We consider
these entries as starting points for future, more com-
prehensive corpora.

We invite contributions through GitHub and
Hugging Face, where researchers can submit new
datasets, improvements, and evaluations. All addi-
tions are reviewed for compliance with our guide-
lines and incorporated into future versions of the
dataset, ensuring proper attribution. We hope this
model of open, collaborative development will lead
to broader coverage and increased utility across
diverse research agendas.

3.1.3. Licensing and Ethics

During our data collection effort, we verified that
all data is released with licenses that permit aca-
demic research, such as Creative Commons or
Public Domain. When licensing information was
missing, the right holders of each source were con-
tacted. We release our corpus with document-level
licensing information and data source attribution
to ensure that each resource is used ethically and
within its rights. In the rare cases where no license
or contact information was available, we decided
to still release the data, but under a restrictive non-
commercial license.

3.2 Dataset Composition

Constructing a multilingual dataset that is both de-
velopmentally plausible and broadly comparable


Padding = Subtitles

Data distribution by category (%)

Tier 1 (100M)

Tier 2 (10M)

= Transcription

= Books, Wiki, News = Education

Tier 3 (1M)

Figure 1: Training data distribution by category across languages for all data tiers in the BabyBabelLM dataset.

requires careful attention to how data is organized.
Languages differ widely in the availability and type
of child-relevant resources, and these differences
must be accounted for without undermining cross-
linguistic consistency. This section outlines how
we approached this challenge, the types of data we
included, and how they differ from one another.

3.2.1 Data categories

Transcription Children learn language mainly
from spoken input, which we therefore use as our
primary data source. This child-directed speech
(or CDS) differs drastically from the language data
found in commonly used pretraining corpora. Usu-
ally, it is structurally short and simple (Genovese
et al., 2020), and features high amounts of syntactic
and lexical repetition (Tal et al., 2024), while its
vocabulary is mostly restricted to everyday topics
and children’s immediate surroundings (Snow and
Ferguson, 1977). The CHILDES database contains
a large amount of such data in the form of recorded
caretaker-child interactions (e.g., during free play,
meal times, or shared book reading) and manually
created transcriptions. We used all CDS available
for our target languages in CHILDES as the base
of our datasets. For some languages not written
in Latin script (e.g., Japanese, Greek, Persian), the
CHILDES data contains transliterations, this data
is excluded from our data collection. As children
also overhear language in their surroundings, we
further included as much child-available speech
(adult-adult dialogue) as possible per language.

Education We included educational content
aimed at children, taken from textbooks and exams,

as children spend a large amount of their time in ed-
ucation and encounter this kind of input regularly.
On the content level, it provides much more direct
instruction than CDS, which we deem useful for
our purposes. After all, our BabyBabelLMs are not
only supposed to learn formal linguistic patterns
from the input, but ideally also more functional (vi-
sual semantic, pragmatic, and world) knowledge.

Books, Wiki, News To approximate the whole
breadth of input that children receive, we further in-
cluded child-oriented media, i.e., children’s books,
children’s wikis, child-targeted news, and other
appropriate media sources. For multilingual re-
sources, we incorporated the Ririro story collec-
tion’, GlotStoryBooks from Kargaran et al. (2023),
and Child Wiki articles across many languages. Ad-
ditionally, individual languages were enriched with
monolingual resources. In contrast to CDS, this
kind of data features longer and more complex sen-
tences (Cameron-Faulkner and Noble, 2013; Bun-
zeck et al., 2025), and much more diverse vocab-
ulary and content. As such, these sources should
provide a useful training signal for more complex
knowledge levels, similar to educational content.

Subtitles Finally, we also used movie/TV show
subtitles suitable for children. While such fictional
speech does differ from natural spoken data — for
example, it features less hesitations, interjections,
false starts or pauses (Bishop, 1991; Jucker, 2021;
Gast et al., 2023) — it still approximates the lin-
guistic properties of speech well and we deem it
developmentally plausible. Furthermore, children

“https ://ririro.com/


are nowadays exposed to a wide variety of (video)
media (Gowenlock et al., 2024), and thus encounter
this kind of content regularly. We also include ed-
ucational content subtitles from the QED corpus
(Abdelali et al., 2014) for a small number of lan-
guages, filtering for data quality.

Padding To create comparable resources across
languages, we pad our datasets to match the size
of different tiers ($3.2.2). For padding, we use
the OpenSubtitles corpora (Lison and Tiedemann,
2016), which are significantly larger than our other
data sources. To ensure our datasets do not contain
content inappropriate for children, we omitted cer-
tain categories (e.g., adult content, crime, horror).
For languages where not enough OpenSubtitles
data is available, we further relied on FineWeb-
C and Wikipedia data, among other resources, as
fallback for additional padding.

3.2.2 Language Tiers and Coverage

Our dataset spans 45 languages drawn from a
wide range of typological families. While Indo-
European languages are well represented (22 out
of 45), the collection also includes Semitic, Uralic,
Bantu, Austronesian, and Sino-Tibetan languages,
among others. This diversity was a key design goal,
enabling investigation of language acquisition and
modelling across distinct linguistic systems.

However, linguistic diversity is closely tied to
disparities in data availability, resulting in big varia-
tions in data quantities for our set of languages. To
enable fair comparisons, we classify languages into
three distinct tiers according to the amount of col-
lected data. Tier 1 includes languages with roughly
100 million English-equivalent tokens, Tier 2 with
10 million, and Tier 3 with 1 million. Ranking
them by decreasing dataset size, the tiers contain
9, 15, and 21 languages respectively. This distri-
bution further underscores the current scarcity of
developmentally plausible corpora and the need for
community-driven collection efforts.

Token thresholds are calibrated using the byte
premium approach (Arnett et al., 2024), which ad-
justs for variation in orthographic and morphologi-
cal structure by measuring the UTF-8 encoded size
needed to express a fixed amount of content. For
each language, we curated as much developmen-
tally plausible content as possible before padding
to the tier threshold using fallback data sources
such as OpenSubtitles. Figure 1 summarizes the
distribution of content categories across languages

and tiers; more detailed per-language statistics are
presented in Table 3.

3.3. Data Preprocessing

The data preprocessing is separated into two stages.
Initially, language-specific preprocessing was car-
ried out by the language leads, as needed by the
specific data and language (more in Appendix
C). Afterwards, we apply (and release) a uniform
pipeline for all data, including standard normal-
ization (unicode, whitespace, punctuation) and
category-specific preprocessing. For dialogue
transcripts, we remove linguistic annotationsFor
subtitle data, we remove speaker labels, music
note symbols, stage directions, and timestamps.
For book-like formats (educational materials, chil-
dren’s books, wikis) and the QED dataset, we re-
move XML tags and URLs.

For language and script validation, we use
GlotLID v3 (Kargaran et al., 2023). We classify
sentence-like chunks of text, created by splitting
documents into paragraphs and applying sentence-
based heuristics. The document’s final language
is assigned via a segment-based majority vote. To
maintain data quality, we filter mismatched seg-
ments within documents and discard any document
that fails the overall validation. Other document
metadata fields, such as the text category and li-
cense, are validated for the correct type and values
when applicable (see Table 4).

4 Evaluation Suite

We create a multilingual evaluation suite that tar-
gets both the formal linguistic competence (knowl-
edge of linguistic rules and patterns), and the func-
tional linguistic competence (understanding and us-
ing language in the world) (Mahowald et al., 2024).
We reviewed a large number of existing multilin-
gual and monolingual benchmarks (Huang et al.,
2025) with the aim of ensuring all our languages
have at least one evaluation dataset testing formal
and one testing functional linguistic competence.

Formal competence To assess formal linguistic
competence, we prioritized high-quality, language-
specific minimal pair benchmarks that target
a diverse set of linguistic phenomena. This
approach was applied to languages such as
Basque (Kryvosheieva and Levy, 2025), Chi-
nese (Liu et al., 2024), Japanese (Someya and Os-
eki, 2023), German (Vamvas and Sennrich, 2021),
and Turkish (Basar et al., 2025). Where this


was not possible, we employed datasets cover-
ing fewer phenomena but spanning multiple lan-
guages. In particular, for English, French, German,
Russian, and Hebrew, we used CLAMS (Mueller
et al., 2020), a cross-lingual minimal pair bench-
mark built from linguist-curated templates, focus-
ing on subject-verb number agreement. In our
experiments we refer to the collection of these
tasks as MonoBLiMP. Finally, we incorporated
MultiBLiMP (Jumelet et al., 2025), a large-scale
dataset of minimal pairs automatically generated
from the Universal Dependencies treebanks (Nivre
et al., 2017). MultiBLiMP targets subject-verb
agreement in number, person, and gender, and
offers the widest language coverage among our
benchmarks, as detailed in Table 1.

Functional competence We include two types
of benchmarks to evaluate functional compe-
tence. The first category focuses on factual
and domain-specific knowledge memorized by
the model, such as Global-MMLU (Singh et al.,
2025), INCLUDE (Romanot et al., 2024), and BM-
LAMA (Qi et al., 2023). The second category as-
sesses general reasoning abilities, including natural
language inference, commonsense reasoning, nar-
rative understanding, and reading comprehension.
Benchmarks in this category include XNLI (Con-
neau et al., 2018), MultiNLI (Williams et al., 2018),
HellaSwag (Zellers et al., 2019), Belebele (Ban-
darkar et al., 2024), ARC (Clark et al., 2018), xsto-
rycloze (Lin et al., 2022b), TruthfulQA (Lin et al.,
2022a), XCOPA (Ponti et al., 2020), SIB-200 (Ade-
lani et al., 2024), and XWinograde (Sakaguchi
et al., 2019; Cheng and Amiri, 2024). Additionally,
we included XCOMPS (He et al., 2025), a mul-
tilingual conceptual minimal pair dataset with 17
languages.

Evaluation We evaluate these tasks in two ways.
Tasks that are expressed as minimal pair compar-
isons are evaluated using zero-shot prompting,
based on the model’s output probabilities. For con-
ducting these evaluations, we relied on Eleuther
Al’s LM Evaluation Harness (Gao et al., 2024).
Tasks in this category are: all linguistic minimal
pair tasks, XCOMPS, HellaSwag, Winogrande and
XStoryCloze. For tasks involving classification and
question answering we report performance after
finetuning. The tasks on which we applied finetun-
ing are: ARC, TruthfulQA, BMMLAMA, Belebele,
INCLUDE, SIB-200, Global-MMLU, MultiNLIL
XNLI and XCOPA. We initially experimented with

zero-shot prompting on these tasks as well, but the
limited data size of our corpora does not allow for
in-context learning mechanisms to be acquired.*
For finetuning, we adapt the pipeline from the
BabyLM Challenge 2024 evaluation framework‘.
We limit the number of training items to a max of
8,000 items, and finetune for 10 epochs using an
80/20 train/test split.

5 Experiments

Building on the resources outlined above, we train
monolingual, bilingual and multilingual models to
evaluate our benchmark suite.

Setup For training our models, we adopt the
model configurations of the GoldFish model suite
(Chang et al., 2024). For the monolingual models,
we use a lightweight GPT-2 architecture with 4
transformer layers, 8 attention heads, and a hidden
size of 512. The model uses GELU activations
and standard dropout regularization (0.1) across
attention, embeddings, and residual connections. It
includes a feedforward inner dimension of 2048
and supports sequences up to 512 tokens. For all
languages, we use a BPE tokenization (trained on
the training corpus), with a vocabulary size of 8,192
tokens (Huebner et al., 2021). This results in small
LMs of only 17.1M parameters. Each model is
trained for 10 epochs.

For the bilingual models, we train a model using
data from each language in Tier 1 and the English
BabyLM (200M tokens total), keeping model con-
figuration the same, but reducing training epochs to
5. For the multilingual model, we increase the num-
ber of layers to 12, hidden size to 768, and vocabu-
lary size to 32,768, accommodating the wide range
of languages and scripts this model should handle.
The model is trained for only 1 epoch (around 1B
tokens in total), and has 111M parameters. We
additionally compare performance against Qwen3-
0.6B (Yang et al., 2025a), a capable multilingual
LM of modest scale. Finally, we also experimented
with training GPT-BERT (Charpentier and Samuel,
2024) models on our data, the architecture that has
won the BabyLM challenge of 2024. Since these
models did not outperform our GPT-2 models, we

3Qlsson et al. (2022) show that the induction heads re-
quired for in-context learning develop only after exposure to
2.5-5 billion tokens. Developing sample-efficient methods that
enable such mechanisms to emerge under much smaller data
budgets, as targeted by the BabyLM challenge, is an important
direction for future work but beyond the scope of this paper.

“github .com/baby1lm/evaluation-pipeline-2024


» G

> 8 Ss y se

eS . s gg © si vr Xs  & &

- > Sf - © ee OS rr FF FF YF —”
Language > = = BS) 3 s F ¥ ¢ aod wv * -
Random 143 33.3 333 25.0 10.0 25.0 25.0 25.0 25.0 50.0 50.0 50.0 50.0 25.0 50.0 50.0
— Bulgarian 63.7 51.0 47.6 26.5 13.7 - 282 29.7 233 - 90.8 - - 268 52.0 49.5
= Chinese 82.6 520 496 30.7 174 281 266 288 261 49.2 — 70.2 55.1 268 49.2 487
S Dutch 72.6 50.1 — 37.1 246 292 261 314 23.9 = 90.5 —- 524 265 50.0 49.1
= English 75.1 50.1 49.1 - 156 287 27.0 22.9 300 473 82.0 65.9 - 265 514 49.5
~ French 722.6 545 454 303 203 282 27.2 246 25.6 = 94.1 69.7 506 264 513 47.6
— German 65.2 51.7 482 516 15.2 275 280 254 26.1 = 88.6 77.1 526 25.9 518 488
& Indonesian B.6 52.4 — 278 134 283 261 25.4 289 49.2 - = = 273 53.1 50.5
= Persian 80.1 50.6 — 313 158 29.0 288 280 27.2 - 113 — 53.6 264 50.7 52.2
Ukrainian 71.1 48.9 - 327 147 283 253 27.1 233 - 88.6 - 506 264 503 47.6
Afrikaans 716 52.6 ~ - 148 — 286 288 288 - ~ ~ - 261 513 49.5
Arabic 458 44.3 37.1 36.8 15.3 28.5 27.8 28.0 25.6 - 75.9 — 529 258 474 468
Basque 72.6 - 454! 30.7 _ — 24.7! 31.5! 244 49.2! 94.5 65.3 = ~ - 50.6
-~ Estonian 55.2 48.2 — 320 142 — 25.1 246 267 49.2 81.5 - - 255 50.7 45.8
S Greek 58.2 488 461 34.7 13.0 261 288 212 261 - 89.2 - 503 264 49.5 49.4
S Hebrew 64.7 48.3 = 227 132. 270 24 239 pote = 70.2 595 516 261 50.2 49.6
TZ Italian 61.7 50.5 - 319 146 283 27.0 280 21.1 55.0 115 = - 265 50.1 50.2
Japanese 67.7 44.6 - 260 119 279 280 27.1 244 - - 619 508 25.1 475 47.8
~ Polish 53.7 46.7 — 274 125 288 284 280 267 - 75.9 = - 255 49.0 49.5
HQ Portuguese 61.7 49.7 — 282 143 287 25.9 21.2 261 es 80.7 = —- 263 488 488
F Serbian 37.3 41.3 — 380 134 287 253 314 27.8 = = - - 25.6 495 485
Spanish 66.7 505 49.0 342 15.7 282 263 263 23.9 - 83.0 — 51.3 264 49.1 47.28
Swedish 55.2 48.4 = — 139 267 272 23.7 272 = 100.0 = - 25.9 493 481
Welsh 73.6 = - = = - = = - = 91.4 = ~ = = -
Yue Chinese 80.6 - - - - - - - - - - - - - - -
Achinese 35:3 - - - - - - - - - - - - - - -
Balinese 927, - - - - - - - - - - - - - - -
Buginese 29.8 - - - - - - - - - - - - - - -
Croatian 40.3 37.8 - 265 127 - 245 27.1 267 = - = — 258 476 45.6
Czech 35.8 40.6 - - 124 290 263 288 29.4 = 59.0 — —- 258 504 48.6
Danish 423 45.9 - = 153 — 261 23.7 27.2 - 82.0 ~ - 25.7 490 489
Hungarian 26.4 43.0 - 265 14.0 - 278 27.1 283 - 68.9 — 499 256 48.0 48.5
S Icelandic 418 46.0 = - 118 - 26.1 27.1 30.0 = 71.6 = - 254 50.0 45.7
2 Javanese 53.7 48.3 - = 127 - 268 26.3 217 = - — - 258 505 50.6
Korean 418 43.6 —- 25.5 134 27.7 245 33.1 27.2 - ~ — 51.3 25.0 489 47.5
co Makasar 89.17 - - - - = - - - - - - - - - -
= Minangkabau =. 21.4 = = ~ = - = = = ~ = = _ = ~ =
= Norwegian 49.2 473 = = 12.0 - 286 246 25.6 _ “ = - 259 47.0 47.1
F — Sepedi 53.7 - - - - - = - 25.6 - - - - - - -
Romanian 49.8 46.0 = — 121 289 280 280 30.6 es 74.1 = —- 25.5 486 46.2
Russian 433 446 44.0 37.0 12.5 29.1 274 28.0 31.1 = 58.5 52.0 491 25.9 513 488
Sesotho 56.2 - 32.9 - = 26.27 - - 278 - - - - - - -
Sundanese 62.7 = = + al + = - 26.7 + = — ~ = - =
Turkish 34.8 36.7 375 316 143 286 30.7 25.4 25.0 49.2 64.9 598 516 259 49.9 50.1
isiXhosa 46.3 = 3247 = = 27.0 - -— 23.9 = - = = - = =
isiZulu 50.2 - 36.23 _ - 30.33 - — 267 _ “ = _ “ - -

FINETUNED ZERO-SHOT

Table 1: Performance of the monolingual models trained on BabyBabelLM. All scores denote average accuracy
scores, either with 0-shot prompting on the base model or on the finetuned model. Zero-shot performance for all
tasks is provided in Table 6. ‘For Basque we took XNLI, ARC, ThruthfulQA and XCOPA datasets from HiTZ/xnli-eu,
HiTZ/ARC-eu, HiTZ/truthfulqa-multi-MT and HiTZ/XCOPA-eu. 7For Makasar we used a similar task to SIB200 from
nusaparagraph_topic. *For three South African languages (Sesotho, isiXhosa, isiZulu) we employed XNLI and Global-

MMLU data from afrixnli and afrimmlu.

report their performance in Appendix D instead.

Results The results for our monolingual models
are presented in Table 1. Linguistic benchmarks
such as MultiBLiMP yield promising results, with
Tier 1 models typically scoring above 80%. Per-
formance on MultiBLiMP is strongly driven by
data size, with Tier 2 and 3 languages perform-
ing worse. Performance on other benchmarks re-
mains close to random chance (e.g., XCOPA, ARC,
XCOMPS, HellaSwag). As such, our compara-
tively tiny BabyLMs only provide a starting point
for further experimentation.

We further compare the results of our mono-
lingual models for MultiBLiMP and Belebele

to the multilingual BabyLM model (Multi-
BabyBabelLM) and to Qwen3-0.6B. Results are
summarized in Figure 2; full results for Qwen are
included in Table 5. On MultiBLiMP, the monolin-
gual models generally outperform the multilingual
one, except in four Tier 3 languages where the
latter shows modest improvements. Compared to
Qwen, results are mixed: our multilingual model is
outperformed by Qwen in most cases, but remains
stronger in eight languages, with no clear trend by
tier. On Belebele, both our models perform near
chance, while Qwen achieves substantially higher
scores in all languages. This pattern extends to
most other benchmarks, where Qwen consistently


MultiBLiMP MultiBLiMP Belebele
100 | e 60 7
Zi F f 7 Tier
7 7
= o re oe ae ra 1
2 FAD) ® ‘ -) #0 ra @ 2
& 80 i fon®@ é 3
/ 7 7
eS 6 ® e vo ® ° 30 ra e
g ee 7 @D oe :@ @ Call
om ® 7258 if ee 71 @e* edee *e
or / re e, e 20 Pe 4
= / , /
= 60-9 “ ® “
= YY Be 10 7
4 4
¢ 7
7 47
50 Z o%
50 60 70 80 90 100 50 60 70 80 90 100 0 10 20 30 40 50 60
Mono-BabyBabelLM Qwen3-0.6B Qwen3-0.6B

Figure 2: Language-level performance of the multilingual BabyBabelLM model against the monolingual models
and Qwen3-0.6B on MultiBLiMP and Belebele. Each point denotes the accuracy on a specific language. Random

performance for Belebele is denoted in red.

Accuracy A +Eng

oa

Oo

x

20 40 60 80
Monolingual Accuracy

100

ee0 8

r>+OtEe BO

Task
bmlama
include
multiblimp
sib200
truthfulqa
xcomps
xstorycloze
Language
Chinese
Dutch
French
German
Indonesian
Persian
Ukrainian
Other tasks

Figure 3: Impact of training LMs on bilingual corpora
(adding English) across our evaluation suite. The y-axis
denotes the change in accuracy from monolingual to
bilingual performance. Dutch SIB-200 performance is
omitted due to space constraints (+24.8).

exceeds baseline and outperforms our models on
knowledge-intensive and reasoning tasks.

Figure 3 presents results for the bilingual models,
focusing on the three best- and worst-performing
tasks from the monolingual models, along with
SIB-200. All results are reported for zero-shot per-
formance. For several tasks—SIB-200, BMLAMA,
XCOMPS, and INCLUDE—adding English as a
second training language leads to consistent per-
formance gains across most languages. A notable
exception is Dutch on INCLUDE, where bilingual
training slightly reduces performance. This may
be due to domain mismatch: the Dutch corpus in-
cludes high-school exam texts, and the addition of
English data likely shifts the model away from this

domain. Performance on formal linguistic tasks
such as MultiBLiMP remains largely unchanged,
suggesting that syntactic competence is less sensi-
tive to bilingual input in this setup.

6 Future Outlook

BabyBabelLM is shared research. Starting as a
grassroots initiative and conducted in an open and
inclusive manner, this resource was gathered by
multiple experts with a shared goal. Therefore, we
call for this collaboration to continue and welcome
further contributions for BabyBabelLM, even after
the paper is published. In summary, we hope that
BabyBabelLM will serve as a valuable resource for
the community, facilitating reproducible, compara-
ble, and cost-effective exploration.

To act as acomplement to the resource, we pro-
vide a list of potential questions we believe this
resource may aid in answering: Do LMs acquire
language more like language learners of a specific
language than another? Are there critical times for
learning a second language in LMs (Constantinescu
et al., 2025)? Can we replicate results in studies on
the border of linguistics and LLMs, where testing
on only a single language might bias results (Arnett
et al., 2025)? Is there a way to overcome differ-
ent scripts and unshared tokenizers and provide
the same cross-lingual benefits between languages
regardless of differences in script? What is the
right tokenization scheme across languages, and
is tokenization needed at all (Hwang et al., 2025;
Rust et al., 2023)? While humans typically give
consistent answers across languages, current LMs
often do not (Qi et al., 2023; Goldman et al., 2025).
Even when outputs align, internal changes tend to
affect only one language, indicating a degree of


separation not seen in human cognition (Ifergan
et al., 2024). Can that be changed?

We hope that BabyBabelLM will serve as a foun-
dation for addressing the questions outlined above,
and we invite the community to build on this re-
source to advance a more inclusive and systematic
understanding of multilingual language acquisition
and modeling.

Limitations

Our resources target a diverse array of audiences,
and therefore our decisions are bound to not sat-
isfy each of those perfectly. While deciding be-
tween practical constraints, data availability, and
potential research needs we prioritized what we
believed would make research and experimentation
in the BabyLM paradigm easier. Still, we view our
dataset only as a starting point. There are many
more languages to be included, and even for the
featured languages we imagine further untapped
sources of developmentally plausible data.

Despite our language coverage being broader
than usual in NLP (cf. Joshi et al., 2020), many
languages—particularly those with limited digi-
tal presence—remain underrepresented. Especially
lacking are languages common in African countries
and those with smaller speaker populations, which,
despite our efforts, are still underrepresented in
our collection. We provide instructions for submit-
ting new languages in our GitHub and welcome
community contributions.

Although we aimed to collect as much cogni-
tively plausible data as possible, we also want to
stress that our datasets do not contain the actual
language a single native speaker of any of the in-
cluded languages is exposed to. While our data
approximates this input much better than standard
pretraining resources (e.g., Wikipedia dumps or
datasets like Dolma, Soldaini et al., 2024), the dis-
tribution of topics and formats remains only a gross
approximation of the diversity experienced by a na-
tive learner.

While we calibrate dataset sizes using byte-
adjusted thresholds to ensure comparability, the
actual composition of developmentally plausible
content varies substantially across languages. In
several cases, high-quality child-directed speech
(CDS) or educational material is unavailable, and
we rely more heavily on fallback sources such as
subtitles or Wikipedia. This variability may intro-
duce confounds in cross-linguistic analyses and

limits the strength of direct typological compar-
isons. We recommend that future work interpreting
model differences across languages take these com-
positional disparities into account.

Our final limitation is the lack of cross-
linguistically available evaluation resources. Many
languages are only evaluated on monolingual
datasets explicitly created for them, and beyond
MultiBLiMP there is currently no resource that
covers all included languages. As the study of bilin-
gualism or the acquisition of multiple languages
(by models and/or humans) are intended applica-
tions of this dataset, we are also constrained by
a lack of resources that explicitly target multilin-
gual capabilities. We did not create a standardized
testbed to test such questions ourselves, as they
are too varied. However, we hope that our data
and existing evaluations can serve as inspiration for
further research in that direction.

Acknowledgments

This work used the Dutch national e-infrastructure
with the support of the SURF Cooperative using
grant no. EINF-13403. Jaap Jumelet, Francesca
Padovani and Arianna Bisazza were supported by
NWO grant VI.Vidi.221C.009. Bastian Bun-
zeck was supported by the Deutsche Forschungsge-
meinschaft (DFG, German Research Foundation)
— CRC-1646, project number 512393437, project
A02.

References

Ahmed Abdelali, Francisco Guzman, Hassan Sajjad,
and Stephan Vogel. 2014. The AMARA corpus:
Building parallel language resources for the educa-
tional domain. In Proceedings of the Ninth Inter-
national Conference on Language Resources and
Evaluation (LREC’14), pages 1856-1862, Reykjavik,
Iceland. European Language Resources Association
(ELRA).

David Ifeoluwa Adelani, Md Mahfuz Ibn Alam, An-
tonios Anastasopoulos, Akshita Bhagia, Marta R.
Costa-jussa, Jesse Dodge, Fahim Faisal, Christian
Federmann, Natalia Fedorova, Francisco Guzman,
Sergey Koshelev, Jean Maillard, Vukosi Marivate,
Jonathan Mbuya, Alexandre Mourachko, Safiyyah
Saleem, Holger Schwenk, and Guillaume Wenzek.
2022. Findings of the WMT’ 22 shared task on large-
scale machine translation evaluation for African lan-
guages. In Proceedings of the Seventh Conference on
Machine Translation (WMT), pages 773-800, Abu
Dhabi, United Arab Emirates (Hybrid). Association
for Computational Linguistics.


David Ifeoluwa Adelani, Hannah Liu, Xiaoyu Shen,
Nikita Vassilyev, Jesujoba O. Alabi, Yanke Mao, Hao-
nan Gao, and En-Shiun Annie Lee. 2024. SIB-200:
A simple, inclusive, and big evaluation dataset for
topic classification in 200+ languages and dialects.
In Proceedings of the 18th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 226-245,
St. Julian’s, Malta. Association for Computational
Linguistics.

Muhamed AI Khalil, Hind Saddiki, Nizar Habash, and
Latifa Alfalasi. 2018. A leveled reading corpus of
Modern Standard Arabic. In Proceedings of the
Eleventh International Conference on Language Re-
sources and Evaluation (LREC 2018), Miyazaki,
Japan. European Language Resources Association
(ELRA).

Latifa Al-Sulaiti, Noorhan Abbas, Claire Brierley, Eric
Atwell, and Ayman Alghamdi. 2016. Compilation
of an Arabic children’s corpus. In Proceedings of
the Tenth International Conference on Language
Resources and Evaluation (LREC’16), pages 1808—
1812, Portoroz, Slovenia. European Language Re-
sources Association (ELRA).

Iolanda Alfano, Francesco Cutugno, Aurelio De Rosa,
Claudio Iacobini, Renata Savy, Maria Voghera, and 1
others. 2014. Volip: a corpus of spoken italian and a
virtuous example of reuse of linguistic resources. In
Proceedings of the Ninth International Conference
on Language Resources and Evaluation (LREC’ 14),
pages 3897-3901. European Language Resources
Association (ELRA).

Catherine Arnett, Tyler A. Chang, and Benjamin Bergen.
2024. A bit of a problem: Measurement disparities
in dataset sizes across languages. In Proceedings of
the 3rd Annual Meeting of the Special Interest Group
on Under-resourced Languages @ LREC-COLING
2024, pages 1-9, Torino, Italia. ELRA and ICCL.

Catherine Arnett, Tyler A Chang, James A Michaelov,
and Benjamin K Bergen. 2025. On the acquisition
of shared grammatical representations in bilingual
language models. arXiv preprint arXiv:2503.03962.

Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang,
Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei
Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin,
Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu,
Keming Lu, and 29 others. 2023. Qwen technical
report. arXiv preprint arXiv:2309. 16609.

Lucas Bandarkar, Davis Liang, Benjamin Muller, Mikel
Artetxe, Satya Narayan Shukla, Donald Husa, Naman
Goyal, Abhinandan Krishnan, Luke Zettlemoyer, and
Madian Khabsa. 2024. The belebele benchmark: a
parallel reading comprehension dataset in 122 lan-
guage variants. In Proceedings of the 62nd Annual
Meeting of the Association for Computational Lin-
guistics (Volume I: Long Papers), pages 749-775,
Bangkok, Thailand. Association for Computational
Linguistics.

Ezgi Basar, Francesca Padovani, Jaap Jumelet, and
Arianna Bisazza. 2025. Turblimp: A _ turkish
benchmark of linguistic minimal pairs. Preprint,
arXiv:2506.13487.

Yoshua Bengio, S6ren Mindermann, and Daniel Privit-
era. 2025. International ai safety report 2025.

Ryan Bishop. 1991. There’s Nothing Natural About
Natural Conversation: A Look at Dialogue in Fiction
and Drama. Oral Tradition, pages 58-78.

Dominique Brunato, Felice Dell’ Orletta, Giulia Venturi,
and Simonetta Montemagni. 2015. Design and an-
notation of the first italian corpus for text simplifica-
tion. In Proceedings of The 9th Linguistic Annotation
Workshop, pages 31-41.

Bastian Bunzeck and Holger Diessel. 2025. The rich-
ness of the stimulus: Constructional variation and de-
velopment in child-directed speech. First Language,
45(2):152-176.

Bastian Bunzeck, Daniel Duran, and Sina ZarrieB. 2025.
Do construction distributions shape formal language
learning in German BabyLMs? In Proceedings of
the 29th Conference on Computational Natural Lan-
guage Learning, pages 169-186, Vienna, Austria.
Association for Computational Linguistics.

Samuel Cahyawijaya, Holy Lovenia, Alham Fikri Aji,
Genta Winata, Bryan Wilie, Fajri Koto, Rahmad
Mahendra, Christian Wibisono, Ade Romadhony,
Karissa Vincentio, Jennifer Santoso, David Moel-
jadi, Cahya Wirawan, Frederikus Hudi, Muham-
mad Satrio Wicaksono, Ivan Parmonangan, Ika Al-
fina, IIham Firdausi Putra, Samsul Rahmadani, and
29 others. 2023a. NusaCrowd: Open source initiative
for Indonesian NLP resources. In Findings of the As-
sociation for Computational Linguistics: ACL 2023,
pages 13745-13818, Toronto, Canada. Association
for Computational Linguistics.

Samuel Cahyawijaya, Holy Lovenia, Fajri Koto, Dea
Adhista, Emmanuel Dave, Sarah Oktavianti, Salsabil
Akbar, Jhonson Lee, Nuur Shadieq, Tjeng Wawan
Cenggoro, Hanung Linuwih, Bryan Wilie, Galih
Muridan, Genta Winata, David Moeljadi, Al-
ham Fikri Aji, Ayu Purwarianti, and Pascale Fung.
2023b. NusaWrites: Constructing high-quality
corpora for underrepresented and extremely low-
resource languages. In Proceedings of the 13th In-
ternational Joint Conference on Natural Language
Processing and the 3rd Conference of the Asia-Pacific
Chapter of the Association for Computational Lin-
guistics (Volume I: Long Papers), pages 921-945,
Nusa Dua, Bali. Association for Computational Lin-
guistics.

Thea Cameron-Faulkner, Elena Lieven, and Michael
Tomasello. 2003. A construction based analysis of
child directed speech. Cognitive Science, 27(6):843-
873.

Thea Cameron-Faulkner and Claire Noble. 2013. A
comparison of book text and Child Directed Speech.
First Language, 33(3):268-279.


Luca Capone, Alice Suozzi, Gianluca Lebani, and
Alessandro Lenci. 2024. BaBIEs: A benchmark
for the linguistic evaluation of Italian baby language
models. In Proceedings of the 10th Italian Confer-
ence on Computational Linguistics (CLiC-it 2024),
pages 157-170, Pisa, Italy. CEUR Workshop Pro-
ceedings.

Tyler A. Chang, Catherine Arnett, Zhuowen Tu, and
Benjamin K. Bergen. 2024. Goldfish: Monolin-
gual language models for 350 languages. CoRR,
abs/2408.10441.

Lucas Georges Gabriel Charpentier and David Samuel.
2023. Not all layers are equally as important: Every
Layer Counts BERT. In Proceedings of the BabyLM
Challenge at the 27th Conference on Computational
Natural Language Learning, pages 210-224, Singa-
pore. Association for Computational Linguistics.

Lucas Georges Gabriel Charpentier and David Samuel.
2024. GPT or BERT: why not both? In The 2nd
BabyLM Challenge at the 28th Conference on Com-
putational Natural Language Learning, pages 262-
283, Miami, FL, USA. Association for Computa-
tional Linguistics.

Jiali Cheng and Hadi Amiri. 2024. Mu-bench: A multi-
task multimodal benchmark for machine unlearning.
Preprint, arXiv:2406.14796.

Madalina Chitez, Mihai Dascalu, Aura Cristina Udrea,
Cosmin Striletchi, Karla Csiirés, Roxana Rogobete,
and Alexandru Oravitan. 2024. Towards building the
LEMI readability platform for children’s literature
in the Romanian language. In Proceedings of the
2024 Joint International Conference on Computa-
tional Linguistics, Language Resources and Evalu-
ation (LREC-COLING 2024), pages 16450-16456,
Torino, Italia. ELRA and ICCL.

Leshem Choshen, Yang Zhang, and Jacob Andreas.
2024. A Hitchhiker’s Guide to Scaling Law Esti-
mation. arXiv preprint.

Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot,
Ashish Sabharwal, Carissa Schoenick, and Oyvind
Tafjord. 2018. Think you have solved question
answering? try arc, the ai2 reasoning challenge.
Preprint, arXiv: 1803.05457.

Alexis Conneau, Kartikay Khandelwal, Naman Goyal,
Vishrav Chaudhary, Guillaume Wenzek, Francisco
Guzman, Edouard Grave, Myle Ott, Luke Zettle-
moyer, and Veselin Stoyanov. 2020. Unsupervised
cross-lingual representation learning at scale. In Pro-
ceedings of the 58th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 8440-
8451, Online. Association for Computational Lin-
guistics.

Alexis Conneau, Ruty Rinott, Guillaume Lample, Adina
Williams, Samuel Bowman, Holger Schwenk, and
Veselin Stoyanov. 2018. XNLI: Evaluating cross-
lingual sentence representations. In Proceedings of

the 2018 Conference on Empirical Methods in Nat-
ural Language Processing, pages 2475-2485, Brus-
sels, Belgium. Association for Computational Lin-
guistics.

Ionut Constantinescu, Tiago Pimentel, Ryan Cotterell,
and Alex Warstadt. 2025. Investigating critical pe-
riod effects in language acquisition through neural
language models. Transactions of the Association for
Computational Linguistics, 13:96—120.

Yiming Cui, Ting Liu, Zhipeng Chen, Shijin Wang, and
Guoping Hu. 2016. Consensus attention-based neu-
ral networks for Chinese reading comprehension. In
Proceedings of COLING 2016, the 26th International
Conference on Computational Linguistics: Technical
Papers, pages 1777-1786, Osaka, Japan. The COL-
ING 2016 Organizing Committee.

Yiming Cui, Ting Liu, Ziqing Yang, Zhipeng Chen,
Wentao Ma, Wanxiang Che, Shijin Wang, and Guop-
ing Hu. 2020. A sentence cloze dataset for chinese
machine reading comprehension. In Proceedings of
the 28th International Conference on Computational
Linguistics (COLING 2020).

G. William Domhoff and Adam Schneider. 2008. Study-
ing dream content using the archive and search engine
on DreamBank.net. Consciousness and Cognition,
17(4):1238-1247.

Mahmoud El-Haj. 2020. Habibi - a multi dialect multi
national Arabic song lyrics corpus. In Proceedings
of the Twelfth Language Resources and Evaluation
Conference, pages 1318-1326, Marseille, France. Eu-
ropean Language Resources Association.

Ronen Eldan and Yuanzhi Li. 2023. TinyStories: How
Small Can Language Models Be and Still Speak Co-
herent English? Preprint, arXiv:2305.07759.

Steven Y. Feng, Noah Goodman, and Michael Frank.
2024. Is child-directed speech effective training
data for language models? In Proceedings of the
2024 Conference on Empirical Methods in Natural
Language Processing, pages 22055-22071, Miami,
Florida, USA. Association for Computational Lin-
guistics.

Mathieu Fenniak, Matthew Stamy, pubpub zz, Martin
Thoma, Matthew Peveler, exiledkingcc, and PyPDF2
Contributors. 2022. The PyPDF2 library.

Achille Fusco, Matilde Barbini, Maria Letizia Pic-
cini Bianchessi, Veronica Bressan, Sofia Neri, Sarah
Rossi, Tommaso Sgrizzi, and Cristiano Chesi. 2024.
Recurrent networks are (linguistically) better? an
(ongoing) experiment on small-LM training on child-
directed speech in Italian. In Proceedings of the 10th
Italian Conference on Computational Linguistics
(CLiC-it 2024), pages 382-389, Pisa, Italy. CEUR
Workshop Proceedings.

Leo Gao, Jonathan Tow, Baber Abbasi, Stella Bider-
man, Sid Black, Anthony DiPofi, Charles Foster,
Laurence Golding, Jeffrey Hsu, Alain Le Noac’h,


Haonan Li, Kyle McDonell, Niklas Muennighoff,
Chris Ociepa, Jason Phang, Laria Reynolds, Hailey
Schoelkopf, Aviya Skowron, Lintang Sutawika, and
5 others. 2024. The language model evaluation har-
ness.

Volker Gast, Christian Wehmeier, and Dirk Vanderbeke.
2023. A Register-Based Study of Interior Monologue
in James Joyce’s Ulysses. Literature, 3(1):42-65.

Giuliana Genovese, Maria Spinelli, Leonor J.
Romero Lauro, Tiziana Aureli, Giulia Castelletti,
and Mirco Fasolo. 2020. Infant-directed speech as
a simplified but not simple register: A longitudinal
study of lexical and syntactic features. Journal of
Child Language, 47(1):22-44.

Jill Gilkerson, Jeffrey A. Richards, Steven F. Warren, Ju-
dith K. Montgomery, Charles R. Greenwood, D. Kim-
brough Oller, John H. L. Hansen, and Terrance D.
Paul. 2017. Mapping the early language environ-
ment using all-day recordings and automated analy-
sis. American Journal of Speech-Language Pathol-
ogy, 26(2):248-265.

Omer Goldman, Uri Shaham, Dan Malkin, Sivan Eiger,
Avinatan Hassidim, Yossi Matias, Joshua Maynez,
Adi Mayrav Gilady, Jason Riesa, Shruti Rijhwani,
and 1 others. 2025. Eclektic: a novel challenge set
for evaluation of cross-lingual knowledge transfer.
arXiv preprint arXiv:2502.21228.

Zebulon Goriely and Paula Buttery. 2025. IPA
CHILDES & G2P+: Feature-rich resources for cross-
lingual phonology and phonemic language modeling.
In Proceedings of the 29th Conference on Computa-
tional Natural Language Learning, pages 502-521,
Vienna, Austria. Association for Computational Lin-
guistics.

Anna Elizabeth Gowenlock, Courtenay Norbury, and
Jennifer M. Rodd. 2024. Exposure to Language in
Video and its Impact on Linguistic Development in
Children Aged 3-11: A Scoping Review. Journal of
Cognition, 7(1):57.

Francois Grosjean. 1989. Neurolinguists, beware! the
bilingual is not two monolinguals in one person.
Brain and language, 36(1):3-15.

Andreas Hallberg. 2025. An 81-million-word multi-
genre corpus of arabic books. Data in Brief,
60:111456.

Linyang He, Ercong Nie, Sukru Samet Dindar, Arsalan
Firoozi, Adrian Florea, Van Nguyen, Corentin Puffay,
Riki Shimizu, Haotian Ye, Jonathan Brennan, Helmut
Schmid, Hinrich Schiitze, and Nima Mesgarani. 2025.
Xcomps: A multilingual benchmark of conceptual
minimal pairs. Preprint, arXiv:2502.19737.

Michael Y. Hu, Aaron Mueller, Candace Ross, Ad-
ina Williams, Tal Linzen, Chengxu Zhuang, Ryan
Cotterell, Leshem Choshen, Alex Warstadt, and
Ethan Gotlieb Wilcox. 2024. Findings of the sec-
ond BabyLM challenge: Sample-efficient pretraining

on developmentally plausible corpora. In The 2nd
BabyLM Challenge at the 28th Conference on Com-
putational Natural Language Learning, pages 1-21,
Miami, FL, USA. Association for Computational Lin-
guistics.

Kaiyu Huang, Fengran Mo, Xinyu Zhang, Hongliang
Li, You Li, Yuanchi Zhang, Weijian Yi, Yulong Mao,
Jinchen Liu, Yuzhuang Xu, Jinan Xu, Jian- Yun Nie,
and Yang Liu. 2025. A survey on large language
models with multilingualism: Recent advances and
new frontiers. Preprint, arXiv:2405.10936.

Philip A. Huebner, Elior Sulem, Fisher Cynthia, and
Dan Roth. 2021. BabyBERTa: Learning More Gram-
mar With Small-Scale Child-Directed Language. In
Proceedings of the 25th Conference on Computa-
tional Natural Language Learning, pages 624-646,
Online. Association for Computational Linguistics.

Julie Hunter, Jér6me Louradour, Virgile Rennard, Is-
mail Harrando, Guokan Shang, and Jean-Pierre Lorré.
2023. The claire french dialogue dataset. Preprint,
arXiv:2311.16840.

Sukjun Hwang, Brandon Wang, and Albert Gu. 2025.
Dynamic chunking for end-to-end hierarchical se-
quence modeling. arXiv preprint arXiv:2507.07955.

Maxim Ifergan, Omri Abend, Renana Keydar, and Amit
Pinchevski. 2024. Identifying narrative patterns and
outliers in holocaust testimonies using topic model-
ing. In Proceedings of the First Workshop on Holo-
caust Testimonies as Language Resources (HTRes)
@ LREC-COLING 2024, pages 44-52, Torino, Italia.
ELRA and ICCL.

Anna A. Ivanova, Aalok Sathe, Benjamin Lipkin, Un-
nathi Kumar, Setayesh Radkani, Thomas H. Clark,
Carina Kauf, Jennifer Hu, R. T. Pramod, Gabriel
Grand, Vivian Paulun, Maria Ryskina, Ekin Akyiirek,
Ethan Wilcox, Nafisa Rashid, Leshem Choshen,
Roger Levy, Evelina Fedorenko, Joshua Tenenbaum,
and Jacob Andreas. 2024. Elements of World Knowl-
edge (EWOK): A cognition-inspired framework for
evaluating basic world knowledge in language mod-
els. arXiv preprint.

Pratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika
Bali, and Monojit Choudhury. 2020. The state and
fate of linguistic diversity and inclusion in the NLP
world. In Proceedings of the 58th Annual Meeting of
the Association for Computational Linguistics, pages
6282-6293, Online. Association for Computational
Linguistics.

Da Ju, Hagen Blix, and Adina Williams. 2025. Domain
regeneration: How well do LLMs match syntactic
properties of text domains? In Findings of the As-
sociation for Computational Linguistics: ACL 2025,
pages 2367-2388, Vienna, Austria. Association for
Computational Linguistics.

Andreas H Jucker. 2021. Features of orality in the
language of fiction: A corpus-based investigation.
Language and Literature: International Journal of
Stylistics, 30(4):34 1-360.


Jaap Jumelet, Leonie Weissweiler, and Arianna Bisazza.
2025. Multiblimp 1.0: A massively multilingual
benchmark of linguistic minimal pairs. Preprint,
arXiv:2504.02768.

Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B.
Brown, Benjamin Chess, Rewon Child, Scott Gray,
Alec Radford, Jeffrey Wu, and Dario Amodei. 2020.
Scaling laws for neural language models. Preprint,
arXiv:2001.08361.

Amir Hossein Kargaran, Ayyoob Imani, Francois Yvon,
and Hinrich Schuetze. 2023. GlotLID: Language
identification for low-resource languages. In Find-
ings of the Association for Computational Linguis-
tics: EMNLP 2023, pages 6155-6218, Singapore.
Association for Computational Linguistics.

Krisjanis Karins, Robert MacIntyre, Monika Brandmair,
Susanne Lauscher, and Cynthia McLemore. 1997.
CALLHOME German Transcripts.

Daria Kryvosheieva and Roger Levy. 2025. Controlled
evaluation of syntactic knowledge in multilingual lan-
guage models. In Proceedings of the First Workshop
on Language Models for Low-Resource Languages,
pages 402-413, Abu Dhabi, United Arab Emirates.
Association for Computational Linguistics.

Sneha Kudugunta, Isaac Caswell, Biao Zhang, Xavier
Garcia, Derrick Xin, Aditya Kusupati, Romi Stella,
Ankur Bapna, and Orhan Firat. 2023. Madlad-400:
A multilingual and document-level large audited
dataset. In Advances in Neural Information Process-
ing Systems, volume 36, pages 67284-67296. Curran
Associates, Inc.

Richard Lastrucci, Jenalea Rajab, Matimba Shingange,
Daniel Njini, and Vukosi Marivate. 2023. Prepar-
ing the vuk’uzenzele and ZA-gov-multilingual South
African multilingual corpora. In Proceedings of
the Fourth workshop on Resources for African In-
digenous Languages (RAIL 2023), pages 18-25,
Dubrovnik, Croatia. Association for Computational
Linguistics.

Stephanie Lin, Jacob Hilton, and Owain Evans. 2022a.
TruthfulQA: Measuring how models mimic human
falsehoods. In Proceedings of the 60th Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers), pages 3214-3252, Dublin,
Ireland. Association for Computational Linguistics.

Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu
Wang, Shuohui Chen, Daniel Simig, Myle Ott, Na-
man Goyal, Shruti Bhosale, Jingfei Du, Ramakanth
Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav
Chaudhary, Brian O’Horo, Jeff Wang, Luke Zettle-
moyer, Zornitsa Kozareva, Mona Diab, and 2 others.
2022b. Few-shot learning with multilingual gener-
ative language models. In Proceedings of the 2022
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 9019-9052, Abu Dhabi,
United Arab Emirates. Association for Computa-
tional Linguistics.

Pierre Lison and Jorg Tiedemann. 2016. OpenSub-
titles2016: Extracting large parallel corpora from
movie and TV subtitles. In Proceedings of the Tenth
International Conference on Language Resources
and Evaluation (LREC’ 16), pages 923-929, Portoroz,
Slovenia. European Language Resources Association
(ELRA).

Jing Liu and Abdellah Fourtassi. 2025. Benchmarking
Ilms for mimicking child-caregiver language in inter-
action. In Proceedings of the 29th Workshop on the
Semantics and Pragmatics of Dialogue — Full Papers,
pages 92-103, Bielefeld, Germany. SEMDIAL.

Yikang Liu, Yeting Shen, Hongao Zhu, Lilong Xu, Zhi-
heng Qian, Siyuan Song, Kejia Zhang, Jialong Tang,
Pei Zhang, Baosong Yang, Rui Wang, and Hai Hu.
2024. Zhoblimp: a systematic assessment of lan-
guage models with linguistic minimal pairs in chi-
nese. Preprint, arXiv:2411.06096.

Zhi Liu, Dong Li, Taotao Long, Chaodong Wen, Xian
Peng, and Jiaxin Guo. 2025. CSQ: A Chinese Ele-
mentary Science Question Dataset with Rich Disci-
pline Properties in Adaptive Problem-Solving Pro-
cess Generation.

Emiddia Longobardi, Clelia Rossi-Arnaud, Pietro
Spataro, Diane L Putnick, and Marc H Bornstein.
2015. Children’s acquisition of nouns and verbs in
italian: contrasting the roles of frequency and posi-
tional salience in maternal language. Journal of child
language, 42(1):95-121.

Holy Lovenia, Rahmad Mahendra, Salsabil Maulana
Akbar, Lester James V. Miranda, Jennifer San-
toso, Elyanah Aco, Akhdan Fadhilah, Jonibek
Mansurov, Joseph Marvin Imperial, Onno P. Kamp-
man, Joel Ruben Antony Moniz, Muhammad
Ravi Shulthan Habibi, Frederikus Hudi, Railey Mon-
talan, Ryan Ignatius, Joanito Agili Lopo, William
Nixon, Boérje F. Karlsson, James Jaya, and 42 others.
2024. SEACrowd: A multilingual multimodal data
hub and benchmark suite for Southeast Asian lan-
guages. In Proceedings of the 2024 Conference on
Empirical Methods in Natural Language Processing,
pages 5155-5203, Miami, Florida, USA. Association
for Computational Linguistics.

Anton Lozhkov, Loubna Ben Allal, Leandro von Werra,
and Thomas Wolf. 2024. Fineweb-edu: the finest
collection of educational content.

Brian MacWhinney. 2000. The CHILDES Project:
Tools for Analyzing Talk, 3 edition. Lawrence Erl-
baum Associates, Mahwah, NJ.

Kyle Mahowald, Anna A. Ivanova, Idan A. Blank,
Nancy Kanwisher, Joshua B. Tenenbaum, and
Evelina Fedorenko. 2024. Dissociating language
and thought in large language models. Trends in
Cognitive Sciences, pages 517-540.

Alexis Matzopoulos, Charl Hendriks, Hishaam Ma-
homed, and Francois Meyer. 2025. BabyLMs for
isiXhosa: Data-efficient language modelling in a


low-resource context. In Proceedings of the First
Workshop on Language Models for Low-Resource
Languages, pages 240-248, Abu Dhabi, United Arab
Emirates. Association for Computational Linguistics.

Marina Mayor-Rocher, Cristina Pozo, Nina Melero,
Gonzalo Martinez, Maria Grandury, and Pedro Re-
viriego. 2025. It’s the same but not the same:
Do Ilms distinguish spanish varieties? Preprint,
arXiv:2504.20049.

Cindy McKellar. 2022. Autshumato english-sesotho
parallel corpora. SADiLaR Language Resource
Repository, License: Creative Commons Attribution
4.0 International.

Bettina Messmer, Vinko Saboléec, and Martin Jaggi.
2025. Enhancing multilingual Ilm pretraining with
model-based data selection. arXiv.

Francois Meyer and Jan Buys. 2024.  Triples-to-
isiXhosa (T2X): Addressing the challenges of low-
resource agglutinative data-to-text generation. In
Proceedings of the 2024 Joint International Con-
ference on Computational Linguistics, Language
Resources and Evaluation (LREC-COLING 2024),
pages 16841-16854, Torino, Italia. ELRA and ICCL.

Ludmila Midrigan Ciochina, Victoria Boyd, Lucila
Sanchez-Ortega, Diana Malancea_Malac, Doina
Midrigan, and David P. Corina. 2020. Resources
in underrepresented languages: Building a repre-
sentative Romanian corpus. In Proceedings of the
Twelfth Language Resources and Evaluation Confer-
ence, pages 3291-3296, Marseille, France. European
Language Resources Association.

Steven Moran. 2016. The ACQDIV database:
Min(d)ing the ambient language. In Proceedings
of the Tenth International Conference on Language
Resources and Evaluation (LREC’16), pages 4423—
4429, Portoroz, Slovenia. European Language Re-
sources Association (ELRA).

Aaron Mueller, Garrett Nicolai, Panayiota Petrou-
Zeniou, Natalia Talmina, and Tal Linzen. 2020.
Cross-linguistic syntactic evaluation of word predic-
tion models. In Proceedings of the 58th Annual Meet-
ing of the Association for Computational Linguistics,
pages 5523-5539, Online. Association for Computa-
tional Linguistics.

Alberto Mufioz-Ortiz, Carlos G6mez-Rodriguez, and
David Vilares. 2024. Contrasting linguistic patterns
in human and LLM-generated news text. Artif. Intell.
Rev., 57(10):265.

Joakim Nivre, Daniel Zeman, Filip Ginter, and Francis
Tyers. 2017. Universal Dependencies. In Proceed-
ings of the 15th Conference of the European Chap-
ter of the Association for Computational Linguistics:
Tutorial Abstracts, Valencia, Spain. Association for
Computational Linguistics.

Jessica Ojo, Odunayo Ogundepo, Akintunde Oladipo,
Kelechi Ogueji, Jimmy Lin, Pontus Stenetorp, and

David Ifeoluwa Adelani. 2025. Afrobench: How
good are large language models on african languages?
Preprint, arXiv:2311.07978.

Catherine Olsson, Nelson Elhage, Neel Nanda,
Nicholas Joseph, Nova DasSarma, Tom Henighan,
Ben Mann, Amanda Askell, Yuntao Bai, Anna
Chen, Tom Conerly, Dawn Drain, Deep Gan-
guli, Zac Hatfield-Dodds, Danny Hernandez, Scott
Johnston, Andy Jones, Jackson Kernion, Liane
Lovitt, and 7 others. 2022. In-context learn-
ing and induction heads. Transformer Circuits
Thread. Https://transformer-circuits.pub/2022/in-
context-learning-and-induction-heads/index.html.

Francesca Padovani, Jaap Jumelet, Yevgen Matusevych,
and Arianna Bisazza. 2025. Child-directed language
does not consistently boost syntax learning in lan-
guage models. Preprint, arXiv:2505.23689.

Katerina Papantoniou and Yannis Tzitzikas. 2024. NIp
for the greek language: A longer survey. Preprint,
arXiv:2408.10962.

Guilherme Penedo, Hynek Kydliéek, Vinko Saboléec,
Bettina Messmer, Negar Foroutan, Amir Hossein
Kargaran, Colin Raffel, Martin Jaggi, Leandro Von
Werra, and Thomas Wolf. 2025. Fineweb2: One
pipeline to scale them all — adapting pre-training
data processing to every language. Preprint,
arXiv:2506.20920.

Edoardo Maria Ponti, Goran GlavaS, Olga Majewska,
Qianchu Liu, Ivan Vuli¢é, and Anna Korhonen. 2020.
XCOPA: A multilingual dataset for causal common-
sense reasoning. In Proceedings of the 2020 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), pages 2362-2376, Online. As-
sociation for Computational Linguistics.

Velka Popova. 2020. Childes bulgarian labling corpus.

Laurent Prévot, Sheng-Fu Wang, Jou-An Chi, and Shu-
Kai Hsieh. 2024. Extending the BabyLM initiative :
Promoting diversity in datasets and metrics through
high-quality linguistic corpora. In The 2nd BabyLM
Challenge at the 28th Conference on Computational
Natural Language Learning, pages 147-158, Miami,
FL, USA. Association for Computational Linguistics.

Ayu Purwarianti, Dea Adhista, Agung Baptiso, Mif-
tahul Mahfuzh, Yusrina Sabila, Aulia Adila, Samuel
Cahyawijaya, and Alham Fikri Aji. 2025. NusaDia-
logue: Dialogue summarization and generation for
underrepresented and extremely low-resource lan-
guages. In Proceedings of the Second Workshop in
South East Asian Language Processing, pages 82—
100, Online. Association for Computational Linguis-
tics.

Jirui Qi, Raquel Fernandez, and Arianna Bisazza. 2023.
Cross-lingual consistency of factual knowledge in
multilingual language models. In Proceedings of the
2023 Conference on Empirical Methods in Natural
Language Processing, pages 10650-10666, Singa-
pore. Association for Computational Linguistics.


Angelika Romanou, Negar Foroutan, Anna Sotnikova,
Zeming Chen, Sree Harsha Nelaturu, Shivalika
Singh, Rishabh Maheshwary, Micol Altomare, Mo-
hamed A. Haggag, Snegha A, Alfonso Amayuelas,
Azril Hafizi Amirudin, Viraat Aryabumi, Danylo
Boiko, Michael Chang, Jenny Chim, Gal Cohen,
Aditya Kumar Dalmia, Abraham Diress, and 40 oth-
ers. 2024. Include: Evaluating multilingual language
understanding with regional knowledge. Preprint,
arXiv:2411.19799.

Dimitris Roussis, Leon Voukoutis, Georgios
Paraskevopoulos, Sokratis Sofianopoulos, Prokopis
Prokopidis, Vassilis Papavasileiou, Athanasios
Katsamanis, Stelios Piperidis, and Vassilis Katsouros.
2025. Krikri: Advancing open large language
models for greek. Preprint, arXiv:2505.13772.

Phillip Rust, Jonas F. Lotz, Emanuele Bugliarello, Eliz-
abeth Salesky, Miryam de Lhoneux, and Desmond
Elliott. 2023. Language modelling with pixels. In
The Eleventh International Conference on Learning
Representations.

Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavat-
ula, and Yejin Choi. 2019. Winogrande: An adver-
sarial winograd schema challenge at scale. Preprint,
arXiv:1907.10641.

Suchir Salhan, Richard Diehl Martinez, Zébulon
Goriely, and Paula Buttery. 2024. Less is more: Pre-
training cross-lingual small-scale language models
with cognitively-plausible curriculum learning strate-
gies. In The 2nd BabyLM Challenge at the 28th Con-
ference on Computational Natural Language Learn-
ing, pages 174-188, Miami, FL, USA. Association
for Computational Linguistics.

Guokan Shang, Hadi Abdine, Yousef Khoubrane, Amr
Mohamed, Yassine Abbahaddou, Sofiane Ennadir,
Imane Momayiz, Xuguang Ren, Eric Moulines,
Preslav Nakov, Michalis Vazirgiannis, and Eric Xing.
2025. Atlas-chat: Adapting large language models
for low-resource Moroccan Arabic dialect. In Pro-
ceedings of the First Workshop on Language Moad-
els for Low-Resource Languages, pages 9-30, Abu
Dhabi, United Arab Emirates. Association for Com-
putational Linguistics.

Matthew Shardlow, Fernando Alva-Manchego, Riza
Batista-Navarro, Stefan Bott, Saul Calderon Ramirez,
Rémi Cardon, Thomas Francois, Akio Hayakawa,
Andrea Horbach, Anna Huelsing, Yusuke Ide,
Joseph Marvin Imperial, Adam Nohejl, Kai North,
Laura Occhipinti, Nelson Peréz Rojas, Nishat Rai-
han, Tharindu Ranasinghe, Martin Solis Salazar, and
2 others. 2024. An Extensible Massively Multilin-
gual Lexical Simplification Pipeline Dataset using
the MultiLS Framework. In Proceedings of the 3rd
Workshop on Tools and Resources for People with
REAding DIfficulties (READI).

Zhewen Shen, Aditya Joshi, and Ruey-Cheng Chen.
2024. BAMBINO-LM: (bilingual-)human-inspired
continual pre-training of BabyLM. In Proceedings

of the Workshop on Cognitive Modeling and Compu-
tational Linguistics, pages 1-7, Bangkok, Thailand.
Association for Computational Linguistics.

Maria Shvedova and Arsenii Lukashevskyi. 2024. Plug:
Corpus of old ukrainian texts. Available at https:
//github.com/Dandelliony/pluperfect_grac.

Johannes Sibeko and Menno Zaanen. 2023. A data set
of final year high school examination texts of south
african home and first additional language subjects.
Journal of Open Humanities Data, 9.

Mariana O Silva, Clarisse Scofield, and Mirella M Moro.
2021. Pportal: Public domain portuguese-language
literature dataset. In Dataset Showcase Workshop
(DSW), pages 77-88. SBC.

Shivalika Singh, Angelika Romanou, Clémentine Four-
rier, David Ifeoluwa Adelani, Jian Gang Ngui, Daniel
Vila-Suero, Peerat Limkonchotiwat, Kelly Marchi-
sio, Wei Qi Leong, Yosephine Susanto, Raymond
Ng, Shayne Longpre, Sebastian Ruder, Wei-Yin
Ko, Antoine Bosselut, Alice Oh, Andre Martins,
Leshem Choshen, Daphne Ippolito, and 4 others.
2025. Global MMLU: Understanding and addressing
cultural and linguistic biases in multilingual evalua-
tion. In Proceedings of the 63rd Annual Meeting of
the Association for Computational Linguistics (Vol-
ume I: Long Papers), pages 18761-18799, Vienna,
Austria. Association for Computational Linguistics.

Dan Isaac Slobin. 2014. The crosslinguistic study of
language acquisition: Volume 5: Expanding the con-
texts. Psychology Press.

R. Smith. 2007. An overview of the tesseract ocr engine.
In Ninth International Conference on Document Anal-
ysis and Recognition (ICDAR 2007), volume 2, pages
629-633.

Catherine E. Snow and Charles A. Ferguson, editors.
1977. Talking to Children: Language Input and Ac-
quisition. Cambridge University Press, Cambridge,
MA.

Luca Soldaini, Rodney Kinney, Akshita Bhagia, Dustin
Schwenk, David Atkinson, Russell Authur, Ben Bo-
gin, Khyathi Chandu, Jennifer Dumas, Yanai Elazar,
Valentin Hofmann, Ananya Harsh Jha, Sachin Kumar,
Li Lucy, Xinxi Lyu, Nathan Lambert, Ian Magnusson,
Jacob Morrison, Niklas Muennighoff, and 17 others.
2024. Dolma: An Open Corpus of Three Trillion
Tokens for Language Model Pretraining Research.
Preprint, arXiv:2402.00159.

Taiga Someya and Yohei Oseki. 2023. JBLiMP:
Japanese benchmark of linguistic minimal pairs. In
Findings of the Association for Computational Lin-
guistics: EACL 2023, pages 1581-1594, Dubrovnik,
Croatia. Association for Computational Linguistics.

Maria Spinelli, Chiara Suttora, Adrian Garcia-Sierra,
Fabia Franco, Francesca Lionetti, and Mirco Fasolo.
2023. Editorial: Are there different types of child-
directed speech? dynamic variations according to


individual and contextual factors. Frontiers in Psy-
chology, Volume 13 - 2022.

Sabine Stoll. 2020. Sampling linguistic diversity to
understand language development, pages 247-262.
John Benjamins Publishing Company.

Simon Striibbe, Irina Sidorenko, and Renée Lampe.
2025. Comparison of grammar characteristics of
human-written corpora and machine-generated texts
using a novel rule-based parser. Information, 16(4).

Alice Suozzi, Luca Capone, Gianluca E Lebani, and
Alessandro Lenci. 2025. Bambi: Developing
baby language models for italian. arXiv preprint
arXiv:2503.09481.

Shira Tal, Eitan Grossman, and Inbal Arnon. 2024.
Infant-directed speech becomes less redundant as in-
fants grow: Implications for language learning. Cog-
nition, 249:105817.

Gemma Team, Aishwarya Kamath, Johan Ferret, Shreya
Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin,
Tatiana Matejovicova, Alexandre Ramé, Morgane
Riviere, Louis Rouillard, Thomas Mesnard, Geoffrey
Cideron, Jean bastien Grill, Sabela Ramos, Edouard
Yvinec, Michelle Casbon, Etienne Pot, Ivo Penchev,
and 197 others. 2025. Gemma 3 technical report.
Preprint, arXiv:2503.19786.

Agnes Tellings, Micha Hulsbosch, Anne Vermeer, and
Antal van den Bosch. 2014. Basilex: an 11.5 mil-
lion words corpus of dutch texts written for children.
Computational Linguistics in the Netherlands Jour-
nal, 4:191-208.

Jannis Vamvas and Rico Sennrich. 2021. On the lim-
its of minimal pairs in contrastive evaluation. In
Proceedings of the Fourth BlackboxNLP Workshop
on Analyzing and Interpreting Neural Networks for
NLP, pages 58-68, Punta Cana, Dominican Republic.
Association for Computational Linguistics.

Leon Voukoutis, Dimitris Roussis, Georgios
Paraskevopoulos, Sokratis Sofianopoulos, Prokopis
Prokopidis, Vassilis Papavasileiou, Athanasios
Katsamanis, Stelios Piperidis, and Vassilis Katsouros.
2024. Meltemi: The first open large language model
for greek. Preprint, arXiv:2407.20743.

Xiaoyang Wang, Chen Li, Jianqiao Zhao, and Dong Yu.
2021. Naturalconv: A chinese dialogue dataset to-
wards multi-turn topic-driven conversation. Proceed-
ings of the AAAI Conference on Artificial Intelligence,
35(16):14006-14014.

Alex Warstadt, Aaron Mueller, Leshem Choshen, Ethan
Wilcox, Chengxu Zhuang, Juan Ciro, Rafael Mos-
quera, Bhargavi Paranjabe, Adina Williams, Tal
Linzen, and Ryan Cotterell. 2023. Findings of the
BabyLM challenge: Sample-efficient pretraining on
developmentally plausible corpora. In Proceedings
of the BabyLM Challenge at the 27th Conference on
Computational Natural Language Learning, pages
1-34, Singapore. Association for Computational Lin-
guistics.

Alex Warstadt, Alicia Parrish, Haokun Liu, Anhad Mo-
hananey, Wei Peng, Sheng-Fu Wang, and Samuel R.
Bowman. 2020. BLiMP: The benchmark of linguis-
tic minimal pairs for English. Transactions of the
Association for Computational Linguistics, 8:377—
392.

Anna Whittle and Elena Nuzzo. 2015. L’insegnamento
della grammatica nella classe multilingue. un esperi-
mento di focus on form nella scuola primaria. [tal-
iano LinguaDue, 7(1):369-370.

Wikimedia Foundation. 2025. Wikisource. English
Wikisource. Accessed July 24, 2025.

Ethan Gotlieb Wilcox, Michael Hu, Aaron Mueller, Tal
Linzen, Alex Warstadt, Leshem Choshen, Chengxu
Zhuang, Ryan Cotterell, and Adina Williams. 2024.
Bigger is not always better: The importance of
human-scale language modeling for psycholinguis-
tics.

Adina Williams, Nikita Nangia, and Samuel Bowman.
2018. A broad-coverage challenge corpus for sen-
tence understanding through inference. In Proceed-
ings of the 2018 Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies, Volume
I (Long Papers), pages 1112-1122, New Orleans,
Louisiana. Association for Computational Linguis-
tics.

Genta Indra Winata, Alham Fikri Aji, Samuel Cahyawi-
jaya, Rahmad Mahendra, Fajri Koto, Ade Romad-
hony, Kemal Kurniawan, David Moeljadi, Radi-
tyo Eko Prasojo, Pascale Fung, Timothy Baldwin,
Jey Han Lau, Rico Sennrich, and Sebastian Ruder.
2023. NusaX: Multilingual parallel sentiment dataset
for 10 Indonesian local languages. In Proceedings
of the 17th Conference of the European Chapter of
the Association for Computational Linguistics, pages
815-834, Dubrovnik, Croatia. Association for Com-
putational Linguistics.

Lvxiaowei Xu, Jianwang Wu, Jiawei Peng, Jiayu Fu,
and Ming Cai. 2022. FCGEC: Fine-grained corpus
for Chinese grammatical error correction. In Find-
ings of the Association for Computational Linguis-
tics: EMNLP 2022, pages 1900-1918. Association
for Computational Linguistics.

Aditya Yadavalli, Alekhya Yadavalli, and Vera Tobin.
2023. SLABERT talk pretty one day: Modeling
second language acquisition with BERT. In Proceed-
ings of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers),
pages 11763-11777, Toronto, Canada. Association
for Computational Linguistics.

An Yang, Anfeng Li, Baosong Yang, Beichen Zhang,
Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao,
Chengen Huang, Chenxu Lv, Chujie Zheng, Day-
iheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao
Ge, Haoran Wei, Huan Lin, Jialong Tang, and 41
others. 2025a. Qwen3 technical report. Preprint,
arXiv:2505.09388.


An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui,
Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu,
Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jian-
hong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang,
Jingren Zhou, Junyang Lin, Kai Dang, and 23 oth-
ers. 2025b. Qwen2.5 technical report. Preprint,
arXiv:2412.15115.

Weihao You, Pengcheng Wang, Changlong Li, Zhilong
Ji, and Jinfeng Bai. 2024. Ck12: A rounded k12
knowledge graph based benchmark for chinese holis-
tic cognition evaluation. In Proceedings of the AAAI
Conference on Artificial Intelligence, volume 38,
pages 19431-19439.

Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali
Farhadi, and Yejin Choi. 2019. HellaSwag: Can a ma-
chine really finish your sentence? In Proceedings of
the 57th Annual Meeting of the Association for Com-
putational Linguistics, pages 4791-4800, Florence,
Italy. Association for Computational Linguistics.

Binbin Zhang, Hang Lv, Pengcheng Guo, Qijie Shao,
Chao Yang, Lei Xie, Xin Xu, Hui Bu, Xiaoyu Chen,
Chenchen Zeng, and | others. 2022. Wenetspeech:
A 10000+ hours multi-domain mandarin corpus for
speech recognition. In ICASSP 2022-2022 IEEE In-
ternational Conference on Acoustics, Speech and Sig-
nal Processing (ICASSP), pages 6182-6186. IEEE.

Xiaotian Zhang, Chunyang Li, Yi Zong, Zhengyu Ying,
Liang He, and Xipeng Qiu. 2023. Evaluating the
performance of large language models on gaokao
benchmark. CoRR.

Dongjie Zhou and Tianging Zheng. 2024. Measure-
ment method research of chinese texts’ difficulty
based on two-characters continuations. Plos one,
19(9):e0309717.

Jiaming Zhou, Shiyao Wang, Shiwan Zhao, Jiabei He,
Haogin Sun, Hui Wang, Cheng Liu, Aobo Kong,
Yujie Guo, and Yong Qin. 2024. Childmandarin: A
comprehensive mandarin speech dataset for young
children aged 3-5. CoRR.

A Author Contributions

A detailed breakdown of all author contributions is
provided in Table 2.

B_ Format considerations

In order to make our multilingual dataset easy to
use and access for researchers, we format our data
in a unified schema across languages consisting
of self-contained documents and document-level
metadata. This is applied and verified consistently
for all data, including language-specific resources,
multilingual datasets, and various corpora used for
padding. For each document, we include details
about the license and the source of the data, ensur-
ing proper creator attribution and compliance with

data sharing licenses. Other fields encode informa-
tion about a document’s content, such as the text’s
script, target age estimate, content category, and
number of tokens. The full schema of our docu-
ments and a detailed description of each field, are
presented in Table 4.

C_ Language-specific Details
C.1 Arabic

Dataset Description. In recent years, there has
been substantial effort towards advancing NLP for
the Arabic languages. However, child-oriented re-
sources and developmentally plausible corpora are
still lacking. Some efforts have been made such as
"a Compilation of an Arabic Children’s Corpus"
(Al-Sulaiti et al., 2016), and a "leveled reading cor-
pus of Modern Standard Arabic" (Al Khalil et al.,
2018). However, the data has not been made pub-
licly available. Additionally, natural conversation
and speech data, which is part of the child’s lin-
guistic environment, is often unreleased or avail-
able only under a fee. Despite these restrictions,
we present a developmentally plausible dataset for
Arabic, consisting of children’s books and stories,
song lyrics, natural conversations, and articles from
child wikis. We provide details about each data cat-
egory in the paragraphs below.

Our Arabic dataset includes a large collection
of different language varieties, specifically: Su-
dan, Egyptian, Yemeni, Meghribi, Iraqi, Levan-
tine, Gulf and written language in Modern Stan-
dard Arabic (MSA). Even though spoken Arabic
can vary substantially across different regions, with
speech being often mutually unintelligible, due to
the scarcity of developmentally plausible data we
opted to combine all the different dialects into one
dataset. An important goal for the next iteration
of BabyBabelLM is to release single dialect devel-
opmentally plausible datasets for Arabic, incorpo-
rating data from recent efforts such as Atlas-Chat
(Shang et al., 2025). This will give us the oppor-
tunity to study the unique nature of dialects in the
Arabic language, and how they interact in terms
of language model training and performance in a
developmentally plausible setting.

Books, Wiki, News. For books, we include the
recently released Arabic Book Corpus (Hallberg,
2025), keeping only the "children stories" cate-
gory, containing both translated and original titles,
mostly from the 20th century. We also include chil-
dren stories from GlotStoryBooks and Ririro and


Paper Writing Data Collection Coding Supervision Evaluation
Jaap Jumelet e nld e e °
Abdellah Fourtassi fra
Akari Haga jap
Bastian Bunzeck e deu / pol + Wikis
Bhargav Shandilya OpenSubtitles e
Diana Galvan-Sosa e spa
Faiz Ghifari Haznitrama ° Indonesian langs. + Padding °
Francesca Padovani ita/spa e e
Francois Meyer e SA languages
Hai Hu zho
Julen Etxaniz eus °
Laurent Prévot fra
Linyang He yue / zho
Maria Grandury spa
Mila Marcheva e bul
Negar Foroutan fas e
Nikitas Theodoropoulos e ell/ara/por °
Pouya Sadeghi fas
Siyuan Song e zho
Suchir Salhan ° bul / ron/ spa ° e
Susana Zhou spa
Yurii Paniv ukr °
Ziyin Zhang zho
Arianna Bisazza e e °
Alex Warstadt e °
Leshem Choshen e °

Table 2: Author contributions; language code indicates that the author was responsible for collecting and validating
language-specific data for that language, as outlined in Appendix C.

Children’s Wiki articles.

Transcription. Given that songs form a common
linguistic input for children, we incorporate in our
data the Habibi Corpus (El-Haj, 2020), consisting
of song lyrics in a variety of dialects. Additionally,
adult speech conversation data was collected from
MagicHub> for the Yemeni ° and the Egyptian 7
dialects, as dialogue also contributes in the child’s
learning environment. Lastly, we include all child
directed speech present in CHILDES.

C.2 Bulgarian

Dataset Description. The Bulgarian dataset is a
compilation of children’s literature accessed via a
public library website: https: //chitanka. info.
The Bulgarian BabyLM corpus is the first large-
scale corpus of child-appropriate Bulgarian text.

Books, Wiki, News. The Chitanka portion of
the Bulgarian BabyLM corpus consists of 28M to-
kens, excluding punctuation. To our knowledge,
the only other similarly sourced dataset is from
CHILDES, which is also included in the Bulgarian

Shttps://magichub.com/datasets/

Available here: https: //magichub.com/datasets/
yemeni-arabic-conversational-speech-corpus/

TAvailable here: https: //magichub.com/datasets/
egyptian-arabic-conversational-speech-corpus/

BabyLM Corpus. The Chitanka library consists of
several categories of books, ranging from science
to literature, and has a curated section of Children
and Young Adult’s literature that the site owners
has confirmed are free to distribute.* Chitanka’s
Children and Young Adult Literature sections con-
sists of 670 texts, comprised of novels and short
stories (377 texts) poems and riddles (40 texts);
fairy tales (169 texts); and other children stories
(25 texts); and miscellaneous children and young
adult literature (68 texts).”

Preprocessing. The individual texts have been
cleaned of front and back matter. Each text is pro-
vided alongside the link it was scraped from. The
largest version of the dataset includes children’s
literature for various ages, but if one would like to
restrict the dataset to a subset of earlier-age appro-
priate literature, this can be done by restricting the
URLs which correspond to the Bulgarian Ministry
of Education’s programme for second and third

Excerpt from author correspondence: “Everything in my
library is completely free; you’re welcome to use any of the
available resources. The books we add are supposed to be free
of copyright claims. If such claims do arise—that is, if rights
holders or distributors get in touch with us—those works are

‘quarantined’ until a previously agreed period of time has

elapsed.”
Available here: https: //chitanka. info/books/
category/detska-literatura


grade summer reading (ages 6-8 years), for which
the corresponding URLs are listed in the README
of the dataset. A final notable detail of the dataset
is that the texts are in the Cyrillic alphabet, which
should be considered during preprocessing.

Transcription. The Bulgarian portion of
CHILDES consists of 94K tokens of Child-
Directed Speech (CDS) collected by Popova (2020)
for 5 children aged 1-2 years.

C.3 Cantonese

Dataset Description. We compile our Can-
tonese text corpus by consolidating four publicly
available resources: the Hambaanglaang project,
the GlotStory Book project, and two Cantonese
datasets from CHILDES (HKU-70 Corpus and
Lee/Wong/Leung Corpus).

Books, Wiki, News. Hambaanglaang!® is an
open-source repository of Cantonese graded read-
ers created by volunteers. It offers a collection of
stories designed for children across five proficiency
levels, aiming to support Cantonese literacy and
reading skills within the community. Detailed in-
formation about this project can be found in its
official documentation. GlotStory Book (Hong
Kong edition)!! is a free, open-source literacy
site that localizes 40 children’s stories—originally
from the African Storybook Project—into multiple
languages used in Hong Kong’s “two scripts / three
languages” environment (spoken & written Can-
tonese, Mandarin, English). Here we only extracted
Cantonese. Each story is tagged with one of five
length/lexical-complexity levels and accompanied
by narrated audio recordings intended to support
family-, school-, and community-based language
learning. The HKU-70 Corpus! contains 70 tran-
scripts of interviews with 70 Cantonese-speaking
children aged 2 years 6 months to 5 years 6 months.
The data were collected at the University of Hong
Kong and represent naturalistic child—adult interac-
tions in preschool settings. Each child participated
in a one-hour recording session, with conversa-
tions organized around familiar daily routines (e.g.,
bathing, dressing, feeding) to elicit a diverse range
of utterances and syntactic structures. The sam-
ple was balanced by gender, and all children were
prescreened using the Cantonese version of the

https: //hambaanglaang.hk/about-us-2/

"https: //global-asp. github. io/
storybooks-hongkong

https: //talkbank.org/childes/access/Chinese/
Cantonese/HKU. html

Reynell Developmental Language Scales. Finally,
the Lee/Wong/Leung Corpus!?, which provides
longitudinal data on eight Cantonese-speaking chil-
dren, each recorded for approximately one year.
The recordings capture natural interactions be-
tween children, their caregivers, and occasionally
other adults. Detailed metadata about the children,
including their ages and family backgrounds, are in-
cluded, providing valuable sociolinguistic context
for the dataset.

Preprocessing. All datasets were cleaned to
retain only complete Traditional Chinese text,
with non-textual annotations such as speaker la-
bels and syntactic tags removed. Each storybook
page or conversational block is treated as a single
passage-level entry. All text is tokenized using the
Qwen1.5-7B (Bai et al., 2023) tokenizer to ensure
compatibility with downstream language modeling
tasks.

C.4. Mandarin Chinese

Dataset Description. In addition to multilingual re-
sources (CHILDES and GlotStoryBook), our Man-
darin Chinese dataset includes data from multiple
resources.

Books, Wiki, News. We use children’s book and
stories data collected from various sources. We first
obtained children’s stories from Quangushi (full
stories) !*. Then, we used children’s stories from
and two Chinese reading comprehension datasets:
CFT (Cui et al., 2016) and CMRC-2019 (Cui et al.,
2020). These two datasets are respectively Cloze
and sentence ordering benchmarks derived from
children’s stories. We reconstructed the complete
stories using the answers provided by the authors
and included the stories in our dataset. We also col-
lected open-source children’s book and children’s
wiki data from WikiJunior and Wikibooks.

Education. For educational materials, we used
several datasets that evaluate models’ general
knowledge through exam-style questions, as these
datasets are typically well-documented and come
with openly available licenses:

* GAOKAO (Zhang et al., 2023): an evaluation frame-
work that uses Chinese National College En-
trance Examination (GAOKAO) questions as a
dataset to evaluate LLMs. The dataset includes
subjective and objective questions from exams
from 2010 to 2024.

Bhttps://talkbank. org/childes/access/Chinese/

Cantonese/LeeWongLeung. html
http: //quangushi.com/


* CK-12 (You et al., 2024): an evaluation for Chi-
nese LLMs. Constructed based on multi-level
knowledge graph and covers most comprehen-
sive knowledge points in Chinese K12 field.

¢ CSQ (Liu et al., 2025): a Chinese Science Ques-
tion dataset covering four subjects and multiple
topics at the Chinese primary school.

We included the full question prompts, answer

choices, correct answers, and explanations. Ques-

tions in English are excluded. In addition, we col-
lected grammatical and corrected sentences from

FCGEC (Xu et al., 2022), a human-annotated corpus

based on multi-choice grammatical error problems.

We also collected data from a hierarchical corpus of

primary school students’ compositions (Zhou and

Zheng, 2024). The primary source of this corpus

is elementary school student composition maga-

zines, which ensures that the essays are of relatively
high quality. We also incorporated transcriptions in

ChildMandarin (Zhou et al., 2024). This dataset

contains high-quality speech data collected from

397 children in China, along with carefully crafted,

character-level manual transcriptions. We included

data from NaturalConv (Wang et al., 2021), a

multi-turn topic-driven conversation dataset is also

included as such conversations on daily topic are
considered as children available.

Transcription Finally, we included data from
Wenetspeech (Zhang et al., 2022), a multi-domain
Mandarin corpus consisting of transcribed speech,
collected from Youtube and Podcast. We only used
the high-quality labeled part of the dataset, which
shall be considered as children available.

C.5 Dutch

Dataset Description. The Dutch data is built from
various educational sources. Licensing laws are
very strictly defined in the Netherlands, which
makes it challenging to find children’s literature
with creative commons licenses. Educational re-
sources, however, are often released under CC-BY
license.

Books, Wiki, News. We include the texts of
all high school exams! from 1999 to 2024, for
all Dutch high school levels: VMBO (age 15-16),
HAVO (age 16-17), and VWO (age 17-18), resulting
in 6.87M tokens. We extracted 8.78M tokens from
WikiWijs!°, a platform for sharing educational ma-
terials by teachers for both primary and high school

'SReleased publicly by examenblad.nl, with archives avail-

able at alleexamens.nl.
6 Wikiwijs.nl

level. KlasCement!” provides a similar platform,

focused on Flemish education, from which we ex-
tract 0.14M tokens. Next to these educational re-
sources, we also incorporate BasiLex (Tellings
et al., 2014) into the Dutch section. BasiLex
contains a collection of child-directed resources,
extracted from children’s media, children’s books,
and educational materials. We collect 11.37M to-
kens from BasiLex.

C.6 French

Dataset Description. In addition to child-directed
speech from CHILDES (around 4 million tokens),
we include the following developmentally plausible
resources, covering a range of spoken and written
language that children are likely to hear or read.
Books, Wiki, News. We included eighteen chil-
dren’s books (around 1 million tokens).'* These
were selected to match the reading level of chil-
dren aged 6 to 12 and to cover a variety of story
types. The collection includes classic fairy tales
(Contes de Perrault, Grimm, Andersen), simple
educational texts (Abécédaire du petit naturaliste,
Histoires comme ¢a pour les petits), and famous
adventure and fantasy stories like Le Tour du
monde en quatre-vingts jours, L’fle au trésor, Al-
ice au pays des merveilles, and Croc-Blanc. Our
data also includes subtitles (around 6 million to-
kens). This portion is made mostly of subtitles
from the popular animated series Caillou, aimed
at toddlers and shared on YouTube by the chan-
nel Caillou Francais - WildBrain.!° It in-
cludes 1,539 video episodes. In addition to Caillou,
we included other well-known children’s shows
in France, such as Olive et Tom (171 videos),
Lou (52 videos), La vie (8 videos), and a few
other youth-oriented clips (15 videos). Each sub-
title document includes the YouTube video ID so
the original video can be accessed. We obtained
raw transcripts via the YouTubeTranscriptApi is
filtered for manually entered transcripts (as op-
posed to automatically created ones), and fed
them through the library’s built-in TextFormatter,
which strips out all timing information and reassem-
bles each subtitle fragment as plain text. Addi-
tionally, we included transcripts of spoken con-

'7lascement.net

'8Hand-picked from the Wikisource category:
gorie:Littérature jeunesse

https: //www. youtube. com/@CaillouFrench

https ://pypi.org/project/
youtube-transcript-api/

Caté-


versations (around 2 million tokens) that are not
directly addressed to children, but that children
could realistically overhear. We selected a number
of sources from Claire-Dialogue-French-®. 17!
(Hunter et al., 2023), including three types of
settings: spontaneous everyday conversations (in
homes, cafés, or on the street), guided one-on-
one interviews, and workplace meetings. The data
comes from sources like PFC_free, OFROM, CLAPI,
ORFEO_coralrom, ParisStories, CFPP, ACSYNT,
and ORFEO_reunions_de_travail.

C.7 German

Dataset Description. Our German data builds
upon the existing German BabyLM corpus by Bun-
zeck et al. (2025), extending it with more develop-
mentally plausible data and discarding the major-
ity of their padding data in favor of the multilin-
gual padding data compiled in the current project.
As German is a comparatively high-resource lan-
guage, we are able to supplement the multilingual
resources with a variety of monolingual corpora.
Books, Wiki, News. Five different children’s
wikis are available for German, including the state-
sponsored Klexikon and MiniKlexikon, but also
comparable efforts for Austrian German like the
Kiwithek. In addition, we supplement this kind of
educational data with the WikiBooks Wikijunior
bookshelf, which is fairly comprehensive for Ger-
man. As for books, we aim to make an educated
selection of the Project Gutenberg collection
featuring works for children and young adults. We
include books that are considered classics of chil-
dren’s literature and read to this day. We further
also include classics of German literature that are
regularly read in middle school (e.g. works by
Franz Kafka). Although they are located at the
end of the “developmentally plausible’ timeline,
they are plausibly encountered by many young
adults in the German education system. Similarly,
we also include the archives of the Fluter mag-
azine, published by the German Federal Agency
for Civic Education, which contains a large body
of non-fiction writing aimed at adolescents and
young adults. Moving from child-directed to child-
available language, we furthermore incorporate the
German section of the CallHome corpus (Karins
et al., 1997), which contains transcribed telephone
conversations between adults. Such conversations
could i) be plausibly overheard by children, and ii)

*lhttps://huggingface.co/datasets/
OpenLLM-France/Claire-Dialogue-French-@.1

approximate child-directed input nicely by being
transcribed from spoken data, which differs quite
dramatically from written data in composition (cf.
Cameron-Faulkner et al., 2003; Cameron-Faulkner
and Noble, 2013; Bunzeck and Diessel, 2025). In
a similar vein, we also incorporate the German
portion of Dreambank (Domhoff and Schneider,
2008), a large corpus of dream reports by adults
and children. Despite not being originally spoken,
the ‘self-reporting’ register included in this data is
closer to spoken data than ordinary writing, and
social storytelling is an important component of
language acquisition. Therefore, we conclude that
this dataset also enhances the variety and develop-
mental plausibility of the German data.

C.8 Greek

Dataset Description. NLP for the Greek language
has developed drastically over the past few years
(Papantoniou and Tzitzikas, 2024), with a notable
example being the recent release of large language
models for the Greek language: Meltemi 7B (Vouk-
outis et al., 2024) the first such open LLM for
Greek, and Krikri 8B (Roussis et al., 2025) fur-
ther scaling up data and model sizes. Here we
present, to our knowledge, the first developmen-
tally plausible corpus for the Greek language. The
data is curated as a collection of publicly available
datasets, sourced mostly from CLARIN “EL”, and
original web-scraped children’s books and stories.
We present details about the dataset composition
and preprocessing below. In the future we plan to
include more child-directed speech data in collabo-
ration with language acquisition researchers, incor-
porating efforts such as the Greek Children Spoken
Language Corpus ** and the Greek-speaking Chil-
dren Corpus 74.

Education. We incorporate into our data a va-
riety of educational textbooks. We include a se-
lection of Primary School Books ”° in the fields
of arts, language, religion, history, and social and
political sciences, aimed at grades 1-6 (ages 6-12).
Apart from textbooks aimed at children, we decided
to additionally include material designed for later
grades and ages. Even though this content is aimed
at the tail end of our target ages for developmen-
tally plausible corpora, we consider it sufficiently

https: //inventory.clarin. gr/

3http://gcsl.ece.uth.gr/

“https: //gavriilidou.gr/
greek-speaking-children-corpus/

Shttps://inventory.clarin.gr/corpus/1075


relevant and representative of the linguistic input
of children. Thus, we collect the CGL Modern
Greek Texts corpus 7°, which comprises around
2 million words from textbooks published by the
Greek Ministry of Education taught through grades
7-12 (ages 13-18) in the public school system. We
also include the corpus of Pedagogical Greek L2
textbooks *’, addressed to indigenous populations
or minorities learning Greek as a second language,
aimed at proficiency levels Al to C2 and ages 6-
18+. Even though this resource is designed for
non-native learners, we believe the material to be
sufficiently close in nature to the learning resources
for native Greek speakers. Finally, we include arti-
cles from Children’s Wikis.

Books, Wikis, News. Numerous websites host
open access children e-books and children stories
for the Greek language. We identified openbook.
gr?8 and free-ebooks.gr’ as the largest such
sites, and manually scraped them, selecting e-books
from the categories of children, young-adult,
and preschool-education. The data consists
of children books in the Public Domain, as well
as open access books released with permissive li-
censes. We also include a collection of children
stories scraped from paidika-paramythia. gr aul,
The site enables any author to make a submission
in collaboration with the moderators, and includes
stories from tradition and mythology, as well as
original entries. Lastly, we include sort stories pro-
vided in the GlotStoryBooks corpus.

Transcription. We collect publicly available data
corresponding to child-produced and child-directed
speech. Child Speech *! contains transcriptions of
children’s speech with a focus on narration; as the
result of interviews conducted by university stu-
dents with children related to them either by friend-
ship or kinship. Our second addition is the Greek
Student Chat Dataset *? consists of chat among stu-
dents (grades 4-18) in online collaborative learning
environments (wikis). Finally, we also include the

http: //hdl. handle. net/11500/
KEG-@000-0000-24FD-B
7http://hdl. handle. net/11500/
ATHENA- 0000- 0000-2631-E
8https://www.openbook.gr/literature
https: //free-ebooks.gr/tag/16?
https: //www. paidika-paramythia.gr/16
"http: //hdl.handle.net/11500/
CLARIN-EL-000-0000-610D-5
*http://hdl.handle.net/11500/
IONION-000-0000-5E14-1

Greek portion of CHILDES noting that speech is
transcribed in the Latin script. In future efforts we
plan on either removing this data or transliterating
it to the Greek script.

Everyday conversations between adults are a nat-
ural stimulus for children during language develop-
ment. We include in our data a corpus of written
transcripts of everyday conversations between stu-
dents of the Department of Linguistics ** that took
place between 2001 and 2006. The data is further
supplemented by the Babiniotis archive **, consist-
ing of the same data variety recorded in 2020. The
speech is authentic and idiomatic with speakers
labeled, resulting in a high quality spoken Greek
corpus.

Preprocessing. For the education datasets in
our corpus, standard pre-processing was applied.
Notably, the Primary School Books corpus re-
quired considerable cleaning and normalization
efforts, containing web-scraping artifacts such as
javascript code. Regarding e-books, processing
the text proved challenging, and required a sub-
stantial amount of manual labor. Initially licens-
ing information was extracted, and the corpus was
filtered to include only permissive licenses (e.g.,
cc-by-nc). For openbook. gr, license information
is provided as metadata for each entry, while for
free-ebooks.gr we manually annotate each book
with its license as stated in the text. The stories in
paidika-paramythia.gr are released as Public
Domain. The text is first extracted from e-books
using PyMuPDF”», and is then filtered to remove
license statements, author biographies, and other
information deemed irrelevant. Further document-
specific normalization follows, fixing text extrac-
tion errors, removing unwanted unicode characters,
and ensuring the validity of the book content. As
part of this process, documents deemed unsuitable
for children are excluded. As for the transcription
data, standard pre-processing was applied. Mor-
phological and other linguistic annotations where
removed from speech data. We note that to ensure
anonymity, placeholders exist in conversational text
that substitute real information (e.g., names, loca-
tions).

3http://hdl.handle.net/11500/
UOA-0000-0000-5D9C-9

*http://hdl.handle.net/11500/
UOA-0000-0000-2515-F

Shttps://github.com/pymupdf /PyMuPDF


C.9 = Italian

Dataset Description. Interest in developmentally
plausible NLP models for Italian has recently
increased, as shown by new training setups and
evaluation resources targeting child-directed-
language (Fusco et al., 2024; Suozzi et al., 2025;
Capone et al., 2024). In assembling our corpus
beyond the multilingual resources described in
the body of the paper, we enrich it with a set of
Italian-specific materials.

Books, Wikis, News. We were able to include
approximately thirty books from the independent
Italian publishing house Biancoenero Edizioni *°,
which kindly shared them with us upon request.
The publisher has long been committed to the
Alta Leggibilita (“High Readability”) project,
aimed at making books accessible to all children,
including those with reading difficulties. All books
are written by Italian authors and are targeted at
readers between the ages of 4 and 10. The themes
span a range of topics including environment and
ecology, bullying, mystery, diversity and inclusion,
growing up and intergenerational relationships, and
adventure, according to the categories listed in the
publisher’s updated catalog. In addition to these
recently published works, we also incorporate
books from the Logos Group library *’. This
collection comprises classic children’s stories and
fairy tales authored by both Italian and foreign
writers whose works are translated into Italian.
The estimated target reading age for these texts
ranges from approximately 6 to 14 years; however,
some of these stories may be orally presented to
younger children. Furthermore, we include a series
of fairy tales (all from copyright expired sources)
curated by the researchers in this study (Fusco
et al., 2024). The book section concludes with
a manually curated selection of approximately
50 titles from the Project Gutenberg catalog.
These works are either explicitly included in the
national curriculum for lower and upper secondary
education, or authored by canonical figures whose
writings are frequently excerpted in educational
contexts and whose titles are broadly recognized
within the Italian school system. These include
both Italian and non-Italian authors. Although
the language used in these works is occasionally
archaic and stylistically distant from contemporary

https: //www.biancoeneroedizioni.it/
https: //children. logoslibrary.eu/

Italian, as similarly observed in the case of German
(and other languages, where applicable), their
inclusion aligns with the upper boundary of the
"developmentally plausible" timeline. Neverthe-
less, these texts remain realistically encountered
by a substantial portion of young adults within
the Italian educational system. To complement
these literary sources, we also include the Italian
portion of the WikiBooks Wikijunior bookshelf.
This collection comprises a range of accessible
entries on diverse topics (e.g., the human body,
dinosaurs, the solar system), thereby extending
our coverage of child-oriented reading materials
beyond narrative texts.

Education. Our educational resources cover a
range of materials reflecting both formal and infor-
mal learning contexts. We begin with standardized
assessments, including the Italian portion of past
INVALSI tests in Italian and Math at both primary
and secondary levels** . INVALSI is the national
body responsible for evaluating student competen-
cies and the quality of the education system. In ad-
dition, we incorporate an archive of national high
school final examination prompts released by the
Italian Ministry of Education *? , covering the past
20 years. These standardized exams, taken by all
students aged 18-19 to obtain their diploma, vary
across school types but collectively represent the
curricular exposure of the vast majority of Italian
students and offer a representative snapshot of the
competencies expected of young adults within the
national system. Finally, we leverage a dataset pre-
viously curated by Suozzi et al. (2025) that includes
children’s songs from the Zecchino D’ Oro archive,
a long-standing and renowned Italian music festi-
val for children. In addition, we include around
60 YouTube video transcripts from the animated
cartoon Calimero 4°. Cartoons, while primarily de-
signed for entertainment, also foster and support
children’s language development. Our selection
prioritizes episodes with consistent and realistic
punctuation, filtering out automatically generated
transcripts containing grammatical errors or typos.

Lastly, we complement these resources with two
text simplification datasets. The first, from Brunato
et al. (2015), comprises Terence and Teacher:
Terence contains 32 short children’s stories with
expert-produced simplifications for readers with

https: //www. invalsi.it/invalsi/index.php
https: //www.mim. gov. it/
“https: //www. youtube. com/@calimeroitaliano2815


comprehension difficulties, while Teacher includes
18 pairs of simplified and original texts from a
variety of genres (e.g., literature, textbooks). The
second dataset, MultiLS, was developed for the
MLSP2024 shared task (Shardlow et al., 2024) and
focuses on lexical simplification.

Transcription — Child Directed Speech. We use
transcripts from psycholinguistic studies on child
language acquisition (Longobardi et al., 2015;
Whittle and Nuzzo, 2015; Spinelli et al., 2023),
which have already been employed as training data
in Suozzi et al. (2025). These materials originate
from in vivo conversations recorded during
experimental sessions and consist of utterances
produced by caregivers and directed to children.

Transcription — Child Available Speech. In ad-
dition to direct caregiver input, we also consider
speech that children are indirectly and routinely
exposed to in their environment by overhearing
adult—adult conversations. To capture this dimen-
sion, we incorporate an open-source dataset com-
prising 10.43 hours of transcribed conversational
speech on specific topics*! , as well as VolIP, a
dataset of telephone conversations (Alfano et al.,
2014) already used in Fusco et al. (2024) work.

C.10 Japanese

Dataset Description. In addition to multilingual re-
sources, our Japanese dataset includes educational
content from Wikibooks” and Wikijunior*’, as
well as children’s books from Aozora Bunko“.
Books, Wiki, News. For educational mate-
rials, we took data from Wikibooks. We used
the “Elementary School Learning” section, which
targets Japanese elementary school students, typ-
ically aged 6 to 12. The content covers ma-
jor school subjects, including the Japanese lan-
guage, social studies, mathematics, and science.
We excluded pages that were still under construc-
tion, as well as those consisting primarily of nu-
merical content(e.g., math drills). The resulting
Wikibooks corpus contains approximately 0.2M
words. We also used Wikijunior, which offers
educational content designed for Japanese children
aged approximately 8 to 11. As with Wikibooks,
we excluded pages that were under construction

“https: //magichub.com/datasets/

“https: //ja.wikibooks.org/wiki/
Bhttps://ja.wikibooks.org/wiki/Wikijunior
“https: //www.aozora.gr. jp/

or contained only numerical content. The final
Wikijunior corpus consists of 75 pages, total-
ing approximately 0.07M words from Wikijunior.
We complemented our data with texts from Aozora
Bunko, a Japanese digital library that provides ac-
cess to literary works in the public domain. We
used the aozorabunko-clean dataset*, a cleaned
version of the original collection, that includes only
books whose copyrights have expired. This dataset
contains storybooks, biographies, poetry, and other
literary genres, with the majority being storybooks.
It also contains Japanese translations of foreign
literature. From this dataset, we selected only chil-
dren’s books. The list of children’s book titles
was scraped from the category-wise list of titles on
Aozora Bunko*®. Books written in old character
forms were excluded. This subset comprises 1,111
titles and totals approximately 8.7M words.

C.11 Persian

Dataset Description. Our Persian dataset includes
several curated subcategories designed to support
both child-centered and educational language mod-
eling. The final collection contains about 98.5 mil-
lion words across 217,880 records and consists of
four parts: Children’s Books, Educational Docu-
ments, Child-Directed Speech, and Subtitles used
as supplementary padding.

Books, Wiki, News. To construct a sub-
set of educational documents, we started with
FineWeb2-HQ (Messmer et al., 2025), a high-
quality, multilingual dataset built on top of
FineWeb2 (Penedo et al., 2025), as the base for our
educational subset. To identify educational content
within the Persian subset, we fine-tuned an XLM-
R (Conneau et al., 2020) model using a regres-
sion task inspired by the FineWeb-edu (Lozhkov
et al., 2024) methodology. The training data for
this model were annotated using Qwen2.5-72B-
Instruct (Yang et al., 2025b), following a 5-point ad-
ditive rubric designed to assess the educational suit-
ability of a document for primary to grade school
learners. The documents were then scored between
O and 5, which were later normalized to the 0-1
range. We trained the XLM-R model to predict
these normalized scores. For our final dataset se-
lection, we applied the trained model to Persian
FineWeb2-HQ documents. We selected documents
that (1) were under 3,000 words in length (to avoid

https: //huggingface.co/datasets/
globis-university/aozorabunko-clean
“https: //yozora.main. jp/


structural drift across sections), (2) had a quality
score of at least 0.35 based on FineWeb2-HQ meta-
data, and (3) received a predicted educational score
of 0.9 or higher. This filtering ensures that the se-
lected documents meet at least the first four points
of the rubric, which means they are coherent, suit-
able for grade-school learners, and contain well-
structured educational material. Our subset of chil-
dren’s books includes child-friendly Persian texts
sourced from two main corpora: Ririro (Persian
section) “7 and GlotStoryBook. We scraped texts
from the Persian section of the Ririro story col-
lection. Although the content was mostly clean, we
noticed minor inconsistencies in orthography and
annotation. We applied light post-processing to fix
punctuation, normalize spelling, and standardize
diacritics, resulting in a clean and consistent cor-
pus. GlotStoryBook included several very short
entries, such as single-word or phrase-level records.
To ensure data quality and narrative coherence, we
filtered out all records with fewer than three words,
resulting in the removal of 123 entries from an orig-
inal total of 1,150. Notably, about one-third of the
GlotStoryBook dataset consists of “fa-diacritics”
texts, which are Persian sentences written with full
diacritics. These fully vocalized texts are typically
used in early literacy education in Persian-speaking
contexts, particularly during the first stages of pri-
mary school. They are the first form of written Per-
sian encountered by children as they begin learning
to read and write, offering a bridge toward later
reading of undiacritized Persian. Their inclusion
enriches the dataset with pedagogically relevant
material closely aligned with actual educational
practice in early schooling.

For child-directed speech, we utilized Persian
transcripts from the CHILDES project. Notably, al-
though the spoken language is Persian, the tran-
scripts are written in Latin script using phonetic
representations, a transcription style known as Ro-
manized Persian. Apart from standard normaliza-
tion and deduplication, no further preprocessing
was applied to preserve the phonetic and linguistic
characteristics of child-directed speech.

To meet our target budget of approximately 100
million words, we supplemented the dataset with
Persian subtitle data. Subtitles were selected for
their syntactic diversity and colloquial tone, help-
ing to enrich the stylistic and lexical range of the
dataset. The subtitles act as neutral padding rather

“https://ririro.com/fa/

than targeted educational or child-focused content.

C.12 Polish

Dataset Description In addition to the multilin-
gual resources, we add three further data sources to
the Polish data. Besides these resources, we were
unable to find further child-available data. Unfor-
tunately, no spoken Polish corpora are freely avail-
able. Although some larger Polish corpora exist,
projects like the National Corpus of Polish only of-
fer rudimentary search functions and no accessible
data for our purposes.

Books, Wiki, News. The Wolne Lektury
archive contains a large number of Polish ebooks.
We systematically scraped all virtual bookshelves
that contain child-directed/child-available literature
and included all ebooks that could be plausibly en-
countered by children currently learning Polish. In
order to do so, we consulted native speakers of
Polish and articles on classical Polish children’s
literature. Furthermore, we opt to include books
that are translations of global children’s classics
(e.g. Tom Sawyer or Alice’s Adventures in Won-
derland), as they could plausibly encountered by
children learning Polish. Besides these ebooks
we also include all educational materials from the
WikiJunior bookshelf of Polish Wikibooks, and
educational materials from the Polish Wikikids
website, which — despite its name — is not a classi-
cal wiki, but rather a general educational website.

C.13 Portuguese

Dataset Description. We present a first iteration of
a developmentally plausible dataset for Portuguese.
During our initial collection efforts a variety of po-
tentially relevant resources were found, but due to
time constraints have not been included in this itera-
tion of the data. Two such resources are PPORTAL,
the Public Domain Portuguese-language Literature
Dataset (Silva et al., 2021), and a collection of
natural speech data from CORAA*®.

Books, News, Wiki. Our BabyLM dataset for the
Portuguese language consists primarily of sort sto-
ries from GlotStoryBooks and Ririro, and articles
from a children’s wiki.

Transcript. We include child-directed speech
from the Portuguese portion of CHILDES, We

‘https://sites. google.com/view/tarsila-c4ai/
coraa-versions


supplement this data with conversational spoken
Brazilian Portuguese speech *?.

C.14. Romanian

Dataset Description. The Romanian BabyLM cor-
pus consists of texts from CHILDES . We addition-
ally include data from two pre-existing resources.
Chitez et al. (2024) introduce the LEMI Roma-
nian children’s literature corpus, which consists
of 33,154 words. We also include data the chil-
dren’s portion of the Romanian Language Corpus
collected by Midrigan Ciochina et al. (2020). *°
The corpus consists of children’s literature in its
poetry and fairy tales section.

C.15 South African languages: Afrikaans,
isiXhosa, isiZulu, Sesotho, Sepedi

Dataset Description. The number of large-scale
datasets and benchmarks for African languages has
grown in recent years, but the African continent
remains under-resourced and under-represented
in NLP research (Ojo et al., 2025). Collecting
BabyLM datasets for African languages presents
several challenges. Besides lacking child-directed
speech corpora, most African languages lack even
domain-general datasets of sufficient quality and
scale to approximate developmentally plausible
training.

As a first attempt to create BabyLM datasets for
African languages, we focus specifically on the lin-
guistically diverse context of South Africa. South
Africa has 12 official languages, some of which
are commonly included in massively multilingual
web-scraped datasets. Importantly, all languages
have some high-quality, manually curated datasets
that are publicly available. This is thanks to gov-
ernment initiatives, such as the South African
Centre for Digital Language Resources
(SADiLaR)>!, which prioritise the development of
language resources in all official languages. Af-
ter surveying available datasets across languages,
we conclude that five languages are candidates for
BabyLM datasets with meaningful amount of data:
Afrikaans, isiXhosa, isiZulu, Sesotho (Southern
Sotho), and Sepedi (Northern Sotho).

Afrikaans is comparably more resourced and we
were able to collect a tier 2 corpus. For the other

“https: //magichub.com/datasets/

brazilian-portuguese-conversational-speech-corpus/

https: //lmidriganciochina. github. io/
romaniancorpus/
“https://repo.sadilar.org/

four languages, we were limited to tier 3 corpora.
The proportion of data that is truly developmentally
plausible varies between languages and, in some
cases, falls short in comparison to higher-resourced
languages. While limited in scale, our datasets
demonstrate the practical feasibility of BabyLM
research for low-resource languages. We hope our
work serves as a starting point for future research
on developmentally plausible language modelling
for African languages.

Books, Wiki, News. Only Afrikaans and
Sesotho are represented in CHILDES, but we obtain
child-directed and child-adult interaction corpora
for all five languages from the SA-CDI project.>?
We include children’s books for all five languages
from the GlotStoryBook dataset (Kargaran et al.,
2023), originally scraped from Nalibali>’, an
initiative promoting children’s literacy in South
Africa. For educational content, we include high
school exams (Sibeko and Zaanen, 2023) for lan-
guage subjects (home language and first additional
language) for all five languages and QED (Abdelali
et al., 2014) for Afrikaans, isiXhosa, and isiZulu.
For isiXhosa, we include the descriptive sentences
in T2X (Meyer and Buys, 2024), a data-to-text
dataset containing simplified isixXhosa sentences
describing (subject, relation, object) triples in a
knowledge base.

To match the target dataset sizes (tier 2
Afrikaans and tier 3 for isiXhosa, isiZulu, Sesotho,
and Sepedi), we include additional high-quality
data to supplement the developmentally plausi-
ble data as needed. For Afrikaans, we include
OpenSubtitles (Lison and Tiedemann, 2016). For
all five languages we include language-specific
Wikipedia corpora. This still leaves us short for
Sesotho and Sepedi. For Sepedi, we include
government news articles from Vukenzele (Las-
trucci et al., 2023). Finally, we use sentences
from parallel corpora for machine translation
to reach our target sizes for Sesotho and Se-
pedi. For Sepedi we include the highest qual-
ity Sepedi sentences in WMT22 (Adelani et al.,
2022), as measured by language identification
score. For Sesotho we include sentences from
the Autshumato English-Sesotho Parallel
Corpus (McKellar, 2022).

https: //sa-cdi.org/
https: //nalibali.org/


C.16 Indonesian and its local languages:
Javanese, Sundanese, Balinese, Buginese,
Makassarese, Minangkabau, Acehnese

Dataset Description. Recent years have seen a
significant increase in resources for Indonesian and
its local languages, mainly due to collective ef-
forts by NusaCrowd (Cahyawijaya et al., 2023a)
and SEACrowd (Lovenia et al., 2024). These ini-
tiatives have contributed a wide range of datasets,
including conversational corpora, written texts, and
multilingual collections. However, developmen-
tally plausible and child-related data are still lack-
ing. Below, we describe the data resources we
found.

Transcription. We can only find one dataset
available from the aforementioned collective ef-
forts: ASR-INDOCSC, which consists of 4.5 hours
of daily conversational speech from children in In-
donesia, along with multilingual resources.

Books, Wiki, News. The main sources for cog-
nitively and developmentally plausible data for
Indonesian and its local languages come mainly
from books obtained from a repository provided
by the Ministry of Education & Culture™*. These
are primarily educational books and storybooks for
children aged 2 to 12. Since these books are in
PDF format, we used PyPDF2 (Fenniak et al., 2022)
and Tesseract (Smith, 2007) to extract their con-
tent. For data preprocessing, we use Gemma3-27B
(Team et al., 2025) for content filtering in three
steps: filter out non-child-related books, clean and
reformat the extracted book content, and then re-
move non-child-related content. After cleaning,
GlotLID v3 (Kargaran et al., 2023) was used for
language detection and grouping, allowing data
collection for Javanese, Sundanese, Balinese, Bug-
inese, Makassarese, Minangkabau, and Acehnese.
Another major source is the Bobo children’s
magazine>>, which contains child-targeted articles
from January 2020 to May 2025, all of which are
exclusively in Indonesian. In addition to these,
we incorporated data from multilingual resources,
specifically GlotStoryBook (Kargaran et al., 2023)
and Ririro>, for Indonesian language data.

To pad the data and reach the required tiers,
OpenSubtitles (Lison and Tiedemann, 2016)
data were utilized for Indonesian to reach Tier
1. For local languages to reach Tier 3, we priori-

“https://repositori.kemdikbud. go. id
Shttps://bobo.grid.id
https://ririro.com

tized high-quality, manually curated datasets from
NusaxX (Winata et al., 2023), NusaWrites (Cahyaw-
yaya et al., 2023b), and NusaDialogue (Purwari-
anti et al., 2025), followed by Wikipedia and
MADLAD-400 (Kudugunta et al., 2023) data for ad-
ditional padding as needed.

C.17 Spanish

Dataset Description. As the predominant lan-
guage in 21 countries, Spanish is a pluricentric
language and exhibits rich diatopic variations. Far
from being a homogeneous language, it encom-
passes a wide range of national and regional va-
rieties, marked by distinct morphosyntactic and
lexical features (Mayor-Rocher et al., 2025). As
such, the term “Spanish” does not denote a sin-
gle standardized form, but rather a set of linguistic
norms shaped by diverse cultural and geographic
contexts. The resources compiled in this dataset
reflect this inherent diversity: our search for de-
velopmentally plausible materials was deliberately
international, resulting in the inclusion of content
from at least eight different countries.

Books, Wiki, News. A substantial portion of
children’s books is sourced from the Elejandria
collection °’, which features 19 translated bed-
time stories from classical authors like Andersen,
Grimm, and Perrault; 20 translated young adult
classics, including "Gulliver’s Travels" and "Alice
in Wonderland"; and 35 original Spanish-language
books by authors from Spain, Uruguay, Mexico,
Nicaragua, Cuba, and Argentina, categorized un-
der Discovering Spain and Hispanic American Lit-
erature. Additional books were sourced from the
Logos Group library, which granted us access upon
request. This collection includes Spanish trans-
lations of well-known children’s literature, such
as The Adventures of Tom Sawyer, as well as
a smaller number of original Spanish texts. It
also features songs, traditional Christmas carols,
legends, and famous fables like The Ant and the
Grasshopper. Our dataset also includes a range
of children’s stories, fairy tales, poems, traditional
literature, and songs accessed via the Ministries
of Education of Argentina ** and Colombia >’, the
provincial government of Salta in Argentina °°, and

https: //www.elejandria.com/coleccion/

https: //www. argentina. gob. ar/educacion/
historiasxleer

https: //v1.maguared.gov.co/
serie-leer-es-mi-cuento-todos-los-titulos/

https: //planeamiento. edusalta.gov.ar/


the educational website educ.arportal °!.

To capture spoken Spanish that is accessible to
children, we incorporated two complementary re-
sources. First, we included an open-source dataset
from MagicHub®, comprising 5.56 hours of tran-
scribed conversational speech in Peninsular Span-
ish. This dataset features 17 dialogues recorded
between four pairs of speakers, covering a variety
of everyday topics. Additionally, we incorporated
the SpinTX video archive °, which offers cu-
rated video clips and transcripts from the Spanish
in Texas Corpus. This collection of interviews with
bilingual Spanish speakers residing in Texas covers
a wide range of topics relevant to daily life, in-
cluding family, friendship, food, culture, parenting,
education, and school.

C.18 Ukrainian

Dataset Description. The Ukrainian dataset is a
collection of different resources. To the best of our
knowledge, there is no CHILDES-like corpus for
the Ukrainian language; therefore, it has been sub-
stituted with a set of monolingual and multilingual
data.

Books, Wiki, News. For the majority of de-
velopmentally plausible data, we use the GRAC
corpus (Shvedova and Lukashevskyi, 2024). This
corpus consists of copyright-free texts concerning
Ukraine till 1954. The dataset is heavily filtered,
reducing from 100M tokens to 29M, to extract the
most developmentally plausible data. First, lan-
guage filtering restricts content to Ukrainian, ex-
cluding all other languages, including English, Ger-
man, Russian, and others. Style-based filtering
removes journalistic content, personal memoirs,
religious materials, public speeches, official doc-
uments, and texts with unknown style classifica-
tions. Additionally, non-fiction works published
before 1900 are excluded to maintain temporal
relevance. The remaining texts are categorized
into educational content (academic materials and
popular science works), child-appropriate books
(fiction, folklore, and poetry), and other materials
(internet communication and private oral content).
Additionally, we utilize the Ukrainian portion of
Wikisource (Wikimedia Foundation, 2025) as a
source of fairy tales and fiction books, thereby ex-
panding the dataset by an additional 1 million to-
kens.

®' https://www.educ.at/

“https: //magichub.com/datasets/
8https://spintx.org/

To expand the developmentally plausible
data, we incorporate the previously mentioned
GlotStorybook and Ririro datasets. Wikipedia
serves as a significant source of encyclopedic con-
tent, contributing approximately 29.1M tokens.
The FineWeb-C corpus provides an additional
174K tokens of contemporary language use. Fi-
nally, OpenSubtitles contributes nearly 29.5M to-
kens of conversational Ukrainian text from movie
and television subtitles, to which a child would
most likely be exposed.

C.19 Other Languages

For the rest of the languages in the BabyBabelLM
dataset, no language-specific resources were col-
lected. Instead, these languages are populated by
multilingual data resources, namely: CHILDES,
GlotStoryBooks, Ririro, and Child Wikis. These
languages are: Basque, Croatian, Czech, Danish,
Estonian, Hebrew, Hungarian, Icelandic, Korean,
Norwegian, Romanian, Russian, Serbian, Turkish,
Swedish, and Welsh for a total of 16 out of 45 lan-
guages. We welcome contributions for these, and
other languages, details presented in the project
website.

D GPT-BERT

We trained monolingual GPT-BERT (Charpentier
and Samuel, 2024) models on all our languages in
Tier 1 and 2. Models were trained for 500 steps
on Tier 1 languages (10 epochs) and for 250 steps
on Tier 2 languages (25 epochs). All models had
a vocab size of 16,384, 12 layers, 768 hidden size,
and 2560 intermediate size.

We report the results in 4, plotting GPT-BERT
against the GPT-2 models on SIB-200 and Multi-
BLiMP. As can be seen, our GPT-2 models con-
sistently outperform GPT-BERT. We leave a more
extensive exploration into finding a more optimal
GPT-BERT configuration open for future work.


Language ISO Tier Byte Actual Data Transcription Education Books, Wiki, Subtitles Padding Total

639-3 Premium Size (MB) Tokens Tokens News Tokens Tokens Tokens Tokens
Chinese zho Tier 1 0.936 518.85 108,368,032 13,037,234 16,429,780 0 0 137,835,046
French fra Tier 1 1.174 634.88 6,234,743 0 13,987,611 5,750,144 100,608,287 126,580,785
Bulgarian bul Tier 1 1.812 981.07 0 0 24,799,312 0 90,563,381 115,362,693
Indonesian ind Tier 1 1.179 638.87 17,824 62,188 17,225,662 0 96,044,750 113,350,424
Dutch nid Tier 1 1.052 569.49 3,304,756 19,146,045 17,428,015 971,334 69,035,414 109,885,564
German deu Tier 1 1.054 568.98 8,518,785 257,233 7,655,975 0 91,478,846 107,910,839
English eng Tier 1 1.0 539.18 36,814,704 0 41,357,314 0 20,706,303 98,878,321
Persian fas Tier 1 1.597 867.3 0 94,320,928 67,165 0 4,117,988 98,506,081
Ukrainian ukr Tier 1 1.751 945.57 0 12,003,085 16,786,100 0 58,804,062 87,593,247
Japanese jpn Tier 2 1,322 71.78 0 291,053 9,712,521 0 6,520,750 16,524,324
Serbian srp Tier 2 0.826 77.21 1,489,908 0 29,896 0 13,707,246 15,227,050
Cantonese yue Tier 2 0.862 43.34 2,982,684 0 191,861 0 11,870,650 15,045,195
Portuguese por Tier 2 1.098 59.5 956,441 0 382,562 0 10,348,599 11,687,602
Swedish swe Tier 2 1.021 55.21 750,286 0 526,330 0 9,810,043 11,086,659
Greek ell Tier 2 1.967 106.81 1,945,604 2,577,703 1,402,782 0 4,956,467 10,882,556
Polish pol Tier 2 1.077 58.29 1,257,155 0 48,831 0 8,906,729 10,212,715
Estonian est Tier 2 0.968 52.37 1,026,491 0 0 0 8,814,184 9,840,675
Spanish spa Tier 2 1.084 58.75 2,978,384 0 5,385,855 0 1,344,853 9,709,092
Italian ita Tier 2 1.067 57.96 1,189,631 990,522 6,797,154 0 490,380 9,467,687
Afrikaans afr Tier 2 1.037 56.28 272,434 116,380 153,914 464,009 8,300,684 9,307,421
Welsh cym Tier 2 1.027 55.39 1,109,683 0 0 0 7,602,459 8,712,142
Basque eus Tier 2 1.06 57.06 201,402 0 1,716,026 0 6,271,869 8,189,297
Korean kor Tier 3 1.293 7.07 2,163,779 0 15,458 0 273,838 2,453,075
Sesotho sot Tier 3 1.166 6.31 420,926 106,253 141,012 0 557,003 1,225,194
Sepedi nso Tier 3 1.116 6.06 0 92,589 122,083 0 871,565 1,086,237
Buginese bug Tier 3 1.228 6.67 ) 0 41,174 0 961,405 1,002,579
Romanian ron Tier 3 1.115 6.1 294,696 0 284,101 0 393,308 972,105
Acehnese ace Tier 3 1.242 6.74 0 0 242,613 0 725,581 968,194
Javanese jav Tier 3 1.147 6.23 0 0 307,282 0 645,365 952,647
Balinese ban Tier 3 1.27 6.87 ) 0 63,826 0 874,899 938,725
Icelandic isl Tier 3 1.154 6.27 452,099 0 0 0 470,031 922,130
Croatian hrv Tier 3 0.99 5.39 469,078 0 0 0 445,976 915,054
Makassarese mak Tier 3 1.251 6.79 0 0 34,080 0 873,230 907,310
Nowegian nor Tier 3 1.125 6.11 404,670 0 290 0 496,473 901,433
Sundanese sun Tier 3 1.097 5.96 0 177 17,264 0 874,647 892,088
Danish dan Tier 3 1.021 5.53 372,836 0 8,848 0 457,152 838,836
Hebrew heb Tier 3 1.355 T3T 309,854 0 0 0 509,056 818,910
Minangkabau min Tier 3 0.95 5.16 0 0 122,536 0 663,669 786,205
Czech ces Tier 3 1.036 5.64 377,313 0 0 0 385,263 762,576
isiZulu zul Tier 3 1.164 6.31 62,772 56,641 96,383 5,402 532,402 753,600
Russian rus Tier 3 1.823 10.0 0 0 92,462 0 655,911 748,373
Hungarian hun Tier 3 1.02 5:55 391,041 0 6,234 0 322,636 719,911
isixhosa xho Tier 3 1.199 6.52 74,950 65,208 98,144 29,099 412,004 679,405
Turkish tur Tier 3 1.044 52 248,397 0 11,193 0 405,478 665,068

Table 3: Detailed data statistics for all languages in the BabyBabelLM dataset. Tiers indicate target size equivalence
to English tokens: Tier 1 (100M), Tier 2 (10M), Tier 3 (1M).


Field Type Values Description
text string Una volta, c’erano... The content of the document.
category string Transcription
* child-directed-speech Speech directed to children and speech produced by children.
¢ child-available-speech Speech children are exposed to without being the target recipients (e.g., adult conversations).
Education
¢ educational School textbooks, exams, and other educational material designed for children.
Wiki, News, Books
* child-books Books and stories created for children.
* child-wiki Children wiki articles.
* child-news News directed to children.
Subtitles
* subtitles Subtitles for child-appropriate material (e.g., children TV shows).
*qed Subtitles from the QED dataset.
Padding
* padding-wikipedia Wikipedia articles.
* padding-[placehorder ] Other forms of padding, used primarily for low-resource languages.
data-source string CHILDES, www. ririro.com, ... The source of the document: dataset name, url, or item identifier.
script string Latn, Grek, Cyr, ... The script of the text: a validated ISO-15924 code string.
language string por, ell, bul, ... The language of the text: a validated ISO-639-3 code string.
age-estimate string 3-6, children, adults, n/a,... For text data: estimated age of target audience. For speech data: estimated age of speakers.
license string cc-by-nc, public domain, ... The license under which the document is released.
misc string CPintole ©. sty «soy Optionally included supplementary information as a valid JSON string.
num-tokens integer 15364 The number of white-separated (or tokenizer-based) tokens present in the document text.
doc-id string 7a2b3a1d9... Unique document ID computed as a sha256 string of it’s content, used for de-duplication.

Table 4: Document-level schema for the BabyBabelLM datasets. For each document field, we define its type,
include sample values, and give a description of its use and contents. The values of the category field are grouped
based on which high-level content category they are part of (defined in §3.2.1).


» @ @
Se 8 y 0 ov RS Cy
mS oy - » » * < eS - Ss
* - » eX > . * © * s S$ sv S&S s
Language = s BS) = Y Dy ev SS - + * Ss >
Random 50.0 50.0 25.0 25.0 33.3 33.3 250 25.0 250 33.3 500 50.0 500 50.0 25.0 25.0
Standard Arabic - - - - - - - - - - - - - - - -
Bulgarian 83.5 - 375 33.7 (STAN 506 = B28 29.7 37.1 - 528 - $1.0 308 25.0
— Chinese — BBS S25 5339 54.6 WELT PNAS 8SN5)) 37.1 35.5. M638 E33 645 560 26.0 25.0
~ Dutch 82.8 - 334 404 430 501 376 33.2 30.0 - - 540 53.2 516 240 25.0
= English 9829) 81.0 - 665 581 55.9 50.0 57.3 40.0 53.4 73.0 67.0 - 556 224 27.9
f= - French 96.7 846 422 46.7 610 567 389 414 334 44.7 - 58.1 530 542 260 25.5
German 93.7 868 360 51.9 332 540 38.7 374 32.3 44.0 - 563 549 534 269 25.5
Indonesian - - 449 463 360 53.1 388 388 32.3 — S78" 337 — $5.8 233 25.0
Persian 81.1 - 336 279 499 460 326 314 29.3 - - 548 520 52.8 243 25.0
Ukrainian 85.1 - 475 334 32.7 450 34.7 344 30.3 - - 509 528 52.5 276 25.0
Afrikaans - - - 341 37.7 43.8 — 28.3 28.3 - - 512 - 514 218 25.0
Basque 89.0 41.6 30.0 - - 33.9 - 254 - 335 496 49.6 - - - 25.0
Estonian 61.5 — 30.8 23.8 38.1 35.7 - 265 274 - 474 49.3 - 493 226 25.0
Greek 025 —- 331 307 359 427 3235 292 292 363 - 519 506 524 284 25.0
aq Hebrew 73.0 644 42.7 283 455 40.3 309 306 28.6 - - $15 505 49.2 31.5 25.5
wy Italian 88.4 - 458 464 386 536 40.2 39.5 33.2 —- 568 57.0 - 524 294 25.5
m Japanese - 746 447 341 580 47.1 381 39.1 314 - - 56.2 528 51.2 272 26.0
f —~ Polish 81.5 —- 38.1 310 39.7 486 363 34.7 29.8 - - 53.8 —- $35 276 25.0
Portuguese 93.4 - 43.2 41.5 386 552 36.7 41.2 33.9 - -— 587 - ‘$3.1 285 25.5
Serbian - - 293 314 415 478 324 285 29.6 - - 53.5 = $2.3 29.2 25.0
Spanish 93.2 - 422 47.7 618 48.7 376 422 345 414 596 58.0 543 53.9 28.7 25.5
Swedish - - - 42.9 536 49.3 360 32.1 303 - -— 52.2 - 50.3 25.7 25.5
Welsh 70.8 - - - - - - - - - - - - - - -
Yue Chinese - - - - - - - - - - - - - - — 26.0
Achinese - - - - - - - - - - - - - - -— 25.0
Balinese - - - - - - - - - - - - - - — 25.0
Buginese - - - - - - - - - - - - - - — 25.0
Croatian - - 33.3 32.1 35.9 469 — 30.6 29.2 - - 516 -— 52.3 28.2 25.0
Czech 71.8 - — 30.1 388 48.9 36.0 33.5 29.7 - - 53.1 - 50.8 24.7 25.0
Danish 92.0 - - 40.2 368 464 — 32.0 30.0 - - 53.8 - 524 279 25.5
Hungarian 84.5 - 325 266 53.1 40.7 -— 293 284 - - 525 S515 51.1 274 25.0
Icelandic 63.2 - -— 21.7 35.8 35.4 -— 26.0 26.7 - - 46.5 - 490 21.9 25.0
cn __ Javanese - - - 368 37.0 36.3 -— 284 27.9 - - 49.9 - $0.6 9191) 25.0
w~ Korean - - 406 323 53.1 474 35.1 380 30.2 - - 543 53.2 51.1 260 304
1 Makasar - - = - - = - - = _ - — _ - = _
f= - Minangkabau - - = - - - - - = - - = - - -— 25.0
Norwegian - - - 40.7 385 46.3 - 318 29.7 - - 53.2 - 50.9 240 25.0
Sepedi - - = - - 29.6 -— 26.1 - - - - - - -— 25.0
Romanian 85.0 - - 354 560 51.7 37.3 33.2 30.5 - - 534 — $3.2 255 25.0
Russian 89.6 856 444 359 492 534 379 418 33.5 43.7 — | 894 559 S37 274 25.0
Sesotho - - - - - 29.1 27.6 - — 33.3 - - - - -— 25.0
Sundanese - - - - - 31.6 - - - - - - - - — 25.0
Turkish 792 754 385 32.7 490 41.8 341 363 294 385 562 523 513 486 26.9 25.0
isiXhosa - - - - -— 28.7 26.2 - — 33.3 - - - - -— 25.0
isiZulu - - - - - 32.0 25.0 263 — 33.3 - - - - - 25.0

Table 5: Performance of Qwen3-0.6B (Yang et al., 2025a). All scores denote average 0-shot accuracy. Columns are
sorted by the column order of Table 1.


e
es se 2 ° Fo mS eo RS s @ s RS

SS * a © s ¥ »s > . s - ~~ * a » se »

Language = = s * Y Ss = * Ss Do ¥ S = s
Random 50.0 50.0 10.0 500 25.0 500 250 333 33.3 50.0 143 25.0 25.0 25.0 50.0 25.0
—> Bulgarian 90.8 -— 247 -— 25.3 - 268 345 32.0 520 196 28.3 — 28.0 49.5 25.5
= Chinese — §7029 345 $12. 369 55.1 268 33.3 35.8 49.2. 9113) 223 230 239 48.7 22.1
S Dutch 90.5 - 294 - 303 524 265 - 346 50.0 93 27.0 245 324 491 224
— English 620, 659 318 580 288 - 265 363 318 514 240 23.0 23.2 - 495 224
~ French O41 69.7 22.7 - 275 506 264 361 35.7 513 S3y 273 239 22.7 476 204
~~ German Secu 771 26.3 - 271 526 25.9 349 32.3 518 118 247 246 163 488 23.8
4 Indonesian - - 256 53.6 30.4 - 273 —- 31.7 53.1 108 254 261 229 505 243
zy Persian als -— 29.6 -— 29.7 536 26.4 — 35.3 50.7 98 260 238 230 522 26.9
Ukrainian 88.6 -— 248 —- 284 506 264 - 316 503 8.3 228 234 306 47.6 247
Afrikaans - — 28.5 — 28.3 - 261 - 320 513 108 22.1 - - 495 22.6
Arabic 75.9 - 172 - 2.7 $29 258 330 324 474 191 22.9 23.1 22.1 468 223
Basque 94.5 65.3 - 498 28.5 - -— 33.6 - - 103 26.0 - 254 506 28.0
_~_ Estonian 81.5 - 210 53.0 248 - 25.5 - 35.9 50.7 12.2 22.0 -— 214 458 22.6
S Greek 892 — 23.2 - 269 503 264 356 31.7 495 196 22.8 23.1 20.9 494 25.7
© Hebrew 10,2 595 23.0 - 298 516 26.1 - 325 50.2 12.2 229 23.1 248 496 23.1
cc Italian TS —- 263 520 264 - 26.5 - 31.7 S501 11.3 246 23.3 20.7 50.2 25.2
a Japanese — (69 199 - 278 508 25.1 - 31.7 475 196 234 230 261 47.8 22.1
~ Polish 159 - 19.4 -— 26.1 - 25.5 - 32.0 490 12.2 219 266 182 49.5 21.8
m Portuguese 80.7 -— 217 - 254 - 26.3 — 31.7 4838 122 239 235 222 488 23.6
Ex Serbian - - 244 -— 25.5 - 25.6 - 324 49.5 899 229 23.1 202 485 23.5
Spanish 83.0 - 241 -— 280 513 264 355 33.7 491 186 249 244 23.7 47.8 23.0
Swedish - - 233 -— 26.2 - 25.9 -— 31.7 493 12.2 283 246 - 48.1 24.5
Welsh 91.4 - - - - - - - - - - - - - - -
Yue Chinese - - - - - - - - - - 19.6 - - - - -
Achinese - - - - - - - - - - 18.1 - - - - -
Balinese = ~ = al = = = ~ + ~ (235 = = ~ + al
Buginese - - - - - - = - - - 19.6 - - - - -
Croatian - - 178 -— 26.1 - 25.8 -— 31.7 476 12.2 224 - 254 456 21.1
Czech 59.0 - 13.1 -— 248 - 25.8 - 359 504 196 229 23.1 -— 486 20.2
Danish 82.0 - 172 — 24.6 -— 25.7 - 35.9 490 12.2 23.6 - - 489 21.8
Hungarian 68.9 - 10.2 - 243 499 25.6 -— 31.7 480 12.2 22.9 —- 304 485 18.9
S Icelandic 71.6 - 134 — 243 - 254 - 3L7 500 122 229 - - 45.7 22.6
2 Javanese - - I74 = 25.2 - 25.8 - 317 505 19.6 28.2 - - 506 241
\~ Korean - - 191 -— 255 51.3 25.0 —- 325 489 108 216 265 218 47.5 23.3
on Makasar - - - - - - - - - - 124 - - - - -
~ Minangkabau - - = = - = - - - - 19.6 = - - - =
2 Norwegian - - 214 -— 264 - 25.9 = 359 470 9122 22.9 - - 47.1 223
EF Sepedi - - - -— 25.9 - - - - - 108 241 - - - -
Romanian 74.1 - 154 — 25.3 - 25.5 —- 35.7 486 147 240 244 - 462 21.8
Russian 58.5 52.0 17.2 - 25.2 491 25.9 33.3 35.9 51.3 12.2 28.9 249 205 488 214
Sesotho - - - - - - — 33.3 - - 939 22.9 § 200 - - -
Sundanese - - - - - - - - - -— 19.6 27.2 - - - -
Turkish 6499 598 179 538 254 516 259 333 359 499 122 219 27.1 230 S01 247
isiXhosa - - - - - - — 33.3 = -— )4108) 22.9 9200 - = -
isiZulu - - - -— 29.7 - — 33.3 - —- 108 23.0 22.8 - - -

Table 6: Zero-shot performance across all tasks of the monolingual GPT-2 models trained on BabyBabelLM.
Columns are sorted by difference of the average task performance against random chance.


SIB-200

GPT2

0.4 0.6 0.8 1.0
GPT-BERT

MultiBLiMP

GPT2

0.4 0.6 0.8 1.0
GPT-BERT

Figure 4: GPT-2 and GPT-BERT accuracy scores on
SIB-200 and MultiBLiMP.
