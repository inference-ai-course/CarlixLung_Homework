2510.11444v1 [cs.CL] 13 Oct 2025

arXiv

GenCNER: A Generative Framework for Continual
Named Entity Recognition

1“ Yawen Yang
School of Software
Tsinghua University

Beijing, China

yyw 19 @mails.tsinghua.edu.cn

4" Aiwei Liu
School of Software
Tsinghua University
Beijing, China
liuaw20 @ mails.tsinghua.edu.cn

Abstract—Traditional named entity recognition (NER) aims to
identify text mentions into pre-defined entity types. Continual
Named Entity Recognition (CNER) is introduced since entity
categories are continuously increasing in various real-world
scenarios. However, existing continual learning (CL) methods
for NER face challenges of catastrophic forgetting and semantic
shift of non-entity type. In this paper, we propose GenCNER,
a simple but effective Generative framework for CNER to
mitigate the above drawbacks. Specifically, we skillfully convert
the CNER task into sustained entity triplet sequence generation
problem and utilize a powerful pre-trained seq2seq model to
solve it. Additionally, we design a type-specific confidence-based
pseudo labeling strategy along with knowledge distillation (KD)
to preserve learned knowledge and alleviate the impact of label
noise at the triplet level. Experimental results on two benchmark
datasets show that our framework outperforms previous state-
of-the-art methods in multiple CNER settings, and achieves the
smallest gap compared with non-CL results.

Index Terms—Named Entity Recognition, Continual Learning,
Generative Framework, Confidence-based Pseudo Labeling

I. INTRODUCTION

Named Entity Recognition (NER) is one fundamental task in
NLP fields due to its wide application in entity linking [1], re-
lation extraction [2] and knowledge graph [3]. Conventionally,
NER involves recognizing text mentions into fixed pre-defined
entity categories (e.g., “Person”, “Organization”) and the NER
model only experiences one-time complete training process.
While in real world, new entity types continue to emerge
over time, which requires the model to perform incremental
learning rather than training from scratch. As an example,
voice assistants like Siri and Xiao Ai are frequently expected
to extract new entity types for accurate understanding of user
intents [4], [5]. Thus the technique for Continual Named Entity
Recognition (CNER) has attracted growing attention to learn
new entity types incrementally without forgetting the old ones.

*Corresponding author.

2™¢ Fukun Ma
School of Software
Tsinghua University
Beijing, China
mfk22 @mails.tsinghua.edu.cn

3" Shiao Meng
School of Software
Tsinghua University
Beijing, China
msa21 @mails.tsinghua.edu.cn

5" Lijie Wen*
School of Software
Tsinghua University

Beijing, China

wenlj @tsinghua.edu.cn

Welcome to Focus Today hosted by Wang Shilin

< oO O 'B-ORG I-ORG!O O; O oO |
i | i
|

oO O0!o Oo !0
Conflicts!
(a) Sequence Labeling

O |B-PER I-PER|

Conflicts!

ORG Task
, s Welcome to Focus Today hosted by Wang Shilin
i Y J wee b - J eee $d
O-ORG « ORG O-ORG
O-PER -* O-PER oe PER
(b) Span-Based
PER Task

Welcome to Focus Today hosted by Wang Shilin
C Focus Today ORG <end>

Wang Shilin PER <end>

(c) Ours GenCNER

Fig. 1. Changes of current ground-truth labels for sequence labeling, span-
based and ours GenCNER method as CNER tasks increase. The red dashed
box indicates conflicts between training targets, which leads to the semantic
shift problem of the non-entity.

Some efforts have been devoted to solve CNER tasks
effectively. Existing works could be mainly divided into two
strategies: sequence labeling and span-based models. The
sequence labeling methods [4], [6], [7] assign each token
one tag to indicate the entity boundary and type, and employ
knowledge distillation (KD) to maintain old knowledge with
entity type increasing. Nevertheless, such mechanism often
encounters the semantic shift of non-entity type [5], [8]. In
conventional NER labeling paradigm, tokens marked as non-
entity do not belong to any entity type. While in CNER
setting, the non-entity mark only indicates the corresponding
tokens do not belong to current entity type(s). Consequently,
the non-entity type will inevitably encompass the context
token, previously learned entity types and future ones not yet
encountered. As illustrated in Fig. 1, besides true non-entity
tokens, the non-entity mark “O” also covers future entity type
“PER” in the current “ORG” task. The problem of semantic


shift leads to inconsistent training objectives and exacerbates
catastrophic forgetting among CL steps.

The span-based methods [9], [10] formulate CNER as a
continuous binary classification task of the candidate entity
spans and leverage knowledge distillation (KD) to retain
memory. By changing from token-level labeling to span-level
binary classification, the semantic shift of non-entity type
could be avoided. As depicted in Fig. 1, the non-entity mark
regards entity span as non-(certain)-entity (“O-ORG”), which
has no conflict with future entity type (“PER”). However, the
basic framework proposed by Zhang and Chen [9] ignores
label noise brought by previous teacher model. To address
catastrophic forgetting and label noise problems, Chen and
He [10] introduces Reinforcement Learning to span-based
Knowledge Distillation for further improvement, but increases
model complexity and computation costs.

The success of generative pre-trained language models
(BART [11], T5 [12], etc.) has recently aroused interest in
leveraging generative methods to solve information extraction
tasks. Inspired by this, we propose GenCNER, a Generative
framework with confidence-based pseudo labeling and knowl-
edge distillation (KD) to reduce catastrophic forgetting and
label noise. To be specific, we formulate continual NER
task as sustained entity triplet label generation problem and
employ the pre-trained seq2seq model BART with pointer
network to generate target triplet sequence. In order to re-
tain previously learned entity types and mitigate label noise,
we first develop a confidence-based pseudo labeling strategy
which removes pseudo entity triplets (predicted by teacher
model) with lower confidence than type-specific thresholds,
then empirically adopt knowledge distillation (KD) to transfer
old knowledge to student model more accurately.

Compared with sequence labeling methods for CNER, our
generative framework GenCNER well avoids the problem of
semantic shift since it has no need of non-entity marks in the
generative background. As shown in Fig. 1, the entity triplet
is defined as “(start token, end token, entity type)” and the
target sequence will continuously append triplets of new entity
types as tasks increase. We can observe that the generative
method updates learning targets for CNER task in a more
natural and reasonable manner. Furthermore, GenCNER even
supports both nested and discontinuous entity structures while
other methods cannot or struggle to do so. Experimental results
on OntoNotes and Few-NERD show that GenCNER achieves
the highest Fl score at each CL step as well as the smallest
performance gap to non-CL settings. The main contributions
of this work can be summarized as follows:

e We propose an effective generative framework to tackle
CNER task, which innovatively transforms continual
named entity recognition into consecutive entity triplet
generation process. To the best of our knowledge, we
are the first to introduce the generative mechanism to
explorations of CNER tasks.

e We develop a confidence-based pseudo labeling strat-
egy with type-specific thresholds filtering to preserve
high-quality entity triplets generated by old model for

knowledge distillation (KD), weakening the influence of
catastrophic forgetting and label noise.

e We conduct adequate experiments on two public NER
datasets in class incremental settings. Experimental re-
sults show that our proposed method outperforms strong
baselines consistently on each dataset and achieves new
state-of-the-art in different CL settings.

II. RELATED Work
A. Named Entity Recognition

Named Entity Recognition (NER) aims to locate text men-
tions with specific meanings and classify them into prede-
fined entity categories [13]. Recent works for various NER
subtasks could be primarily divided into sequence labeling,
span-based, hypergraph-based and seq2seq methods [14], [15].
The sequence labeling methods [16], [17] annotate each to-
ken with one tag indicating the entity boundary and type.
Common tagging schemes include BIO and BIOES, where
“B” represents the start of an entity, “O” stands for the
context token not belonging to any entity. The span-based
methods [18], [19] consider NER as a classification task
of the candidate entity spans extracted from input sentence.
Hypergraph-based methods [20] construct hypergraphs based
on the entity structure and introduce graph neural network to
learn semantic features. Most recently, the seq2seq framework
which converts entity extraction into sequence generation has
been proposed to solve multi-type NER subtasks uniformly
[21], achieving surprising performance.

B. Continual Learning NER

Continual Learning NER solves continuous tasks where
training targets of new entity types emerge as a stream.
Existing works treat Continual NER as the class-incremental
problem [22] where the training data only contains labels of
current entity type(s). Early explorations like AddNER and
ExtendNER [6] employed the basic sequence labeling frame-
work to tag tokens and knowledge distillation to prevent model
from forgetting old entity types. To reduce the dependency of
type co-occurrence during KD, Xia et al. [4] proposed L&R,
which provided ExtendNER with synthetic samples of old
types for further distillation. Considering the semantic shift of
non-entity type, Zheng et al. [7] designed a causal framework
to retrieve the causality from both new entity types and Other-
Class, Zhang et al. [5] developed a confidence-based pseudo-
labeling for the non-entity type and Ma et al. [23] proposed to
learn discriminative representations for entity types and “O”
labels. On the other hand, SpanKL [9] and SKD-NER [10]
introduced span-based classification to CNER, which avoided
the problem of semantic shift and achieved satisfactory results.

C. Seq2seq Framework

The seq2seq model with encoder-decoder structure has been
successfully adopted in various NLP tasks. It was first pro-
posed by Cho et al. [24] in order to solve machine translation
tasks. Bahdanau et al. [25] applied the attention mechanism to
the decoder and obtained better translation performance. On


this basis, the Pointer Network [26] and CopyNet [27] were
proposed to get the token probability distributions of input
sentences. With the increase of pre-trained language models,
several attempts have been made to pre-train a seq2seq model,
including MASS [28], BART [11] and T5 [12]. In this paper,
we focus on BART model due to its simplicity and promising
performance in generative NLP tasks.

III. PRELIMINARY
A. Problem Formulation

We follow previous works [6] to consider CNER as the
class-incremental problem. We train the model on a sequence
of tasks T,,T,..., Ty, where each task T;,(1 < k < 1) has its
own training dataset D;, annotated only for new entity types
E,. Note that entity types involved in different tasks are non-
overlapping (ie., E; ME; = 0 when i ¥ j). Meanwhile,
sentences in each specific training dataset potentially also
contain other entity types in previous or future steps, which
are certainly not annotated in current task. At the first step, we
train model M, on D, from scratch to identify entity types
in £,. At the k-th (& > 1) incremental step, our goal is to
train a model M/;, based on the training set Dz and previously
learned model M;,_; to recognize entities of all types seen so
far, represented as U?_, Ej.

B. Learning Targets Construction

In order to apply the generative framework to handle CNER
task, we empirically represent each target entity as the triplet
containing start token, end token and entity type. Given an
input training sentence of n tokens X = [21,22,...,%nl,
the learning targets of different CNER tasks could be for-
mulated as follows: At the first step, we expect to identify
entities of types in /, and construct the target sequence
Yi = [81, €1,t1, $2, €2, ta, ..., 8g, €g, tg] to train the model Mj,
where g is the total number of entities, s;,e;(1 < i < g)
indicate the start and end token of the 7-th entity respectively
and t; € FE, represents the entity type. At the k-th (k > 1)
learning step with the previous model M;_, available, we first
adopt Mj;,_1 to predict pseudo triplet sequence Y,? including
all the previously learned entity types Ur EE, then connect
the ground truth of triplet sequence Y,’ only containing Ex
types at the end of Y, to form the final target sequence
Y;, = [Y?, Y,2] for model M;, training.

ITV. MeTHop

The architecture of our framework is illustrated in Fig. 2,
consisting of two necessary components: Entity Triplet Se-
quence Generation (ETSG) and Confidence-based Pseudo La-
beling (CBPL). In the first task of CNER, we train the model
M, on D, with CE loss to make ETSG generate entity triplets
of FE, types. In other incremental tasks, we first use previous
model to make a one-off prediction on training data, then prune
the pseudo triplet sequence by confidence-based threshold
filtering. We train the current model with KD loss and CE loss
together to make ETSG capable of generating entity triplets
of all seen types.

A. Entity Triplet Sequence Generation

As mentioned above, we need to predict entity triplet
sequence in each incremental task of CNER. Considering
previous works [21], [29] which effectively employ generative
framework to solve the unified or multimodal NER tasks,
we adopt the pre-trained seq2seq model BART with encoder-
decoder structure to generate entity triplet sequence. Addi-
tionally, we introduce the idea of pointer network to BART
decoder since the start and end tokens of each entity triplet
both come from the input sentence. The BART encoder deals
with the raw sentence X = [%, £2, ..., Zp] to get the contextual
sentence-level representation H® € R"*@ as:

H° = BartEncoder(X), (1)

where e represents the encoder output, n is the sentence length
and d is the hidden dimension.

The BART decoder aims to generate boundary token or
entity type index at each time step P, = P(y:|H*°,Yez).
However, the previous triplet sequence Y<, cannot be put
into the decoder module directly since it contains boundary
token as well as entity type index. To tackle this problem,
we continuously add new entity types as special tokens to the
BART Tokenizer so that the sentence tokens and entity cate-
gories always share the same vocabulary. Then we develop an
Index2Token mode to convert predicted indexes into practical
tokens at each generative time step:

. ati if ye<n

a [VE Ely if w>n,

where [U*_, £;] represents all the entity types learned so far
in the k-th incremental CNER task.

After converting indexes into tokens in this way, we can

put the encoder output and previous triplet sequence into

the decoder network and obtain the last hidden state, which
formulates as:

(2)

hé = BartDecoder(H’*; ¥4), (3)
where Ye, = [f1,{2,-.-,§:—1], representing the generated
index triplet sequence for time step f.

Then we apply the pointer mechanism to generate index
probability distribution P; as:

H° = MLP(H°*), (4)
[U*_,E,]° = BartTokenEmbed(U*_, E;), (5)
L, =(A°@hi; [ULB] ehi, ©
P, = Softmax(L:), (7)

where the MLP module makes a linear transformation on the
encoder output, BartTokenEmbed function means the token
embeddings shared between encoder and decoder. Suppose the
number of entity types in U*_, E; is ek, then He € R°*¢.
[Ut_,E;]° e R&xd. T, © Rtx(™tek). @ means the dot
product of multi-dimension vectors and [-;-] concats the two
vectors in the first dimension.


Pseudo Labels Current Labels

<s> \Focus \ Today \<ORG>\ Wang \ Shilin \<PER>

I

Cxs>

f

Cto

t

€shilin

f

C</s>

welcome

Current|/Model

Inputs:
Full Lables:

<s> Welcome to Focus Today hosted by Wang Shilin </s>
3 4 10 7 8 Il </s>

Confidence Threshold Filtering

<s> \Focus \ Today \<ORG>\ Focus \ Shilin \<ORG>

I I t I

C</s>

Ccs>  &welcome eto €shilin

Oldi Model

Fig. 2. Overview of the proposed generative framework for Continual NER. Since the input sentence has 10 tokens, we conduct the 10 shift to entity type
indexes. Thus index 0-9 indicates entity boundary tokens, and index larger than 9 represents different entity categories. ec word> denotes BART embeddings.

B. Confidence-based Knowledge Distillation

GenCNER uses knowledge distillation to avoid forgetting
old types of entities while learning the new ones. At the k-
th incremental task, we make a one-off prediction with the
previously learned model M;,_1 on the current training dataset
for all the seen types Us E;. Next, we connect the pseudo
triplet sequence generated by model M;,_, with the annotated
triplet sequence of current entity type(s) E,, to construct
target triplet sequence for model M;, optimization. During KD
process, the previous model M;_, plays the role of teacher to
distill old knowledge into the current student My.

It is worth noting that the pseudo triplet sequence possibly
brings label noise which interferes the training of current
model. In order to reduce model noise and improve distillation
efficiency, we empirically design a confidence-based pseudo
labeling mechanism for the filtering of poor predictions.
Specifically, towards each training sentence in D,, we first
compute the probability of each token predicted by M;,_1.
Since it is difficult to evaluate the quality of one single
token, we split the probability sequence every three generative
steps, corresponding to each predicted entity triplet. Then we
obtain the minimum value of each probability triplet to stand
for the generation quality of different entity triplets. Since
different entity types have diverse learning difficulties, we
define the confidence threshold in a type-specific way referring
to previous semi-supervised works [30], [31].

6) = min(d, median{min(p(s), p(e), p(c))|(s, e, ¢) € ve

where 6 is the type-specific hyper-parameter, s(or e) denotes
the start(or end) token of a predicted entity, c © URE;
represents one specific entity type and S*~! denotes the whole
entity triplet set predicted by M/;,_1. Such a threshold ensures
that we keep at least 50% pseudo triplets of each entity type
to train a new model.

For noise minimization, entity triplets with token probability
lower than the type-specific thresholds are removed from
predicted entity triplet sequence, forming the new pseudo label
sequence as follows:

YP" = {(si, ec, ti) | min(p(s;), p(ex), p(ti)) = 5}, (9)

where (s;,e;,t;) € Y,? denotes the i-th entity triplet generated
by the old model M;_1.

The pruned pseudo triplet sequence Y?"" is used to compute
the KL divergence loss of soft labels with the current model
My, which formulates as:

L

1 TU
Lp = Z S- Py")

t=1

where L is the length of pruned pseudo triplet sequence,
yt" € YP" stands for the boundary token or entity type
predicted by old model M;,_; at the ¢-th generative step,
P(y?’) means the corresponding probability distribution of

y?", fg represents the current student model My.

(log P(y?") —log fo(X,Y<z)), (10)

C. Model Training

Considering that we expect the model to learn new entity
types by extending entity triplet sequence, the cross entropy


loss is computed as:
1 L+G .
Log =~ S- Pone—not (Y? ) log fo(X, Yet),
t=L+41

where G represents the length of current ground truth of triplet
sequence, y/ € Y,’ means the (¢ — L)-th value of current
annotated triplet sequence and f» represents the current model
Mrz, as mentioned above.

Following previous continue learning methods for NER [6],
[9], the final loss in the k-th incremental task (& > 1) is the
weighted sum as:

(11)

L=alxp+ Ler, (12)
where a and £ are both the weights of different losses to
balance the learning of past and present.

V. EXPERIMENTS

We conduct extensive experiments on two public datasets to
prove the effectiveness of our proposed model in recognizing
entities for growing CNER tasks. Then the detailed analyses
are given to show the strengths of each component.

A. Datasets

For the evaluation of proposed generative framework, we
conduct main experiments on two public NER datasets:
OntoNotes [32] and Few-NERD [33]. To imitate the class-
incremental setting, we follow previous works [4], [6] to split
the above standard NER corpora into separate datasets used
in a series of CL tasks. Compared with OntoNotes which
only annotates one single entity type within each task, the
fine-grained dataset Few-NERD allows learning multiple types
per task. Some basic information of them is described below.
OntoNotes-5.0 English is one flat NER dataset in the field of
news, containing 18 entity categories. We follow recent works
[9] to select 6 types to ensure sufficient training samples, in-
cluding Organization, Person, GPE, Date, Cardinal and NORP.
Each entity type is annotated only in the corresponding CL
task. Few-NERD is first proposed for few-shot NER research,
which consists of 8 coarse-grained and 66 fine-grained entity
types as presented in Table I. For simplicity, we employ the
supervised full version of Few-NERD and construct a sequence
of CL tasks via each coarse-grained type. Consequently, each
task can be seen as a semantic domain with some relative
fine-grained entity types, more similar to the complicated
applications in the real world.

B. CNER Settings

Before experimental evaluation, we need to split the orig-
inal dataset reasonably to construct a series of CL dataset.
Nevertheless, we discover the obvious diversity of different
split methods in previous works, thus making their results
difficult to compare. Following Zhang and Chen [9], the
diversity of CL datasets includes two aspects: 1) To divide the
initial train/dev dataset into a series of train/dev dataset for
each CL task, Monaikul et al. [6] separates original samples
randomly into disjoint datasets, while Xia et al. [4] filters
samples having entity types designated to be learned in that

TABLE I
THE FINE-GRAINED ENTITY TYPES OF FEw-NERD.

Coarse-grained category | Fine-grained types

GPE, park, island, mountain, bodiesofwater,

lesation (LOG) road/railway/highway/transit, other

actor, athlete, scholar, director, soldier,

person (EER) politician, artist/author, other

company, religion, education, sportsteam,
sportsleague, politicalparty, showorganization,
media/newspaper, government, other

organization (ORG)

god, law, astronomything, award, biologything,
chemicalthing, currency, disease, language,
educationaldegree, livingthing, medical

other (OTH)

airplane, car, food, game, ship,

product (PROD) software, train, weapon, other

airport, hospital, hotel, restaurant,

build (BUID) library, sportsfacility, theater, other

broadcastprogram, film, music,

art. (ART) painting, writtenart, other

attack/battle/war/militaryconflict, disaster,

event (EVET .
vent( ) election, protest, sports, other

corresponding task. The above division patterns are defined
as Split and Filter, respectively. 2) When constructing the test
dataset evaluated in each CL task, Monaikul et al. [6] directly
adopt the full version of initial test set, while Xia et al. [4]
still filters test samples having one or more entity categories
learned so far. The different splits of test data are represented
as All and Filter, similarly.

Armed with these observations, there exist four combi-
nations of CNER training and testing: Split-All, Split-Filter,
Filter-All, Filter-Filter. We select Split-All and Filter-Filter for
comprehensive evaluation of proposed framework and reliable
comparisons with previous works.

C. Baselines and Evaluation metrics

We compare GenCNER with typical baselines utilizing
different recognizing mechanisms. 1) Sequence labeling:
AddNER and ExtendNER [6] are the early state-of-the-art
works to apply sequence labeling and knowledge distillation
to CNER task. L&R [4] enhances ExtendNER with an extra
reviewing stage of synthetic augmented samples. We can not
compare with CFNER [7], CPFD [5] and O_CILNER [23]
since they employ data sampling operations and different CL
settings. 2) Span-based: SpanKL [9] is the first to intro-
duce span-based classification to achieve coherent optimization
in CNER. SKD-NER [10] employs reinforcement learning
strategies during span-based KD process to optimize the soft
labeling and distillation loss.

For evaluation metrics, we employ the Macro FI score
of all seen types up to each learning step, and report the
average results of tests on different learning orders predefined
in Table I. Since the fine-grained types in Few-NERD are
not balanced, we first compute the Micro F1 of each coarse-
grained type then fairly report the Macro F1 of all seen coarse-
grained types. Additionally, we report the gap between non-CL


TABLE II
DIFFERENT LEARNING ORDERS OF CL TASKS ON TWO DATASETS.

6 OntoNotes Permutations (—)

1; ORG PER GPE DATE CARD NORP
2: DATE NORP PER CARD = ORG GPE
a GPE CARD ORG NORP_ DATE PER
4: NORP ORG DATE PER GPE CARD
5: CARD GPE NORP ORG PER DATE
6: PER DATE CARD GPE NORP ORG
4 Few-NERD Permutations (—)
1: LOC PER ORG OTH PROD BUID ART EVET
2 ORG PROD ART EVET OTH PER LOC BUID
3: PROD EVET OTH PER ART LOC BUID ORG
4: BUID OTH PROD PER ORG LOC ART EVET

and CL results in each incremental task. The non-CL setting
adds all the previous training datasets to the current one and
provides full annotations of entity types learned so far, which
serves as the upper bound of F1 performance at each step.

D. Implementation Details

During data preparation, we continuously add entity types
as special tokens to the BART Tokenizer with CL tasks
increasing. Meanwhile, we apply the n shift (n is the length of
input sentences after padding) to each entity type index, which
helps to identify whether the predicted index is a boundary
token or an entity type.

Towards model components, we apply the pre-trained
seq2seq model BART-large to continuously generate entity
triplet sequence. We only use BART embeddings with the
dimension of 1024. During confidence-based pseudo labeling,
we remove entity triplets predicted by old model with lower
confidence than type-specific thresholds defined in formula 8.
Considering the diverse learning difficulties of different entity
types and the trade-off between quantity and quality of training
samples, we select the threshold hyperparameter 6 according
to Table III. To effectively balance KD and CE losses, the
corresponding weights are set to l(a) and 0.5().

In model training, we choose the AdamW optimizer with
the learning rate Se-5 and set warmup ratio to 0.1 for both
datasets. The epoch number of each CL task is 10 and the
batch size is set to 8. We perform each experiment on a single
GeForce RTX 3090 GPU.

E. Main Results

We evaluate GenCNER performance on OntoNotes in two
CNER settings: Split-All and Filter-Filter. The former ran-
domly splits the original training dataset into disjoint subsets
and adopts the full version of initial test set, which is the most
common setup for CNER. The latter selects samples having
current entity types from initial training set and filters samples
with types seen so far in original test set, lacking training
samples without any entity.

As shown in Table IV, GenCNER significantly outperforms
other baselines in both CNER settings. It not only achieves

TABLE III
TYPE-SPECIFIC THRESHOLD SETTINGS OF TWO DATASETS. WE TEST A RANGE OF
THRESHOLDS ON THE VALIDATION SET AND SELECT THE OPTIMAL ONE FOR EACH
ENTITY TYPE.

Dataset Involved Entity Type | Threshold 6
ORG 0.78
PER 0.84
GPE 0.74
OntoNotes 5.0 DATE 071
CARD 0.63
NORP 0.77
LOC 0.60
PER 0.58
ORG 0.54
OTH 0.54
Few-NERD PROD 0.49
BUID 0.45
ART 0.46
EVET 0.51

the highest Macro F1 scores at each step, but also has the
smallest gap to the non-CL performance. Compared with
previous SOTA method SpanKL, GenCNER achieves +0.97%,
+0.69% FI higher, and narrows the performance gap by the
absolute value of 0.14, 0.36 at the final learning step in Split-
All and Filter-Filter settings, respectively. Experimental results
on OntoNotes demonstrate the effectiveness of GenCNER to
recognize entities of growing types. We also discover that
different methods perform similarly in non-CL setup but quite
diversely for CNER, revealing they may be strong enough to
solve traditional NER but have varying degrees of difficulty in
handling a series of CL tasks.

Following recent works [4], [9], we test GenCNER on
a more complicated dataset Few-NERD under typical Split-
All CL setting and display the results in Table V. Each
step represents one coarse-grained entity type, which contains
several fine-grained ones and well imitates real-life scenarios.
From Table V, we observe that although facing the challenge of
learning multiple fine-grained types per task, GenCNER still
performs better than other baselines. To be specific, GenCNER
improves the F1 score by 0.81% at the final step and reduces
the gap from -3.61 to -3.35.

We briefly analyze the core factors that lead to performance
improvement. As we convert CNER into sequence generation
of rising entity triplets, the problem of semantic shift no
longer exists, thus achieving coherent optimization. During KD
stage, we abandon pseudo triplets with lower confidence in a
type-specific way, which reduces the label noise and prevents
subsequent error accumulation.

F. Further Analysis

Ablation Study To explore the effectiveness of confidence-
based filtering strategy and KL divergence loss of soft
pseudo labels, we conduct necessary ablation experiments
on OntoNotes. As shown in Table VI, when we remove
confidence threshold filtering from GenCNER, the Fl score


TABLE IV
Macro FI OF DIFFERENT MODELS AT EACH CL sTeP IN SpLit-ALL AND FILTER-FILTER SETTINGS ON ONTONoreEs. A = CL — Non-CL. THE HIGHEST F1 scorE AT
FINAL LEARNING STEP IS BOLDED ALONG WITH ITS GAP. ALL METHODS ADOPT THE LARGE VERSION OF BERT or BART As ENCODER, ENSURING THEIR PARAMETER
SIZES ARE AT THE SAME LEVEL.

eiethad Train(Split)-Test(All) Train(Filter)-Test(Filter)

Stepl Step2 Step3 Step4 Step5 Step6 | Step! Step2 Step3 Step4 StepS Step6
non-CL 82.52 86.42 87.32 88.84 89.62 89.27 | 90.78 91.54 90.76 90.60 90.50 90.48
AddNER [6] 82.52 83.90 84.66 85.02 85.48 85.03 | 90.78 89.82 88.92 87.20 86.16 85.82
A -0.00 -252 -2.66 -382 -4.14 -4.24 | -0.00 -1.72  -184 -240 -3.34 -4.66
non-CL 82.79 86.49 87.70 8846 89.02 89.19 | 90.62 91.70 91.02 90.79 90.92 90.10
ExtendNER [6] 82.79 83.54 8448 84.67 85.12 84.96 | 90.62 88.92 87.55 86.30 84.77 81.37
A -0.00 -2.95 -3.22  -3.79 -3.90 -4.23 | -0.00 -2.78 -347 -449 -6.15 = -8.73
non-CL - - - - - - 92.06 91.16 90.50 89.69 89.57 89.30
L&R [4] - - - - - - 92.06 88.09 85.69 83.79 83.38 83.02
A - - - - - - -0.00  -3.07 -481 -5.90 -6.19 § -6.28

SKD-NER [10] 87.33, 91.47 92.36 90.76 88.54 88.17 - - - - - -
non-CL 85.60 88.16 88.64 89.39 89.69 89.74 | 92.37 92.65 92.78 92.06 92.10 91.90
SpanKL [9] 85.60 87.92 88.22 88.76 89.02 88.98 | 92.37 90.81 90.38 89.50 89.18 88.07
A -0.00 -0.24 -042 -0.63 -0.67  -0.76 | -0.00 -184 -240 -2.56 -2.92 — -3.83
non-CL 86.37 89.26 89.41 89.93 90.40 90.57 | 92.79 93.48 93.67 92.96 92.91 92.23
GenCNER(ours) | 86.37 88.84 89.06 8942 89.71 89.95 | 92.79 91.86 91.39 90.13 89.73 88.76
A -0.00 -042 -035 -051 -0.69 -0.62 | -000 -162 -2.28 -2.83  -3.18  -3.47

TABLE V performance of involved entity types at each CL step.

Macro F1 on Few-NERD IN THE Spuit-ALL CL SETTING. EACH STEP INVOLVES
ONE COARSE-GRAINED ENTITY TYPE CONTAINING SOME FINE-GRAINED ONES.

Train(Split)-Test(All)

Method
Step! Step2 Step3 Step4 Step5 Step6 Step7  Step8
non-CL 64.01 62.25 61.88 61.07 61.28 62.43 63.83 63.65
AddNER [6] 64.01 61.32 60.54 59.43 58.74 59.32 60.41 59.32
A -0.00  -0.93 -1.34 -1.64 -254 -3.11 -3.42  -4.33
non-CL 64.06 62.08 61.76 60.94 61.29 62.02 63.62 63.32
ExtendNER [6] 64.06 59.02 57.05 55.72 55.46 55.96 56.85 56.16
A -0.00  -3.06 -4.71 -5.22 -5.83 -6.06 -6.77  -7.16
L&R [4] 68.13 66.72 64.51 6344 60.97 61.23 60.88 60.32
non-CL 67.81 65.22 64.97 64.18 64.22 64.94 66.10 65.76
SpanKL [9] 67.81 64.16 63.62 62.31 61.67 62.17 63.24 62.15
A -0.00 -1.06 -1.35 -186 -255 -2.77 -2.86 -3.61
non-CL 68.27 65.73 65.36 64.63 64.92 65.48 66.52 66.31
GenCNER(ours) | 68.27 64.75 64.10 63.02 62.28 62.95 63.74 62.96
A -0.00 -0.98 -1.26 -161 -2.64 -2.53  -2.78  -3.35

decreases by 0.52%, 1.35% at the final step. Meanwhile, we
find the Filter-Filter setting suffers more obvious performance
decline. That may be because Filter-Filter constructs training
sets by filtering samples with specific entity types, causing
intersection between different sets. Thus there exist more
samples of type co-occurence in Filter-Filter CL setting,
potentially bringing more noise during old model prediction.
With regard to pseudo label format and optimized objectives,
the Fl score reveals a slight decrease if we replace KL
divergence with cross entropy loss, indicating the strength of
soft label learning, as expected.

Type-Level Comparison We further study the instant

Following a certain learning order, We plot their Fl curves
on OntoNotes in Split-All setting and add an extra dashed
curve to denote the overall Macro Fl up to per step. As
illustrated in Fig. 3, GenCNER outperforms other baselines
in the following aspects: 1) The starting point of each curve
in GenCNER is always superior to that in other methods,
indicating the stronger power of GenCNER in acquiring new
type knowledge. 2) The trend of most Fl curves in GenCNER
is obviously smoother with CL tasks growing, which reveals
it effectively prevents the new model from forgetting already
learned entity categories.

Effect of triplet compositions During entity triplet
sequence generation, we utilize the classic autoregressive
framework, where current decoder input depends on the
output token from last time step. Considering the influence of
conditional probability in seq2seq models, we evaluate three
compositions of entity triplet on Ontonotes in Split-All: TSE
(type, start, end), STE and SET. From Table VII, we find
that the composition of triplet has a certain impact on model
performance and SET defined as (start, end, type) achieves
the best Fl, indicating the recognition of boundary tokens
promotes the classification of entity types.

Analysis of Threshold Selection We finally study the
selection of type-specific threshold 6 on two datasets at the
second CL step in Split-All setting. Fig. 4 reveals that Fl
score first increases then decreases as the threshold increases
progressively. Such trend indicates that reasonable threshold


TABLE VI
THE ABLATION STUDY ON ONTONOTES IN TWO CL SETTINGS. “CTF” REPRESENTS CONFIDENCE THRESHOLD FILTERING. “w/o Lp” DENOTES REPLACING KL
DIVERGENCE WITH CROSS ENTROPY LOSS AT THE KD sTAGE.

Method | Train (Split)-Test(All)

Train(Filter)-Test(Filter)

| Step]  Step2 Step3 Step4 Step5 Step6 | Step! Step2 Step3 Step4 StepS5  Step6
GenCNER | 86.37 88.84 89.06 89.42 89.71 89.95 | 92.79 91.86 91.39 90.13 89.73 88.76
w/o CTF 86.37 88.56 88.67 89.10 89.38 89.43 | 92.79 91.14 9043 89.07 88.68 87.41
wlo Lep 86.37 88.65 88.81 89.26 89.32 89.58 | 92.79 91.46 90.72 89.62 89.23 88.29
ExtendNER SpanKL GenCNER
95.0 | —_ +~—_+_—__+—__,
—_—_>—_1.____+_”
92.54 Re J aS
a _— ote wet See,
a. aa g 90.0 + 1 sie ies weal 7 7 ena t rain “tenet
== 2 Yo a Leet Pe
—e— CARD S a ae “ cco
“ g25)
80.04
ine
1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6

incremental step

Fig. 3. Fl curves of involved OntoNotes entity type(s) at each step with a certain learning order in Split-All setup.

TABLE VII
Macro F1 OF DIFFERENT ENTITY TRIPLET COMPOSITIONS ON ONTONOTES IN
Spuit-ALL SETTING.

Method | Train(Split)-Test(All)

| Step]  Step2 Step3 Step4 StepS5 —Step6
TSE | 86.05 88.46 88.77 88.89 89.32 89.63
STE | 86.16 88.53 88.70 89.22 89.48 89.79
SET | 86.37 88.84 89.06 89.42 89.71 89.95

wo
oO

a a a milan deinen Gaia nk le

foe)
ul

—t— OntoNotes 5.0(old class: ORG)
—®— Few-NERD(old class: LOC)

Seid

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

Macro F1(%)
a
ui oO

~~
o

Fig. 4. Effect of type-specific threshold 6 selection at the second CL step.

settings can help reduce label noise, while excessive thresholds
may lead to insufficient training samples. Additionally, it
is necessary to set confidence thresholds in a type-specific
way since different entity categories have diverse optimal
thresholds for knowledge distillation.

VI. CoNCLUSION

In this paper, we propose a novel generative framework
for continual NER. By formulating CNER into sequence
generation of increasing entity triplets, GenCNER averts the

semantic shift of non-entity and solves a series of CL tasks
excellently. We perform type-specific confidence threshold
filtering to select high-quality pseudo triplets generated by
old model, which effectively reduces the potential noise and
enhances knowledge distillation. Experiments on two NER
datasets show GenCNER achieves new SOTA performance
over strong baselines in multiple CL settings.

Meanwhile, our framework also has some limitations. Com-
pared with other methods, GenCNER costs more training and
inference time since it adopts the autoregressive structure to
generate triplet sequences in each CL task. In addition, the
knowledge distillation greatly depends on the co-occurrence of
entity types between different tasks. The model performance
will significantly decrease if the current task contains fewer
previously learned entity types. We plan to explore the above
issues for future work.

ACKNOWLEDGMENT

This work is supported by the National Key Research and
Development Program of China (No.2024YFB3309702), the
National Nature Science Foundation of China (No.62021002),
Tsinghua BNRist and Beijing Key Laboratory of Industrial Big
Data System and Application.

REFERENCES

[1] Phong Le and Ivan Titov, “Improving Entity Linking by Modeling
Latent Relations between Mentions,” in Proceedings of the 56th Annual
Meeting of the Association for Computational Linguistics (Volume 1:
Long Papers), Melbourne, Australia, 2018, pp. 1595-1604.


[2]

[3]

[4]

[5]

[6]

[7]

[8

[10

{11

[12]

[13]

[14]

[15

[16

[17

[18

Xuming Hu, Chenwei Zhang, Fukun Ma, Chenyao Liu, Lijie Wen,
and Philip S. Yu, “Semi-supervised Relation Extraction via Incremental
Meta Self-Training,” in Findings of the Association for Computational
Linguistics: EMNLP 2021, Punta Cana, Dominican Republic, 2021, pp.
487-496.

Yuhao Yang, Chao Huang, Lianghao Xia, and Chenliang Li, “Knowledge
Graph Contrastive Learning for Recommendation,” in Proceedings of the
45th International ACM SIGIR Conference on Research and Develop-
ment in Information Retrieval, New York, USA, 2022, pp. 1434-1443.
Yu Xia, Quan Wang, Yajuan Lyu, Yong Zhu, Wenhao Wu, Sujian
Li, and Dai Dai, “Learn and Review: Enhancing Continual Named
Entity Recognition via Reviewing Synthetic Samples,” in Findings of the
Association for Computational Linguistics: ACL 2022, Dublin, Ireland,
2022, pp. 2291-2300.

Duzhen Zhang, Wei Cong, Jiahua Dong, Yahan Yu, Xiuyi Chen,
Yonggang Zhang, and Zhen Fang, “Continual Named Entity Recognition
without Catastrophic Forgetting,” in Proceedings of the 2023 Conference
on Empirical Methods in Natural Language Processing, Singapore, 2023,
pp. 8186-8197.

Natawut Monaikul, Giuseppe Castellucci, Simone Filice, and Oleg
Rokhlenko, “Continual Learning for Named Entity Recognition,” Pro-
ceedings of the AAAI Conference on Artificial Intelligence, vol. 35, no.
15, pp. 13570-13577, May 2021.

Junhao Zheng, Zhanxian Liang, Haibin Chen, and Qianli Ma, “Distilling
Causal Effect from Miscellaneous Other-Class for Continual Named
Entity Recognition,’ in Proceedings of the 2022 Conference on Em-
pirical Methods in Natural Language Processing, Abu Dhabi, United
Arab Emirates, 2022, pp. 3602-3615.

Shengjie Qiu, Junhao Zheng, Zhen Liu, Yicheng Luo, and Qianli Ma,
“Incremental Sequence Labeling: A Tale of Two Shifts,” in Findings
of the Association for Computational Linguistics: ACL 2024, Bangkok,
Thailand, 2024, pp. 777-791.

Yunan Zhang and Qingcai Chen, “A neural span-based continual named
entity recognition model,” in Proceedings of the AAAI Conference on
Artificial Intelligence, 2023, vol. 37, pp. 13993-14001.

Yi Chen and Liang He, “SKD-NER: Continual Named Entity Recogni-
tion via Span-based Knowledge Distillation with Reinforcement Learn-
ing,” in Proceedings of the 2023 Conference on Empirical Methods in
Natural Language Processing, Singapore, 2023, pp. 6689-6700.

Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdel-
rahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer,
“BART: Denoising Sequence-to-Sequence Pre-training for Natural Lan-
guage Generation, Translation, and Comprehension,’ in Proceedings
of the 58th Annual Meeting of the Association for Computational
Linguistics, Online, 2020, pp. 7871-7880.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan
Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu,
“Exploring the limits of transfer learning with a unified text-to-text
transformer,” J. Mach. Learn. Res. vol. 21, no. 1, Jan. 2020.

Jing Li, Aixin Sun, Jianglei Han, and Chenliang Li, “A Survey on
Deep Learning for Named Entity Recognition,” in IEEE Transactions
on Knowledge and Data Engineering, vol. 34, no. 1, pp. 50-70, 2022.
Yongliang Shen, Xinyin Ma, Zeqi Tan, Shuai Zhang, Wen Wang, and
Weiming Lu, “Locate and Label: A Two-stage Identifier for Nested
Named Entity Recognition,” in Proceedings of the 59th Annual Meeting
of the Association for Computational Linguistics and the 11th Inter-
national Joint Conference on Natural Language Processing (Volume 1:
Long Papers), Online, 2021, pp. 2782-2794.

Jingye Li, Hao Fei, Jiang Liu, Shenggiong Wu, Meishan Zhang, Chong
Teng, Donghong Ji, and Fei Li, “Unified Named Entity Recognition as
Word-Word Relation Classification,’ Proceedings of the AAAI Confer-
ence on Artificial Intelligence, vol. 36, no. 10, pp. 10965-10973, 2022.
Alejandro Metke-Jimenez and Sarvnaz Karimi, “Concept extraction to
identify adverse drug reactions in medical forums: A comparison of
algorithms,” arXiv preprint arXiv:1504.06936, 2015.

Jana Strakova, Milan Straka, and Jan Hajic, “Neural Architectures for
Nested NER through Linearization,” in Proceedings of the 57th Annual
Meeting of the Association for Computational Linguistics, Florence,
Italy, 2019, pp. 5326-5331.

Juntao Yu, Bernd Bohnet, and Massimo Poesio, “Named Entity Recogni-
tion as Dependency Parsing,” in Proceedings of the 58th Annual Meeting
of the Association for Computational Linguistics, Online, 2020, pp.
6470-6476.

[19]

[20]

[21]

[22]

[23]

[24]

[25]

[26]

[27]

[28]

[29]

[30]

[31]

[32]

[33]

Chuangi Tan, Wei Qiu, Mosha Chen, Rui Wang, and Fei Huang,
“Boundary Enhanced Neural Span Classification for Nested Named
Entity Recognition,” Proceedings of the AAAI Conference on Artificial
Intelligence, vol. 34, no. 05, pp. 9016-9023, 2020.

Arzoo Katiyar and Claire Cardie, “Nested Named Entity Recogni-
tion Revisited,’ in Proceedings of the 2018 Conference of the North
American Chapter of the Association for Computational Linguistics:
Human Language Technologies, Volume | (Long Papers), New Orleans,
Louisiana, 2018, pp. 861-871.

Hang Yan, Tao Gui, Junqi Dai, Qipeng Guo, Zheng Zhang, and Xipeng
Qiu, “A Unified Generative Framework for Various NER Subtasks,”
in Proceedings of the 59th Annual Meeting of the Association for
Computational Linguistics and the 11th International Joint Conference
on Natural Language Processing (Volume 1: Long Papers), Online, 2021,
pp. 5808-5822, Association for Computational Linguistics.

Da-Wei Zhou, Qi-Wei Wang, Zhi-Hong Qi, Han-Jia Ye, De-Chuan
Zhan, and Ziwei Liu, “Class-Incremental Learning: A Survey,’ IEEE
Transactions on Pattern Analysis and Machine Intelligence, vol. 46, no.
12, pp. 9851-9873, 2024.

Ruotian Ma, Xuanting Chen, Zhang Lin, Xin Zhou, Junzhe Wang, Tao
Gui, Qi Zhang, Xiang Gao, and Yun Wen Chen, “Learning “O” Helps
for Learning More: Handling the Unlabeled Entity Problem for Class-
incremental NER,” in Proceedings of the 61st Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers),
Toronto, Canada, 2023, pp. 5959-5979.

Kyunghyun Cho, Bart van Merriénboer, Caglar Gulcehre, Dzmitry Bah-
danau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio, “Learning
Phrase Representations using RNN Encoder—Decoder for Statistical Ma-
chine Translation,” in Proceedings of the 2014 Conference on Empirical
Methods in Natural Language Processing (EMNLP), Doha, Qatar, 2014,
pp. 1724-1734.

Dzmitry Bahdanau, Kyung Hyun Cho, and Yoshua Bengio, “Neural
machine translation by jointly learning to align and translate,” in 3rd
International Conference on Learning Representations (ICLR), 2015.
Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly, “Pointer networks,”
in Proceedings of the 29th International Conference on Neural Infor-
mation Processing Systems - Volume 2, Cambridge, MA, USA, 2015,
NIPS’15, pp. 2692-2700.

Jiatao Gu, Zhengdong Lu, Hang Li, and Victor O.K. Li, “Incorporating
Copying Mechanism in Sequence-to-Sequence Learning,” in Proceed-
ings of the 54th Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), Berlin, Germany, 2016, pp. 1631—
1640.

Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu, “Mass:
Masked sequence to sequence pre-training for language generation,” in
International Conference on Machine Learning, 2019, pp. 5926-5936.
Jianfei Yu, Ziyan Li, Jieming Wang, and Rui Xia, “Grounded Mul-
timodal Named Entity Recognition on Social Media,” in Proceedings
of the 61st Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), Toronto, Canada, 2023, pp. 9141—
9154.

Bowen Zhang, Yidong Wang, Wenxin Hou, Hao Wu, Jindong Wang,
Manabu Okumura, and Takahiro Shinozaki, “FlexMatch: boosting semi-
supervised learning with curriculum pseudo labeling,’ Advances in
neural information processing systems, vol. 34, pp. 18408-18419, 2021.
Yidong Wang, Hao Chen, Qiang Heng, Wenxin Hou, Yue Fan, Zhen Wu,
Jindong Wang, Marios Savvides, Takahiro Shinozaki, Bhiksha Raj, et al.,
“Freematch: Self-adaptive thresholding for semi-supervised learning,”
in The Eleventh International Conference on Learning Representations,
2022.

Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and
Ralph Weischedel, “OntoNotes: The 90% Solution,” in Proceedings of
the Human Language Technology Conference of the NAACL, Compan-
ion Volume: Short Papers, New York City, USA, 2006, pp. 57-60.
Ning Ding, Guangwei Xu, Yulin Chen, Xiaobin Wang, Xu Han, Pengjun
Xie, Haitao Zheng, and Zhiyuan Liu, “Few-NERD: A Few-shot Named
Entity Recognition Dataset,” in Proceedings of the 59th Annual Meeting
of the Association for Computational Linguistics and the 11th Interna-
tional Joint Conference on Natural Language Processing (Volume 1:
Long Papers), Online, 2021, pp. 3198-3213.
