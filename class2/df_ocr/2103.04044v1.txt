arX1v:2103.04044v1 [cs.CL] 6 Mar 2021

Putting Humans in the Natural Language Processing Loop: A Survey

Zijie J. Wang* Dongjin Choi* Shenyu Xu* Diyi Yang
College of Computing, Georgia Institute of Technology

{jayw, jin.choi, shenyuxu, dyang888}@gatech.edu

Abstract

How can we design Natural Language Process-
ing (NLP) systems that learn from human feed-
back? There is a growing research body of
Human-in-the-loop (HITL) NLP frameworks
that continuously integrate human feedback to
improve the model itself. HITL NLP research
is nascent but multifarious—solving various
NLP problems, collecting diverse feedback
from different people, and applying different
methods to learn from collected feedback. We
present a survey of HITL NLP work from
both Machine Learning (ML) and Human-
Computer Interaction (HCI) communities that
highlights its short yet inspiring history, and
thoroughly summarize recent frameworks fo-
cusing on their tasks, goals, human interac-
tions, and feedback learning methods. Finally,
we discuss future directions for integrating hu-
man feedback in the NLP development loop.

1 Introduction

Traditionally, Natural Language Processing (NLP)
models are trained, fine-tuned, and tested on exist-
ing dataset by machine learning experts, and then
deployed to solve real-life problems of their users.
Model users can often give invaluable feedback
that reveals design details overlooked by model de-
velopers, and provide data instances that are not
represented in the training dataset (Kreutzer et al.,
2020). However, the traditional linear NLP devel-
opment pipeline is not designed to take advantage
of human feedback. Advancing on the conven-
tional workflow, there is a growing research body
of Human-in-the-loop (HITL) NLP frameworks,
or sometimes called mixed-initiative NLP, where
model developers continuously integrate human
feedback into different steps of the model deploy-
ment workflow (Figure 1). This continuous feed-
back loop cultivates a human-AI partnership that

“denotes equal contribution

Raw Data Model Model
Data Labeling Selection Training

Evaluation
Deployment

Figure 1: Collaboration between the human and the
model in the Natural Language Processing Loop. The
human provides feedback in different stages of the loop
to improve the performance, interpretability, and us-
ability of NLP models.

not only enhances model accuracy and robustness,
but also builds users’ trust in NLP systems.

Just like traditional NLP frameworks, there is
a high-dimensional design space for HITL NLP
systems. For example, human feedback can come
from end users (Li et al., 2017) or crowd workers
(Wallace et al., 2019), and human can intervene
models during training (Stiennon et al., 2020) or
deployment (Hancock et al., 2019). Good HITL
NLP systems need to clearly communicates to hu-
mans of what the model needs, provide intuitive
interfaces to collect feedback, and effectively learn
from them. Therefore, HITL NLP research spans
across not only NLP and Machine Learning (ML)
but also Human-computer Interaction (HCI). A
meta-analysis on existing HITL NLP work focus-
ing on bridging different research disciplines is vi-
tal to help new researchers quickly familiarize with
this promising topic and recognize future research
directions. To fill this critical research gap, we pro-
vide a timely literature review on recent HITL NLP
studies from both NLP and HCI communities.

This is the first comprehensive survey on the
HITL NLP topic. We make two main contributions:
(1) We summarize recent studies on HITL NLP
and position each work with respect to its task,


goal, human interaction, and feedback learning
method (Table 2); (2) We critically discuss existing
knowledge gaps and highlight important research
directions that we distilled from the survey.

2 Related Surveys

To our best knowledge, there is no existing sur-
vey work on this topic, as the field for HITL NLP
just starts growing. Regarding interactive machine
learning, related surveys like Amershi et al. (2014)
focus on problems in interactive machine learning
in general. Specifically for reinforcement learn-
ing and dialogue system, there is one overview
article (Kreutzer et al., 2020) focusing on offline di-
alogue system. Different from the aforementioned
articles, our survey provides a comprehensive re-
view on HITL in NLP with critical discussions.

3 Human-in-the-Loop NLP Tasks

This section describes what NLP sub-problems cur-
rently can benefit from a HITL approach. Over re-
cent years, researchers and practitioners have made
great advancements in NLP — enabling many dif-
ferent NLP tasks and applications, such as text clas-
sification, summarization, and machine translation.
To effectively integrate humans into these task-
specific development loops, people have developed
many application-specific HITL paradigms. In this
section, we categorize surveyed HITL paradigms
based on their corresponding tasks.

3.1 Text Classification

Text classification is a classic problem in NLP to
categorize text into different groups. Trained on
a set of text documents (X) and their categorical
labels (Y), a text classifier can predict Y value of an
unseen X. For example, a movie review sentiment
classifier can predict if one review is positive or
negative. Many HITL frameworks are developed
for this problem, where most of them start with
training a text classifier, then recruiting humans to
annotate data based on the current model behavior,
and eventually retraining the classifier on the larger
dataset continuously.

For example, Godbole et al. (2004) develop a
HITL paradigm where users can interactively edit
(add or remove) text features and label new docu-
ments. Also, Godbole et al. integrate active learn-
ing in their framework—instead of arbitrarily pre-
senting data for users to annotate, they strategically
choose samples that can maximize the expected

information gain. With active learning, labelers
can annotate fewer data to achieve the same model
improvement of a framework using random sam-
pling. Settles (2011) further improves this HITL
workflow by extending the active learning compo-
nent to features (words) sampling in addition to
labels (documents). To ease the deployment of
HITL text classifiers, Simard et al. (2014) develop
a robust web-based tool that supports general text
classification tasks. Researchers have also devel-
oped domain-specific HITL text classification sys-
tems. For instance, a rumor classification system
developed for journalists tightly integrates model
retraining, data collection, and data annotation in
deployment (Karmakharm et al., 2019).

Bag-of-words feature is commonly used in text
classifiers. However, Jandot et al. (2016) explore
alternative feature representations to better support
a HITL pipeline. A dictionary, also called lexicon
and gazetteer, is a set of words sharing the same
semantics. Well-defined dictionaries give higher
accuracy and are more interpretable than bag-of-
words. In Jandot et al.’s HITL system, users can
easily create semantic dictionaries through a web-
based user interface, and the text classifier is con-
tinuously trained on new dictionaries.

3.2 Parsing and Entity Linking

Besides classifying documents, recent research
shows great potential of HITL approach in enhanc-
ing the performance of existing parsing and entity
linking models. Parsing in NLP is a process to
determine the syntactic structure of the input text.
Entity linking aims to assign unique identity to
entities in the text, such as names and locations.

Advancing traditional Combinatory Categorial
Grammars (CCG) parsers, He et al. (2016) crowd-
source parsing tasks—a trained parser is uncertain
about—to non-expert mechanical turks, by ask-
ing them simple what-questions. Using human
feedback as a soft constraint to penalize the parser
during retraining, the performance of the original
parser improves significantly. Similarly, Klie et al.
(2020) recruit humans to interactively annotate cor-
rect entities in text samples where an entity linking
model performs poorly. Also, with more strategic
sampling methods to select instances to present to
humans, a smaller set of feedback can quickly im-
prove the entity linking model performance (Klie
et al., 2020; Lo and Lim, 2020).


TASK
f=
ox} ®
2 8
BG
7)
& ©
F 6
o s
£ @
= = §s
= o> aH] o
c > = oO iS)
rol 2 o 5 c
gh 2 8 Sle
SY ££ g ziys
= oO oO =
86 8 8 ols
Sop S & S/O
Oo £ G& E— Bla
¢ fs —€ =/cs
$s §& 3 £\g
Work F Q@ F ®DW ASS
Godbole et al. (2004
Settles (2011
Simard et al. (2014
Karmakharm et al. (2019
Jandot et al. (2016
Kaushik et al. (2019
He et al. (2016
Klie et al. (2020
Lo and Lim (2020

Trivedi et al. (2019
Lawrence and Riezler (2018
Kim et al. (2019
Kumar et al. (2019
Smith et al. (2018
Stiennon et al. (2020
Kreutzer et al. (2018
Hancock et al. (2019
Liu et al. (2018

Li et al. (2017
Wallace et al. (2019

2

E
o ©

Lo»)
g g2 (35
g £ > 2 3 3
£& & es 8 3 SG
c a £2 So 9
2 > zw © =e

e Oo > 2
= 2? &@ 8 3 § o @o
c° ££
> S$ £¢ § & 8 = = Cc
§$ 2m 20 5 6
= woe ! t t 1 is
PJ S tI o o oo o €<]tl tl §
ra essSSEEBlIE FS B

=
a |e §f®fFeer gle 2s
o cs &€ « &£ = = F\|S E fs
o = ££ G GF FG FG FILE F€
a GO 26° 6 © © €/6 6 8B
2 ) 7+ £ 2 2 2 £/2 2 B
o Ss DD DBD ZT e
€ s/2 © © © © GG FC/R DE
£ 2/6 € © © © © 6/5 5 A
> =i5B Bue ue He ple =< GF
Se/S 5 5 5 5 5 FI/S FB
S vn; 2 GL H H HH H £ |B GB LF
=>o;lete 2390 59 279 2579 £/0 QA sz

Table 1: Overview of representative works in HITL NLP. Each row represents one work. Works are sorted by their
task types. Each column corresponds to a dimension from the four subsections (task, goal, human interaction, and

feedback learning method).

3.3. Topic Modeling

In addition to using a HITL approach to enhance
learning the low-level semantic relationships, re-
searchers apply similar frameworks to topic model-
ing techniques that are used to analyze large doc-
ument collections. People traditionally use take it
or leave it algorithms for this task, such as infor-
mation retrieval and document clustering. Over the
past few years, there is a growing research body
of HITL topic modeling (Lee et al., 2017). For
example, Hu et al. (2014)’s and Jaegul Choo et al.
(2013)’s systems allow users to refine a trained
model through adding, removing, or changing the
weights of words within each topic. Then, using the
user-updated features and weights, trained models
are more likely to generate useful topics.

More recently, researchers focus on developing
more human-centered HITL topic modeling meth-

ods. These methods emphasize the needs of topic
modeling end users, mostly NLP non-experts, in-
stead of only collecting algorithmically convenient
human feedback (Lee et al., 2017). For example,
Kim et al. (2019) develop an intuitive visualization
system that allows end users to up-vote or down-
vote specific documents to inform their interest to
the model. Smith et al. (2018) conduct users studies
with non-experts and develop a responsive and pre-
dictable user interface that supports a broad range
of topic modeling refinement operations. These
examples show that HITL NLP systems can benefit
from HCI design techniques.

3.4 Summarization and Machine Translation

Besides using a HITL approach to analyze existing
documents, researchers also apply them to gener-
ate new texts. Text summarization and machine
translation have seen major breakthroughs in re-


cent years (Brown et al., 2020), which draw at-
tentions from both NLP and HCI communities to
design and develop HITL systems. For example,
Stiennon et al. (2020) collect human preferences
on pairs of summaries generated by two models,
then train a reward model to predict the preference.
Then, this reward model is used to train a policy
to generate summaries using reinforcement learn-
ing. Similarly, Kreutzer et al. (2018) collect both
explicit and implicit human feedback to improve a
machine translation model by using the feedback
with reinforcement learning. Experiments show
that the model trained on human preference data
has higher accuracy and better generalization.

3.5 Dialogue and Question Answering

Recently, many HITL frameworks have been devel-
oped for dialogue and Question Answering (QA)
systems, where the AI agent can have conversation
with users. We can group these systems into two
categories: (1) online feedback loop: the system
continuously uses human feedback to update the
model; (2) offline feedback loop: human feedback
is filtered and aggregated to update the model in
batch (Kreutzer et al., 2020).

Online feedback loop. Traditionally, there is a
mismatch of the training set and online use case for
dialogue systems. To tackle this challenge, online
reinforcement learning can be used to improve
the model with human feedback. For example,
Liu et al. (2018) collect dialogue corrections from
users during deployment, while Li et al. (2017)
collect both binary explicit feedback and implicit
natural language feedback. Also, Hancock et al.
(2019) propose a lifetime learning framework
to improve chatbot performance. The chatbot is
trained not only to generate dialogues but also to
predict user satisfactions. During deployment, the
chatbot predicts user satisfaction after generating
responses, and asks for user feedback if the
predicted satisfaction score is low. Then, the
chatbot uses the feedback as a new training
example to retrain itself continuously.

Offline feedback loop. With offline HITL,
model is updated after collecting a large set of hu-
man feedback. For instance, Wallace et al. (2019)
invite crowd workers to generate adversarial ques-
tions that can fool their QA system, and use these
questions for adversarial training. Offline feedback
loop can be more robust for dialogue systems, be-
cause user feedback can be misleading, so directly

updating the model is risky (Kreutzer et al., 2020).

4 Human-in-the-Loop Goals

Among surveyed papers, the most common mo-
tivation for using a HITL approach in NLP tasks
is to improve the model performance. There are
different metrics to measure model performance,
and experiments in our surveyed papers show that
HITL can significantly and effectively improve
model performance with a relatively small set
of human feedback. For example, for text clas-
sification, HITL improves classification accuracy
(Smith et al., 2018; Jandot et al., 2016). Similarly,
dialogue and question answering systems have
higher ranking metric hits after adapting a HITL
approach (Hancock et al., 2019; Brown et al.,
2020). Researchers also find HITL improves
model’s robustness and generalization on different
data (Stiennon et al., 2020; Jandot et al., 2016).

In addition to model performance, HITL can also
improve the interpretability and usability of NLP
models. For example, Jandot et al. (2016) enable
users to create semantic dictionaries. These fea-
tures have semantic meanings and are more inter-
pretable to humans. Wallace et al. (2019) guide hu-
mans to generate model-specific adversarial ques-
tions that can fool the question answering model.
These adversarial questions can be used as probes
to gain insights of the underlying model behaviors.
On the other hand, HITL can also improve the user
experience with NLP models. For example, Smith
et al. (2018) develop an interface for topic mod-
eling users to intuitively interact and control their
models. User studies show that users gain more
trust and confidence through the HITL system.

5 Human-machine Interaction

This section discusses the mediums that users use
to interact with HITL systems and different types
of feedback that the systems collect. This section is
strongly correlated with section 6, which describes
how existing works leverage user feedback to up-
date models. By first describing how and what
user feedback may be collected (this section), we
can more easily ground our discussion on how to
leverage the feedback (next section).

5.1 Interaction Mediums

There are two common interaction mediums shared
by our surveyed systems: graphical user interface
and natural language interface.


5.1.1. Graphical User Interface

One of the commonly used interaction mediums
for collecting user feedback is the Graphical User
Interface (GUI). The GUI provides a user interface
that allows users to interact with systems through
graphical icons and visual indicators such as sec-
ondary notations. Some HITL NLP systems allow
users to directly label samples in the GUI (Simard
et al., 2014; Godbole et al., 2004; Settles, 2011).
The GUI also makes feature editing possible for
end-users who do not develop the model from ini-
tial (Jandot et al., 2016; Simard et al., 2014; God-
bole et al., 2004). Some other works even use
the GUI for users to rate training sentences in the
text summarization task (Stiennon et al., 2020) and
rank the generated topics in the topic modeling
task (Kim et al., 2019). One obvious advantage of
the GUI is that it visualizes the NLP model run-
ning in the black box, enhancing the interpretabil-
ity of the model as seen in section 4. In addition,
compared to text-based user interfaces, the GUI
supports Windows, Icons, Menus, Pointer (WIMP)
interactions, providing users more accurate control
for refining the model.

5.1.2 Natural Language Interface

Another commonly used interaction medium in
HITL NLP systems is natural language interface.
A natural language interface is an interface where
the user interacts with the computer through natural
language. As this interface usually simulates hav-
ing a conversation with a computer, it mostly comes
with the purpose of building up a dialogue sys-
tem (Hancock et al., 2019; Liu et al., 2018; Li et al.,
2017). The natural language interface not only sup-
ports users to provide explicit feedback (Liu et al.,
2018; Li et al., 2017), such as positive or nega-
tive responses. It also allows users to give implicit
feedback with natural language sentences (Han-
cock et al., 2019; Li et al., 2017). Compared to the
GUI, the natural language interface is more intu-
itive to use as it simulates the process of human’s
conversation and thus needs no additional tutorial.
It can also be perfectly integrated with the dialogue
system and supports the collection of natural lan-
guage feedback, providing users more freedom for
refining the model, as discussed in section 6.

5.2 User Feedback Types

Above, we discussed that the GUI and the natu-
ral language interface are two common interaction

mediums implemented in the HITL systems we sur-
veyed for collecting user feedback. In the follow-
ing, we will discuss four major types of user feed-
back supported by the two interaction mediums, in-
cluding binary user feedback, scaled user feedback,
natural language user feedback, and counterfactual
example feedback.

5.2.1 Binary User Feedback

Binary user feedback is the feedback which has two
categories that are usually opposite to each other,
such as “like” and “dislike”. It can be collected by
both the GUI and the natural language interface.
As discussed above, the GUI can collect binary
user feedback from the user’s adding or removing
labels (Simard et al., 2014) and features (Godbole
et al., 2004). The natural language interface can
also support binary user feedback collection with
simple short natural language response, such as
“agree” or “reject” (Liu et al., 2018; Li et al., 2017).
As binary user feedback only contains two cate-
gories, this kind of user feedback is usually easy
to collect but sometimes may over-simplify users’
intention by ignoring the potential intermediate
situations. Binary user feedback can be used to
provide explicit feedback for the system to update
training datasets or directly manipulate models, as
discussed in section 6.

5.2.2 Scaled User Feedback

Scaled user feedback is the feedback which has
scaled categories and is usually in numerical for-
mats, such as the 5-point scale rating. It often can
only be collected through the GUI as it is diffi-
cult to express accurate scaled feedback in natural
language. Such user feedback is collected in the
GUI when users rate their preferences of training
data or model results (Kreutzer et al., 2018) and
adjust features on a numerical scale (Simard et al.,
2014). Similar to binary user feedback, scaled user
feedback can provide explicit feedback for the sys-
tem to update the models but with more options to
cover intermediate cases (e.g. adjusting the weight
of one feature from 1 to 3 on a scale of 5 points).
Besides, the scaled ratings of user preferences can
also be used as implicit guidance for the system to
improve the model, as discussed in subsection 6.1
and subsection 6.2.

5.2.3. Natural Language User Feedback

Compared with binary user feedback and scaled
user feedback, natural language user feedback is


Offline Model Update

Online Model Update

Model Direct Manipulation

Binary Klie et al. (2020), Lo and Lim
(2020), Trivedi et al. (2019), Kar-
makharm et al. (2019), Wallace
et al. (2019), Godbole et al.

(2004), etc.

Scaled Stiennon et al. (2020), Simard

et al. (2014)

Natural
Language

Kaushik et al. (2019), Trivedi
et al. (2019), Wallace et al.
(2019), Lawrence and Riezler
(2018), Li et al. (2017)

Counterfactual Kaushik et al. (2019), Wallace —

Example et al. (2019), Lawrence and Rie-

zler (2018)

Kim et al. (2019), Kumar
et al. (2019), Smith et al.
(2018), Liu et al. (2018), Li
et al. (2017)

Kumar et al. (2019), Smith
et al. (2018)

Hancock et al. (2019), Liu
et al. (2018), Li et al. (2017)

Liu et al. (2018), Li et al.

(2017)

Kreutzer et al. (2018)

Liu et al. (2018), Li et al.
(2017)

Table 2: Relationship between the user feedback types and how they are used. Each row represents one feedback
type (subsection 5.2), and each column corresponds to a model learning method (section 6).

a better way for representing users’ intention but
vague and hard for the machine to interpret because
of the intuitive property of human language. As
mentioned above, natural language user feedback
can only be collected through the natural language
interface. Users provide this type of user feedback
by directly inputting natural language text into
the system (Hancock et al., 2019; Li et al., 2017).
By analyzing the user input sentences, the system
implies the user’s intention and accordingly
updates the model, as seen in subsection 6.1 and
subsection 6.2.

5.3. Counterfactual Example Feedback

Similar to the natural language user feedback, coun-
terfactual example feedback is usually in the form
of natural language text and collected through the
natural language interface. A counterfactual ex-
ample describes a causal situation in the form:
“If X had not occurred, Y would not have oc-
curred.” The HITL NLP systems collect and an-
alyze user-modified counterfactual text examples
and retrain the model accordingly (Kaushik et al.,
2019; Lawrence and Riezler, 2018), as more details
covered in subsection 6.1.

5.4 Intelligent Interaction

In addition to the choice of the interaction medium
and the collected user feedback types, some HITL
NLP systems also leverage intelligent interaction
techniques to enhance human-machine interaction.
As discussed in section 3, active learning and
reinforcement learning are two commonly used

techniques we observed in our surveyed systems.
Active learning allows the system to interactively
query a user to label new data points with the de-
sired outputs (Godbole et al., 2004; Settles, 2011;
Lo and Lim, 2020). By strategically choosing sam-
ples to maximize information gain with fewer it-
erations, active learning not only reduces human
efforts on data labeling but also improves the effi-
ciency of the system. Compared to active learning,
reinforcement learning takes actions based on user
feedback to maximize the notion of cumulative re-
ward (Stiennon et al., 2020; Kreutzer et al., 2018;
Li et al., 2017; Liu et al., 2018). By considering
each user feedback as a new action, reinforcement
learning supports accurate understanding of human
intention and updating the model accordingly, as
discussed in section 6.

6 How to Use User Feedback

This section summarizes how existing HITL NLP
systems utilize feedback. Different feedback types
described in subsection 5.2 are leveraged by the
systems with different update methods (Table 2).
In the following, we will discuss two major update
methods, including data augmentation and model
direct manipulation.

6.1 Data Augmentation

One popular approach is to consider the feedback
as a new ground truth data sample. For example, a
user’s answer to a model’s question can be a data
sample to retrain a QA model. We describe two
types of techniques to use augmented data set: Of-


fline update retrains NLP model from scratch after
collecting human feedback, while Online update
trains NLP models while collecting feedback at the
same time.

Offline model update is usually performed af-
ter certain amount of human feedback is collected.
Offline update does not need to be immediate, so it
is suitable for noisy feedback with complex models
which takes extra processing and training time. For
example, Simard et al. (2014) and Karmakharm
et al. (2019) use human feedback as new class la-
bels and span-level annotations, and retrain their
models after collecting enough new data.

Online model update is applied right after user
feedback is given. This is effective for dialogue
systems and conversational QA systems where
recent input is crucial to machine’s reasoning (Li
et al., 2017). Incremental learning technique is
often used to learn augmented data in real-time
(Kumar et al., 2019). It focuses on making an
incremental change to current system using the
newly come feedback information effectively.
Interactive topic modeling systems and feature
engineering systems widely use this technique. For
example, Kim et al. (2019) incrementally updates
topic hierarchy by extending or shrinking topic
tree incrementally. Also, some frameworks use
the latent Dirichlet allocation (LDA) to adjust
sampling parameters with collected feedback in
incremental iterations (Smith et al., 2018).

6.2 Model Direct Manipulation

Collected numerical human feedback are usually
directly used to adjust model’s objective function.
For example, Li et al. (2017) collect binary feed-
back as rewards for reinforcement learning of a dia-
logue agent. Similarly, Kreutzer et al. (2018) use a
5-point scale rating as reward function of reinforce-
ment and bandit learning for machine translation.
Existing works have focused more on numerical
feedback than natural language feedback. Numeri-
cal feedback is easier to be incorporated into mod-
els, but provides limited information compared to
natural language. For future research, incorporat-
ing more types of feedback (e.g., speech, log data)
will be an interesting direction to gain more useful
insights from humans. With more complex feed-
back types, it is critical to design both quantitative
and qualitative methods to evaluate collected feed-
back, as they can be noisy just like any other data.

7 Research Directions & Open Problems

In this section, we highlight research directions
and open problems, which are distilled from the
surveyed papers, for future research.

7.1 Broader Roles of HITL NLP System

Improving model performance is the most popu-
lar goal among surveyed NLP HITL frameworks.
However, researchers have found HITL method
also enhances NLP model interpretability (Wal-
lace et al., 2019) and usability (Lee et al., 2017).
Therefore, we encourage future NLP researchers to
explore HITL as a mean to better understand their
models and improve the user experience of model
end users. For example, user feedback can be used
to mitigate harms caused by NLP model bias (Blod-
gett et al., 2020). While many recent models gain
feedback from mechanic turks (He et al., 2016),
future researchers can consider involving model
engineers and end users in their NLP development
loop (Hancock et al., 2019). For example, one
can develop a web-based tool where end users can
interactively modify the feature weights of a text
classifier and observe the model behavior at run
time. By performing these “what-if” operations,
users can gain additional insights of how model in-
ternally uses these features. Similarly, a HITL chat-
bot could grant users more control by supporting
model parameter modification through natural lan-
guage input. For instance, a non-binary user Alex
could correct the chatbot’s pronoun use by typing
“Hello chatbot, could you use they/them/theirs to
refer me in the future please?”

7.2 Human-centered System Design

In this survey, we found most of the HITL NLP sys-
tems and techniques are designed and developed
by NLP researchers. We believe that this area of
research will be greatly benefited from a deeper
involvement of the HCI community. Human feed-
back is the key for HITL systems. However, with a
poorly designed human-machine interface, the col-
lected human feedback are more likely to be incon-
sistent, incorrect, or even misleading. Therefore,
better interface design and user studies to evalu-
ate HITL system interface can greatly enhance the
quality of feedback collection, which in turn im-
proves the downstream task performance.

To shed light on HITL NLP research from a HCI
perspective, Wallace et al. (2019) explore the effect


of adding model interpretation cues in the HITL in-
terface on the quality of collected feedback; Schoch
et al. (2020) investigate the impacts of question
framing imposed on humans; similarly, Rao and
Daumé III (2018) study how to ask good questions
to which humans are more likely to give helpful
feedback. There are many exciting research oppor-
tunities and challenges in designing and evaluating
HITL interface. As a starting point for develop-
ing more human-centered HITL NLP systems, we
provide the following concrete research directions:

> As human feedback can be subjective, who
should HITL NLP systems collect feedback
from? Is there any expertise levels required to
perform certain tasks (Kreutzer et al., 2020)?

> How to present what the model has learned and
what feedback is needed? How to visualize
the model change after learning from user feed-
back (Lee et al., 2017)?

> How to dynamically choose the most helpful
feedback to collect (Settles, 2011)? How to
guide users to provide useful feedback (Wallace
et al., 2019)?

> How to evaluate the collected human feedback
as it can be noisy and even misleading (Kreutzer
et al., 2020)?

> Conduct rigorous user studies to evaluate the
effectiveness of HITL systems in addition to
model performance (Smith et al., 2018).

> Open-source tools and share user study protocols
when publishing new HITL NLP work.

> Create and share human feedback datasets.

8 Conclusion

In this paper, we conduct a comprehensive survey
on HITL NLP. We summarize recent literature on
HITL NLP from both NLP and HCI communities,
and position each work with respect to its task,
goal, human interaction, and feedback learning
method. The field of HITL NLP is still relatively
nascent, and we see very diverse system design
methods. To help new researchers and practitioners
quickly familiarize with the field, we recognize the
great potential of HITL NLP systems in different
NLP tasks and highlight open challenges and future
research directions. The research directions rest
on a greater collaboration between NLP and HCI
researchers and practitioners—a paramount step
to create next-generation NLP technologies that
deeply align with people’s needs.

References

Saleema Amershi, Maya Cakmak, William Bradley
Knox, and Todd Kulesza. 2014. Power to the people:
The role of humans in interactive machine learning.
Ai Magazine, 35(4):105-120.

Su Lin Blodgett, Solon Barocas, Hal Daumé III, and
Hanna Wallach. 2020. Language (technology) is
power: A critical survey of “bias” in NLP. In Pro-
ceedings of the 58th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 5454—
5476, Online. Association for Computational Lin-
guistics.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
Clemens Winter, Christopher Hesse, Mark Chen,
Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin
Chess, Jack Clark, Christopher Berner, Sam Mc-
Candlish, Alec Radford, Ilya Sutskever, and Dario
Amodei. 2020. Language Models are Few-Shot
Learners. arXiv:2005.14165 [cs].

Shantanu Godbole, Abhay Harpale, Sunita Sarawagi,
and Soumen Chakrabarti. 2004. Document Classi-
fication Through Interactive Supervision of Docu-
ment and Term Labels. In Knowledge Discovery in
Databases: PKDD 2004, volume 3202, pages 185-
196. Springer Berlin Heidelberg, Berlin, Heidelberg.

Braden Hancock, Antoine Bordes, Pierre-Emmanuel
Mazaré, and Jason Weston. 2019. Learning from Di-
alogue after Deployment: Feed Yourself, Chatbot!
arXiv:1901.05415 [cs, stat].

Luheng He, Julian Michael, Mike Lewis, and Luke
Zettlemoyer. 2016. Human-in-the-Loop Parsing. In
Proceedings of the 2016 Conference on Empirical
Methods in Natural Language Processing, pages
2337-2342, Austin, Texas. Association for Compu-
tational Linguistics.

Yuening Hu, Jordan Boyd-Graber, Brianna Satinoff,
and Alison Smith. 2014. Interactive topic modeling.
Machine Learning, 95(3):423-469.

Jaegul Choo, Changhyun Lee, Chandan K. Reddy, and
Haesun Park. 2013. UTOPIAN: User-Driven Topic
Modeling Based on Interactive Nonnegative Matrix

Factorization. [EEE Transactions on Visualization
and Computer Graphics, 19(12):1992-—2001.

Camille Jandot, Patrice Simard, Max Chickering,
David Grangier, and Jina Suh. 2016. _ Interac-
tive Semantic Featuring for Text Classification.
arXiv: 1606.07545 [cs, stat].

Twin Karmakharm, Nikolaos Aletras, and Kalina
Bontcheva. 2019. Journalist-in-the-Loop: Contin-
uous Learning as a Service for Rumour Analysis.


In Proceedings of the 2019 Conference on Empiri-
cal Methods in Natural Language Processing and
the 9th International Joint Conference on Natu-
ral Language Processing (EMNLP-IJCNLP): Sys-
tem Demonstrations, pages 115-120, Hong Kong,
China. Association for Computational Linguistics.

Divyansh Kaushik, Eduard Hovy, and Zachary C Lip-
ton. 2019. Learning the difference that makes
a difference with counterfactually-augmented data.
arXiv preprint arXiv: 1909.12434.

Hannah Kim, Dongjin Choi, Barry Drake, Alex En-
dert, and Haesun Park. 2019. TopicSifter: Interac-
tive Search Space Reduction through Targeted Topic
Modeling. In 2019 IEEE Conference on Visual Ana-
lytics Science and Technology (VAST), pages 35-45,
Vancouver, BC, Canada. IEEE.

Jan-Christoph Klie, Richard Eckart de Castilho, and
Iryna Gurevych. 2020. From Zero to Hero: Human-
In-The-Loop Entity Linking in Low Resource Do-
mains. In Proceedings of the 58th Annual Meet-
ing of the Association for Computational Linguistics,
pages 6982-6993, Online. Association for Computa-
tional Linguistics.

Julia Kreutzer, Shahram Khadivi, Evgeny Matusov,
and Stefan Riezler. 2018. Can Neural Machine
Translation be Improved with User Feedback?
arXiv: 1804.05958 [cs, stat].

Julia Kreutzer, Stefan Riezler, and Carolin Lawrence.
2020. Learning from Human Feedback: Challenges
for Real-World Reinforcement Learning in NLP.
arXiv:2011.02511 [cs].

Varun Kumar, Alison Smith-Renner, Leah Findlater,
Kevin Seppi, and Jordan Boyd-Graber. 2019. Why
Didn’t You Listen to Me? Comparing User Control
of Human-in-the-Loop Topic Models. In Proceed-
ings of the 57th Annual Meeting of the Association
for Computational Linguistics, pages 6323-6330,
Florence, Italy. Association for Computational Lin-
guistics.

Carolin Lawrence and Stefan Riezler. 2018. Coun-
terfactual learning from human proofreading feed-
back for semantic parsing. arXiv preprint
arXiv: 1811.12239.

Tak Yeon Lee, Alison Smith, Kevin Seppi, Niklas
Elmqvist, Jordan Boyd-Graber, and Leah Findlater.
2017. The human touch: How non-expert users per-
ceive, interpret, and fix topic models. International
Journal of Human-Computer Studies, 105:28-42.

Jiwei Li, Alexander H. Miller, Sumit Chopra,
Marc’ Aurelio Ranzato, and Jason Weston. 2017.
Dialogue Learning With Human-In-The-Loop.
arXiv: 1611.09823 [cs].

Bing Liu, Gokhan Tur, Dilek Hakkani-Tur, Pararth
Shah, and Larry Heck. 2018. Dialogue Learn-
ing with Human Teaching and Feedback in End-
to-End Trainable Task-Oriented Dialogue Systems.
arXiv: 1804.06512 [cs].

Pei-Chi Lo and Ee-Peng Lim. 2020. Interactive En-
tity Linking Using Entity-Word Representations. In
Proceedings of the 43rd International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval, pages 1801-1804, Virtual Event
China. ACM.

Sudha Rao and Hal Daumé III. 2018. Learning to Ask
Good Questions: Ranking Clarification Questions
using Neural Expected Value of Perfect Information.
arXiv: 1805.04655 [cs].

Stephanie Schoch, Diyi Yang, and Yangfeng Ji. 2020.
This is a Problem, Don’t You Agree?” Framing and
Bias in Human Evaluation for Natural Language
Generation.

Burr Settles. 2011. Closing the loop: Fast, interactive
semi-supervised annotation with queries on features
and instances. In Proceedings of the 2011 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 1467-1478, Edinburgh, Scotland,
UK. Association for Computational Linguistics.

Patrice Y. Simard, David Maxwell Chickering, Aparna
Lakshmiratan, Denis Xavier Charles, Léon Bot-
tou, Carlos Garcia Jurado Suarez, David Grang-
ier, Saleema Amershi, Johan Verwey, and Jina Suh.
2014. ICE: enabling non-experts to build models in-
teractively for large-scale lopsided problems. CoRR,
abs/1409.48 14.

Alison Smith, Varun Kumar, Jordan Boyd-Graber,
Kevin Seppi, and Leah Findlater. 2018. Closing
the Loop: User-Centered Design and Evaluation
of a Human-in-the-Loop Topic Modeling System.
In Proceedings of the 2018 Conference on Human
Information Interaction&Retrieval - IUI 18, pages
293-304, Tokyo, Japan. ACM Press.

Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M.
Ziegler, Ryan Lowe, Chelsea Voss, Alec Rad-
ford, Dario Amodei, and Paul Christiano. 2020.
Learning to summarize from human feedback.
arXiv:2009.01325 [cs].

Gaurav Trivedi, Esmaeel R Dadashzadeh, Robert M
Handzel, Wendy W Chapman, Shyam Visweswaran,
and Harry Hochheiser. 2019. Interactive nlp in clini-
cal care: Identifying incidental findings in radiology
reports. Applied clinical informatics, 10(4):655.

Eric Wallace, Pedro Rodriguez, Shi Feng, Ikuya Ya-
mada, and Jordan Boyd-Graber. 2019. Trick Me If
You Can: Human-in-the-Loop Generation of Adver-
sarial Examples for Question Answering. Transac-
tions of the Association for Computational Linguis-
tics, 7:387—-401.
