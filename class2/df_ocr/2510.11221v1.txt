arXiv:2510.11221vl [cs.CL] 13 Oct 2025

WEBROUTER: QUERY-SPECIFIC ROUTER VIA VARIATIONAL INFORMATION
BOTTLENECK FOR COST-SENSITIVE WEB AGENT

Tao Li’, Jinlong Hu’,

Yang Wang’,

Junfeng Liu", — Xuejun Liu!

‘College of Artificial Intelligence, Nanjing University of Aeronautics and Astronautics, Nanjing, China
"Hong Kong Baptist University, Hong Kong SAR
3SKLCCSE Lab, Beihang University, Beijing, China
4Pengcheng Laboratory, Shenzhen, China

ABSTRACT

LLM-brained web agents offer powerful capabilities for web
automation but face a critical cost-performance trade-off.
The challenge is amplified by web agents’ inherently com-
plex prompts that include goals, action histories, and envi-
ronmental states, leading to degraded LLM ensemble perfor-
mance. To address this, we introduce WebRouter, a novel
query-specific router trained from an information-theoretic
perspective. Our core contribution is a cost-aware Variational
Information Bottleneck (ca-VIB) objective, which learns a
compressed representation of the input prompt while explic-
itly penalizing the expected operational cost. Experiments
on five real-world websites from the WebVoyager benchmark
show that WebRouter reduces operational costs by a striking
87.8% compared to a GPT-40 baseline, while incurring only
a 3.8% accuracy drop.

Index Terms— GUI Agent, LLM Ensemble, Information
Bottleneck

1. INTRODUCTION

The advent of Large Language Models (LLMs) has catalyzed
a paradigm shift in the automation of GUI, moving from tra-
ditional script-based or rule-based methods to a new era of
LLM-brained autonomous agents (14). These agents under-
stand instructions and navigate complex digital environments
with remarkable flexibility. Web agents, in particular, stand
out for their practical uses, such as automated information
retrieval, e-commerce navigation, and data extraction, high-
lighting their important value in research and industry [5}H8}.
Modern web agents are fundamentally LLM-brained.
With substantial research dedicated to refining their com-
ponents, e.g., planners and perception modules, an agent’s
ability to understand its environment has significantly im-
proved (8). As a result, its task-completion capability now
hinges directly on the reasoning prowess of its core LLM.

+ Corresponding author
This paper is under review at ICASSP 2026.

WebRouter

oo oe:

i
! =a)
Emb.e. |
| ayl | Claude
Search Button"? % |
|
Emb . e.
|
|
|
|

ry @ <
a , !
I
ma gow
J

{eens

Fig. 1: The inference pipeline of WebRouter.

Queryq;: “Click a

However, employing state-of-the-art LLMs presents a
challenging cost-performance trade-off (i) (5). Upgrading to
a more powerful model often yields only marginal accuracy
gains while substantially increasing operational costs, e.g.,
price. This trade-off makes it impractical to use a single “best
model” in real-world web agents. Therefore, it is important
to develop a dynamic router that matches each web query to
the most cost-effective LLM capable of resolving it.

Indeed, several pioneering works have explored the con-
cept of LLM ensemble and routing [9}{13]. Within the routing
sub-domain, for example, ZOOTER employs knowledge dis-
tillation from a reward model using KL divergence (13),
while RouterDC utilizes contrastive learning to differentiate
between strong and weak models for a given query (12).
However, these methods face significant challenges in web
agent scenarios due to verbose and complex prompts, i.e.,
concatenating user goals, action histories (memory), and de-
tailed environmental states (perception). This informational
redundancy can degrade the performance of conventional
routing mechanisms, as illustrated in Fig. [2]

To address this, we propose a router trained under the
Variational Information Bottleneck (VIB) principle [14], as
compared in Fig. VIB offers a principled framework to
learn a compressed representation of the input, explicitly fil-
tering out irrelevant information while preserving only the
features critical for the routing decision. This approach yields
a more robust and efficient routing function, specifically tai-
lored for the noisy, high-dimensional inputs of web agents (1).


65.0 64.6
62.9
62.5

62,0 ea
x aL
< 60.0 as
fe) :
57.5
5

Fe
= 55.0

52.5

50.0

EL MSE VIB ca-VIB

KL
Loss Type

Fig. 2: Query routing accuracy with different loss functions.

Our contributions are threefold: 1) We are the first to
formulate web agent routing from an information-theoretic
perspective, using VIB to handle the noisy and redundant
prompts inherent to this domain. 2) We design a novel cost-
aware VIB objective that integrates a pre-defined cost func-
tion, creating a principled trade-off between accuracy and
cost. 3) We achieve state-of-the-art cost-efficiency on five
real-life websites (15), reducing operational costs by 87.8%
with only a 3.8% drop in accuracy.

2. RELATED WORK

GUI and Web Agents. LLM-brained GUI agents represent a
new paradigm, using an LLM as a cognitive “brain” to oper-
ate graphical interfaces based on natural language commands
(5}{8}. These agents typically operate in a loop, perceiving
the environment via screenshots or DOM trees, maintaining
an action history in memory, and planning subsequent ac-
tions [1][2}|4]|6|{16]. Current research focuses on improving
agent autonomy and reliability when navigating the complex
nature of real-world web environments [17/18].

LLM Ensembling and Routing. To harness the diverse ca-
pabilities of multiple LLMs, ensembling strategies such as
token-level and span-level [20], are employed [9/10/21].
LLM routing and cascading have thus emerged as a cost-
effective alternative, training a lightweight model to direct
each query to the most suitable LLM from a pool of candi-
dates e.g., ZOOTER and RouterDC (12).
Variational Information Bottleneck (VIB). The Informa-
tion Bottleneck (IB) principle provides a theoretical frame-
work for learning a compressed representation Z of an input
xX (23). This is formally expressed by the objective:

Ly = 1(Z;Y) — BI(Z; X), (1)

which seeks to maximize the mutual information with the tar-
get Y while penalizing the mutual information with the input
X, balanced by the hyperparameter (. As direct computation
of mutual information is often intractable in deep learning, the
VIB was developed, which minimizes a tractable variational

bound of this objective [14|/24|[25}.

3. METHOD OF WEBROUTER

Problem Formulation. Let M = {M,}7_, be a set of
candidate LLMs. In the context of web agents, a query q; is
a complex prompt with the user’s high-level goal, the agent’s
action history, and the current web representation. Given
a training dataset Dirain = {(@;, yi) }%_1, where y; is the
ground-truth outcome, our objective is to learn a router w.
The router ~ takes a query q; as input and outputs a proba-
bility distribution p,; = u(q;) € R* over the set of LLMs,
indicating the suitability of each model for the given task.

3.1. Scoring

To train the router, we require a supervision signal that bal-
ances task performance with operational cost. We design a
scoring function that assigns a score 3 to each query-model
pair (q;,M,). Our scoring is conditioned on task-level suc-
cess: we only generate scores for the constituent queries q;
of a task if the chosen model M; successfully completes the
overall task. This score is only non-zero if the model is suc-
cessful, and its magnitude is inversely proportional to the op-
erational cost, thus rewarding both correctness and cost.

Specifically, we first define the operational cost C(q;, Mz)
for model M, to process query q;:

C(qy, Mz) = np - of) tne: c, (2)

where n, and n, are the number of prompt and completion
tokens, respectively, and of) and ol)
per-token costs for model M;.

Next, let P(q;, Mz) € {0, 1} be a binary indicator of task
success, where 1 denotes a correct outcome. To transform the
unbounded operational costs into a bounded utility measure,
we employ an exponential utility function, U(c) = exp(—c).
This choice is motivated by its property of disproportionately
penalizing higher costs, reflecting the severe impact of ex-
pensive LLM calls. This utility is then min-max normalized

are the corresponding

across all models to produce the final cost score, Seost (CL),
which scales the utility to a range in {0, 1} where 1 represents
the most cost-effective model.

The final training score sv is the product of task success
and this normalized cost score, ensuring that only correct and
cost-effective models receive a positive supervision signal:

a = P(q;, Mt) x Scost(C{). (3)

This score creates a high-contrast supervision signal that
clearly distinguishes the most cost-effective models from
both the unsuccessful and the inefficient ones, providing a
clear signal for training our VIB-based router.

3.2. Cost-aware VIB Loss

As a web agent progresses through a task, its input prompts
become increasingly verbose and noisy. This is because each


5 — 2.5Flash
i
1

— 40

H
N
76x

a nh |

3.5 4.0 4.5 5.0
Token Count (log1o)

Fig. 3: Distribution of query token lengths for various LLMs.

query, q;, is a dynamic concatenation of the user’s high-level
goal, the current web representation, and a growing action
history from the agent’s memory. As illustrated in Fig.
this accumulation process results in a significant portion of
queries exceeding thousands of tokens, leading to substantial
informational redundancy. We posit that this inherent noise
challenges traditional routing mechanisms that rely on direct
semantic embeddings . Fortunately, the Informa-
tion Bottleneck principle [23] directly addresses this chal-
lenge. It provides a formal framework, defined in Eq. (ip,
for learning a compressed representation of the input that is
minimally sufficient for the downstream task, thus inherently
filtering out superfluous information.

To incorporate both cost and performance into a unified
objective, we derive a novel cost-aware VIB loss. We begin
with the standard variational bound of the IB objective [14].
which is minimized during training:

Lyip = Ep(z|q)[— log pe(yl2)] + PKL [pa(zla)|ir(2)], A

where po(z|q) is the stochastic encoder that maps an input
query q to a latent representation z, and pg(y|z) is the de-
coder that predicts the target model distribution y from z. The
first term is a standard prediction loss (cross-entropy) ensur-
ing accuracy, while the second KL-divergence term enforces
the compression

To specifically address the token-level redundancy in web
agent prompts, we implement the compression term by learn-
ing a stochastic binary mask, inspired by (26]. We define the
latent representation z as the element-wise product of the in-
put’s feature representation hg and a stochastic binary mask
m: z = m© hg. With this masking formulation, the KL-
divergence term simplifies, as it becomes proportional to the
KL-divergence of the mask distribution after dropping terms
that are constant w.rt the model parameters:

KL(po(2/q)|I7(z)) « KL(pa(mlq)||r(m)). GB)

After dropping the entropy of the input features, which is con-
stant w.rt. the model parameters, the effective regularization
term becomes simply KL(p9(m|q)||7(™)).

On this basis, we introduce our cost-aware VIB (ca-VIB)
loss. We augment the standard VIB objective with an explicit

a
uo

huiw
uo

Accuracy(%)

b
o

—<— LR=1le-5
—&— LR=1.5e-5
~~) LR=2e-5

w
a

w
o

i?) 480 1000 1520 2040
#i\teration

Fig. 4: Training loss curves for different learning rates.

cost regularization term that represents the expected opera-
tional cost of the router’s decision. For a training set Dirain of
N samples, our final objective to minimize is:

N

1
LeaVIB = WN S- ( EL n9 (zila;) = log ps (yilzi)]
7=1
+ 8 - KL|pe(milq;)||r(m)]
T
+ A+ Epo (zila:) [Sopot cum] )
t=.

(6)
where A is a hyperparameter controlling cost-sensitivity, and
C(M,) is the pre-defined, query-agnostic unit cost of invok-
ing model M,. We use a unit cost (e.g., of) +l from Eq.
for a single token) rather than the full query-specific cost be-
cause the latter depends on the completion length, which is
unknown at routing time. This formulation allows the loss to
directly penalize the inherent expense of selecting a model.

The learning process is guided by the training scores 3
defined in Eq. (3). The prediction loss term, E[— log pg(y;|zi)].
is a cross-entropy loss between the router’s output and a tar-
get distribution derived from a softmax over the score vec-
tor s;. By jointly minimizing this prediction error and the
expected operational cost, WebRouter learns to generate a
compressed representation z; that is sufficient to select the
most cost-effective LLM, effectively learning to replicate the
high-contrast signal embedded in our scoring function.

4. EXPERIMENT

4.1. Experiment Setup

Dataset. We evaluate WebRouter on five real-world web-
sites from WebVoyager dataset (15): Apple, Arxiv, Cours-
era, Google, and Huggingface. Following the data prepro-
cessing in (5). each website contains at least 46 distinct tasks
for evaluation. Due to the significant API costs, our training
set, Dtrain, 18 limited to 11,800 samples.

Baselines. We compare WebRouter against strong baselines,
including the state-of-the-art web agent, i.e., browser-use
configured with individual LLM backbones, and the Rou-
terDC router. All models were accessed through the


Table 1: Main Results of WebRouter. The best is in bold and the second-best is underlined.

2.5Flash 4.1Mini 4o routerDC WebRouter
Dataset —— = = ; — :
#steps acc.(%) price($) | #steps acc.(%) price($) | #steps acc.(%) price($) | #steps acc.(%) price($) | #steps acc.(%) price($)

Apple 22.26 34.8 0.98 | 11.39 78.3 0.52 7.65 87.0 0.80 9.13 78.3 0.16 9.00 78.3 0.12
Arxiv 21.43 34.8 1.21 13.04 82.6 0.84 7.65 91.3 1.04 10.00 69.6 0.24 8.70 87.0 0.14
Coursera 21,22, 52.2 1.03 10.61 82.6 0.49 8.52 82.6 1.04 7.57 78.3 0.14 7.96 82.6 0.12
Google 16.13 65.2 0.80 7.52 87.0 0.34 5.70 82.6 0.94 9.00 31.8 0.17 6.14 82.6 0.08
Huggingface | 21.43 34.8 1.05 8.52 78.3 0.36 8.61 87.0 1.08 | 11.30 81.0 0.21 | 10.10 81.0 0.16
Average 20.49 44.3 1.01 10.22 = 81.7 0.51 7.63 86.1 0.98 9.40 67.8 0.18 8.38 82.3 0.12

1.01 0.93 MmPrompt Price 350} 336.2
1.0 (mami Completion Price
| 300
= 2230 216.9 222.8
& a
a ~— 200 194.1
gos 0.51 v 168.8
= 72% ae 27% E 150
0.4
a 3 100
So 0.1
02 ao OA oe
84% rs2% |
0.0 0

2.5Flash = 4.1Mini 4o
Method

RouterDC WebRouter 2.5Flash = 4.1Mini 40

Method

RouterDC WebRouter

(a) Price breakdown. (b) Average running time.

Fig. 5: Analysis of cost composition and execution time.

OpenRouter API, and all pricing is based on their listed rates:
Gemini-2.5Flash (0.30/M in, 2.50/M out), GPT-4.1Mini
(0.40/M, 1.60/M), and GPT-40 (5/M, 15/M).
Implementation Details. We use mDeBERTaV3-base
as the query encoder 7 with a 768-dimensional embedding
space. The router is trained for 2000 steps using the Adam W
optimizer with a learning rate of 2 x 10~°, which we selected
based on its stable convergence as shown in Fig [4] We set
ca-VIB loss with 6 = 0.3 and A = 0.2.

4.2. Experimental Result

Main Results. Table [I] presents our main results, evaluating
performance across task accuracy (acc.), the average price,
and the average number of steps. WebRouter demonstrates a
superior performance-to-cost trade-off. This is most evident
when compared to browser-use with GPT-40: WebRouter re-
duces the operational cost by a striking 87.8% (from 0.98$
to 0.12$) while incurring only a minor 3.8% drop in accu-
racy. This cost reduction is a direct outcome of the cost-
regularization term in our ca-VIB loss (Eq. |6), which explic-
itly trains the router to favor less expensive models. Cru-
cially, this efficiency is achieved while maintaining high accu-
racy because the VIB successfully distills the true complexity
from verbose prompts. Furthermore, WebRouter outperforms
the competing routing baseline, RouterDC, in both accuracy
(82.3% vs. 67.8%) and efficiency (8.38 vs. 9.40 steps), which
we attribute to VIB’s superior ability to handle the informa-
tional redundancy inherent in web agent queries.

Cost and Running Time. Fig. 5[a) analyzes the cost compo-

0.6

0.5

0.4
x

0.3

0.2

aT 02 #03 O04 O58 0.6
B

(a) Hyperparameter sensitivity.

(b) Learned query affinity.

Fig. 6: Analysis of hyperparameters and representations.

sition, revealing that prompt tokens, as defined in Eq. (2). con-
tribute to over 70% of the total price for all models. This high-
lights the importance of our cost-aware ca-VIB loss, which
directly penalizes the selection of inherently expensive mod-
els at routing time. In terms of running time(Fig. [{b)), We-
bRouter is only marginally slower than the GPT-40 baseline
(14%), demonstrating that its significant 87.8% price reduc-
tion comes at a minimal cost to execution speed.

Ablation and Analysis. We analyze the sensitivity of our
key hyperparameters ( and X in Fig. [6{a). The model’s per-
formance is stable across a range of values, with optimal
accuracy achieved around A = 0.4. Fig. [6{b) visualizes
the router’s learned representations, showing a clear affinity
between queries and the embeddings of their optimally se-
lected LLMs (measured by cosine similarity). This indicates
that our VIB-based approach successfully learns meaningful,
task-relevant features for the routing decision.

5. CONCLUSION

In this paper, we introduced WebRouter, a novel query-
specific router for LLM-brained web agents. We addressed
the dual challenges of high operational costs and noisy, redun-
dant input prompts by proposing a cost-aware VIB loss. Our
experiments show that this information-theoretic approach
greatly reduces web agent operating costs with minimal im-
pact on task accuracy.


6. REFERENCES

[1] Deng X, Gu Y, Zheng B, and et al., “Mind2web: To-

[14

aay

wards a generalist agent for the web,” in Jn Proc.

NeuriPS, 2023.

Wu J, Li B, Fang R, and et al., “Webdancer: Towards
autonomous information seeking agency,’ CoRR, vol.
abs/2505.22648, 2025.

Wu J, Yin W, Jiang Y, and et al., “Webwalker: Bench-
marking Ilms in web traversal,” in In Proc. ACL, 2025,
pp. 10290-10305.

Zhou S, Xu F F, Zhu H, and et al., ““Webarena: A real-
istic web environment for building autonomous agents,”
in In Proc. ICLR, 2024.

Magnus Miiller and Gregor Zunié, “Browser use: En-
able ai to control your browser,” 2024.

Mozannar H, Bansal G, Tan C, and et al., “Magentic-ui:

Towards human-in-the-loop agentic systems,’ CoRR,
vol. abs/2507.22358, 2025.
Luo T, Logeswaran L, Johnson J, and et al, “Visual

test-time scaling for gui agent grounding,” CoRR, vol.
abs/2505.00684, 2025.

Zhang C, He S, Qian J, and et al., “Large language

model-brained gui agents: A survey,’ CoRR, vol.
abs/2411.18279, 2024.
Park S, Liu X, Gong Y, and et al., “Ensembling

large language models with process reward-guided tree
search for better complex reasoning,’ CoRR, vol.
abs/2412.15797, 2024.

Chen Z, Li J, Chen P, and et al., “Harnessing multi-
ple large language models: A survey on Ilm ensemble,”
CoRR, vol. abs/2502.18036, 2025.

Dekoninck J, Baader M, and Vechev M, “A unified ap-
proach to routing and cascading for Ilms,” CoRR, vol.
abs/2410.10347, 2024.

Chen S., Jiang W., Lin B., Kwok J., and Zhang Y., “Rou-
terdc: Query-based router by dual contrastive learning
for assembling large language models,’ in In Proc.
NeuriPS, 2024.

Lu K, Yuan H, Lin R, and et al., “Routing to the
expert: Efficient reward-guided ensemble of large lan-
guage models,” in In Proc. NAACL, 2024, pp. 1964—
1974.

Alemi A A, Fischer I, Dillon J V, and et al, “Deep
variational information bottleneck,” CoRR, vol.
abs/1612.00410, 2016.

[15]

[19

—“

[20]

[21

sy

[22]

a
N
(eS)

fit

[24

sy

[25

“4

[26

=

[27]

He H, Yao W, Ma K, and et al, “Webvoyager: Building
an end-to-end web agent with large multimodal mod-
els,’ CoRR, vol. abs/2401.13919, 2024.

Lt X H, Kamath G, Mosbach M, and et al., “Build the
web for agents, not agents for the web,’ CoRR, vol.
abs/2506.10953, 2025.

Jia C, Luo M, Dang Z, and et al, “Agentstore: Scalable
integration of heterogeneous agents as specialized gen-
eralist computer assistant,’ in In Proc. ACL, 2025, pp.
8908-8934.

Sun Q, Cheng K, Ding Z, and et al, “Os-genesis: Au-
tomating gui agent trajectory construction via reverse
task synthesis,” in In Proc. ACL, 2025, pp. 5555-5579.

Huang Y, Feng X, Li B, and et al, “Ensemble learn-
ing for heterogeneous large language models with deep
parallel collaboration,” in In Proc. NeuriPS, 2024, pp.
119838-119860.

Fu Y, Zhu Y, Chai J, and et al., “Rlae: Reinforce-
ment learning-assisted ensemble for Ilms,’ CoRR, vol.
abs/2506.00439, 2025.

Pan Z, Zhang K, Zhao Y, and et al., “Route to reason:
Adaptive routing for Ilm and reasoning strategy selec-
tion,’ CoRR, vol. abs/2505.19435, 2025.

Yue M, Zhao J, Zhang M, and et al, “Large lan-
guage model cascades with mixture of thoughts rep-

resentations for cost-efficient reasoning,’ CoRR, vol.
abs/2310.03094, 2023.
Tishby N, Pereira F C, and Bialek W., “The infor-

mation bottleneck method,” CoRR, vol. arXiv preprint
physics/0004057, 2000.

Goldfeld Z, Berg E, Greenewald K, and et al, “Estimat-
ing information flow in deep neural networks,” CoRR,
vol. abs/1810.05728, 2018.

Saxe A M, Bansal Y, Dapello J, and et al, “On the infor-
mation bottleneck theory of deep learning,” Journal of
Statistical Mechanics: Theory and Experiment, vol. 12,
pp. 124020, 2019.

Paranjape B, Joshi M, Thickstun J, and et al., “An infor-
mation bottleneck approach for controlling conciseness
in rationale extraction,’ CoRR, vol. abs/2005.00652,
2020.

He P, Gao J, and Chen W., “Debertav3: Im-
proving deberta using electra-style pre-training with
gradient-disentangled embedding sharing,’ CoRR, vol.
abs/2111.09543, 2021.
