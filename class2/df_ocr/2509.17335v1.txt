2509.17335v1 [cs.SE] 22 Sep 2025

arXiv

BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via

Automated Fuzz Testing

MINGXUAN XIAO, Hohai University, China

YAN XIAO*, Sun Yat-sen University, China
SHUNHUI Jl, Hohai University, China

JIAHE TU, Hohai University, China
PENGCHENG ZHANG, Hohai University, China

Fuzzing has shown great success in evaluating the robustness of intelligent natural language processing (NLP) software. As large
language model (LLM)-based NLP software is widely deployed in critical industries, existing methods still face two main challenges: @
testing methods are insufficiently coupled with the behavioral patterns of LLM-based NLP software; @ fuzzing capability for the testing
scenario of natural language generation (NLG) generally degrades. To address these issues, we propose BASFuzz, an efficient Fuzz
testing method tailored for LLM-based NLP software. BASFuzz targets complete test inputs composed of prompts and examples, and
uses a text consistency metric to guide mutations of the fuzzing loop, aligning with the behavioral patterns of LLM-based NLP software.
A Beam-Annealing Search algorithm, which integrates beam search and simulated annealing, is employed to design an efficient
fuzzing loop. In addition, information entropy-based adaptive adjustment and an elitism strategy further enhance fuzzing capability.
We evaluate BASFuzz on six datasets in representative scenarios of NLG and natural language understanding (NLU). Experimental
results demonstrate that BASFuzz achieves a testing effectiveness of 90.335% while reducing the average time overhead by 2,163.852

seconds compared to the current best baseline, enabling more effective robustness evaluation prior to software deployment.
CCS Concepts: » Software and its engineering — Software testing and debugging; Search-based software engineering.
Additional Key Words and Phrases: Test Generation, Fuzzing, Robustness, Natural Language Processing

ACM Reference Format:
Mingxuan Xiao, Yan Xiao, Shunhui Ji, Jiahe Tu, and Pengcheng Zhang. 2025. BASFuzz: Towards Robustness Evaluation of LLM-based
NLP Software via Automated Fuzz Testing. 1, 1 (September 2025), 33 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn

1. Introduction

Large language model (LLM)-based software, as a crucial component of intelligent software, refers to software systems
that utilize LLMs as core components to perform language understanding, generation, or reasoning tasks [2, 48]. With
the remarkable progress of LLMs in numerous natural language processing (NLP) tasks, LLM-based NLP software
has gradually evolved from research prototypes into deployable product systems. It has been widely applied in practical

“Corresponding author

Authors’ Contact Information: Mingxuan Xiao, xiaomx@hhu.edu.cn, Hohai University, Nanjing, China; Yan Xiao, Sun Yat-sen University, Shenzhen,
China, xiaoy367@mail.sysu.edu.cn; Shunhui Ji, Hohai University, Nanjing, China, shunhuiji@hhu.edu.cn; Jiahe Tu, Hohai University, Nanjing, China,
tujh@hhu.edu.cn; Pengcheng Zhang, Hohai University, Nanjing, China, pchzhang@hhu.edu.cn.

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components
of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on
servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.

© 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.

Manuscript submitted to ACM

Manuscript submitted to ACM 1


2 M. Xiao et al.

Please translate the following
German text into English: Der
Kdufer darf den Vertrag unter

bestimmten Bedingungen kiindigen.

Please translate the following
German clause into English: Der
Kdufer darf den Vertrag in ee

pertebation bestimmten Fallen kiindigen.

la la

s s

9 The buyer may terminate the 9 The buyer must terminate the
{eh contract under certain conditions. fee contract under certain conditions.

Fig. 1. An example of robustness flaws in LLM-based NLP software. In the contract translation scenario, slight perturbations (red) in
the prompt and example section cause the software to mistranslate a clause expressing permission to terminate the contract into an
obligation to terminate.

1
1
H
'
1 subtle
H
1
1
H
H

scenarios such as machine translation software [54], intelligent question-answering assistants [53], and financial
analysis systems [68]. However, similar to traditional intelligent software, concerns have been raised regarding the
robustness of LLM-based NLP software [10]. Specifically, when confronted with carefully crafted inputs containing subtle
perturbations, the software’s output often exhibits highly inconsistent behaviour, resulting in semantic misjudgments
or logical errors, thereby jeopardizing software reliability and user trust. As shown in Figure 1, in a contract translation
scenario, the translation software, due solely to subtle wording mutations in the input, mistranslated a clause expressing
permission to terminate a contract into an obligation to terminate, causing a significant semantic error. Such behavioural
instability not only affects user experience but may also trigger catastrophic consequences in high-stakes domains such
as law [20] and healthcare [50], including invalid contracts and ambiguous attribution of breach liabilities. Therefore,
testing LLM-based NLP software to evaluate its robustness is of critical importance [30, 82].

In the software development process, testing has always been regarded as a critical means to ensure software quality
and uncover potential flaws. Current work primarily focuses on jailbreak robustness [79, 80], fairness robustness [59],
and factual robustness [22]. These methods are respectively used to evaluate whether LLM-based software can resist
toxic prompting, maintain neutrality towards sensitive attributes (e.g., gender, race), and preserve factual consistency
and accuracy. Although these directions are of significant value in ensuring software reliability and security, adversarial
robustness, as a form of robustness more closely aligned with real-world applications, remains insufficiently explored
in current research [2, 49], with this gap being particularly evident in natural language generation (NLG) tasks.
Unlike natural language understanding (NLU) tasks such as text classification or semantic entailment, user inputs
in NLG tasks are open-ended and compositional natural language texts, making them highly susceptible to adversarial
perturbations [83]. For example, input perturbations similar to those shown in Figure 1 may not necessarily originate
from malicious attackers. However, they could also arise from challenging or borderline content unintentionally created
by users during actual usage, leading the software to exhibit severely inconsistent behaviour. More critically, such flaws
are often only exposed through user feedback after software deployment, resulting in significantly increased costs for
fault remediation and rollback [25]. Therefore, there is an urgent need for a pre-deployment adversarial robustness
testing method to evaluate the robustness of LLM-based NLP software in NLG tasks.

Fuzz testing is a widely adopted automated testing technique. Its core principle is to automatically generate a large
number of mutated input examples to explore the boundaries of software behaviour and identify hidden vulnerabili-
ties [41]. This approach has proven effective in security testing [70] and vulnerability discovery [18]. In recent years,
with the rapid adoption of intelligent software, researchers have extended fuzz testing to deep learning models [72].

Manuscript submitted to ACM


BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing 3

Target systems include image classifiers [21], speech recognition systems [42], and text classification models [65]. These
studies typically introduce small input perturbations or guide model decision paths to expose the inconsistent behaviours
of neural networks (named threat models) under specific conditions, thereby enabling robustness evaluation. Existing
fuzzers can be classified into generation-based, learning-based, and mutation-based approaches [64]. Generation-based
fuzzers create input data offline using predefined mutation rules. Learning-based fuzzers employ neural networks to
generate test cases. Mutation-based fuzzers iteratively execute fuzzing loops following mutation rules, often combined
with search-based software engineering techniques [5]. However, all three fuzzing approaches face the following
challenges when used in testing LLM-based NLP software:

Challenge #1: Insufficient coupling between testing methods and the behavioural patterns of LLM-based
NLP software. Most existing robustness testing methods for LLM-based NLP software focus on NLU tasks such as text
classification [16] and sentiment analysis [66]. These tasks have relatively fixed output structures and limited label
sets. Their primary goal is to evaluate the software’s sensitivity under structured output settings, making it easier to
identify the robustness flaws caused by perturbed inputs. In practical applications, however, users more frequently
interact with LLM-based software through NLG tasks, including machine translation [54] and dialogue generation [35].
These tasks exhibit highly open input contexts, diverse output spaces, and more complex control over linguistic styles,
which makes conventional testing approaches inadequate for capturing robustness defects [2, 49]. As illustrated in
Figure 1, the software produces semantically directional mistranslations when faced with subtle linguistic perturbations
(e.g., “unter Bedingungen” vs. “in Fallen”), highlighting the unique challenges of adversarial robustness in NLG tasks.
Furthermore, the multilingual nature of tasks such as translation amplifies this problem, requiring testing methods
with stronger semantic modelling and cross-linguistic adaptation capabilities.

Challenge #2: Degraded fuzzing capability in the testing scenario of NLG. We evaluate the performance
of existing fuzzing techniques [17] when applied to the NLG scenario. The evaluation includes fuzzers designed for
LLM-based NLU tasks [66, 67, 69] and those developed for traditional deep neural network (DNN)-based NLG
tasks [12, 27, 51, 57]. The former shows a reduction of 14.198%-85.191% in testing effectiveness on generative tasks,
primarily due to their inability to adapt to open-ended output spaces. The latter have shown success in generative
settings; however, when transferred to LLM-based software, their testing efficiency is severely constrained and fails to
capture the dynamic response behaviours of threat models. These findings suggest that when encountering LLM-based
NLP software with strong generalisation capabilities and complex language generation patterns [11], even after unifying
and refining the objective function, the original mutation strategies and sampling logic are insufficient to expose
robustness flaws. Therefore, it is essential to design an efficient fuzzing approach with stronger task adaptability for
NLG tasks, enabling effective robustness evaluation in open-ended generative scenarios.

Proposed Technique. To address the above challenges, this paper proposes BASFuzz, a fuzzing approach for
evaluating the adversarial robustness of LLM-based NLP software. To align with real-world software usage scenarios,
BASFuzz adopts a holistic input perturbation strategy, treating user prompts and task examples as a unified testing unit.
Considering the open-ended nature of output spaces in generative tasks, BASFuzz employs the bilingual evaluation
understudy (BLEU) score [47] as a text consistency metric to guide fuzzing towards perturbations that are minimal
in input mutation but impactful on output, thereby mitigating the coupling gap identified in Challenge #1. To ensure
that perturbed test cases remain semantically aligned with the original input, BASFuzz introduces a mutation strategy
based on multilingual word network [7] and LLM-based word embeddings [31]. By combining perturbations with
semantic constraints, it constructs a diverse set of variants, making it particularly effective for robustness evaluation in

multilingual NLG tasks. During iterative exploration of the perturbation space, conventional search methods often fall
Manuscript submitted to ACM


4 M. Xiao et al.

into local optima due to the high-dimensional input space of LLM-based software. To mitigate this, BASFuzz integrates
beam search [38] with a simulated annealing [29] mechanism to form a dynamic search process with global exploration
capability. Beam search maintains multiple perturbation paths in parallel to improve coverage of the input space. At
the same time, simulated annealing allows the acceptance of perturbation paths with slight quality degradation to
escape early search traps, enabling the discovery of deeper robustness. Considering the constraint of computational
resources in practical testing, BASFuzz incorporates the information entropy [52] of candidate perturbation distributions
as a dynamic signal to adjust the beam width in real-time. In high-entropy phases, the search expands to enhance
exploration; in low-entropy phases, it converges to improve efficiency. This adaptive mechanism achieves efficient
testing while enhancing the effectiveness of robustness evaluation.

We select five threat models with varying parameter scales and three real-world machine translation datasets to
evaluate BASFuzz’s effectiveness in multilingual settings. The baselines include six of the most recent and representative
robustness testing approaches to ensure broad comparability of results. Experimental results show that existing methods
are insufficient for effectively testing LLM-based NLP software. For example, VFA achieves a testing success rate
of 57.958% on Llama3_70B, whereas BASFuzz reaches 89.138%, indicating its ability to uncover significantly more
robustness flaws during the software testing phase. We further evaluate the quality of BASFuzz-generated test cases
using change rate, perplexity, and grammatical error count. Across 15 experimental settings, BASFuzz achieves an
average change rate of only 3.748%, with both perplexity and grammatical errors lower than those of existing baselines.
This demonstrates that BASFuzz produces more covert input perturbations and generates more fluent test cases.
BASFuzz not only efficiently exposes robustness flaws in LLM-based NLP software across different languages and threat
model scales, but also demonstrates strong test transferability and task scalability. The main contributions of this

work are as follows:

e Method. We propose BASFuzz, a mutation-based fuzzing method designed for LLM-based NLP software to evaluate
adversarial robustness in NLG tasks. BASFuzz supports black-box testing and is built to address the weak mutation
capability and low testing effectiveness of existing approaches in generative tasks. It combines a word network
and LLM-based word embeddings to automatically generate multidimensional semantic perturbations. The input
perturbation space is explored using a beam-annealing search algorithm with adaptive path maintenance and
diversity guidance, enhancing the evaluation of software robustness.

e Tool. We implement and release an open-source mutation-based fuzzing tool [17] that provides full automation,
covering objective function selection, input perturbation generation, and search control. The tool provides a
unified interface and configuration mechanism, eliminating task-type restrictions inherent in existing testing
frameworks. It supports multi-task extension: testing strategies originally designed for NLG tasks can be directly
applied to NLU tasks and vice versa, significantly improving the scalability of current robustness testing methods.

e Study. We conduct a series of comparative and ablation studies on three multilingual translation datasets using
five mainstream LLMs as threat models and six baseline methods. Experimental results demonstrate that BASFuzz
outperforms existing approaches in terms of testing effectiveness, efficiency, and scalability. It demonstrates
stronger robustness evaluation capability and better adaptability to practical applications, providing empirical

evidence for advancing robustness testing in LLM-based NLP software engineering.

The remainder of this paper is organised as follows: Section 2 introduces adversarial robustness and conventional search
strategies. Section 3 describes the research motivation for designing BASFuzz. Section 4 presents the BASFuzz testing
method. Section 5 details the datasets, threat models, and six baselines used in the experiments. Section 6 evaluates the

Manuscript submitted to ACM


BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing 5

fuzzing capability of BASFuzz across six metrics. Section 7 discusses threats to validity. Section 8 reviews existing work

on the robustness testing of NLP software. Finally, Section 9 concludes the paper.

2 Background
2.1. Robustness of LLM-based NLP software

LLMs are emerging as general-purpose natural language processing engines and are increasingly becoming the core
computational components of intelligent software. In recent years, LLM-based NLP software has been widely deployed
in various safety-critical scenarios, such as traffic rule parsing in autonomous driving [15], text classification in financial
trading platforms [23], and question answering generation in medical decision-support systems [58]. Robustness issues
are particularly prominent in LLM-based software. LLMs operate in high-dimensional embedding spaces and rely on
prompt-example combinations to model semantics, making them extremely sensitive to the overall input [66, 75].
Compared to traditional DNNs, LLMs contain orders of magnitude more parameters. They are trained on far more
complex data, which amplifies their sensitivity to input details and further increases behavioural uncertainty. Prior
studies have shown that LLM-based software often produces entirely different outputs for inputs with slight mutations in
expression. This phenomenon is especially pronounced in generative tasks, posing a direct threat to software reliability
and user trust.

According to the IEEE definition [24], robustness in software engineering is “degree to which a system, product
or component performs specified functions under specified conditions for a specified period of time”. In the machine
translation software, let the threat model ¥ be trained on (Tx, Ty) ~ D, where T, is the source-language text and T, is
the corresponding reference translation. A practical user input can be formed by concatenating a prompt template P
with T,, denoted as I = [P; T,.]. We focus on the following question: for perturbed P’ and (Ty, T,) ~ D’ # D, yielding
an adversarial test case Iggy = [P’;T,], can the software generate a translation result that remains as consistent as
possible with T,? If the software frequently produces outputs significantly different from T, on P’ and D’, it indicates a
lack of necessary robustness when faced with natural language mutations. Therefore, the above robustness testing
problem can be formalized as finding an adversarial input Iggy within the perturbation space C(J,,;), such that subtle
perturbations can lead to changes in the software output [56]:

argmin A(Iori, Iadv)
Tadv€CUori) (1)
s.t. F (lori) # F adv)

where A(Iori; Iadv) denotes the perturbation magnitude metric, such as word replacement rate or text perplexity, and C
represents the perturbation constraints to ensure the stealthiness of test cases. With the widespread deployment of
LLM-based NLP software in mission-critical domains, developing efficient and scalable testing methods has become a

key step in evaluating software robustness.

2.2 Beam Search

Beam search is a heuristic search strategy widely used to approximate optimal solutions in high-dimensional discrete
spaces, particularly in problems involving a combinatorial explosion with exponential-scale output spaces. The algorithm
was first applied to speech recognition [38], which has since been extended to natural language generation [4] and

code completion [77]. Compared with single-path greedy search [13], beam search retains multiple candidate paths

Manuscript submitted to ACM


6 M. Xiao et al.

at each step, striking a balance between accuracy and computational efficiency. This design provides greater search
diversity and a stronger ability to avoid local optima.

The core idea of beam search is that, at each generation step t, the algorithm selects the top-k candidate paths (where
k is the beam width) based on their cumulative scores and expands them before pruning. Taking machine translation as
an example, let the current search state at step t — 1 be the candidate set B,_ = y{7',..., yess where the score of each
path yj! is denoted as S(y!~'). The expansion and selection at step ¢ proceed as follows:

(1) Expansion: For each path y/~' in B;_1, generate extended paths y/ = [yj~’

;w] according to the next-token
probability distribution p(-|y{~) predicted by the machine translation model.

(2) Scoring: Compute the cumulative score S(y;) for each extended path, typically using a log-probability accumulation:

S(yj) = log p(w... ws) = >) log p(w; | we) (2)

j=l

(3) Pruning: Select the top-k paths with the highest scores from all extensions to form the new candidate set B;.

(4) Termination: When all candidate paths satisfy stopping conditions, such as containing an end-of-sequence token
or reaching the maximum length, output the highest-scoring path as the final result.

Beam search imposes a width constraint at each step to control computational complexity and avoid the exponential
cost of full-space search. Although beam search is effective in handling exponential search spaces, its use in robustness
testing for LLM-based NLP software faces limitations. A fixed beam width often leads to premature convergence in
the perturbation space. Search paths become dominated by the initial quality of mutations, increasing the risk of
local optima. Moreover, fixed-width strategies fail to account for the dynamic complexity of the perturbation process,
making it difficult to adapt resource allocation to the evolving search state. This limitation can result in computational

redundancy or the omission of critical perturbation paths.

2.3. Simulated Annealing

Simulated annealing is a global optimization algorithm based on stochastic search, inspired by the thermodynamic
behaviour of metal annealing in solid-state physics. First introduced by Kirkpatrick et al. [29] in 1983, simulated
annealing has been widely applied to combinatorial optimization problems, including circuit layout [34], production
scheduling [33], and feature selection [44]. In recent years, simulated annealing has also been adopted in software
testing [84] and deep learning [28] to prevent search processes from being trapped in local optima and to enhance
diversity in exploring the perturbation space.

Simulated annealing constructs a non-greedy search process with a temperature control mechanism. At high
temperatures in the early search phase, it allows acceptance of inferior solutions to facilitate broad exploration of the
solution space. As the temperature gradually decreases, the algorithm transitions to fine-grained local optimization,
effectively mitigating the tendency of traditional greedy search to converge to local optima. Let the objective be to
minimize a target function L£(s), where s denotes a state in the search space, such as a candidate test case. The standard
simulated annealing procedure consists of:

(1) Initialization: Randomly select an initial state so and set the initial temperature temp.

(2) Perturbation generation: Generate a candidate solution s’ in the neighbourhood of the current state s;.

(3) Energy evaluation: Compute the change in the objective function, AL = L£(s’) — L(s;).

(4) Probabilistic acceptance: Apply the Metropolis criterion [43] to decide whether to accept s’:

e If L(s’) < L(s;): always accept.
Manuscript submitted to ACM


BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing 7

e If L(s’) = L(s;): accept with probability p = exp(-AL/tem;), where tem; is the current temperature.

(5) Temperature update: Update the temperature using the annealing schedule tem; — temy,,1.

(6) Termination: Stop when the maximum number of iterations is reached or the temperature drops below a predefined
threshold.

A common temperature schedule is exponential decay, ten; = y - term;_,, where y € (0, 1) is the cooling factor. As
tem, decreases, the algorithm shifts from high-temperature global exploration with high freedom to low-temperature
local convergence, achieving a controlled balance between exploration and exploitation. However, when applied to
robustness testing, especially for NLG tasks in LLM-based software, simulated annealing exhibits two limitations. It
performs perturbation jumps on a single path without a path management mechanism, making it prone to missing
high-quality perturbation sequences. Additionally, fixed cooling schedules fail to adapt to the dynamic fluctuations of
the perturbation process, thereby reducing testing efficiency. To overcome these limitations, this paper designs a beam-
annealing search strategy (cf. Section 4.5) that integrates multi-path management of beam search with logarithmic-decay

simulated annealing, thus achieving a better balance between global exploration and testing efficiency.

3. Motivation

The software testing phase inevitably incurs substantial labor and resource costs. In the United States alone, software
testing labor expenses amount to approximately 48 billion USD annually [14]. In domains such as legal contracts [20]
and financial analysis [68], constructing test cases and validating results for NLP software often require domain
experts, further increasing testing investment. The high human and time costs of manual testing [78] severely limit its
feasibility for robustness evaluation of LLM-based software and make it prone to missing edge cases. Moreover, the
input feature space of LLM-based software is not a finite discrete set in the traditional sense. Inputs are represented in a
high-dimensional discrete word embedding space; even for short sentences in translation or classification tasks, the
number of potential linguistic variants reaches billions. This immense combinatorial space makes it virtually impossible
to manually craft test cases that exhaustively cover potential risk variants. Therefore, robustness testing for LLM-based
NLP software must rely on automated testing to balance effectiveness and efficiency.

In terms of testing paradigms, white-box methods depend on access to internal gradients and network structures.
However, in most real-world engineering scenarios, LLMs are provided as encapsulated APIs or commercial services,
leaving developers without access to internal parameters or gradients. Even with open-source models, the sheer scale
of LLM parameters makes efficient access during testing impractical [9]. In contrast, black-box testing is not only
a practical necessity but also inherently advantageous for supporting diverse testing scenarios and task generality.
Black-box approaches evaluate robustness solely through input-output interactions, avoiding dependency on threat
model internals. For these reasons, BASFuzz is designed to perform robustness testing under black-box settings. It is
worth noting that many current generation-based fuzzers [61, 76] adopt a static testing paradigm in which a large set
of test cases is generated offline, then executed in batch against the threat model. This design introduces two critical
issues. First, static test data quickly becomes obsolete as LLMs are updated, failing to capture the behavioral patterns
of new model versions. Second, generating large-scale offline data carries a high risk of overlapping with training
data, which may lead to data leakage and biased testing results. Learning-based fuzzers [36, 60, 71] attempt to address
this by training DNNs to learn input perturbation distributions. However, during testing, they must execute both the
fuzzer and the target LLM simultaneously, which significantly increases runtime. Our empirical evaluation of popular
learning-based fuzzers [19, 32] on LLM-based NLP software shows that generating a single valid test case requires more

Manuscript submitted to ACM


8 M. Xiao et al.

than 300 minutes. This result fundamentally contradicts the goal of automated testing, which is to reduce testing costs
and accelerate software iteration. BASFuzz belongs to the mutation-based fuzzing class [21, 48, 65, 79]. Such fuzzers
perform an iterative search over candidate variants and dynamically adjust mutation strategies based on real-time
feedback from the threat model. It does not rely on secondary training or offline data storage, thereby avoiding dataset
obsolescence and enabling continuous exploration of the perturbation space. This capability significantly improves the
detection of complex robustness flaws. For NLG tasks, where the output space is highly open-ended, mutation-based
fuzzing establishes a closed-loop validation process between perturbations and software responses, making it more
adaptive and practically valuable.

To address the high-dimensional and discrete nature of the perturbation space in LLM-based NLP software, we
design a new hybrid heuristic search algorithm to perform iterative mutation fuzzing. In BASFuzz, beam search is
introduced to address the combinatorial explosion of natural language inputs. Effective software testing requires broad
coverage of such high-dimensional yet semantically sensitive spaces. Single-path greedy perturbation easily converges
prematurely, missing effective test inputs. Beam search mitigates this by maintaining multiple perturbation paths in
parallel at each iteration, delaying convergence decisions and improving both coverage and perturbation diversity,
which satisfies the software engineering requirement for representative test cases. At the same time, considering the
nonlinear and highly sensitive decision boundaries of LLM outputs, we integrate simulated annealing into the beam
search process. Its core is a temperature-controlled probabilistic acceptance mechanism that allows degraded paths
to be retained with a certain probability, thereby escaping local convergence traps. This design enables more global
exploration of the perturbation space. It is particularly suited to robustness evaluation in black-box testing scenarios

where gradient information and interpretable internal states are unavailable.

4 Methodology

In this section, we elaborate on BASFuzz, our method for robustness testing of LLM-based NLP software. We first

provide an overview of BASFuzz and then detail its key components.

4.1. Overview of BASFuzz

To evaluate the robustness of LLM-based NLP software under black-box settings, we propose BASFuzz. This automated
testing method combines LLM-driven perturbation space construction with a hybrid search-based fuzzing loop. The
overall architecture of BASFuzz is shown in Figure 2. The entire testing process is guided by a robustness objective
function (cf. Section 4.2), and the fuzzing loop terminates when the objective reaches a predefined threshold. Given
a target threat model under test, BASFuzz takes user input, consisting of a prompt P and an original text example
Tori, as seed input. During the preprocessing stage, the input text undergoes a filtering operation to extract a set of
perturbable words I (cf. Section 4.3), ensuring that subsequent perturbations are applied only to semantically sensitive
words, thereby improving testing efficiency. In the perturbation stage (cf. Section 4.4), BASFuzz queries the open
multilingual wordNet (OMW) to retrieve synonyms, near-synonyms, and hypernyms&hyponyms for each word
in the perturbable set J. It then uses LLM-based word embeddings to compute semantic similarity for the retrieved
candidates and replaces original words with semantically similar alternatives to generate variants. This process builds a
diverse perturbation space for the source text, laying the foundation for high-quality and multilingual-adaptive test
cases.

BASFuzz then enters the fuzzing loop (cf. Section 4.5), performing an iterative search over the perturbation space

using an innovative beam-annealing search. Beam search maintains multiple perturbation paths in parallel within the
Manuscript submitted to ACM


BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing 9

1 4
H 1
|} v
“TY Word Set | Vocabulary Olollo Variants
User Input p> “G6 S) Sues

Perturbati | | Fuzzi
erturbation era taal uzzing

Simulated Best Result. -=—]
Annealing © pest NSU </>

Ol =) ;

Filtering Retrieval LLM-based Beam wy Entropy-based | Test Case
U I sea Encoding Generation coo Pruning |
Threat Model (on ap
i1tism ;

Fig. 2. Overview of BASFuzz.

high-dimensional input space, increasing coverage of the input space. To avoid local optima, a simulated annealing-based
probabilistic acceptance mechanism allows the retention of candidate test cases with temporarily lower scores, enhancing
global exploration. Furthermore, BASFuzz computes the entropy of the perturbation distribution to dynamically adjust
beam width, achieving an adaptive balance between perturbation diversity and computational resource allocation. An
elitism mechanism is also introduced to probabilistically track top-performing candidates across iterations, improving
testing efficiency. After multiple rounds of selection, perturbation, and convergence, BASFuzz outputs the optimal

candidate as the final test case.

4.2 Objective Function

In BASFuzz, we formulate robustness testing as a combinatorial optimization problem, where the objective is to maximize
performance degradation of the model output with input perturbations as variables. Specifically, for evaluating the
robustness of LLM-based NLP software on machine translation tasks, given an example dataset D = {(Ti, The , and
an original prompt P such as “Please translate the following German sentence into English:”, we apply perturbations 6
to the combined input [P; T,.] to generate adversarial test cases. To address Challenge #1, under the constraint set C
and a predefined perturbation budget, BASFuzz searches for perturbation paths that cause the threat model output to
deviate as much as possible from the reference translation T,. The objective function can be formalized as:

arg max Er, tye D£[F ([P; Tx] + 5), Ty] (3)

deC

where L£(-, -) is the loss function measuring the difference between the software-generated translation and the reference.
In this study, we adopt the negative BLEU score as £. BLEU, proposed by Papineni et al. [47], is a standard automatic
evaluation metric for machine translation. It measures similarity between machine-generated and reference translations
by computing n-gram overlap. The BLEU computation consists of two steps:

(1) N-gram precision: For a given n-gram length, count the overlapping n-grams between the generated and reference
translations, divided by the total number of n-grams in the generated translation. Formally expressed, for an n-gram set
G, the precision is:

p, . Zaeo Countarp(9)

Dig’ ec’ Counterip(9’)

where Count,jip(g) is the clipped count of g in the generated translation, limited by its maximum occurrence in the

(4)

reference, and G’ denotes all n-grams in the generated translation.

Manuscript submitted to ACM


10 M. Xiao et al.

(2) Weighted geometric mean with brevity penalty (BP): Combine multiple n-gram precisions using a weighted

geometric mean and apply BP to penalize overly short outputs:

N
BLEU = BP - exp(>} wn log Pn) (5)
n=1
where w, are typically uniform weights. BP is computed as:
1, ife>r
BP = (6)

exp(1—r/c), ife<r

with c and r denoting the lengths of the generated and reference translations, respectively. As a mainstream metric
for machine translation, BLEU balances precision and fluency, scales well for large-scale robustness testing, and is
widely adopted in translation benchmarks, ensuring comparability and acceptance. In the robustness evaluation of
LLM-based NLP software, a higher BLEU score indicates that the output is closer to the reference in wording and
structure. In comparison, a lower score reflects degraded translation quality. Therefore, BASFuzz defines £ as the
negative BLEU score and generates input variants that reduce BLEU below a given threshold to expose robustness
flaws. This strategy is not limited to machine translation and can be extended to NLU tasks such as text classification

by selecting appropriate task-specific evaluation metrics (cf. Section 6.5).

4.3 Filtering Criteria

In mutation-based fuzzing, filtering criteria are a critical first step to ensure both the validity and efficiency of generated
variants. BASFuzz introduces stop-word filtering prior to constructing the perturbation space. This step removes stop
words from the input text so that subsequent perturbations focus on core words with substantive semantic impact. Stop
words are high-frequency functional words in natural language text that contribute little to the main semantics, such
as “the”, “and”, “to” in English, or “und”, “der”, “zu” in German. They are often ignored in various NLP tasks because
their role in semantic modeling and task discrimination is limited. Given an input sentence I = [wj, w2,..., Wn] anda

predefined stop-word set S, the filtering operation can be defined as:
T= [wilwi € 1A wi ¢ Ssrop] (7)

where I denotes the retained word set containing only non-stop words. For example, for the sentence “Please translate
the following German sentence into English:”, the filtering step removes “the” and “into”, retaining words such as
“Please”, “translate”, and “German” for perturbation.

In BASFuzz, we adopt the standard stop-word lists provided by the NLTK library [37]. Applying stop-word filtering
before perturbation reduces the size of the perturbation space. For a sentence of length n with an average stop-word
rate p, the effective perturbation space is reduced to (1 — p)” of the original, improving testing efficiency. Furthermore,
perturbing stop words often degrades text fluency or introduces unnecessary noise; excluding them helps maintain the

stealthiness of generated test cases.

4.4 Perturbation Space Construction

Perturbation space construction is the foundation for generating high-quality test cases. The perturbation space defines

the range of input variants BASFuzz can explore during automated testing, and its diversity and validity directly

Manuscript submitted to ACM


BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing 11

determine the effectiveness of robustness evaluation. BASFuzz employs a two-stage perturbation strategy: multilingual

WordNet-based lexical retrieval (cf. Section 4.4.1) and LLM-based semantic constraints (cf. Section 4.4.2).

4.4.1. Perturbation Words Retrieval. To build a diverse perturbation space, BASFuzz uses OMW as the core lexical
resource. Unlike traditional WordNet resources limited to English, OMW integrates Princeton WordNet with semantic
mappings across dozens of languages, providing a unified multilingual concept hierarchy. This enables the generation
of semantically related lexical perturbations in multilingual tasks such as machine translation. Given an input text J,
for each retained word w,; after filtering, BASFuzz retrieves a candidate word set S(w;) from OMW. Three semantic
perturbation modes are applied:

(1) Synonym Substitution: For word wj;, define a synonym set: Ssyn(wi) = {s | s € Synonyms(wj), s # wi}. All members
are semantically equivalent to w;. For example, “translate” may map to “render” or “interpret.”

(2) Near-Synonym Substitution: Retrieve words with short semantic paths to w; (e.g., co-occurrence context or shared
composite meaning), and define the set: Spear(wi) = {s | s € nearSynonyms(w;)}. For example, “error” may be perturbed
into “fault” or “issue”, allowing evaluation under subtle shifts in meaning.

(3) Hypernym/Hyponym Substitution: Based on OMW’s concept hierarchy, retrieve direct hypernyms and hyponyms
of wj: Shyp(wi) = {s | s € Hypernyms(w;) U Hyponyms(w;)}. For example, “vehicle” may be replaced by “car” or
“transport” to test generalization and reasoning ability of the threat model.

The final candidate perturbation set for each word is the union: S(w;) = Ssyn(wi) U Snear(wi) U Shyp(wi). Compared
to most WordNet-based fuzzing approaches, BASFuzz benefits from OMW’s finer-grained sense hierarchy and higher
semantic resolution. This design accommodates the complex requirements of NLG robustness testing and mitigates per-
turbation sparsity and semantic drift caused by limited single-language resources. By integrating the three perturbation
modes, BASFuzz not only enriches the perturbation space but also improves its applicability to robustness testing for

multilingual NLP software.

4.4.2 LLM-based Encoding. After retrieving candidate perturbation words, BASFuzz incorporates a word embedding
LLM to evaluate semantic similarity, enhancing both the semantic precision of variants and their multilingual adaptability.
Although OMW-based lexical retrieval provides a rich candidate set, its static dictionary-style semantic relations have
inherent limitations for NLG tasks. From a linguistic perspective, OMW defines similarity primarily through hierarchical
lexical relations and fails to capture context-sensitive semantic dynamics fully. In addition, the fixed symbolic network
is prone to introducing inappropriate substitutions when handling polysemous words or phrase-level expressions
subject to semantic drift. To address these issues, BASFuzz employs a Gemma2-based embedding model [31] to encode
both the original word w; and all candidate words into high-dimensional vectors. Trained on large-scale multilingual
corpora, this model has strong contextual modeling capability, and its output vectors implicitly capture the semantic
distribution of words in diverse contexts. Given a word w, and its candidate set S(wj;) = {s1, So,..., 5%}, BASFuzz obtains
their embeddings 0,,, = E(w;) and vs, = E(s;) for Vj = 1,...,k. Semantic similarity between the original word and each
candidate is measured using cosine similarity:

Vw; * Us;

- (8)

sim(wij, S;) = x l
2s,||

loss |
Candidates are ranked by similarity scores, and w; is replaced with the top-K closest candidates to generate variants. By

introducing LLM-based semantic constraints on top of OMW retrieval, BASFuzz expands perturbation diversity while

Manuscript submitted to ACM


12 M. Xiao et al.

Algorithm 1 Fuzzing Loop in BASFuzz

Input: T,,;: original text example, P: user prompt, b: beam width, tems: simulated annealing temperature.
Output: Igqy: adversarial test case.
1: beam, I*—Join(P, Tori); > Initialize the fuzzing loop
2: indexOrder<argsort(WIR(beam), order=descend);
: tems,a—1;
: iterNum0;
: while iter Num<|indexOrder| do
candidateText—Perturbation(beam, indexOrder); > Generate candidate variants
for each I’ €candidateText do
pPsa‘Compute simulated annealing acceptance probability via Eq.12;
if rand()<ps, then
tempBeam<tempBeamuUI’; > Accept with simulated annealing probability
end if
end for
iterNum<iterNum+1;
Update I*, tems, via Eq.13;
if Igdy in tempBeam then
return Iggy l* > Output successful test case
end if
HpeamEntropy(L(tempBeam));
9: Update b with Hpeam via Eq.16; > Entropy-based pruning
20: Compute elite retention probability pe via Eq.18;
21: if rand()<pe then

22: next BeamnextBeamvUI*; > Probabilistically retain elite variant
23: tempBeamtempBeam\{I"};

24: b—b-1;

25: end if

26: beam<—nextBeamUSoftSample(tempBeam,b,L(tempBeam));
27: end while
28: return Igqy<I*

maintaining text quality through semantic consistency, providing a high-quality perturbation space for the subsequent

fuzzing loop.

4.5 Fuzzing Loop

In high-dimensional natural language perturbation spaces, efficient robustness testing relies on automated search
processes with global exploration capability and adaptability to dynamic feedback. To address the degradation of
fuzzing capability in NLG tasks identified in Challenge #2, BASFuzz designs a fuzzing loop driven by beam annealing
search. The execution workflow is illustrated in Algorithm 1. This algorithm maintains multiple perturbation paths in
parallel through a beam mechanism, incorporates simulated annealing criteria to escape local optima, and integrates
entropy-based beam-width adjustment with elitism to enable efficient automated robustness testing.

The fuzzing loop concatenates the original text example T,,; and the user prompt P into the initial input J,,;,
which serves as both the starting node and the global best result I* (Line 1). BASFuzz then computes word im-
portance ranking (WIR) to determine the perturbation priority index indexOrder for each word (Line 2). Given

Tori = (wi, W2,...,Wi,..-;Wn} and a masked version I’. = {w1,w2,...,[UNK],..., wn} where the i-th word w; is

ori

replaced with an unknown token, the perturbation effect of w; is measured by the loss difference between Io,; and Ea.

The word importance score is thus defined as:
WIR(wi) = softmax(L(Ij,;, Ty) — Loris Ty) «(Loris Ty) — Loris Ty) (9)

By ranking words based on the BLEU loss, the more they influence the output loss, the higher their importance score.
BASFuzz prioritizes indexOrder on positions with the greatest impact on the generated output, improving search

Manuscript submitted to ACM


BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing 13

efficiency and reducing redundant mutations on low-sensitivity words. The fuzzing loop is initialized by setting the
simulated annealing temperature to 1 and the iteration counter to 0 (Lines 3-4).

The fuzzing loop continues execution until a successful test case Igy is found or indexOrder is fully traversed (Lines
5-27). In each iteration, BASFuzz sequentially selects the next high-importance word from indexOrder for perturbation
and generates a batch of new candidate texts candidateText (Line 6). For each candidate variant I’, BASFuzz computes
the acceptance probability ps4 based on the simulated annealing criterion and uses this probability to decide whether
to include the variant in the temporary beam for the current round (Lines 7-12). After annealing-based selection of
all candidates, the iteration counter is incremented, and both J* and the simulated annealing temperature tems, are
updated (Lines 13-14). If a successful test case is found within the current beam, the loop terminates immediately (Lines
15-17). To enhance search diversity and control exploration breadth, BASFuzz computes the entropy Hpeam of the loss
distribution in the temporary beam during each iteration and dynamically adjusts the beam width based on information
entropy, adapting resource allocation to the dispersion of the distribution (Lines 18-19). Next, with probability pe,
BASFuzz carries I* over to the next beam to avoid losing high-value candidates during the loop (Lines 20-25). After
updating the beam width, BASFuzz applies weighted sampling using the loss scores of remaining variants to fill the
beam to capacity, forming the next-generation beam (Line 26). Finally, the global best variant is output as the test case

Tnay (Line 28). We now present the detailed procedures of the four main modules in the fuzzing loop.

4.5.1 Beam Generation. In the fuzzing loop of BASFuzz, beam generation is the key step that enables parallel exploration
of the high-dimensional perturbation space. Compared with the single-path greedy strategy, beam search maintains
multiple perturbation paths in parallel during each iteration, increasing perturbation diversity and effectively exposing
potential robustness flaws in LLM-based NLP software. Given the current beam B’ = {If, I, a Th, where b is the
current beam width and each I i represents an input text in this iteration, BASFuzz selects one word position w; per

round based on indexOrder obtained from WIR and generates a set of candidate variants:
Replace(/;, wi) = {i [wi = c]|c € Cand(w;)} (10)

where Cand(w;) is the perturbation word set constructed in the perturbation space. All generated variants are merged

to form the next-step candidate text set:
candidateText = ) Replace(J;, w;) (11)

Test

For each candidate text generated through perturbation, subsequent steps combine simulated annealing probabilities
with objective function scores to determine which variants advance to the next beam. For NLP software, the input space
is discrete, sparse, and subject to a combinatorial explosion. Beam generation mitigates premature convergence to local
optima by preserving and expanding multiple candidate paths at each iteration. This design ensures that robustness
testing meets the fundamental requirement of testing effectiveness. The multi-path parallel expansion significantly
increases the likelihood of reaching complex perturbation trajectories and enables deeper probing of the software’s

decision boundaries, thereby facilitating more comprehensive robustness evaluation.

4.5.2. Selection via Simulated Annealing. Although beam generation provides diversity for test cases, in NLG tasks, the
nonlinear decision boundaries of LLMs and their high sensitivity to input perturbations make beam search guided by the
greedy strategy prone to local optima. To address this, BASFuzz introduces a simulated annealing-based probabilistic
acceptance strategy. During high-temperature phases, it accepts a certain degree of quality degradation in variants,

Manuscript submitted to ACM


14 M. Xiao et al.

enhancing global search capability and mitigating the early convergence to local optima inherent in traditional greedy
search. For each candidate text I’, BASFuzz computes its loss increment relative to the original input using the objective
function: AL = LI’, Ty) — LUori, Ty). A temperature parameter tems, is then introduced, and the acceptance of a

candidate is determined using the following probability function:

1, AL >0
exp (AL), AL <0
That is, when the candidate I’ achieves a better objective score, it is always accepted; otherwise, it is accepted with

AL
tems,

logarithmic decay schedule to gradually reduce the annealing temperature, guiding the search from exploration to

Psal’) = (12)

), allowing some degraded candidates to enter subsequent search rounds. BASFuzz applies a

probability exp (

convergence x
temsa(0)

1+y-In(1+t) 5)

where y is the cooling factor and tems,(0) is the initial temperature. In the early high-temperature phase, BASFuzz

temsa(t) =

relaxes the acceptance threshold for suboptimal perturbations, encouraging paths that cross larger semantic gaps to
escape local optima. As iterations progress and the temperature decreases, the search converges and increasingly favors
better perturbations. This balance between early-stage exploration and late-stage fine convergence makes the approach

particularly suitable for black-box robustness testing scenarios with no gradients and no interpretable internal states.

4.5.3 Entropy-based Pruning. In standard beam search, the beam width b is a fixed hyperparameter that remains
constant throughout the search. Formally, at each iteration, only the top-b candidates are retained based on their scores.
While this approach controls search complexity to some extent, it exhibits significant limitations for NLG tasks. In
the early stages of the fuzzing loop, the perturbation space is not yet sufficiently explored; a fixed small beam width
restricts variant diversity and increases the risk of local optima. In later stages, when candidates begin to converge, a
fixed large beam width wastes resources on redundant perturbations. More critically, during different phases of testing,
the BLEU score distribution of candidate texts changes dynamically. A single static beam width cannot adapt to the
structural complexity of the perturbation space, ultimately reducing the efficiency of robustness testing.

To address the shortcomings of a fixed beam width, BASFuzz draws inspiration from information theory and proposes
an entropy-based beam pruning strategy. The key idea is that the entropy of the score distribution of candidate texts
can measure the diversity and uncertainty of the current perturbation space. When the score distribution entropy is
high, large mutations exist among different paths, indicating that the beam width should be expanded to strengthen
global exploration. When the entropy is low, candidate paths become homogeneous, allowing the beam width to be
reduced, which in turn improves fuzzing efficiency and convergence speed. Given the current beam B’ = {I[,Ij,....]p},

BASFuzz first normalizes the loss scores of all candidate texts to obtain a probability distribution:

LI, T,)
p= (14)
y LUT)

then computes the information entropy of the current beam using Shannon’s formula:

b
beam = — »s Pi log(pi +€) (15)

i=1

Manuscript submitted to ACM


BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing 15

where € is a small positive constant to avoid the logarithm of zero, a higher Hpeqm indicates greater diversity among
candidate texts and higher exploration potential. Unlike traditional methods with fixed beam width, BASFuzz adjusts b
dynamically based on Hpyeam:

Ayeam

bist = max(Dmin, min(Dmax, bt: qd +

), bt + 0) (16)

Pmax
where bmin and Dmax are the minimum and maximum beam widths to keep fuzzing overhead within a controllable range;
by (1+ “beam ) is a scaling factor to expand the beam width in high-entropy phases; and o is a smoothing term to avoid
overly rapid contraction in low-entropy phases. Compared with standard beam search, the entropy-based pruning
strategy overcomes the inherent limitation of static beam width. It integrates the information-theoretic principle into

NLP software robustness testing, improving both the effectiveness and efficiency of large-scale fuzzing.

4.5.4 Elitism. After entropy-based beam width adjustment, BASFuzz can dynamically allocate search resources ac-
cording to the uncertainty of the variant distribution. However, the responses of LLM-based NLP software often
exhibit nonlinear jumps. Dynamic beam width alone is difficult to mitigate against accidentally discarding promising
perturbation sequences during simulated annealing selection, especially near decision boundaries. To address this issue,
we introduce an elitism mechanism to track the best perturbation path discovered so far robustly. Conventional elitism
unconditionally carries the current global best candidate into the next fuzzing iteration. While this guarantees that
the optimal perturbation path is not lost, it can cause all variants to converge prematurely to a local extremum during
the early stages of testing, reducing the ability to explore the broader perturbation space. This behavior is particularly
detrimental in software testing, as it risks missing robustness flaws hidden in alternative subspaces of perturbations.
To mitigate this over-convergence, BASFuzz employs probabilistic elitism to balance persistent tracking of the global
best with the exploration of diverse perturbations. For the current global best input J* generated in the fuzzing loop, its

soft retention probability relative to all candidates is defined as:

LUT,
pr = PCLT) -

exp(L(Ij, Ty))

“tiie

i=1

The elitism retention probability is then computed using a base elitism rate pj and the soft retention probability p*:
Pe = Po + (1— Po) P (18)

when the global best is significantly superior to other candidates, p* is high, which further increases p, and reinforces
focus on the optimal perturbation path. When I* is only marginally better, p. decreases accordingly, allowing BASFuzz
to retain I* with high but not absolute probability, encouraging diverse perturbation paths to enter the next fuzzing
iteration. By establishing an elastic transition between local exploitation and global exploration, the probabilistic
elitism mechanism ensures the global best is not easily lost while preventing early convergence to a single path. This
mechanism guarantees that even when simulated annealing accepts a large number of suboptimal perturbations, the
current best sequence is preserved in a steady state, enhancing the fuzzing capability of BASFuzz.

After elitism retention, BASFuzz performs soft-probability weighted sampling, similar to p*, to fill the remaining
beam width without replacement. The fuzzing loop continues until termination, and the final global best I” is output as

the test case generated by BASFuzz.

Manuscript submitted to ACM


16 M. Xiao et al.

5 Experimental Settings

To evaluate the effectiveness, efficiency, and practical value of BASFuzz in robustness testing for LLM-based NLP
software, we design and conduct extensive experiments. All code and data used in the experiments are released in
a reproducible repository [17] to facilitate community replication and further research. The experimental design is

structured around the following five research questions (RQs):

e RQ1: How effective is BASFuzz in generating high-quality test cases?
e RQ2: How lightweight is BASFuzz when performing robustness testing?
e RQ3: What is the contribution of different components to BASFuzz’s testing effectiveness?

e RQ4: How transferable are BASFuzz-generated test cases across different threat models?

RQ5: Can BASFuzz maintain robustness testing effectiveness when applied to the NLU task?

5.1 Datasets

For the first four RQs, we select machine translation as the NLG task scenario. As a representative task in the NLG
domain, machine translation produces open-ended text sequences without fixed-category constraints, fully reflecting
the semantic flexibility and diversity challenges faced by LLM-based software in generative tasks. In addition, machine
translation is highly sensitive to subtle input perturbations, making it well-suited for validating robustness testing
methods. Specifically, we adopt the WMT16 dataset! [6], a widely recognized benchmark in the machine translation
field. WMT16 has long been used in international machine translation competitions and contains high-quality parallel
corpora across multiple language pairs. It features strong linguistic diversity, rich syntactic structures, and a broad
topical distribution, making it a representative choice for robustness evaluation in NLG tasks. From WMT16, we select
three language pairs as the source datasets: Czech-to-English (CS2EN), German-to-English (DE2EN), and Russian-to-
English (RU2EN). Czech, as a Slavic language, exhibits rich morphological mutation; German has complex grammatical
structures and long compound words; and Russian differs from English in word order. These characteristics allow us to
validate BASFuzz’s effectiveness under multilingual settings.

For RQ5, we extend the study to NLU tasks and use text classification as a typical representative. Text classification
requires the software to perform semantic understanding of input examples and accurately assign them to predefined
category labels, exemplifying structured prediction in LLM-based software. This setup facilitates the investigation
of BASFuzz’s scalability across different task types. We employ several widely used datasets in text classification:
Financial Phrasebank (FP)* [39], AG’s News? [81], and MR?‘ [46]. Financial Phrasebank contains short sentences with
sentiment labels extracted from 10,000 real-world financial news articles and analysis reports. It is widely used in
financial sentiment classification research and reflects the impact of highly structured domain-specific language on
the scalability of testing methods. AG’s News consists of news headlines and summaries across topics such as world
news, sports, business, and technology. It includes 496,835 articles from over 2,000 news sources and is used to examine
BASFuzz’s capability in multi-class classification tasks and general-topic scenarios. MR is a dataset focused on sentiment
polarity detection in movie reviews. It contains 10,662 review snippets written by professional film critics from Rotten

Tomatoes, representing a fine-grained and challenging environment for robustness testing.

‘https://huggingface.co/datasets/wmt/wmt16
“https://huggingface.co/datasets/financial_phrasebank
3https://s3.amazonaws.com/fast-ai-nlp/ag_news_csv.tgz
‘https://huggingface.co/datasets/rotten_tomatoes

Manuscript submitted to ACM


BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing LZ

5.2 Threat models

In current software engineering practice, most LLM-based NLP software tends to perform inference by directly invoking
APIs of pre-trained LLMs rather than training task-specific models or building complex post-processing pipelines. This
approach reduces deployment and maintenance costs and enables rapid integration of advanced natural language
capabilities into various products. However, it also implies that the robustness of the software system is largely
constrained by the underlying LLM on which it depends. Therefore, treating the LLM as the threat model in robustness
testing helps reveal fundamental vulnerabilities and provides a more intrinsic assessment of the robustness of higher-
level software applications. To evaluate the effectiveness of BASFuzz in diverse LLM-based NLP environments, we
select five open-source LLMs as threat models. This choice also addresses the stringent requirements for auditability
and compliance of software components in high-security domains such as finance and healthcare, providing greater
transparency and regulatory assurance. Compared with closed-source LLMs, the use of open-source models enhances
the reproducibility of experimental results and provides a solid foundation for verifiability in the research process. We
select five popular LLMs, all accessible through the Hugging Face platform: Mistral-7B-Instruct-v0.3° [26], Phi-4° [1],
InternLM2.5-20b-chat’ [8], Yi-1.5-34B-Chat® [73], and Llama-3-70B-Instruct? [3]. These models span small, medium,
and ultra-large parameter scales and cover current mainstream LLM architectures, enabling the evaluation of BASFuzz

under varying levels of linguistic reasoning complexity.

5.3 The Settings of Test Generation

All experiments in this study are conducted on an Ubuntu 22.04.1 LTS operating system. The hardware configuration
consists of two Intel Xeon Platinum 8358 processors with 32 physical cores running at 2.60 GHz, NVIDIA A100 Tensor
Core GPUs, and 1 TB of physical memory. All baselines and threat models are deployed and configured following
their official documentation. Each experiment is independently repeated six times, and the arithmetic mean of all
evaluation metrics is reported to ensure statistical robustness of the conclusions. For every experiment, the threat model
randomly selects 1,000 text examples from the dataset as user inputs to guarantee diversity of input types and enhance
the representativeness and reliability of results.

Following common practice in machine translation security testing [55], we set the BLEU threshold in the objective
function to 0.2. A generated input variant is considered a successful test case only when it causes the software output’s
BLEU score to drop below 0.2. BLEU is computed using the widely adopted 4-gram configuration [47], simultaneously
evaluating 1-gram to 4-gram segments to balance quality assessment for both short and long text generation. During
perturbation space construction, we set the number of candidate words K = 10 for each word selected for perturbation
to ensure sufficient diversity while preventing exponential growth of the perturbation space. In the fuzzing loop stage,
all hyperparameters are tuned through pilot experiments and informed by industry best practices. Table 1 summarizes

the main hyperparameter settings.

5.4 Baselines

To evaluate the performance of BASFuzz in testing the robustness of LLM-based NLP software, we select six recently

proposed or widely adopted testing methods as baselines. Since most existing automated testing approaches are designed

Shttps://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3
®https://huggingface.co/microsoft/phi-4
7https://huggingface.co/internlm/internlm2_5-20b-chat
Shttps://huggingface.co/01-ai/Yi-1.5-34B-Chat
°https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct

Manuscript submitted to ACM


18 M. Xiao et al.

Table 1. Hyperparameter settings in the fuzzing loop.

Hyperparameter Symbol Value
Cooling factor y 0.3
Entropy smoothing € 1x 1071°
Initial beam width bo 2
Min beam width bmin 2
Max beam width bmax 6
Beam width increment o 1
Elitism base probability Po 0.9

for DNN-based NLP software rather than directly targeting black-box LLM-based software, relevant baselines in this
setting are limited. To bridge this gap, we adapt several methods originally developed for DNN-based NLP software by
modifying their interaction mechanisms and objective functions for application to the emerging scenario studied in this
paper. In preliminary experiments, we observe that population-based metaheuristic search algorithms, such as genetic
algorithm [63] and particle swarm optimization [65], incur extremely high testing costs, with the average generation
time per successful test case exceeding 500 minutes. Although these methods have demonstrated strong global search
capabilities in small-scale DNN-based software testing, their application to large-scale LLM-based robustness testing
violates the fundamental goal of automated testing, which is to improve development efficiency and maintainability.
Therefore, we introduce an efficiency threshold in baseline selection, including only methods whose average generation
time per successful test case does not exceed 180 minutes. For the first four RQs, we compare BASFuzz against six
representative methods: ABS [66], ABFS [67], GreedyFuzz, VFA [69], Seq2Sick [12], and MORPHEUS [57]. Among them,
GreedyFuzz is a comparative method designed in this study based on standard fuzz testing and employing a classical
greedy search strategy. For the scalability study in RQ5, we note that VFA, Seq2Sick, and MORPHEUS are primarily
designed for machine translation and are not directly applicable to NLU tasks. Therefore, we include two widely used
testing methods, TextFooler [27] and PWWS [51], as supplementary baselines. TextFooler generates test cases using a
deletion-based selection mechanism that targets words with the greatest impact on the final decision while aiming to
preserve semantic similarity. PWWS extends synonym substitution with a new word replacement order determined by

word importance and classification probability, also employing a greedy search strategy.

5.5 Evaluation Metrics

In the experiments, we use six metrics to evaluate the testing effectiveness of BASFuzz, the quality of generated test
cases, and the testing efficiency of BASFuzz. Following prior work [64], we perform the Mann-Whitney U-test [40] to
calculate the statistical significance of the experimental results for RQ1 and RQ5, with the significance level set to a =
0.05.

(1) Success Rate (S-rate) [45] measures the proportion of test cases generated by a testing method that successfully

mislead the threat model’s output over the total number of tested examples. In this study, it is defined as:
N.
S-rate = a x 100% (19)

where Nsuc is the number of test cases that successfully mislead the threat model, and N is the total number of input
texts for the current testing method. A higher S-rate indicates greater effectiveness of the testing method in evaluating
software robustness.

Manuscript submitted to ACM


BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing 19

(2) Change Rate (C-rate) [45] measures the average proportion of perturbed words relative to the original input text.
It is defined as:

bt fen (i) x 100% (20)

where diff(J,) denotes the number of replaced words in input text J,, and len(-) denotes the sequence length. A higher
C-rate implies stronger perturbations, which may reveal more robustness flaws but can reduce the stealthiness of test
cases.

(3) Perplexity (PPL) [45] is used to evaluate the fluency of generated test cases. PPL is defined as the exponential of

the average negative log-likelihood of the input text. For a tokenized input I = (wi, w2,..., Wn), it is computed as:
1 n
PPL(I) = exp {-+ ») log po (wi | wa)| (21)
i

where log pe(w: | w<i) is the log-likelihood of token w; given the preceding tokens under a language model. Intuitively,
the more fluent a test case is for the language model used to compute PPL, the less likely it is to introduce confusion.
(4) Grammar Errors (G-E) [45] represent the average number of grammatical errors per successful test case generated

by the testing method. It is defined as:

1 Nsuc
G-E = Dy Ek (22)
SUC f=]

where E; is the number of grammatical errors in the k-th test case. We use the open-source grammar and spell-checking
tool LanguageTool to compute E;,. Excessive grammatical errors can degrade the text quality of test cases and reduce
the accuracy and validity of testing results.

(5) Time Overhead (T-O) [45] measures the average time required by the testing method to generate one successful
test case.

(6) Query Number (Q-N) [45] measures the average number of queries to the threat model needed to generate one

successful test case. Together, Q-N and T-O reflect the overall efficiency of the testing method.

6 Results and Analysis
6.1 RQI1: How effective is BASFuzz in generating high-quality test cases?

We use the success rate to evaluate the effectiveness of test cases generated by BASFuzz and analyze perturbation
stealthiness and language fluency using change rate, perplexity, and grammar errors. Table 2 reports the comparative
results across different datasets and threat models. In terms of testing effectiveness, MORPHEUS, ABS, and ABFS achieve
average success rates of 72.363%, 62.912%, and 58.660%, respectively, showing the strongest performance among current
baselines. The best-performing baseline, MORPHEUS, reaches a success rate of 82.691% on traditional DNN-based NLP
software, indicating that existing methods retain some adaptability to LLM-based NLP testing scenarios but exhibit
degraded fuzzing capability. BASFuzz achieves an average success rate of 77.701% and consistently outperforms all
baselines across every dataset and threat model. Taking the challenging cross-linguistic translation task RU2EN as
an example, the six baselines achieve success rates of 55.853%, 42.418%, 2.448%, 59.936%, 77.446%, and 38.279% on
InternLM2.5_20B, while BASFuzz reaches 85.051%, demonstrating further improvement in testing effectiveness. A
higher success rate indicates that BASFuzz can cover a broader range of potential failure cases, providing more test
cases for robustness evaluation and continuous improvement during deployment. Although MORPHEUS and ABS

achieve success rates close to BASFuzz in some scenarios, they often sacrifice perturbation stealthiness and linguistic

Manuscript submitted to ACM


20 M. Xiao et al.

Table 2. Comparison of the quality of test cases generated by seven testing methods. We use boldface to indicate the best result
under each specific setting and gray shading to highlight the performance of our method. An asterisk * denotes statistical significance
(Mann-Whitney U-test, sig. level < 0.05).

Mistral0.3_7B Phi4_14B InternLM2.5_20B Yil.5_34B Llama3_70B
S-rate C-rate PPL S-rate C-rate PPL S-rate C-rate PPL S-rate C-rate PPL S-rate C-rate PPL
ABS 62.194 4.681 189.740 | 41.949 8.961 202.251 | 69.763 9.117 232.283 | 54.876 8.441 238.425 | 71.037 5.289 185.698
ABFS 59.344 3.042 183.233 | 38.444 7.894 193.607 | 66.189 6.932 180.284 | 52.254 7.666 205.078 | 73.988 4.716 183.453
GreedyFuzz| 5.637 5.674 180.257 | 3.952 4.862 230.411] 7.475 4.946 214.967 | 3.661 5.826 175.165] 4.548 5.165 192.989
CS2EN VFA 48.229 4.542 187.565 | 55.073 5.107 180.682 | 51.775 5.155 194.607 | 53.788 4.931 180.172 | 62.603 5.537 186.298
MORPHEUS} 65.893 15.435 281.861 | 54.886 22.958 349.175 | 87.106 14.331 245.482 | 73.857 15.693 278.879 | 76.322 6.803 200.375
Seq2Sick | 55.268 4.588 191.355 | 26.234 5.006 193.463 | 46.153 4.677 192.597 | 35.712 5.365 195.881] 73.96 5.451 194.183
BASFuzz |68.551* 4.511 173.828*|64.601* 3.553* 170.092*|88.611* 3.712* 136.955*|75.432* 3.739* 166.643*|79.497* 3.324* 181.264”
ABS 73.241 4.629 125.279 | 46.491 10.414 188.578 | 75.253 11.841 180.776 | 61.181 11.557 188.434 | 84.543 6.425 136.524
ABFS 69.542 4.415 121.433 | 37.439 8.999 166.078 | 72.616 7.392 163.389 | 54.776 10.617 125.489 | 81.083 4.982 121.389
GreedyFuzz| 3.305 5.206 124.412 | 2.417 5.503 126.794] 5.978 5.058 125.741 | 2.292 5.138 168.612] 7.166 5.331 123.936
DE2EN VFA 51.736 3.905 133.074 | 65.179 5.124 129.028 | 63.022 4.614 129.965 | 64.684 5.499 121.526 | 72.396 5.045 137.398
MORPHEUS} 74.187 14.525 167.870 | 62.297 36.003 488.856 | 70.726 15.439 169.613 | 72.071 15.307 169.298 | 86.789 12.606 151.181
Seq2Sick | 64.108 4.283 116.181 | 38.347 6.265 126.475 | 52.408 6.104 118.206 | 41.872 7.291 119.889 | 47.574 5.669 113.286
BASFuzz |77.368* 3.118* 115.104*|72.651" 4.743* 124.292*|87.796* 4.291* 116.331*|80.167* 4.385* 116.664*|90.335* 3.198* 108.883*
ABS 64.585 6.335 66.896 | 60.599 8.589 66.332 | 55.853 11.745 71.349 | 51.401 10.527 68.021 | 70.713 8.812 70.296
ABFS 61.917 5.456 66.545 | 61.042 3.563 64.423 | 42.418 13.491 68.803 | 49.358 6.544 64.824 | 59.497 7.869 64.768
GreedyFuzz| 7.127 3.104 67.809 | 3.913 6.594 68.432 | 2.448 4.459 69.916 | 4.984 4.623 66.307 | 8.581 4.859 68.776
RU2EN VFA 48.874 4.367 73.714 | 60.971 4.835 72.728 | 59.936 3.545 73.858 | 61.068 4.289 73.534 | 57.958 4.413 78.645
MORPHEUS} 70.513 16.046 69.525 | 67.684 25.613 85.233 | 77.446 15.868 70.878 | 59.523 18.459 74.826 | 86.143 15.232 70.137
Seq2Sick | 51.363 4.798 65.175 | 66.008 3.469 65.302 | 38.279 5.259 65.854 | 51.149 3.643 65.317 | 55.459 4.298 64.793
BASFuzz | 70.525 4.216 64.762* |69.899* 3.147* 62.374* |85.051* 3.254* 63.674* |65.899* 3.463" 64.556 |89.138* 3.572* 63.635"

Dataset| Baseline

fluency of the generated test cases. Unlike traditional software, the decision-making process of LLM-based NLP software
relies heavily on model knowledge rather than developer-defined system rules. Comprehensive robustness testing is
therefore essential for establishing reliable software quality evaluation. The additional test cases discovered by BASFuzz
identify critical risk regions in real-world applications, making the approach particularly suited for software safety
evaluation in high-stakes domains.

The change rate reflects the stealthiness of perturbations introduced during testing and provides a more reproducible
metric compared to subjective human evaluation. Owing to the mutation strategy combining a multilingual word
network with LLM-based word embeddings, BASFuzz achieves consistently lower change rates in most cases. For
example, although MORPHEUS shows strong performance in terms of success rate, its average change rate reaches
17.355%, far exceeding BASFuzz’s 3.748%. Excessive perturbation often causes test cases to deviate from real-world.
inputs, reducing the practical significance of testing results. While ABFS and GreedyFuzz occasionally approach or
slightly outperform BASFuzz in change rate on smaller models such as Mistral0.3_7B, this is typically associated with
the higher tendency of small-parameter LLMs to hallucinate. When a test case triggers hallucination, the LLM generates
incorrect or irrelevant outputs, which can lead to BLEU scores that appear closer to the reference, thus reducing
the apparent change rate. This phenomenon does not indicate better perturbation stealthiness but instead exposes
robustness flaws in smaller LLMs that struggle to maintain stable semantic expression. For PPL as a quantitative measure
of text fluency, BASFuzz also performs strongly, achieving an average perplexity of 115.271, lower than all compared
baselines. This indicates that the generated test cases are more natural and deceptive. Higher linguistic fluency directly
increases the threat to deployed software, as malicious users can induce software errors using inputs that are nearly
indistinguishable from normal ones, thereby uncovering hidden security blind spots in real-world environments.

In NLP software testing, perturbations that preserve semantic integrity but degrade grammatical correctness can lead
to false-positive test cases. To further evaluate test case quality and potential false alarms, we measure the number of
grammatical errors in successful test cases. Figure 3 shows the comparative results of seven testing methods. Although

Manuscript submitted to ACM


BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing 21

Grammatical error
Grammatical error
Grammatical error

/

Mistral0.3_7B  Phid_14B InternLM2.5 20B Yil.S_ 34B ——Llama3_70B Mistral0.3 7B Phid_14B_IntermLM2.5 20B Yil.5 348 Llama3_70B Mistral0.3_7B Phid_14B Intern M2.5 0B Yil.S 34B —— Llama3_70B

(a) CS2EN (b) DE2EN (c) RU2ZEN

10

Fig. 3. Comparison of the average number of grammatical errors per test case (want |).

all methods generate test cases with some grammatical errors, moderate errors do not reduce the effectiveness of
robustness testing. They can even help expose software robustness against non-standard inputs. BASFuzz consistently
produces test cases with the fewest grammatical errors, averaging 12.541 errors per case, compared to 15.892 for
VFA, which also leverages LLM-based semantic understanding. This demonstrates that BASFuzz can maintain testing
effectiveness while minimizing false positives caused by minor linguistic defects, focusing evaluation precisely on the

true robustness of the software.

Answer to RQ1: BASFuzz significantly outperforms all baselines in success rate and generates higher-quality test
cases. This indicates that BASFuzz is more effective at exposing robustness flaws, supporting more comprehensive

and stealthy evaluations prior to software deployment.

6.2 RQ2: How lightweight is BASFuzz when performing robustness testing?

While ensuring the quality of test case generation, automated software testing must also focus on the execution efficiency
of the testing process. Excessive time overhead and inference call costs can undermine the usability of testing methods
in large-scale quality assurance processes. Therefore, this study evaluates the lightweight characteristics of BASFuzz
in robustness testing, considering both testing time overhead and query number. To ensure the representativeness of
the comparison, we select the two baseline methods, MORPHEUS and ABS, which performed best in terms of testing
effectiveness in RQ1, and compare them with BASFuzz across all datasets and threat models. Figure 4 reports the time
overhead required to generate a single successful test case. Given the significant differences in time costs between
methods (ranging from hundreds to thousands of seconds), we use a logarithmic scale on the vertical axis for better
visualization of the large-scale differences. The experimental results show that BASFuzz generates successful test cases
in less time. Its average time overhead is reduced by 2163.852 seconds compared to MORPHEUS and by 160.469 seconds
compared to ABS. This efficiency is attributed to BASFuzz’s structural innovation in the fuzzing loop process, which
combines beam search with simulated annealing. This approach significantly compresses redundant search paths while
improving testing effectiveness. Additionally, BASFuzz introduces entropy-based beam width pruning to control the
number of candidate variants per round dynamically, prioritizing high-value perturbation areas and effectively reducing
invalid mutations.

Figure 5 shows the average number of queries made to the threat model during the testing process. For each successful
test case generated, BASFuzz initiates 591.451 fewer inference calls than MORPHEUS, reducing the computational load
on the underlying LLM during testing. MORPHEUS, which heavily relies on dense candidate sampling and large-scale

morphological mutation strategies, is feasible in traditional DNN-based NLP software testing, as DNNs typically have
Manuscript submitted to ACM


22

M. Xiao et al.

0!
[a MORPHEUS|
ABs

BR BASFuzz

DE2EN
(@) Mistral0.3_7B

a MORPHEUS}
a ABs
I BASFuzz

DEEN
(b) Phid_14B

0!
ES MORPHEUS]
ABS

IR BASFuzz

CS2EN

DE2EN
(©) IntemLM2.5_20B

RUEN

a MORPHEUS]
ABs
I BASFuzz

DE2EN
(@ Yils 4B

Fig. 4. Results of test time overhead on different datasets and threat models (want |).

DEEN
(e) Llama3_70B

RU2EN

DE2EN
(a) Mistral0.3_7B

RU2EN

CS2EN

DE2EN
(6) Phid_ 148

RU2EN

DEEN

(©) IntemLM2.5_20B

RUJEN

DE2EN
(Yi. MB

RU2EN

[ MoRPHEUS| [EB MoRPHEUS| [SB MoRPHEUS| [RB MoRPHEUS| SE MORPHEUS
ABs ABs I ABs
 BASFuzz I BasFuzz HM BasFwz

DE2EN
(¢) Llama3_70B

Fig. 5. Results of test query number for different datasets and threat models (want |).

fast inference speeds. However, when applied to large-scale LLMs with greater parameter sizes and longer response
times, the inference cost is magnified, significantly reducing MORPHEUS’s overall testing efficiency. The improvement
in efficiency is especially important in industrial scenarios. LLM-based NLP software is often encapsulated through
commercial APIs, and each inference call during testing incurs time delays and financial costs, such as cloud service
charges based on the number of calls or characters processed. In sensitive industries that require frequent regression
testing or security audits, excessive threat model calls quickly accumulate substantial costs. In contrast, BASFuzz,
with its hybrid heuristic fuzzing loop, reduces redundant inference calls during the testing process, achieving higher

robustness testing effectiveness with fewer software interactions.

Answer to RQ2: BASFuzz, with its efficient fuzzing loop combining beam search, simulated annealing, and
entropy-based beam width pruning, significantly reduces time overhead and query number while ensuring testing
effectiveness. This lightweight characteristic makes BASFuzz more practically valuable in resource-constrained or

large-scale testing scenarios.

6.3 RQ3: What is the contribution of different components to BASFuzz’s testing effectiveness?

To evaluate the effectiveness of perturbation space construction and fuzzing loop, we perform an ablation study on
BASFuzz across three datasets. Table 3 shows the robustness testing results for Phi4_14B using popular perturbation space
construction methods. BASFuzz, combining the multilingual word network OMW with LLM-based word embeddings,
achieves a success rate of 72.651%, also demonstrating superior performance in test case stealthiness and fluency.
BASFuzz-G, which uses GloVe for word substitution, benefits from the efficiency of preloaded word embedding space
and distance calculation, enabling quick construction of candidate word sets, and exhibits the lowest time overhead.
However, this simplified strategy falls behind BASFuzz in other evaluation metrics, particularly in test effectiveness
and perturbation stealthiness. Test success rate, as a core metric of robustness testing ability, plays a decisive role
in enhancing software robustness evaluation. Focusing solely on time efficiency while neglecting test effectiveness

undermines the practical engineering value of the testing method. Moreover, although BASFuzz-G is the fastest in
Manuscript submitted to ACM


BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing 23

Table 3. Robustness testing results for Phi4_14B using popular perturbation space construction methods, including synonym
substitution with GloVe word embeddings (BASFuzz-G), synonym substitution with WordNet (BASFuzz-W), and related word
substitution with OMW (BASFuzz-O).

Dataset Method S-rate C-rate PPL G-error TO ON
BASFuzz-G | 61.168 4.634 189.478 15.066 223.599 209.773
CS2EN BASFuzz-W | 51.961 8.810 202.362 14.286 346.023 276.552
BASFuzz-O | 58.829 5.991 182.361 13.748 325.697 239.495
BASFuzz 64.601 3.553 170.092 12.029 284.207 148.974
BASFuzz-G | 67.988 4.992 129.077 15.853 362.758 311.942
DE2EN BASFuzz-W | 64.158 8.065 131.587 14.975 598.149 385.207
BASFuzz-O | 70.687 6.089 127.587 14.254 587.463 331.036
BASFuzz 72.651 4.743 124.292 12.618 553.291 286.607
BASFuzz-G | 63.123 4.462 66.459 14.105 221.173 218.674
RU2EN BASFuzz-W | 59.860 = 7.128 76.313 13.829 463.262 369.199
BASFuzz-O | 64.222 4.236 69.313 13.113 435.882 335.341
BASFuzz 69.899 3.147 64.423 12.727 350.431 188.334

terms of testing speed, it queries the threat model more frequently than BASFuzz, with an average of 60.799 more
queries per test case. The root cause lies in the static word vectors, which fail to accurately capture the semantic
relationships between candidate words, resulting in a perturbation space filled with low-quality variants that require
more attempts to generate effective perturbations. In contrast, BASFuzz uses LLM-based word embeddings, which excel
at semantic understanding, to compute semantic consistency and further optimize the perturbation space, effectively
improving testing efficiency. The comparison between BASFuzz-O and BASFuzz also shows that, although the two-stage
perturbation space construction strategy introduces a semantic constraint step, the effective focus on high-quality
candidate words greatly reduces subsequent invalid queries. This not only prevents an increase in overall time overhead
due to encoding word vectors but also enhances test effectiveness while reducing query counts.

Table 4 presents the ablation results for the main submodules of the fuzzing loop. Based on standard beam search (w/o
SA&EP), the method can achieve a certain level of global search and efficient perturbation, but is prone to local optima
in high-dimensional and complex perturbation spaces, leading to poor test effectiveness and efficiency. After integrating
the simulated annealing-based acceptance strategy into the fuzzing loop (w/o EP), test effectiveness and perturbation
stealthiness improve significantly, indicating that our simulated annealing mechanism provides a probabilistic acceptance
channel for non-optimal perturbations, allowing the fuzzing process to maintain global exploration capability despite
short-term score fluctuations. Upon introducing the entropy-based pruning strategy (w/o SA), BASFuzz demonstrates
even better efficiency in time overhead and query number. By calculating the distribution entropy of the current beam
using BLEU scores, the beam width is dynamically adjusted to avoid redundant computations and inefficient paths.
With the combination of these components, BASFuzz, in its complete configuration, demonstrates the best performance
across all metrics on the three datasets, with test effectiveness improving by 7.852%—-9.869%. The new fuzzing loop
enables BASFuzz to effectively uncover robustness flaws while enhancing its usability in large-scale quality assurance

processes, even under limited computational resources.

Answer to RQ3: Through the two-stage perturbation space construction strategy and modular fuzzing loop

design of BASFuzz, not only improves testing effectiveness and efficiency, but also enhances the text quality of

the generated test cases.

Manuscript submitted to ACM


24 M. Xiao et al.

Table 4. Ablation results of standard beam search (w/o SA&EP), selection via simulated annealing (w/o EP), and entropy-based
pruning (w/o SA) on Phi4_14B.

Dataset Method S-rate C-rate PPL G-error TO QN
w/o SA&EP | 54.732 9.331 233.934 15.425 454.877 155.648
CS2EN w/o EP 57.656 6.722 204.914 14.282 391.283 176.196
w/o SA 56.715 7.365 219.243 15.121 317.529 = 152.983
BASFuzz 64.601 3.553 170.092 12.029 284.207 148.974
w/o SA&EP | 64.125 7.145 156.587 14.844 649.448 303.617
DE2EN w/o EP 69.049 5.643 141.229 13.534 656.024 321.804
w/o SA 65.705 6.669 150.143 14.556 598.263 291.452
BASFuzz 72.651 4.743 124.292 12.618 553.291 286.607
w/o SA&EP | 62.047 7.956 67.518 14.072 414.546 190.662
RU2EN w/o EP 65.464 5.097 65.425 12.932 439.074 221.421
w/o SA 63.287 = 7.123 66.133 13.440 364.937 189.793
BASFuzz 69.899 3.147 64.423 12.727 350.431 188.334

6.4 RQ4: How transferable are BASFuzz-generated test cases across different threat models?

In robustness testing, the transferability of test cases is an important metric for evaluating their broad applicability. We
select the three baselines with the best current testing effectiveness and compare them with the test cases generated
by BASFuzz across three datasets. Table 5 presents the transferability results across different threat models, where
“14b—>70b” indicates the transfer of test cases generated for Phi4_14B to the testing effectiveness on Llama3_70B, and
vice versa. The test cases generated by BASFuzz maintain a high success rate in both settings, demonstrating better
transferability than the baselines. In the scenario of transferring test cases from Phi4_14B to Llama3_70B, BASFuzz
achieves a success rate of 87.101%, which is 4.016% higher than MORPHEUS’s success rate when tested directly on
Llama3_70B. This suggests that the test cases generated by BASFuzz have broader applicability across different LLM-
based software and can cover common robustness flaws present in various threat models. BASFuzz’s perturbation space
construction not only relies on static word substitution but also incorporates semantic constraints through LLM-based
word embeddings, which include contextual knowledge. This ensures that the test cases generated by BASFuzz maintain
semantic consistency across multiple threat models, avoiding over-reliance on training biases from a single model or
overfitting to specific language patterns. Higher transferability offers better engineering value, reducing the workload
and cost of testing each software separately, and ensuring long-term maintenance, especially as LLM-based software
frequently updates. BASFuzz can efficiently and reliably perform robustness evaluations in such environments.

We also observe that the success rate of transferring test cases generated for Llama3_70B to Phi4_14B is typically lower
than the reverse. Although Llama3_70B has a larger parameter scale than Phi4_14B, its older design and architecture
result in less effective test cases when transferred to Phi4_14B compared to test cases generated from Phi4_14B. As
a more recent model, Phi4_14B has been optimized in terms of language modeling and training strategies, better
adapting to complex language patterns and subtle perturbations, thus demonstrating greater robustness with test
cases transferred from Llama3_70B. This difference reflects the varying adaptability of different threat models when
handling perturbations, further demonstrating that BASFuzz generates highly transferable test cases while considering

the specific characteristics of LLM-based software.

Manuscript submitted to ACM


BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing 25

Table 5. The success rates of transferred adversarial test cases on the three datasets (want 1).

Dataset | Transfer relation | MORPHEUS ABS ABFS  BASFuzz
CS2EN 14B—70B 81.954 87.183 88.275 89.967
70B—14b 42.857 51.709 50.602 66.063
DE2EN 14B—70B 73.334 76.538 75.667 83.902
70B—14b 30.321 33.333 34.259 50.704
RU2EN 14B—70B 85.121 84.557 81.665 87.435
70B—14b 41.189 42.718 44.569 49.087

Answer to RQ4: The test cases generated by BASFuzz exhibit higher transferability compared to other baselines,
reducing the time and resources required for testing each software individually, thereby enhancing the broad

applicability and long-term value of the testing process.

6.5 RQ5: Can BASFuzz maintain robustness testing effectiveness when applied to the NLU task?

To validate the scalability of BASFuzz across different NLP task types, we apply it to text classification, a downstream
task in NLU. To this end, we design and open-source a mutation-based fuzz testing tool based on BASFuzz, which
supports full automation of the process, from objective function configuration and input perturbation generation to
search process control. The tool, through a unified interface and highly configurable design, overcomes the current
limitation of existing testing tools that are bound to specific task types, allowing testing methods originally designed
for NLG tasks to be applied to NLU tasks and vice versa. Specifically, we use the confidence of the original labels in
classification tasks as the objective function. If the generated variant causes the software to flip the input label, it is
considered a successful test case. This setup not only retains the numerical optimization goal form consistent with NLG
tasks but also maintains a consistent objective function semantics across multi-task testing, making the fuzz testing
more efficient across different tasks.

Table 6 shows the comparison results of BASFuzz with five recent or widely used baselines. BASFuzz achieves the
best testing effectiveness across all datasets and threat models, with an average success rate of 78.331%, outperforming
the classic DNN-based NLP software testing method TextFooler, which achieves a success rate of 67.912%. BASFuzz’s
two-stage perturbation space construction improves the relevance and mutation quality of candidate words, ensuring
that perturbations in NLU tasks maintain high semantic consistency. Furthermore, the collaborative design of beam
search and simulated annealing in the fuzzing loop enhances the global search ability, thereby generating more effective
test cases. In terms of the quality of the generated text, BASFuzz also performs excellently, with an average change rate
of only 1.085 and an average perplexity of 51.347, outperforming other baselines in most cases. This indicates that the
perturbations introduced by BASFuzz in NLU tasks are similarly hard to detect. We also observe cases where BASFuzz
does not surpass the best-performing baselines. On certain models of the AG’s News and MR datasets, ABFS shows
a slight advantage in change rate, while TextFooler achieves lower perplexity in a few cases. These results mainly
stem from the fact that such baselines adopt more aggressive perturbation strategies or stricter text quality constraints,
thereby gaining certain advantages in preserving fluency or minimizing perturbations, though often at the expense of
testing effectiveness. Nevertheless, the magnitude of these differences is limited and does not undermine the significant
advantages of BASFuzz in overall testing effectiveness and text quality. The testing strategy of BASFuzz exhibits good
scalability across diversified inputs and task settings, making it highly significant for the broad application of current
LLM-based NLP software in multi-task and multi-domain scenarios.

Manuscript submitted to ACM


26 M. Xiao et al.

Table 6. Comparison of the quality of test cases generated by six testing methods for the NLU task.

Mistral0.3_7B Phi4_14B InternLM2.5_20B Yi1.5_34B Llama3_70B

S-rate C-rate PPL S-rate C-rate PPL S-rate C-rate PPL S-rate C-rate PPL S-rate C-rate PPL
ABS 66.173 1.756 52.771 | 88.894 0.987 47.542 | 77.058 1.283 49.102 | 75.305 1.663 52.641 | 62.411 1.316 48.548
ABFS 65.124 0.996 50.899 | 88.857 0.976 47.412 | 74.254 1.127 48.448 | 72.016 1.295 51.714 | 61.759 124 48.272
GreedyFuzz| 51.597 1.885 57.342 | 33.728 1.898 58.703 | 73.952 1.943 56.151 | 21.073 1.971 56.542 | 12.761 1.763 57.669
TextFooler | 62.949 1.095 51.363 | 79.492 1.541 52.822 | 73.345 1.251 50.363 | 73.232 1.881 52.937 | 59.499 -168 50.749
PWWS 61.565 1.715 52.101 | 73.831 1.043 50.459 | 74.417 1.211 50.319 | 69.889 2.203 54.967 | 61.437 1.242 52.594
BASFuzz |72.041* 0.961* 49.139*|91.149* 0.942* 46.954*|83.118* 0.936* 45.169*|77.078* 1.225* 51.334*|65.177* 0.949* 47.755"
ABS 66.93 1.197 46.905 | 73.083 1.002 46.439 | 72.026 1.199 48.148 | 75.943 1.641 49.919 | 68.369 407 46.898

Dataset} Baseline

FP

4
ABFS 67.912 0.885 46.363 | 72.736 0.921 46.098 | 68.574 1.129 46.103 | 76.777 0.999 46.797 | 62.682 1.093 46.507
AG’s |GreedyFuzz| 48.999 1.477 52.626 | 18.978 1.443 53.364 | 50.168 1.511 51.886 | 2.212 1.046 58.035 | 12.151 1.504 49.053
5
8

News | TextFooler | 66.44 1.479 47.254 | 43.664 1.378 46.992 | 71.562 1.849 48.378 | 74.403 2.439 51.546 | 59.481 1.648 48.141
PWWS 68.488 0.892 47.759 | 41.845 0.933 47.538 | 71.633 1.512 48.001 | 75.292 1.054 46.892 | 61.474 1.865 48.594
BASFuzz_ |73.025* 0.818* 45.351*|76.055" 0.898" 45.326" | 74.098" 0.868" 44.163*|78.176" 2.161 50.506 |75.538* 0.889" 45.425*

ABS 48.915 2.799 73.099 | 86.516 1.230 59.391 | 83.086 1.666 61.869 | 83.786 1.867 63.589 | 71.336 1.954 61.411
ABFS 46.855 1.265 63.211 | 84.862 1.176 58.755 | 79.318 1.502 58.121 | 78.927 1.218 60.271 | 68.017 1.168 58.178

GreedyFuzz| 28.981 1.892 67.262 | 27.872 1.919 65.722 | 61.645 1.941 66.622 | 10.782 1.947 68.162 | 41.315 1.922 68.574

TextFooler | 58.418 1.287 61.287 | 70.795 1.529 60.915 | 82.211 1.913 62.139 | 80.747 1.945 63.623 | 62.433 2.053 62.779
PWWS 47.815 4.877 87.523 | 59.312 1.796 58.741 | 78.031 2.048 63.011 | 81.164 2.092 66.575 | 68.127 1.324 60.772
BASFuzz |69.077* 1.282 62.998 |89.158" 1.099* 57.094* | 88.066" 1.023" 61.397*|87.169* 1.105* 59.859*|76.044* 1.117" 57.729*

MR

Answer to RQ5: With the configurable objective function and fuzzing technique of BASFuzz, it achieves leading
testing effectiveness and perturbation stealthiness in NLU tasks, such as text classification. This result fully
demonstrates the scalability of BASFuzz across multiple NLP task scenarios, laying the foundation for generalized

fuzz testing of LLM-based NLP software.

7 Threats to Validity
7.1 Internal Threats

The internal validity of BASFuzz is primarily influenced by its supporting components, including the multilingual
word network, LLM-based word embeddings, beam search, and simulated annealing. While these modules have been
widely adopted and empirically validated in their respective domains, the fuzzing workflow they collectively form
can only approximate global optima. It cannot guarantee the generation of absolutely optimal test cases in every
trial, which is a common limitation shared by all heuristic search-based methods. To mitigate the impact of these
components, we conduct a set of experiments on testing effectiveness, perturbation stealthiness, and testing efficiency,
comparing BASFuzz against representative baselines. BASFuzz consistently outperforms the baselines across all key
metrics, suggesting that its advantage lies not only in component synergy but also in its methodological innovations.
In addition, hyperparameter settings may also pose threats to internal validity—for instance, beam width range and
cooling factor in the fuzzing loop. To control such bias, we strictly follow original configurations reported in the
literature when reproducing baselines, ensuring experimental fairness and reproducibility. For BASFuzz, we perform
parameter tuning and apply consistent hyperparameter configurations across all datasets and threat models, ensuring
cross-setting comparability. To further eliminate potential sources of error, we conduct a validation of the experimental
code and procedures. All experimental artifacts, including code and data, are made publicly available in a reproducible

repository [17] to support independent verification and further research by the community.

7.2. External Threats

The external validity of BASFuzz is mainly constrained by dataset coverage and method generalizability. Our evaluation

focuses on multilingual machine translation tasks within the Indo-European language family. These languages typically
Manuscript submitted to ACM


BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing 27

feature rich morphological systems, which may not fully represent challenges posed by typologically distant or
logographic languages. Nevertheless, BASFuzz leverages OMW, which natively supports dozens of natural languages and
exhibits strong multilingual morphological compatibility. Additionally, the LLM-based word embeddings incorporated
into BASFuzz enable context-aware semantic encoding across languages, providing adaptability and scalability in
multilingual settings. In our experiments, we construct source inputs from three language pairs and evaluate across
five threat models. BASFuzz achieves the highest testing effectiveness in all cases, further validating its cross-lingual
generalizability. Although the main experiments center on NLG tasks, the fuzzing strategy of BASFuzz does not rely
on task-specific textual features. Instead, it focuses on generic perturbation and search mechanism. By adapting the
objective function for different downstream NLP tasks, BASFuzz can be readily transferred to other application scenarios.
In RQS, we extend BASFuzz to text classification as a representative NLU task, demonstrating its scalability and laying
a solid foundation for broader applications in LLM-based NLP software testing.

8 Related Work

With the widespread integration of LLMs into NLP software, the research community increasingly recognizes the
potential risks posed by robustness issues [2, 83]. In both security-critical domains such as finance [68], healthcare [50],
and public-facing applications like dialogue and generative systems [53, 54], robustness defects may lead to severe
safety hazards. As a testing technique that does not require white-box access, fuzz testing has been widely adopted
in recent years for robustness evaluation of intelligent software [12, 27, 51, 57, 66, 67, 69]. Its primary objective is
to generate input variants that can expose robustness vulnerabilities. In robustness evaluation for LLM-based NLP
software, the stronger resilience and longer inference time of LLMs compared to DNNs make manual construction of
test cases inefficient and costly. Therefore, this work focuses on automated fuzzing techniques, which can be classified

into three classes [64]: generation-based fuzzers, learning-based fuzzers, and mutation-based fuzzers.

8.1. Generation-based Fuzzer

Generation-based fuzzers are a traditional approach in automated software testing. They typically rely on predefined
mutation rules or generation templates to systematically produce test cases that cover diverse regions of the input space.
This paradigm has also been widely applied to robustness testing in NLP software. In the context of content moderation
systems, Wang et al. [62] proposed a taxonomy of 11 transformation strategies spanning character, word, and sentence
levels to generate test cases automatically. For named entity recognition, Yu et al. [74] introduced TIN, a testing method
that constructs semantically similar yet syntactically altered variants via paraphrasing, structural transformation, and
entity shuffling. Another common practice is to construct offline datasets that contain a large number of inputs with
potential robustness flaws, forming static testing benchmarks. Wang et al. [61] built robustness testing datasets based
on AdvGLUE and ANLI by injecting word-level, sentence-level, and manually crafted perturbations. Yuan et al. [76]
proposed BOSS, which covers five major NLP tasks, each with one in-distribution dataset and three out-of-distribution
robustness datasets. However, static dataset construction raises the risk of data leakage. If the threat model is exposed
to similar inputs during training, the fairness and credibility of testing results can be compromised. Moreover, as
LLM-based software evolves rapidly, static test sets struggle to align with shifting software semantics and behavior,
leading to reduced coverage and representativeness. To overcome these limitations, BASFuzz avoids static generation
strategies. Instead, it constructs test cases dynamically through real-time interaction with the threat model, making it
better suited to the evolving nature and agile development requirements of LLM-based NLP software.

Manuscript submitted to ACM


28 M. Xiao et al.

8.2 Learning-based Fuzzer

To address the limitations of traditional fuzzing in complex task settings and emerging software types, researchers have
recently proposed learning-based fuzzers. These approaches aim to incorporate neural models into the testing process to
generate more adaptive test cases automatically. Yao et al. [71] employed the policy gradient method from reinforcement
learning, designing a reward function based on code-text consistency, fluency, and alienation rate to generate minimally
perturbed inputs. For mobile applications, Liu et al. [36] utilized LLMs to generate text inputs that can pass graphical
user interface-based page validation and then leveraged LLMs again to create mutation rules for constructing fuzzing
generators. Ugarte et al. [60] defined a jailbreak robustness coverage matrix from three perspectives—safety category,
writing style, and persuasive technique—using OpenAI API assistants and retrieval-augmented generation to create
test cases. While learning-based fuzzers improve automation and adaptability, their effectiveness remains constrained
by the capacity of their underlying models. When the threat model possesses significantly stronger representational
power than the model used for generation, the latter often fails to produce effective test cases, resulting in conservative
robustness assessments. Furthermore, learning-based fuzzers suffer from slow convergence and poor generalization,
which undermines testing efficiency. BASFuzz does not rely solely on neural generation. Instead, it combines multilingual
lexical resources and a dynamic fuzzing loop to explore the perturbation space heuristically. This design avoids the

performance bottlenecks inherent in learning-based fuzzers.

8.3. Mutation-based Fuzzer

Mutation-based fuzzers iteratively apply transformations to seed inputs to generate new mutated variants. Earlier
mutation-based techniques mainly focused on two input components: prompts and examples, applying perturbations
to evaluate robustness. Zhang et al. [79] analyzed the software architecture of LLM-based systems to identify sensitive
features, crafting test cases by modifying key information or distorting prompt semantics. For chatbot-based web
applications, Pedro et al. [48] evaluated jailbreak robustness using both direct malicious prompt injection via web
interfaces and stored malicious content in user-generated data. These methods target prompt injection to trigger
prohibited behavior, such as generating unethical content. In contrast, BASFuzz focuses on assessing the software’s
decision consistency under fine-grained perturbations. This fundamental difference in testing objectives and impact
scope distinguishes BASFuzz from prior methods. In an example-oriented robustness evaluation, Huang et al. [21]
extracted semantic features from each neuron of the threat model, constructing natural language descriptions linked
to neural functionalities and applying transformations like pixel-level noise, affine modifications, and style transfer
to enrich test diversity. Xiao et al. [65] used WordNet to construct the perturbation space and employed adaptive
particle swarm optimization with Lévy flights to enhance fuzzing efficiency on DNN-based NLP software. Notably,
current mutation-based fuzzers often neglect the complex interaction between prompts and examples during real-world
software execution. Since the output of LLM-based NLP software is jointly influenced by both components, fuzzing
either in isolation fails to expose robustness flaws fully and can lead to false conclusions. To address this, BASFuzz
tests the entire input, capturing its interaction to more accurately evaluate software robustness under joint input

perturbation.

9 Conclusion

In this paper, we present BASFuzz, a mutation-based fuzzing method designed for LLM-based NLP software. BASFuzz
targets the full input, composed of both prompts and examples. It constructs a semantics-preserving perturbation space

Manuscript submitted to ACM


BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing 29

using multilingual lexical resources and LLM-based word embeddings. BASFuzz employs a fuzzing loop driven jointly by
beam search and simulated annealing to evaluate adversarial robustness efficiently. We conduct extensive experiments
across six real-world datasets and five threat models. Results show that BASFuzz achieves a 5.338% improvement in
average testing effectiveness compared to the strongest existing baselines, while reducing the time cost per successful
test case by 82.984%. This demonstrates that BASFuzz enables more effective robustness evaluations with significantly
lower testing overhead. Furthermore, the generated test cases exhibit superior stealth and transferability. In future
work, we plan to enhance BASFuzz’s applicability to commercial closed-source software and investigate its adaptability

in multilingual and multimodal scenarios to strengthen its practical utility further.

Acknowledgments

The work is supported by the National Natural Science Foundation of China (62272145, U21B2016), and the Fundamental
Research Funds for the Central Universities (B240205001).

References

[1] Marah I Abdin, Jyoti Aneja, Harkirat S. Behl, Sébastien Bubeck, Ronen Eldan, Suriya Gunasekar, Michael Harrison, Russell J. Hewett, Mojan
Javaheripi, Piero Kauffmann, James R. Lee, Yin Tat Lee, Yuanzhi Li, Weishung Liu, Caio C. T. Mendes, Anh Nguyen, Eric Price, Gustavo de Rosa, Olli
Saarikivi, Adil Salim, Shital Shah, Xin Wang, Rachel Ward, Yue Wu, Dingli Yu, Cyril Zhang, and Yi Zhang. 2024. Phi-4 Technical Report. CoRR
abs/2412.08905 (2024). https://doi.org/10.48550/arXiv.2412.08905

2] Iftekhar Ahmed, Aldeida Aleti, Haipeng Cai, Alexander Chatzigeorgiou, Pinjia He, Xing Hu, Mauro Pezzé, Denys Poshyvanyk, and Xin Xia. 2025.
Artificial Intelligence for Software Engineering: The Journey So Far and the Road Ahead. ACM Trans. Softw. Eng. Methodol. 34, 5, Article 119 (May
2025), 27 pages. doi:10.1145/3719006

3] Al@Meta. 2024. Llama 3 Model Card. (2024). https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md

4] Farah Atif, Ola El Khatib, and Djellel Difallah. 2023. BeamQA: Multi-hop Knowledge Graph Question Answering with Sequence-to-Sequence
Prediction and Beam Search. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval
(Taipei, Taiwan) (SIGIR ’23). Association for Computing Machinery, New York, NY, USA, 781-790. doi:10.1145/3539618.3591698

5] Daniel Blasco, Antonio Iglesias, Jorge Echeverria, Francisca Pérez, and Carlos Cetina. 2025. Introducing Phylogenetics in Search-based Software
Engineering: Phylogenetics-aware SBSE. ACM Trans. Softw. Eng. Methodol. (Jan. 2025). doi:10.1145/3715002 Just Accepted.

6] Ond rej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, Antonio Jimeno Yepes, Philipp Koehn, Varvara

Logacheva, Christof Monz, Matteo Negri, Aurelie Neveol, Mariana Neves, Martin Popel, Matt Post, Raphael Rubino, Carolina Scarton, Lucia Specia,
Marco Turchi, Karin Verspoor, and Marcos Zampieri. 2016. Findings of the 2016 Conference on Machine Translation. In Proceedings of the First
Conference on Machine Translation. Association for Computational Linguistics, Berlin, Germany, 131-198. http://www.aclweb.org/anthology/W/
W16/W16-2301
[7] F. Bond, P.-TJ.M. Vossen, J. McCrae, and C. Fellbaum. 2016. CILI: the Collaborative Interlingual Index. In Proceeding of the 8th Glbal WordNet
Conference, V. Barbu Mititelu, C. Forascu, P-TJ.M. Vossen, and C. Fellbaum (Eds.). GWC2016 ; Conference date: 01-01-2016 Through 01-01-2016.
[8] Zheng Cai, Maosong Cao, Haojiong Chen, Kai Chen, Keyu Chen, Xin Chen, Xun Chen, Zehui Chen, Zhi Chen, Pei Chu, Xiaoyi Dong, Haodong
Duan, Qi Fan, Zhaoye Fei, Yang Gao, Jiaye Ge, Chenya Gu, Yuzhe Gu, Tao Gui, Aijia Guo, Qipeng Guo, Conghui He, Yingfan Hu, Ting Huang, Tao
Jiang, Penglong Jiao, Zhenjiang Jin, Zhikai Lei, Jiaxing Li, Jingwen Li, Linyang Li, Shuaibin Li, Wei Li, Yining Li, Hongwei Liu, Jiangning Liu, Jiawei
Hong, Kaiwen Liu, Kuikun Liu, Xiaoran Liu, Chengqi Lv, Haijun Lv, Kai Lv, Li Ma, Runyuan Ma, Zerun Ma, Wenchang Ning, Linke Ouyang, Jiantao
Qiu, Yuan Qu, Fukai Shang, Yunfan Shao, Demin Song, Zifan Song, Zhihao Sui, Peng Sun, Yu Sun, Huanze Tang, Bin Wang, Guoteng Wang, Jiaqi
Wang, Jiayu Wang, Rui Wang, Yudong Wang, Ziyi Wang, Xingjian Wei, Qizhen Weng, Fan Wu, Yingtong Xiong, Xiaomeng Zhao, and et al. 2024.
InternLM2 Technical Report. CoRR abs/2403.17297 (2024). https://doi.org/10.48550/arXiv.2403.17297
[9] Daihang Chen, Yonghui Liu, Mingyi Zhou, Yanjie Zhao, Haoyu Wang, Shuai Wang, Xiao Chen, Tegawendé F. Bissyandé, Jacques Klein, and Li Li.
2025. LLM for Mobile: An Initial Roadmap. ACM Trans. Softw. Eng. Methodol. 34, 5, Article 128 (May 2025), 29 pages. doi:10.1145/3708528
(10] Junkai Chen, Li Zhenhao, Hu Xing, and Xia Xin. 2025. NLPerturbator: Studying the Robustness of Code LLMs to Natural Language Variations. ACM
Trans. Softw. Eng. Methodol. (July 2025). doi:10.1145/3745764 Just Accepted.
{11] Xiang Chen, Chaoyang Gao, Chunyang Chen, Guangbei Zhang, and Yong Liu. 2025. An Empirical Study on Challenges for LLM Application
Developers. ACM Trans. Softw. Eng. Methodol. (Jan. 2025). doi:10.1145/3715007 Just Accepted.
[12] Minhao Cheng, Jinfeng Yi, Pin-Yu Chen, Huan Zhang, and Cho-Jui Hsieh. 2020. Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models
with Adversarial Examples. Proceedings of the AAAI Conference on Artificial Intelligence 34, 04 (Apr. 2020), 3601-3608. doi:10.1609/aaai.v34i04.5767
[13] George B Dantzig. 1957. Discrete-variable extremum problems. Operations research 5, 2 (1957), 266-288.

Manuscript submitted to ACM


30

15]

16]

[17]

18]

[19]

[20]

[21]

22]

[23]

[24]
[25]

[26]

27]

[28]

29]

[30]

31]

[32]

33]

[34]

[35]

36]

M. Xiao et al.

[14] Matthew C. Davis, Sangheon Choi, Sam Estep, Brad A. Myers, and Joshua Sunshine. 2023. NaNofuzz: A Usable Tool for Automatic Test Generation.

In Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (San
Francisco, CA, USA) (ESEC/FSE 2023). Association for Computing Machinery, New York, NY, USA, 1114-1126. doi:10.1145/3611643.3616327

Yao Deng, Zhi Tu, Jiaohong Yao, Mengshi Zhang, Tianyi Zhang, and Xi Zheng. 2025. TARGET: Traffic Rule-Based Test Generation for Autonomous
Driving via Validated LLM-Guided Knowledge Extraction. IEEE Transactions on Software Engineering 51, 7 (2025), 1950-1968. doi:10.1109/TSE.2025.
3569086

Timothy Elvira, Tyler Thomas Procko, Lynn Vonderhaar, and Omar Ochoa. 2024. Exploring Testing Methods for Large Language Models. In 2024
International Conference on Machine Learning and Applications (ICMLA). 1152-1157. doi:10.1109/ICMLA61862.2024.00177

M. Xiao et al. 2025. BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing. https://github.com/lumos-
xiao/BASFuzz.

Andrea Fioraldi, Alessandro Mantovani, Dominik Maier, and Davide Balzarotti. 2023. Dissecting American Fuzzy Lop: A FuzzBench Evaluation.
ACM Trans. Softw. Eng. Methodol. 32, 2, Article 52 (March 2023), 26 pages. doi:10.1145/3580596

Siddhant Garg and Goutham Ramakrishnan. 2020. BAE: BERT-based Adversarial Examples for Text Classification. In Proceedings of the 2020
Conference on Empirical Methods in Natural Language Processing (EMNLP), Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liu (Eds.). Association
for Computational Linguistics, Online, 6174-6181. doi:10.18653/v1/2020.emnlp-main.498

Jakub Harasta, Tereza Novotna, and Jaromir Savelka. 2024. It cannot be right if it was written by AI: On lawyers’ preferences of documents perceived
as authored by an LLM vs a human. Artificial Intelligence and Law (2024), 1-38.

Li Huang, Weifeng Sun, Meng Yan, Zhongxin Liu, Yan Lei, and David Lo. 2025. Neuron Semantic-Guided Test Generation for Deep Neural Networks
Fuzzing. ACM Trans. Softw. Eng. Methodol. 34, 1, Article 15 (Dec. 2025), 38 pages. doi:10.1145/3688835

Yuheng Huang, Jiayang Song, Qiang Hu, Felix Juefei-Xu, and Lei Ma. 2025. AcTracer: Active Testing of Large Language Model via Multi-Stage
Sampling. ACM Trans. Softw. Eng. Methodol. (Aug. 2025). doi:10.1145/3744340 Just Accepted.

Giorgos Iacovides, Thanos Konstantinidis, Mingxue Xu, and Danilo Mandic. 2024. FinLlama: LLM-Based Financial Sentiment Analysis for Algorithmic
Trading. In Proceedings of the 5th ACM International Conference on AI in Finance (Brooklyn, NY, USA) (ICAIF ’24). Association for Computing
Machinery, New York, NY, USA, 134-141. doi:10.1145/3677052.3698696

IEC ISO and N IEC. 2017. ISO/IEC. IEEE International Standard-Systems and software engineering—Vocabulary (2017), 1-541.

Shunhui Ji, Changrong Huang, Bin Ren, Hai Dong, Lars Grunske, Yan Xiao, and Pengcheng Zhang. 2025. TAEFuzz: Automatic Fuzzing for
Image-based Deep Learning Systems via Transferable Adversarial Examples. ACM Trans. Softw. Eng. Methodol. (Jan. 2025). doi:10.1145/3714463 Just
Accepted.

Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
Lengyel, Guillaume Lample, Lucile Saulnier, et al. 2023. Mistral 7B. arXiv preprint arXiv:2310.06825 (2023).

Di Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter Szolovits. 2020. Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text
Classification and Entailment. Proceedings of the AAAI Conference on Artificial Intelligence 34, 05 (Apr. 2020), 8018-8025. doi:10.1609/aaai.v34i05.6311
Sofian Kassaymeh, Mohamad Al-Laham, Mohammed Azmi Al-Betar, Mohammed Alweshah, Salwani Abdullah, and Sharif Naser Makhadmeh. 2022.
Backpropagation Neural Network optimization and software defect estimation modelling using a hybrid Salp Swarm optimizer-based Simulated
Annealing Algorithm. Knowledge-Based Systems 244 (2022), 108511. doi:10.1016/j.knosys.2022.108511

S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi. 1983. Optimization by Simulated Annealing. Science 220, 4598 (1983), 671-680.
arXiv:https://www.science.org/doi/pdf/10.1126/science.220.4598.671 doi:10.1126/science.220.4598.671

Thanh Le-Cong, Thanh-Dat Nguyen, Bach Le, and Toby Murray. 2025. Towards Reliable Evaluation of Neural Program Repair with Natural
Robustness Testing. ACM Trans. Softw. Eng. Methodol. (Feb. 2025). doi:10.1145/3716167 Just Accepted.

Chaofan Li, Minghao Qin, Shitao Xiao, Jianlyu Chen, Kun Luo, Yingxia Shao, Defu Lian, and Zheng Liu. 2024. Making Text Embedders Few-Shot
Learners. CoRR abs/2409.15700 (2024). https://doi.org/10.48550/arXiv.2409.15700

Linyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue, and Xipeng Qiu. 2020. BERT-ATTACK: Adversarial Attack Against BERT Using BERT. In
Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Bonnie Webber, Trevor Cohn, Yulan He, and Yang
Liu (Eds.). Association for Computational Linguistics, Online, 6193-6202. doi:10.18653/v1/2020.emnlp-main.500

Cong Liu, Fangqing Zhang, Hong Zhang, Zanxi Shi, and Hanqing Zhu. 2023. Optimization of assembly sequence of building components based on
simulated annealing genetic algorithm. Alexandria Engineering Journal 62 (2023), 257-268. doi:10.1016/j.aej.2022.07.025

Han Liu, Chuan Li, Songbai He, Weimin Shi, Yin Chen, and Wen Shi. 2022. Simulated Annealing Particle Swarm Optimization for a Dual-Input
Broadband GaN Doherty Like Load-Modulated Balance Amplifier Design. IEEE Transactions on Circuits and Systems II: Express Briefs 69, 9 (2022),
3734-3738. doi:10.1109/TCSII.2022.3173608

Yi Liu, Junzhe Yu, Huijia Sun, Ling Shi, Gelei Deng, Yuqi Chen, and Yang Liu. 2024. Efficient Detection of Toxic Prompts in Large Language Models.
In Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering (Sacramento, CA, USA) (ASE ’24). Association for
Computing Machinery, New York, NY, USA, 455-467. doi:10.1145/3691620.3695018

Zhe Liu, Chunyang Chen, Junjie Wang, Mengzhuo Chen, Boyu Wu, Zhilin Tian, Yuekai Huang, Jun Hu, and Qing Wang. 2024. Testing the Limits:
Unusual Text Inputs Generation for Mobile App Crash Detection with Large Language Model. In Proceedings of the IEEE/ACM 46th International
Conference on Software Engineering (Lisbon, Portugal) (ICSE ’24). Association for Computing Machinery, New York, NY, USA, Article 137, 12 pages.
doi:10.1145/3597503.3639118

Manuscript submitted to ACM


BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing 31

[37]

[38]

[39]

40]

[41]

42]

43]

44]

45]

46]

47]

48]

49]

[50]

[51]

[52]
[53]
[54]

[55]

[56]

[57]

[58]

59]

[60]

Edward Loper and Steven Bird. 2002. NLTK: the Natural Language Toolkit. In Proceedings of the ACL-02 Workshop on Effective Tools and Methodologies
for Teaching Natural Language Processing and Computational Linguistics - Volume 1 (Philadelphia, Pennsylvania) (ETMTNLP ’02). Association for
Computational Linguistics, USA, 63-70. doi:10.3115/1118108.1118117

Bruce T Lowerre. 1976. The harpy speech recognition system. Carnegie Mellon University.

Pekka Malo, Ankur Sinha, Pekka Korhonen, Jyrki Wallenius, and Pyry Takala. 2014. Good debt or bad debt: Detecting semantic orientations in
economic texts. Journal of the Association for Information Science and Technology 65, 4 (2014), 782-796.

H. B. Mann and D. R. Whitney. 1947. On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other. The Annals of
Mathematical Statistics 18, 1 (1947), 50-60. http://www.jstor.org/stable/2236101

Valentin J.M. Manés, HyungSeok Han, Choongwoo Han, Sang Kil Cha, Manuel Egele, Edward J. Schwartz, and Maverick Woo. 2021. The Art,
Science, and Engineering of Fuzzing: A Survey. IEEE Transactions on Software Engineering 47, 11 (2021), 2312-2331. doi:10.1109/TSE.2019.2946563
Jian Mao, Ziwen Liu, Qixiao Lin, and Zhenkai Liang. 2022. Semantic-Fuzzing-Based Empirical Analysis of Voice Assistant Systems of Asian Symbol
Languages. IEEE Internet of Things Journal 9, 12 (2022), 9151-9166. doi:10.1109/JIOT.2021.3113645

Nicholas Metropolis, Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H. Teller, and Edward Teller. 1953. Equation of State Calculations by
Fast Computing Machines. The Journal of Chemical Physics 21, 6 (1953), 1087-1092. doi:10.1063/1.1699114

Abiot Molla, Shudi Zuo, Weiwei Zhang, Yue Qiu, Yin Ren, and Jigang Han. 2022. Optimal spatial sampling design for monitoring potentially toxic
elements pollution on urban green space soil: A spatial simulated annealing and k-means integrated approach. Science of The Total Environment 802
(2022), 149728. doi:10.1016/j.scitotenv.2021.149728

John Morris, Eli Lifland, Jin Yong Yoo, Jake Grigsby, Di Jin, and Yanjun Qi. 2020. TextAttack: A Framework for Adversarial Attacks, Data Augmentation,
and Adversarial Training in NLP. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations.
119-126.

Bo Pang and Lillian Lee. 2005. Seeing stars: exploiting class relationships for sentiment categorization with respect to rating scales. In Proceedings of
the 43rd Annual Meeting on Association for Computational Linguistics. 115-124.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings
of the 40th Annual Meeting on Association for Computational Linguistics (Philadelphia, Pennsylvania) (ACL ’02). Association for Computational
Linguistics, USA, 311-318. doi:10.3115/1073083.1073135

Rodrigo Pedro, Miguel E. Coimbra, Daniel Castro, Paulo Carreira, and Nuno Santos. 2025. Prompt-to-SQL Injections in LLM-Integrated Web
Applications: Risks and Defenses. In 2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE). 1768-1780. doi:10.1109/ICSE55347.
2025.00007

Mauro Pezzé, Silvia Abrahao, Birgit Penzenstadler, Denys Poshyvanyk, Abhik Roychoudhury, and Tao Yue. 2025. A 2030 Roadmap for Software
Engineering. ACM Trans. Softw. Eng. Methodol. 34, 5, Article 118 (May 2025), 55 pages. doi:10.1145/3731559

Jianing Qiu, Kyle Lam, Guohao Li, Amish Acharya, Tien Yin Wong, Ara Darzi, Wu Yuan, and Eric J Topol. 2024. LLM-based agentic systems in
medicine and healthcare. Nature Machine Intelligence 6, 12 (2024), 1418-1420.

Shuhuai Ren, Yihe Deng, Kun He, and Wanxiang Che. 2019. Generating Natural Language Adversarial Examples through Probability Weighted
Word Saliency. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Anna Korhonen, David Traum, and Lluis
Marquez (Eds.). Association for Computational Linguistics, Florence, Italy, 1085-1097. doi:10.18653/v1/P19- 1103

C. E. Shannon. 1948. A mathematical theory of communication. The Bell System Technical Journal 27, 3 (1948), 379-423. doi:10.1002/j.1538-
7305.1948.tb01338.x

Geovana Ramos Sousa Silva and Edna Dias Canedo. 2025. Privacy in Chatbot Conversation-Driven Development: A Comprehensive Review and
Requirements Proposal. ACM Trans. Softw. Eng. Methodol. (April 2025). doi:10.1145/3730578 Just Accepted.

Zeyu Sun, Zhenpeng Chen, Jie Zhang, and Dan Hao. 2024. Fairness Testing of Machine Translation Systems. ACM Trans. Softw. Eng. Methodol. 33, 6,
Article 156 (June 2024), 27 pages. doi:10.1145/3664608

Zeyu Sun, Jie M. Zhang, Mark Harman, Mike Papadakis, and Lu Zhang. 2020. Automatic testing and improvement of machine translation. In
Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering (Seoul, South Korea) (ICSE ’20). Association for Computing
Machinery, New York, NY, USA, 974-985. doi:10.1145/3377811.3380420

Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. 2014. Intriguing properties of
neural networks. In 2nd International Conference on Learning Representations, ICLR 2014.

Samson Tan, Shafiq Joty, Min-Yen Kan, and Richard Socher. 2020. It’s Morphin’ Time! Combating Linguistic Discrimination with Inflectional
Perturbations. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Dan Jurafsky, Joyce Chai, Natalie Schluter,
and Joel Tetreault (Eds.). Association for Computational Linguistics, Online, 2920-2935. doi:10.18653/v1/2020.acl-main.263

Yang Tan, Zhixing Zhang, Mingchen Li, Fei Pan, Hao Duan, Zijie Huang, Hua Deng, Zhuohang Yu, Chen Yang, Guoyang Shen, Peng Qi, Chengyuan
Yue, Yuxian Liu, Liang Hong, Huiqun Yu, Guisheng Fan, and Yun Tang. 2024. MedChatZH: A tuning LLM for traditional Chinese medicine
consultations. Computers in Biology and Medicine 172 (2024), 108290. doi:10.1016/j.compbiomed.2024.108290

Zhao Tian, Minghua Ma, Max Hort, Federica Sarro, Hongyu Zhang, and Junjie Chen. 2025. Enhanced Fairness Testing via Generating Effective
Initial Individual Discriminatory Instances. ACM Trans. Softw. Eng. Methodol. (June 2025). doi:10.1145/3737697 Just Accepted.

Miriam Ugarte, Pablo Valle, José Antonio Parejo, Sergio Segura, and Aitor Arrieta. 2025. ASTRAL: A Tool for the Automated Safety Testing of Large
Language Models. In Proceedings of the 34th ACM SIGSOFT International Symposium on Software Testing and Analysis (Clarion Hotel Trondheim,

Manuscript submitted to ACM


32

[

[

[

[61]

62]

63]

[64]

[65]

66]

[67]

[68]

[69]

[70]

[71]

[72]

73]

74]

75]

76]

[77]

78]

[79]

80]

M. Xiao et al.

Trondheim, Norway) (ISSTA Companion ’25). Association for Computing Machinery, New York, NY, USA, 31-35. doi:10.1145/3713081.3731733
Jindong Wang, Xixu Hu, Wenxin Hou, Hao Chen, Runkai Zheng, Yidong Wang, Linyi Yang, Wei Ye, Haojun Huang, Xiubo Geng, et al. 2024. On the
Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective. IEEE Data Eng. Bull. (2024).

Wenxuan Wang, Jen-tse Huang, Weibin Wu, Jianping Zhang, Yizhan Huang, Shuqing Li, Pinjia He, and Michael R. Lyu. 2023. MTTM: Metamorphic
Testing for Textual Content Moderation Software. In 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE). 2387-2399.
doi:10.1109/ICSE48619.2023.00200

Xiaosen Wang, Jin Hao, Yichen Yang, and Kun He. 2021. Natural language adversarial defense through synonym encoding. In Proceedings of
the Thirty-Seventh Conference on Uncertainty in Artificial Intelligence (Proceedings of Machine Learning Research, Vol. 161), Cassio de Campos and
Marloes H. Maathuis (Eds.). PMLR, 823-833. https://proceedings.mlr.press/v161/wang21a.html

Chunqiu Steven Xia, Matteo Paltenghi, Jia Le Tian, Michael Pradel, and Lingming Zhang. 2024. Fuzz4All: Universal Fuzzing with Large Language
Models. In Proceedings of the IEEE/ACM 46th International Conference on Software Engineering (Lisbon, Portugal) (ICSE ’24). Association for Computing
Machinery, New York, NY, USA, Article 126, 13 pages. doi:10.1145/3597503.3639121

Mingxuan Xiao, Yan Xiao, Hai Dong, Shunhui Ji, and Pengcheng Zhang. 2023. LEAP: Efficient and Automated Test Method for NLP Software. In
2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE). 1136-1148. doi:10.1109/ASE56229.2023.00052

Mingxuan Xiao, Yan Xiao, Shunhui Ji, Hanbo Cai, Lei Xue, and Pengcheng Zhang. 2024. Assessing the Robustness of LLM-based NLP Software via
Automated Testing. arXiv preprint arXiv:2412.21016 (2024).

Mingxuan Xiao, Yan Xiao, Shunhui Ji, Yunhe Li, Lei Xue, and Pengcheng Zhang. 2025. ABFS: Natural robustness testing for LLM-based NLP software.
arXiv preprint arXiv:2503.01319 (2025).

Frank Xing. 2025. Designing Heterogeneous LLM Agents for Financial Sentiment Analysis. ACM Trans. Manage. Inf. Syst. 16, 1, Article 5 (Feb. 2025),
24 pages. doi:10.1145/3688399

Yanni Xue, Haojie Hao, Jiakai Wang, Qiang Sheng, Renshuai Tao, Yu Liang, Pu Feng, and Xianglong Liu. 2024. Vision-fused attack: advancing
aggressive and stealthy adversarial text against neural machine translation. In Proceedings of the Thirty-Third International Joint Conference on
Artificial Intelligence (Jeju, Korea) (IJCAI ’24). Article 730, 9 pages. doi:10.24963/ijcai.2024/730

Huiwen Yang, Yu Zhou, and Taolue Chen. 2025. SimADFuzz: Simulation-Feedback Fuzz Testing for Autonomous Driving Systems. ACM Trans.
Softw. Eng. Methodol. (June 2025). doi:10.1145/3744242 Just Accepted.

Kaichun Yao, Hao Wang, Chuan Qin, Hengshu Zhu, Yanjun Wu, and Libo Zhang. 2024. CARL: Unsupervised Code-Based Adversarial Attacks
for Programming Language Models via Reinforcement Learning. ACM Trans. Softw. Eng. Methodol. 34, 1, Article 22 (Dec. 2024), 32 pages.
doi:10.1145/3688839

Hanmo You, Zan Wang, Junjie Chen, Shuang Liu, and Shuochuan Li. 2023. Regression Fuzzing for Deep Learning Systems. In 2023 IEEE/ACM 45th
International Conference on Software Engineering (ICSE). 82-94. doi:10.1109/ICSE48619.2023.00019

Alex Young, Bei Chen, Chao Li, Chengen Huang, Ge Zhang, Guanwei Zhang, Heng Li, Jiangcheng Zhu, Jianqun Chen, Jing Chang, Kaidong Yu,
Peng Liu, Qiang Liu, Shawn Yue, Senbin Yang, Shiming Yang, Tao Yu, Wen Xie, Wenhao Huang, Xiaohui Hu, Xiaoyi Ren, Xinyao Niu, Pengcheng
Nie, Yuchi Xu, Yudong Liu, Yue Wang, Yuxuan Cai, Zhenyu Gu, Zhiyuan Liu, and Zonghong Dai. 2024. Yi: Open Foundation Models by 01.AI. CoRR
abs/2403.04652 (2024). https://doi.org/10.48550/arXiv.2403.04652
Boxi Yu, Yiyan Hu, Qiuyang Mang, Wenhan Hu, and Pinjia He. 2023. Automated Testing and Improvement of Named Entity Recognition Systems.
In Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (San
Francisco, CA, USA) (ESEC/FSE 2023). Association for Computing Machinery, New York, NY, USA, 883-894. doi:10.1145/3611643.3616295
Zhuohao Yu, Chang Gao, Wenjin Yao, Yidong Wang, Zhengran Zeng, Wei Ye, Jindong Wang, Yue Zhang, and Shikun Zhang. 2024. FreeEval:
A Modular Framework for Trustworthy and Efficient Evaluation of Large Language Models. In Proceedings of the 2024 Conference on Empirical
Methods in Natural Language Processing: System Demonstrations, Delia Irazu Hernandez Farias, Tom Hope, and Manling Li (Eds.). Association for
Computational Linguistics, Miami, Florida, USA, 1-13. doi:10.18653/v1/2024.emnlp-demo.1

Lifan Yuan, Yangyi Chen, Ganqu Cui, Hongcheng Gao, FangYuan Zou, Xingyi Cheng, Heng Ji, Zhiyuan Liu, and Maosong Sun. 2023. Revisiting

Out-of-distribution Robustness in NLP: Benchmarks, Analysis, and LLMs Evaluations. In Advances in Neural Information Processing Systems, A. Oh,
T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine (Eds.), Vol. 36. Curran Associates, Inc., 58478-58507. https://proceedings.neurips.cc/
paper_files/paper/2023/file/b6b5£50a2001ad1cbccca96e693c4ab4-Paper-Datasets_and_Benchmarks.pdf

Eric Zelikman, Eliana Lorch, Lester Mackey, and Adam Tauman Kalai. 2024. Self-Taught Optimizer (STOP): Recursively Self-Improving Code
Generation. In First Conference on Language Modeling. https://openreview.net/forum?id=46Zgqo4QIU

Quanjun Zhang, Weifeng Sun, Chunrong Fang, Bowen Yu, Hongyan Li, Meng Yan, Jianyi Zhou, and Zhenyu Chen. 2025. Exploring Automated
Assertion Generation via Large Language Models. ACM Trans. Softw. Eng. Methodol. 34, 3, Article 81 (Feb. 2025), 25 pages. doi:10.1145/3699598
Quan Zhang, Chijin Zhou, Gwihwan Go, Bingi Zeng, Heyuan Shi, Zichen Xu, and Yu Jiang. 2024. Imperceptible Content Poisoning in LLM-Powered
Applications. In Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering (Sacramento, CA, USA) (ASE ’24).
Association for Computing Machinery, New York, NY, USA, 242-254. doi:10.1145/3691620.3695001

Xiaoyu Zhang, Cen Zhang, Tianlin Li, Yihao Huang, Xiaojun Jia, Ming Hu, Jie Zhang, Yang Liu, Shiqing Ma, and Chao Shen. 2025. JailGuard: A
Universal Detection Framework for Prompt-based Attacks on LLM Systems. ACM Trans. Softw. Eng. Methodol. (March 2025). doi:10.1145/3724393
Just Accepted.

Manuscript submitted to ACM


BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing 33

[81] Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015. Character-level Convolutional Networks for Text Classification. In Advances in Neural
Information Processing Systems, C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett (Eds.), Vol. 28. Curran Associates, Inc. https:
//proceedings.neurips.cc/paper_files/paper/2015/file/250cf8b51c773f3f8dc8b4be867a9a02-Paper.pdf

82] Zhe Zhao, Guangke Chen, Tong Liu, Taishan Li, Fu Song, Jingyi Wang, and Jun Sun. 2024. Attack as Detection: Using Adversarial Attack Methods
to Detect Abnormal Examples. ACM Trans. Softw. Eng. Methodol. 33, 3, Article 68 (March 2024), 45 pages. doi:10.1145/3631977

[83] Shasha Zhou, Mingyu Huang, Yanan Sun, and Ke Li. 2024. Evolutionary Multi-objective Optimization for Contextual Adversarial Example Generation.

Proc. ACM Softw. Eng. 1, FSE, Article 101 July 2024), 24 pages. doi:10.1145/3660808

[84] Kun Zhu, Shi Ying, Nana Zhang, and Dandan Zhu. 2021. Software defect prediction based on enhanced metaheuristic feature selection optimization

and a hybrid deep neural network. Journal of Systems and Software 180 (2021), 111026. doi:10.1016/j.jss.2021.111026

Manuscript submitted to ACM
