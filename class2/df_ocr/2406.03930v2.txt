arXiv:2406.03930v2 [cs.CL] 14 Mar 2025

Culturally Aware and Adapted NLP: A Taxonomy and a Survey of the
State of the Art

Chen Cecilia Liu!” and Iryna Gurevych! and Anna Korhonen?
' UKP Lab, Department of Computer Science and hessian.AlI,
Technical University of Darmstadt
? Konrad Zuse School of Excellence in Learning and Intelligent Systems (ELIZA)
> Language Technology Lab, University of Cambridge
{chen. liu, iryna. gurevych}@tu-darmstadt.de, alk23@cam.ac.uk

Abstract

The surge of interest in culture in NLP has
inspired much recent research, but a shared
understanding of “culture” remains unclear,
making it difficult to evaluate progress in this
emerging area. Drawing on prior research
in NLP and related fields, we propose a fine-
grained taxonomy of elements in culture that
can provide a systematic framework for ana-
lyzing and understanding research progress.
Using the taxonomy, we survey existing re-
sources and methods for culturally aware and
adapted NLP, providing an overview of the
state of the art and the research gaps that still
need to be filled.

1 Introduction

Culture is rapidly becoming an important research
topic in Natural Language Processing (NLP), with
a significant recent surge in the number of pub-
lished papers (Figure 1). Current NLP systems,
especially Large Language Models (LLMs) often
lack fairness and diversity in cultural awareness,
which leads to biased performance that dispropor-
tionately favours certain groups, and causes harm
to others (Sambasivan et al., 2021; Johnson et al.,
2022; Cao et al., 2023; Hofmann et al., 2024b). To
build technology that is equitable, inclusive and
accessible, the NLP community must actively take
the initiative, enhancing LLMs’ cultural awareness
and adaptability. Given the keen interest in this
area and its importance for the safety and fairness
of LLMs, it is now important to consolidate exist-
ing research on culturally aware and adapted NLP
to take stock of the progress made so far and to
identify research gaps. However, this is challenged
by the lack of a common understanding of the con-
cept of “culture” in NLP.

Prior work in NLP such as Hershcovich et al.
(2022) laid the vital foundations for understanding
how language, culture and society interact. Hersh-
covich et al. (2022) proposed a simple taxonomy

1.51%

1.06%

15
250
J
& 0.93%
25 0.49%
0.31% J
> —_

2020-12 2021-12 2022-12 2023-12 2024-11

Figure 1: Papers title and abstract containing "culture"
or "cultural" published in the main and findings of
AACL/EACL/NAACL/ACL/EMNLP and TACL within
5 years, with normalized percentages based on the total
number of papers at included venues to date.

derived from the interaction between language and
culture that captures broad elements of culture (lin-
guistic form and style, objectives and values, com-
mon ground, and aboutness). More recently, Adi-
lazuarda et al. (2024) adopted “proxies of culture”
(semantic or demographic proxies). While neither
provides a shared understanding of culture, perhaps
unsurprisingly, language is an essential component
of culture in NLP.

A shared understanding of culture in NLP could
benefit from examining definitions developed in an-
thropology and social sciences.! In these fields (Ty-
lor, 1871; Kroeber and Kluckhohn, 1952; White,
1959; UNESCO, 1982; Matsumoto and Juang,
1996; Blake, 2000; Geertz, 1973; Goffman, 2023),
most definitions of culture involve people, groups,
and the interactions within and between individuals
and groups.

Murdock (1940) describes culture as
“ideational”? and “social”. White (1959) de-
scribes the locus of culture as: 1) “within human”
(e.g., concepts, beliefs, i.e., ideational), 2) between
“social interaction among human beings”, and 3)
outside of human but “within the patterns of social
interaction”. An examination of such work reveals
that social interactions are critical components of

'They have been thinking about culture for over a century!
The values, beliefs, norms, and ideas that comprise a way
of life (Murdock, 1940; Briggle and Mitcham, 2012b).


Figure 2: An overview of the taxonomy with examples of subcategories of future possible expansions. The elements
in culture are organized into three different branches: ideational, linguistic, and social. The ideational branch (§3.1
encompasses the non-material aspects of culture that constitute a way of life. The linguistic branch (§3.2) focuses
on cultural variations in language and linguistic forms, bridging the ideational and social elements of culture. The
social branch (§3.3) covers key factors in social interaction and communication.

culture, in addition to ideational elements. Notably,
this social aspect is underrepresented in previous
cross-cultural NLP research (Hershcovich et al.,
2022; Adilazuarda et al., 2024).3

Hence, we combine the emphasis on /anguage in
prior NLP work, while integrating the significance
of social and ideational elements that shape culture.
This leads us to a working definition of culture
used to taxonomize recent work in NLP in this
survey: Culture encompasses the collective ideas,
shared language, and social practices that emerge
from and evolve through human social interactions
within a society.

Grounded in this working definition, we intro-
duce a new fine-grained taxonomy of culture by ex-
panding on the basic categories of prior work (Hovy
and Yang, 2021; Hershcovich et al., 2022) to ad-
dress above-mentioned issues. We then use this
taxonomy to organize existing works in culturally
aware and adapted NLP, and identify research gaps.
Our survey of 127 publications in leading *CL
venues (see selection method in Appendix A) pro-
vides an up-to-date view of cultural adaptation re-
sources and models and identifies areas of progress
as well as new research opportunities. We hope our
taxonomy and analysis enable and inspire further
research in this important emerging area.

2 The Taxonomy

In this section, we present our new taxonomy of
culture. Unlike previous NLP studies (Hershcovich
et al., 2022; Hovy and Yang, 2021) that sought

*There is also prior work focusing on social NLP (Hovy

and Yang, 2021) which is related. However, culture is not the
central theme of the work.

to define cultural elements, this taxonomy (1) is
grounded in well-established elements of culture
in anthropology and social sciences (Tylor, 1871;
Kroeber and Kluckhohn, 1952; White, 1959), (ii)
consists of more fine-grained elements than in ear-
lier work, and (iii) allows for a wider consideration
of how social factors and variations in humans in-
fluence culture.

Figure 2 presents a taxonomy of cultural ele-
ments derived from our working definition in §1,
organized into three main branches: ideational, lin-
guistic, and social.* The ideational branch (§3.1;
Murdock 1940; Briggle and Mitcham 2012a) en-
compasses the non-material aspects of culture that
constitute a way of life, such as values or knowI-
edge. The linguistic branch (§3.2) focuses on cul-
tural variations in language and linguistic forms,
bridging the ideational and social elements of cul-
ture. The social branch (§3.3) covers key factors
in social interaction and communication, such as
relationships or communicative goals.> Here, we
define each element based on existing research and
relating to example tasks in the NLP context. We
then provide details and examples from the current
literature in §3.1, §3.2 and §3.3.

Ideational elements are based on well-established
discussions of culture (Tylor, 1871; Kroeber and
Kluckhohn, 1952; White, 1959):

Concepts: basic units of meaning that structure
and facilitate thought, bridging sensory experi-

‘Tcons in Figure 2 are created with the assistance of DALL-
E.

>All cultural elements can interact and influence each other
based on context and can be divided into finer groups. Sim-

ilar to prior work, our taxonomy abstracts away from these
contextual variations.


ence (Jackendoff, 1989, 2012), e.g., cuisines (such
as schnitzel, ratatouille) or holidays (such as Di-
wali, Nowruz). Related NLP task examples: ques-
tion answering, dialogue generation.

Knowledge: information that can be acquired
through education or practical experience, e.g., lo-
cal agricultural knowledge. Related NLP task ex-
amples: dialogue generation, reasoning.

Values: beliefs, desirable end states or behaviours
ranked by importance that can guide evaluations of
things (Schwartz, 1992). Unlike norms and morals,
values do not inherently involve ethical judgment,
e.g., beauty standards, or perception of hate speech.
Related NLP task examples: content moderation,
debiasing.

Norms and Morals: set of rules or principles that
govern people’s behaviour and everyday reason-
ing (Cialdini et al., 1991; Bicchieri et al., 2018;
Hechter and Opp, 2001; Gert and Gert, 2025), e.g.,
filial obedience attitude. Related NLP task exam-
ples: reasoning, safety alignment.

Artifacts: items that are products of human cul-
ture, such as art, poetry (White, 1959) etc. This is
ideational in our taxonomy since we do not work
on physical buildings or tools in NLP. Related NLP
task examples: machine translation of long-form
literature, emotion arc analysis of movies, memes
classification.

Linguistic elements relate to language variations
in the cultural context, based on existing discus-
sions (Wardhaugh and Fuller, 2021):

Dialects: includes variations of languages in a sys-
tematic way (Fromkin et al. 1998; Trudgill 2000;
Wardhaugh and Fuller 2021; such as dialects con-
tinuum, regionalects, sociolects etc.), e.g., African
American (Vernacular) English (AAE/AAVE). Re-
lated NLP task examples: machine translation, de-
biasing.

Styles, Registers, Genres: includes elements such
as formality, variations of language in situation
and communicative forms (Wardhaugh and Fuller,
2021), e.g., formality in text, slang, or specific
genres like news, folk tales. Related NLP task ex-
amples: style transfer, creative writing generation.

Social elements focus on social interactions and
communication among humans within the scope
of NLP. Leveraging the work of (Hovy and Yang,
2021), we identify relevant elements:

Relationship: connection between two or more in-
dividuals or groups, e.g., father-son, colleagues.
Related NLP task examples: creative writing gen-

eration, dialogue generation.

Context: the “containers” of communica-
tions (Yang, 2019), which can be linguistic such as
surrounding sentences or extra-linguistic (Hovy
and Yang, 2021) including social settings (e.g.,
at a wedding), non-verbal cues (e.g., gesture), or
historical contexts (e.g., colonization). Related
NLP task examples: coreference resolution,
pragmatic inference.

Communicative Goals: the intention behind lan-
guage use, e.g., requests, apologies, persuasion.
Related NLP task examples: intent classification,
emotion classification, human-AlI collaboration.
Demographics: the characteristics of people, e.g.,
economic income, education level, nationality, lo-
cation, political view, family status, etc. Related
NLP task examples: content moderation, personal-
ization.

3 Elements of Culture in Current NLP
(Resources) Literature

In this section, we survey and categorize NLP re-
sources. Table 1 shows an overview of papers or-
ganized according to the taxonomy.

We observe that in resources, culture can be
captured in 1) the data itself, or 2) in the labels
(e.g., multi-culturally annotated). Further, while
cultural differences are evident in linguistic and
social elements, most current work relies on stan-
dard language or country boundaries, leaving these
elements understudied.

3.1 Ideational Elements
3.1.1 Concepts

We can divide concepts into 1) basic concepts that
are “configured” differently, reflecting the cultural-
specific way of thinking,° and 2) concepts that are
unique to a culture (Wierzbicka, 1992)?

Recent NLP research has explored grounding
time expressions across cultures (Shwartz, 2022)
and culinary concepts in recipe adaptations (Cao
et al., 2024b). Additionally, studies have exam-
ined how various cultures use concepts across cat-
egories, such as through metaphors (Kabra et al.,
2023) or traditional proverbs and sayings (Liu et al.,

®For example, one can explore the citizen science project
for lexicon associations: https://smallworldofwords.
org/en/project/home.

’For example, “Kopi Ga Dai” in Singaporean English ver-
sus “double-double” in Canada, both referring to coffee with
extra sweetness and creaminess, but very different.


Element

Papers

Concepts

Values - general

Values - bias

Values - hate

Values - other perceptions

Artifacts

Shwartz 2022; Majewska et al. 2023; Hu et al. 2023; Kabra et al. 2023
Liu et al. 2024a; Cao et al. 2024b; Jiang and Joshi 2024; Hu et al. 2024
Vision-Language: Liu et al. 2021; Yin et al. 2021; Thapliyal et al. 2022
Khanuja et al. 2024; Li et al. 2024c; Bhatia et al. 2024; Nayak et al. 2024

Probing: Kassner et al. 2021; Yin et al. 2022; Keleg and Magdy 2023; Zhou et al. 2024; Bhatt and Diaz 2024
MMLWU: Koto et al. 2023; Li et al. 2024b; Koto et al. 2024a; Wang et al. 2024b; Son et al. 2024
Common sense: Ponti et al. 2020; Wibowo et al. 2024; Koto et al. 2024b; Acquaye et al. 2024; Shi et al. 2024

Tay et al. 2020; Ramezani and Xu 2023; Cao et al. 2023; Wang et al. 2024c
Yao et al. 2024b; Aakanksha et al. 2024

WEAT: Malik et al. 2022; Espafia-Bonet and Barrén-Cedefio 2022; Mukherjee et al. 2023; Zhao et al. 2023
Sahoo et al. 2023; Naous et al. 2024; Jha et al. 2023; Bhutani et al. 2024; Mukherjee et al. 2024
Sent. Pairs: Nangia et al. 2020; Névéol et al. 2022; Felkner et al. 2023; Sahoo et al. 2024
Other: Campolungo et al. 2022; Sandoval et al. 2023; Attanasio et al. 2023; Bauer et al. 2023
Zhou et al. 2022; Lee et al. 2023a; Palta and Rudinger 2023; An et al. 2023; Jin et al. 2024; Hsieh et al. 2024

Mohamed et al. 2022; Frenda et al. 2023; Casola et al. 2024; Havaldar et al. 2024
Mohamed et al. 2024; Deas et al. 2024

Forbes et al. 2020; Emelin et al. 2021; Ziems et al. 2022b; Kim et al. 2022; Moghimifar et al. 2023
Fung et al. 2023; Pyatkin et al. 2023; CH-Wang et al. 2023; Ziems et al. 2023a; Dwivedi et al. 2023
Rao et al. 2023; Huang and Yang 2023; Sun et al. 2023; Li et al. 2023b
Zhan et al. 2024; Kim et al. 2024; Bhatt and Diaz 2024; Vijjini et al. 2024; Liu et al. 2024c

Epure et al. 2020; Mohamed et al. 2022; Kruk et al. 2023
Jiang et al. 2023; Mohamed et al. 2024; Hobson et al. 2024

Dialects

Styles, Registers, Genres

Ziems et al. 2022a, 2023b; Le and Luu 2023; Pliiss et al. 2023; Kuparinen et al. 2023
Elmadany et al. 2023; Deas et al. 2023; Khondaker et al. 2023; Faisal et al. 2024

Sweed and Shahaf 2021; Sun and Xu 2022; Nadejde et al. 2022
Srinivasan and Choi 2022; Havaldar et al. 2023a

Relationship

Demographics

Li et al. 2023b; Jurgens et al. 2023; Shaikh et al. 2023; Ziems et al. 2023a; Zhan et al. 2024

Forbes et al. 2020; Emelin et al. 2021; Kim et al. 2022; Ziems et al. 2023a; Moghimifar et al. 2023
Rao et al. 2023; Sun et al. 2023; CH-Wang et al. 2023; Zhan et al. 2024

Frenda et al. 2023; Lahoti et al. 2023; Ziems et al. 2023a; Casola et al. 2024; Lee et al. 2024b

Table 1: Recent resource work considered in §3 by elements (selection method in Appendix A). The three blocks

(divided by double lines) correspond to ideational, linguistic, and social elements respectively.

2024a). In vision and language (VL) settings, cul-
turally unique concepts have been integrated into
reasoning and captioning tasks (Liu et al., 2021;
Yin et al., 2021; Thapliyal et al., 2022; Li et al.,
2024c) or assess multimodal content adaptations
(Khanuja et al., 2024) and generation of text-to-
image models (Liu et al., 2023c).

These datasets are often small due to high anno-
tation costs, and most are only available for evalua-
tion. Training and evaluation datasets still lack di-
versity across cultures, languages, and concept cat-
egories (e.g., rituals, aesthetics, spatial relations).

3.1.2 Knowledge

Cultural knowledge can be factual or common
sense.’ What weather phenomena can be expected
if a rapidly rotating tropical storm forms off the
coast of our country? (It’s likely called a hurricane
if one is in US, a typhoon if one is in Korea.) Is tofu

5Common sense and norms are sometimes used inter-
changeably in NLP. Norms are acceptable behavioural patterns
of a group (§2), which we will discuss in §3.1.4.

pudding sweet or salty by default? (In China, it’s
typically sweet in the south but salty in the north.)

We identified three major types of resources in
NLP literature: 1) probing (by masking entities), 2)
multiple choice question answering (MCQA), and
3) knowledge bases.

Assessing language models’ knowledge has
long been important, with early studies examin-
ing this across languages predating LLMs (Kassner
et al., 2021; Yin et al., 2022; Keleg and Magdy,
2023; Zhou et al., 2024). Recently, MMLU-
style (Hendrycks et al., 2021) MCQA benchmarks
have advanced LLM development and inspired cul-
tural variants (e.g., Li et al. 2024b, details in Ta-
ble 1) covering aspects like food, history, and geog-
raphy in respective languages. However, MMLU-
style benchmarks, often based on standard exams
and textbooks, lack integration with broader cul-
tural elements. In contrast, other common sense
knowledge datasets (e.g., Wibowo et al. 2024, Koto
et al. 2024b) can incorporate other elements un-
der “linguistic” (e.g., in dialects) or “social” (such


as from diverse demographics with geographic re-
gions) branches.

Finally, integrating knowledge bases (KB) with
models enhances cultural awareness (Bhatia and
Shwartz, 2023) and supports culturally relevant syn-
thetic data generation (Kim et al., 2023). Despite
recent efforts in creating cultural KB from other
venues (Nguyen et al., 2023; Fung et al., 2024;
Nguyen et al., 2024), *CL community examples
remain limited.

3.1.3. Values

Diverse ranking of values among groups can result
in differences in aboutness, communication styles,
perceptions and multiple other dimensions (Hofst-
ede, 1984, 2011). Such differences in pre-training
data can be reflected in LLMs.

Many recent studies on evaluation (Johnson

et al., 2022; Ramezani and Xu, 2023; Cao et al.,
2023; Durmus et al., 2024; Santurkar et al., 2023;
Masoud et al., 2025; Havaldar et al., 2023b; Wang
et al., 2024c, inter alia) show that LLMs align bet-
ter with values of WEIRD (Western, Educated, In-
dustrialized, Rich and Democratic, Henrich et al.
2010) people, raising concerns about the fairness
and safety of LLMs for others. Here, Pew Global
Attitudes Survey (PEW)?’, the World Values Sur-
vey (WVS)!° and the Hofstede Cultural Dimen-
sions (Hofstede, 1984, 2011) are commonly used
for evaluation, along with regional variants like the
European Values Survey (EVS, EVS 2011). How-
ever, the questions of how to improve the model’s
value alignment with diverse cultures, what re-
sources to collect and whom to collect from remain
unsolved (Kirk et al., 2024).
Biases. In contrast to general cultural values, bi-
ases have been long-studied in NLP, such as gender
bias in machine translation (Stanovsky et al., 2019;
Savoldi et al., 2021; Campolungo et al., 2022; San-
doval et al., 2023; Attanasio et al., 2023, inter alia)
or bias towards particular social groups. Differ-
ences in value “ranking” lead cultures to exhibit
distinct biases toward the same groups or unique bi-
ases specific to certain cultures (e.g., caste systems,
unnatural beauty standards). These variations are
central to the study of cultural biases and are the
focus of our work.

To enable evaluations of cross-cultural variations
in biases and develop transferable de-biasing meth-
ods, recent work has created varieties of culturally

https ://www.pewresearch.org/
https ://www.worldvaluessurvey.org/

aware datasets to aid evaluations, including targets
and attribute word sets, sentence pairs, conversa-
tional and QA data (see Table 1 for the papers).
Overall, this area shows notable progress com-
pared to other sub-areas. Recent surveys on gen-
eral biases cover key topics like evaluation and de-
biasing methods (Sun et al., 2019; Meade et al.,
2022; Dev et al., 2022; Delobelle et al., 2022),
which we refer readers to them for further details.
Hate. Like biases, perceptions of hatefulness in
the text also vary across cultures, as shown in re-
cent research on hate speech classification (Sap
et al., 2022; Zhou et al., 2023a,b; Lee et al., 2023b;
Lwowski et al., 2022; Arango Monnar et al., 2022).
Such model disparities may be due to the data
source (i.e., using machine translations, not native
text) or the labelling process. The first issue can be
addressed by diversifying data sources, incorporat-
ing authentic local data (Shekhar et al., 2022; Jeong
et al., 2022). The second issue can be mitigated by
creating annotations from diverse cultural groups.
Recently, CREHate (Lee et al., 2024b) investigates
variations in hate speech perceptions within the
same language, highlighting the need for further
research.
Other Perceptions. The perception of politeness,
aesthetic appeal or emotions can also vary across
cultures (House and Kasper, 1981; Mesquita et al.,
1997; Masuda et al., 2008; Ringel et al., 2019;
Abdelkadir et al., 2024). For example, whether
a piece of text is deemed humorous or ironic is
culturally dependent. Frenda et al. (2023); Casola
et al. (2024) try to address this with cross-cultural
annotated (multilingual) irony corpora. Similarly,
visual elements in arts can elicit different emotions
in different cultural groups. ArtELingo (Mohamed
et al., 2022, 2024) provides benchmarks with mul-
tilingual captions and emotion labels for artworks
to evaluate models’ cultural-transfer performance.
This research area is significantly limited.

3.1.4 Norms and Morals

In ethics, a distinction is made between descrip-
tive and normative morality (Gert and Gert, 2025).
In NLP, this distinction is often overlooked (Vida
et al., 2023) with a greater emphasis on the “end
product’, which is the final set of rules or principles
and their judgments. !!

Several norm banks exist, built through auto-
matic, semi-automatic, or manual methods using

‘This is reasonable for standard NLP tasks but should be
re-evaluated for high-stakes judgment-based applications.


sources like conversations, social media, or gov-
ernment websites (Forbes et al., 2020; Fung et al.,
2023; CH-Wang et al., 2023; Dwivedi et al., 2023).
These norm banks have also been automatically
adapted to defensible norms in fine-grained situ-
ations (Pyatkin et al., 2023; Rao et al., 2023) or
inference tasks (CH-Wang et al., 2023; Huang and
Yang, 2023) for LLM evaluation and adaptation.

For model alignment, several approaches focus
on “inquisition”, directly questioning LLMs about
issues through conversation or a QA task (Kim
et al., 2022; Sun et al., 2023; Yu et al., 2024; Lee
et al., 2024a; Yuan et al., 2024). A challenge with
this approach is that a model’s responses do not
always align with its behaviour in usage (i.e., con-
versation). Thus, culturally aligned conversational
data show greater potential for behaviour adapta-
tion (Li et al., 2023b; Zhan et al., 2024). However,
existing resources have limited coverage beyond
Western, Chinese, and Indian cultures.

3.1.5 Artifacts

NLP research on artifacts has focused on (monolin-
gual or mono-cultural) artifacts in texts, e.g., fairy
tales, fiction, poetry and songs (Yang et al., 2019;
Haider et al., 2020; Chakrabarty et al., 2021; Xu
et al., 2022; Thai et al., 2022; Jiang et al., 2023;
Ou et al., 2023; Li et al., 2023a), or in multimodal
such as movies, humour and memes (Sharma et al.,
2020; Liu et al., 2022a; Hessel et al., 2023; Hong
et al., 2023), to name a few. While “artifacts” is
an independent cultural element, usage in adap-
tation typically involves tasks that align with one
or more previously mentioned categories, making
design challenging. For example, in ArtELingo (in
§3.1.3), the input data focuses on art, while cross-
cultural measurement studies perceptions, which
reflect cultural values. Similarly, translations of
literary novels need to account for concept differ-
ences such as names (Jiang et al., 2023) across
cultures. Research on integrating cross-cultural dif-
ferences into modelling and data acquisition with
artifacts remains limited.

3.2 Linguistic Elements
3.2.1 Dialects

A dialect is a variant of a language (Haugen, 1966)
at the local regional level (e.g., Hessian German),
national level (e.g., Tunisian Arabic) or by other
factors (e.g., AAVE).

Many existing work focuses on dialect identifi-
cation (Salameh et al., 2018; Abdelali et al., 2021;

Hamiilainen et al., 2021; Yusuf et al., 2022), but
how to enable LLMs to serve dialectal communi-
ties remains an open question. Recently, multiple
studies have identified disparities in NLP models
(Ziems et al., 2022a; Le and Luu, 2023; Paonessa
et al., 2023; Deas et al., 2023) when evaluated
across different language variations.

Current dialect datasets primarily consist of
translations between dialects and standard lan-
guages or are created through dialect normalization,
in text, audio, or both (Pliiss et al., 2023; Kupari-
nen et al., 2023). Few studies focus on traditional
generation tasks like summarization or standard
benchmark tasks (e.g., classifications or inferences
Maronikolakis et al. 2022; Held et al. 2023; Faisal
et al. 2024). Overall, research on German and En-
glish dialects is more advanced (marginally) than
other dialect types.

3.2.2 Styles, Registers and Genres

Styles, registers (e.g., slang), and genres (e.g.,
news) depend on the context of language use (Ward-
haugh and Fuller, 2021). Compared to other el-
ements, recent developments in this area appear
limited, with a handful of examples focusing on
slang, formality or politeness (Sun and Xu, 2022;
Nadejde et al., 2022; Srinivasan and Choi, 2022;
Havaldar et al., 2023a).

3.3 Social Elements

3.3.1 Relationship

In many cultures, communication could differ de-
pending on the relationship between the speakers.
For example, Chinese has distinct terms for elder
vs. younger siblings. Translations to (and from)
a language without this property may result in a
loss of nuances in meaning. In Korea and Japan,
misused politeness level in conversation can vio-
late cultural norms (Matsumoto, 1988; Ambady
et al., 1996), especially in different social rela-
tionships. Additionally, certain relationships exist
uniquely within specific cultures, such as “God-
mother’. Considering relationships is important
for building resources and modelling culturally ap-
propriate methods. Zhan et al. (2024) serve as a
recent example with this consideration.

3.3.2 Context

In NLP, linguistic context could be the surrounding
text. Studies by Hovy et al. (2020); Akinade et al.
(2023); Stewart and Mihalcea (2024) show that


machine translation systems can fail without appro-
priate consideration of linguistic context, revealing
its importance in resource and model development.
However, human communication is much richer,
relying on the extra-linguistic context that situates
language within broader frames of reference.

The extra-linguistic context can be situational
(setting or location where communication occurs,
e.g., at school, in a hospital), historical (past events,
e.g., colonization, that change cultural values or lan-
guage use, like in Hong Kong) or non-verbal (e.g.,
hand gesture, tone of voice). Each type shapes
and reflects culture. These contexts significantly
enhance conversational tasks, norm bank develop-
ment, and visual-language applications (Zhan et al.,
2023; Ziems et al., 2023a), enabling NLP models to
interpret nuanced language elements beyond words,
thus improving response relevance and accuracy.

3.3.3. Communicative Goals

Different cultures can have distinctive communi-
cation styles depending on communicative goals.
For example, people may use indirect language
for refusal (versus direct refusal with a “no’’) to
avoid confrontation (House, 2005). Cultures may
also exhibit variations in responses to the same
situation (e.g., how to make requests and when to
apologize, Blum-Kulka and Olshtain 1984). Taking
this type of variation into account is important for
cross-cultural pragmatic-inspired tasks — an area
that remains understudied, with limited examples
identified in Table 1.

3.3.4 Demographics

A household with a monthly income of less than
50 US dollars is likely to have different house-
hold items than that with 5000 US dollars (Rojas
et al., 2022). Névéol et al. (2022) also found that
the original English CrowS-Pair dataset relied on
names as proxies for a sociodemographic group
(“Amy for women, Tyrone for African American
men’, Névéol et al. 2022), whereas the French ver-
sion features direct references to sociodemographic
groups. These data differences may stem not only
from cultural influences but also from the demo-
graphics of the data contributors. Where and from
whom one collects data matters, as it can result in
dramatic differences in data and modelling.
Demographic information is also important in
annotation (Sap et al., 2022; Pei and Jurgens, 2023;
Santy et al., 2023), where a piece of text can be
humorous to some people but offensive to oth-

ers (Meaney, 2020). In such cases, culture may
exist in the labels rather than in the data. Recently,
Lee et al. (2024b) and Frenda et al. (2023) show
how to capture different cultural views of annota-
tors using the same dataset.

3.4 Usage of the Taxonomy

Covering the key elements of culture, our taxon-
omy can act as a useful reference point for NLP sys-
tem development, in addition to organizing existing
literature. For example, the development of cultur-
ally aware debiasing should consider /deational
elements such as Values, Norms & Morals as well
as Social elements such as Demographics to inform
the focus of debiasing, along with Linguistic ele-
ments such as dialects to inform the choice of data
for the task. The applicable elements of culture
will vary between tasks and contexts, with the tax-
onomy acting as a useful checklist. See Appendix
B for additional examples.

4 Culturally Aware Resource Acquisition

Resources discussed in §3 are essential for cultur-
ally aware NLP. As additional resources are much
needed, this section surveys methods for creating
new resources (an overview in Appendix Figure 4).

Resources can be classified based on their ac-
quisition methods—manual, automatic, or semi-
automatic—and their source types: 1) newly cre-
ated (New, from scratch), or 2) culturally adapted
from existing resources (CA, e.g., through transla-
tion from the original data, followed by culturally
appropriate changes). 1) captures unique cultural
phenomena but is often limited by funding or ac-
cess to native speakers. 2) provides an alternative,
though accurately reflecting cultural phenomena
can be challenging.

4.1 Manual: Incorporating Native Speakers,
Communities, and Experts

A common strategy is to employ native speakers or
experts (e.g., professional translators or students)
for data acquisition. This can be done via crowd-
sourcing platforms such as Amazon Mechanical
Turk and Prolific (Liu et al., 2021, 2024a) or in
a community-driven manner, leveraging networks
such as Masakhane !”, IndoNLP !3, university mail-
ing lists, or Slack/Discord of organizations. Involv-
ing native speakers and communities to address

https: //www.masakhane. io/
SBhttps://indonlp. github. io/


cultural variations requires responsible design and
thoughtful considerations.

New: Most existing culture resources have been
built by involving native speakers or communi-
ties for dataset acquisition (Liu et al., 2021; Ma-
ronikolakis et al., 2022; Koto et al., 2023; Kabra
et al., 2023). For non-language related commu-
nities, WinoQueer (Felkner et al., 2023) utilizes
channels such as Slacks/Discord, and gay Twitter
to reach the LGBTQ+ community and generates
benchmarks based on community survey results.

CA: When starting from existing datasets, some
works also involved communities (e.g., using sur-
veys) in determining the needed modifications and
supplements to datasets (Névéol et al., 2022; Hu
et al., 2023; Majewska et al., 2023; Jin et al., 2024).
These adaptations range from simple changes, such
as updating names and locations to fit the target
culture, to creating entirely new instances.

In general, native speakers are consulted through-
out the life-cycle of new data acquisition (from an-
notations to quality checks). However, the entire
community is rarely consulted during the initiation
stage (i.e., designing tasks). Involving native speak-
ers can be costly and difficult, but is a best practice
that enhances quality and cultural authenticity.

4.2 Automatic: Models and Pipelines

Since manual adaptation is slow and hard to scale,
the use of automation has gained popularity in re-
source acquisition.

New: For instance, CANDLE (Nguyen et al.,
2023) proposes a pipeline to extract cultural com-
monsense knowledge using various techniques like
NER extraction, cultural facet classification, con-
cepts extraction and ranking through algorithms
or LMs. NormsSAGE (Fung et al., 2023) utilizes
LLMs for norm discovery from conversation data,
then performs model self-verification to validate
and filter the data. CultureAtlas (Fung et al., 2024)
extracts cultural knowledge from Wikipedia and hy-
perlinked document pages using LLMs for filtering
and adversarial knowledge generation.

Recent works have also used sociodemographic
prompting (Santurkar et al., 2023; Deshpande et al.,
2023; Hwang et al., 2023; Beck et al., 2024) — ex-
tending input prompts with sociodemographic in-
formation — to generate outputs tailored to specific
groups. Further research could reduce data acquisi-
tion efforts, particularly for generating subcultural
data variations within WEIRD people. However, it

has also been argued that LLMs do not accurately
mimic individual or group behaviours (Argyle et al.,
2023; Aher et al., 2023; Beck et al., 2024).

CA: Putri et al. (2024) examine automatic adap-
tation (paraphrasing and concept replacement) of
Commonsense QA in Indonesian and Sundanese.
Current GPT models, however, reveal disparities in
cultural adaptation across languages, highlighting
the need for further research.

4.3 Semi-Automatic: Structured Resources,
Model-in-the-Loop

As demonstrated by Putri et al. (2024), LLMs strug-
gle with fully automated cultural adaptations. Al-
ternatively, semi-automatic approaches combine
the quality of manual work with scalability.

New: Methods have been developed to gen-
erate seed data for iterative human cleaning and
labelling. NormBank (Ziems et al., 2023a) uses
LLMs to generate seed roles and behaviours as
norm candidates in specific situations, which are
then annotated by humans. Similarly, other studies
(CH-Wang et al., 2023; Liu et al., 2024a; Bhutani
et al., 2024) employ prompting techniques to gen-
erate seed data, followed by human annotation on
tasks like cultural bias and social reasoning.

CA: Ziems et al. (2023b, Multi-Value) intro-
duced a framework that leverages the Electronic
World Atlas of Varieties of English (Kortmann
et al., 2020, eWAVE) to create and adapt datasets
covering 50 English dialects. This framework en-
abled the adaptation of a standard corpus into di-
alectal forms (Held et al., 2023; Xiao et al., 2023).
However, similar structured resources may not ex-
ist or be suitable for adaptation of other cultural
elements (e.g., for concepts, consistently replacing
‘bread’ with ‘rice’ would not be desirable).

5 Creating Culturally Adapted Models

Most culturally aware NLP research has focused
on resource creation and evaluation, with culturally
adapted model development still emerging. Here,
we review current methods for adapting pre-trained
(L)LMs, covering in-context and in-weight adap-
tations (an overview in Appendix Figure 5). We
found that current cultural adaptation methods in
NLP prioritize technical advancements and isolated
cultural elements, measuring effectiveness solely
by standard task performance.


5.1 In-Context Adaptation

The success of LLMs allows for behaviour tuning
by prompts or in-context examples. A straightfor-
ward strategy is to provide the model with sociode-
mographic prompts or use “role-playing” (Park
et al., 2022; Argyle et al., 2023) of a culture, as
seen in Shaikh et al. (2023) and Hwang et al. (2023).
For knowledge-intensive tasks, cultural knowledge
can be added directly to the prompt, and LLMs
can leverage indirect descriptions from external
sources or prior model outputs (Yao et al., 2024a).
Lastly, high-level prompts (or “constitutions”, Bai
et al. 2022b) guiding LLM reasoning could im-
prove cultural alignment alongside demographic-
based prompts (AlKhamissi et al., 2024).

Since different cultures reflect different values,
there is a need to create models that embody plural-
istic cultural values with flexible alignment capa-
bilities (Sorensen et al., 2024). Feng et al. (2024)
propose a framework to achieve this by enhancing
pluralistic alignment in LLMs via collaboration be-
tween a high-level LLM and a group of specialized
community LMs (i.e., an ensemble of LLMs). This
framework enables general-purpose LLMs to flex-
ibly incorporate diverse cultural and ideological
perspectives, reflecting both individual preferences
and broader cultural distributions.

A retrieval-augmented approach can further re-
fine cultural alignment by adjusting responses dy-
namically. Friedrich et al. (2023) propose such a
method for moral reasoning, where culture-specific
contexts are stored in a retrieval engine. When
asked moral questions, relevant contexts are re-
trieved and added to the input, enabling the model
to respond with cultural nuances. This method
shows promise for adapting LLMs to evolving cul-
tural information, an aspect often overlooked in
current adaptation methods.

5.2. In-Weight Adaptation
5.2.1. Data Augmentation

Acquiring large corpora for supervised cultural
adaptation is challenging. Data augmentation helps
address this, enhancing model robustness. Li and
Zhang (2023) present a data augmentation method
for multilingual multicultural VL reasoning tasks,
generating code-mixed data by substituting English
concepts with culturally mapped equivalents. The
cultural concept sets (for mapping) are built by
querying hyponyms, synonyms, and hypernyms
in the ConceptNet (Speer et al., 2017) and Word-

Net (Miller, 1992). However, the optimal resource
depends on the specific cultural element being
adapted (§3.1). For instance, a cultural knowledge
base might be better for norms adaptations.

5.2.2 Continual Pre-training, Auxiliary Losses

Continual pre-training (CPT, including instruction
tuning), intermediate task training, and multi-task
training with auxiliary losses are methods for cul-
tural adaptation. CPT fine-tunes a pre-trained LM
with an unlabeled domain or language corpus be-
fore downstream task fine-tuning. It improves
downstream task performance via full-parameter
training (Xu et al., 2019; Han and Eisenstein, 2019;
Gururangan et al., 2020) or by training a few
additional parameters while keeping the model
frozen (Wang et al., 2021; Ke et al., 2022).

Recently, Hofmann et al. (2024a) show that
when combined with a geo-location prediction loss,
CPT can help to increase the awareness of dialectal
variations of pre-trained LMs. Wang et al. (2024a)
show that instruction tuning with instructions con-
taining cultural knowledge can improve models’
ability in cultural knowledge reasoning. In VL,
Bhatia and Shwartz (2023) use a cultural com-
monsense knowledge graph from (Nguyen et al.,
2023) for CPT to develop a geo-diverse LM for
commonsense reasoning tasks. This method cat-
egory is effective for addressing diverse cultural
elements, but adapting pre-trained LLMs can result
in catastrophic forgetting (McCloskey and Cohen
1989, or termed “alignment tax” due to RLHF tun-
ing, Askell et al. 2021; Ouyang et al. 2022) poten-
tially worsening their performance on general tasks.
This warrants further investigation.

5.2.3. Other Forms of Information Integration

Cao et al. (2024a) propose a method that integrates
cultural dimension vectors (derived through a re-
gression task based on Hofstede Culture Dimen-
sions, Hofstede 1984) with a mT5 Transformer
model (Xue et al., 2021). These cultural dimension
vectors are added to the hidden states at each layer
to enable culturally informed multi-turn dialogue
classification and prediction.

5.2.4 Parameter-Efficient Adaptations

As LMs grow larger, parameter-efficient fine-
tuning methods (i.e., PEFT, by fine-tuning a small
number of parameters, such as the bottle-neck
adapters, Houlsby et al. 2019; LoRA, Hu et al.
2022 etc.) become increasingly important for task


adaptations. Given their success in cross-lingual
transfer learning (Ustiin et al., 2020; Pfeiffer et al.,
2020; Ansell et al., 2021; Liu et al., 2023a, 2024b,
among others), PEFT can be a natural choice for
cultural adaptation of e.g., dialects.

Recently, HyperLoRA (Xiao et al., 2023) uses
the Hypernetwork (Ha et al., 2017, a neural net-
work for generating parameters) to generate LORA
adapters based on dialectal features. DADA (Liu
et al., 2023b) proposes to train a pool of dialectal
linguistic feature adapters and dynamically com-
pose the adapters for dialectal tasks. Being task
agnostic, PEFT methods could prove important for
cultural adaptations beyond dialects.

5.2.5 Outlook: Feedback Learning

The success of LLMs has popularized Reinforce-
ment Learning from Human Feedback (Christiano
et al., 2017; Bai et al., 2022a; Ouyang et al., 2022;
Ivison et al., 2024, RLHF) and Direct Preference
Optimization (Rafailov et al., 2023; Ivison et al.,
2023, DPO) methods. RLHF fine-tunes LMs with
feedback by fitting a reward model with human
preferences, and then training a reinforcement
learning-based policy to maximize the learned re-
ward. DPO avoids RL training by using a simpler
supervised learning objective for an implicit reward
model.

Recent work shows that RLHF can enhance
the performance of multilingual instruction tun-
ing for LLMs (Lai et al., 2023), while DPO can
improve the multilingual reasoning abilities (She
et al., 2024) and multilingual safety (Aakanksha
et al., 2024) of LLMs. The use of RLHF or DPO
for multilingual multicultural adaptation is still lim-
ited, but these examples suggest that the direction
could be promising.

6 Further Discussions and
Recommendations

As we have seen, significant work remains to be
done on both resources and methods for various
elements of culture.

An area that requires attention is the overall pro-
cess of researching culturally aware NLP. As men-
tioned previously, a key practice is community in-
volvement (§4) to get the process right (Bird, 2020;
Liu et al., 2022b; Mager et al., 2023). It is cru-
cial to assess how target communities can benefit
most from technologies. For instance, many di-
alects are primarily oral, and speech-to-speech or

speech-to-text translations could be preferable over
text-based applications (Blaschke et al., 2024). Fur-
thermore, ethical data collection practices are also
critical and technology ownership must be consid-
ered, especially when indigenous and marginalized
communities are involved. For best practices, we
refer the readers to work such as Bird (2020), Smith
(2021) or Cooper et al. (2024) for further details.

Another key consideration is integrating in-
sights from fields beyond NLP. Cultural adapta-
tion has long been practiced in areas like video
games (O’hagan and Mangiron, 2013), movies (Pet-
tit, 2009), online learning (Blanchard et al., 2005),
and clinical psychology (Bernal et al., 1995; Bar-
rera Jr and Castro, 2006). These existing practices
can serve as a foundation for adapting NLP applica-
tions to meet the needs of diverse cultural contexts.

Here, we summarize and recommend best prac-
tices based on our prior discussions and the publi-
cations surveyed in the sections referenced below:
Resource Acquisition.

¢ §4.1, $6: Consult with target cultural groups
throughout design and implementation, wher-
ever possible.
§4.3: Use iterative feedback from culture ex-
perts to refine data quality. Automatically ac-
quired resources should also undergo expert
quality checks.
§6: Ensure an ethical approach to data ac-
quisition and discuss data ownership early
to prevent misuse. This is always important
but particularly critical with indigenous and
marginalized communities.
Model Adaptation.

¢ §5: Incorporate new metrics that assess cul-
tural awareness alongside task performance.
§5: Consider cultural adaptation as an ongo-
ing, systematic process rather than a one-time
task focused on a single element.
§5.1: Monitor adaptation performance over
time, especially for the evolving cultural ele-
ments, to maintain model relevance.
§6: Build on existing knowledge outside of
NLP when applicable.

7 Summary and Future Research
Directions

Culturally aware and adapted NLP has recently
emerged as an important and active research area.
Significant progress has been made in the develop-
ment of resources for capturing various elements


of culture, but the development of NLP methods
is still in its infancy. We will now summarize the
main research gaps identified in this survey with
respect to the categories of our new taxonomy (§2):

Resources. Currently, resources exist for all ele-
ments of culture, with considerable progress made
on values (§3.1.3, particularly in biases) and knowl-
edge (§3.1.2, particularly for MMLU-style cultural
knowledge benchmarks). However, research is
lacking in the following areas:

Gaps in Elements Coverage: While many _re-
sources already exist within concepts (§3.1.1),
multilingual data resources covering a diverse
set of concepts (e.g., aesthetics, spatial relation)
in both unimodal and multimodal (§3.1.1) for
generation tasks is lacking. Moreover, most
recent developments in norms & morals are
predominantly in English, reflecting a monocul-
tural perspective. This highlights the need for
more multilingual and multicultural resources.
Additionally, there is a significant gap in datasets
that focus on different types of value perceptions
(such as emotion and irony, §3.1.3), stylistic
variations (§3.2), and artifacts (§3.1.5) across
various cultural groups, both in different languages
and within languages.

Resources considering social elements of culture
($3.3) also remain limited. For example, collect-
ing speaker relationships in dialogue datasets or
distinguishing age groups in social norms datasets.
These are needed to address the intricate relation-
ship between culture and people in NLP.

Training Data and “CultureGLUE”: Most exist-
ing resources focus on evaluation, providing bench-
marks and test sets that enable researchers to assess
the performance of models. While these evaluation
resources are crucial for cultural adaptation, there
is a pressing need for training data. Further, cur-
rent evaluation resources often focus on individual
elements of culture. A unified, cultural benchmark
like GLUE (Wang et al., 2019) does not yet exist
for all cultural elements across diverse groups. De-
veloping a multicultural “CultureGLUE” may be
challenging at the moment, but a reasonable first
step is to focus on individual cultures, ensuring a
diverse range of tasks and comprehensive element
coverage.

Modelling. While modelling methods for culture
are generally under-explored, continual pretrain-
ing (§5.2.2) and prompting (§5.1) have received
marginally more attention than other approaches.

Research areas needing further exploration include:

PEFT-based Transfer Learning: Exploration of
PEFT-based transfer learning techniques beyond
dialects is limited (§5.2.4). Given their success in
other NLP areas, these techniques warrant further
investigation into other elements of culture, such
as for values or norms & morals. A potential ap-
proach involves using WVS survey data, similar
to Li et al. (2024a), to train PEFT-based modules
focused on values. However, it is crucial to inves-
tigate whether survey data alone is sufficient for
effective training.

Feedback Learning and Other LLM Specialties:
Leveraging the success of LLMs and feedback
learning presents promising new avenues for
cultural adaptation (§5.2.5). A potential bottleneck
is acquiring large, culturally diverse preference
datasets for model adaptation and training cul-
turally aligned reward models. This could be
addressed by large-scale data collection efforts,
as demonstrated by Kirk et al. (2024), or through
the generation of synthetic data (Aakanksha et al.,
2024). For synthetic data, using techniques such
as role-playing and the creation of repositories
of cultural personas could facilitate culturally
sensitive model training.

Evolving Culture: Culture evolves gradually (Boyd
and Richerson, 1988; Whiten et al., 2011), yet there
have been few discussions on how to model and
adapt to evolving culture. Future research should
focus on methods that address the dynamic nature
of culture. One potential approach is the use of
retrieval-augmented systems to integrate evolving
information (§5.1), which ensures models’ rele-
vance to cultural shifts over time.

Overall. Below, we discuss two overall research
gaps.

Adaptation in the Social Context: As a key moti-
vation of this paper, culture emerges from and is
shaped by social interactions among humans within
a society ($1). However, an important question re-
mains unanswered in the existing literature: Should
the cultural adaptation of models occur within a
situated social context and structure? Exploring
this could present new avenues for interdisciplinary
research (e.g., with human-machine collaboration,
social psychology, or anthropology etc.).
“Surface” versus “Deep” Adaptation in NLP:
Resnicow et al. (1999) devise cultural adaptations
for public health research into surface and deep
adaptations, where the former considers familiar



languages and concepts to the target groups, and
the latter considers social and historical factors
that influence the behaviours of the target groups.

In NLP, surface adaptations might include using
the same language as a culture and recognizing ex-
plicit cultural differences (e.g., asking LLMs “what
is the meaning of ...”). In contrast, deep adaptations
might enable a model to “behave” (e.g., make deci-
sions, pragmatically comply etc.) like a member of
a culture without explicit inquisition (see Figure 3
in the Appendix for an illustration).

As we have seen from prior work described in
§3 or §5, only a few current works focus on adapt-
ing the behavioural aspect of models (which is be-
coming increasingly important with LLMs), and
there has been no work to date on measuring the
depth and progress of cultural adaptations or when
a model is fully culturally aware and culturally
competent. Further research could explore these
areas.

8 Conclusions

This work proposes a new extensive taxonomy of
culture that expands on earlier works in NLP and
is grounded in well-established anthropology and
social sciences literature. The taxonomy provides a
systematic framework for understanding and track-
ing progress in the emerging area of culturally
aware and adapted NLP. However, our taxonomy
is not without its limitations. Future research could
refine the taxonomy in areas like values or commu-
nicative goals by adding further subcategories and
providing a better understanding of interactions be-
tween the elements of culture (e.g., shifting values’
impact on social norms over time).

We survey existing resources and methods in this
area according to the taxonomy classes, identifying
areas of strength as well as areas where research
remains to be done. Our paper summarizes the state
of the art and provides ideas for future research in
this exciting and important area.

Acknowledgements

This work was funded by the German Federal Min-
istry of Education and Research (BMBF) under
the promotional reference 13N15897 (MISRIK). It
was also funded by EPSRC grant EP/Y031350/1
under the UK government’s funding guarantee for
ERC Advanced Grants. Chen Cecilia Liu is sup-
ported by the Konrad Zuse School of Excellence in
Learning and Intelligent Systems (ELIZA) through

the DAAD program Konrad Zuse Schools of Ex-
cellence in Artificial Intelligence, sponsored by the
Federal Ministry of Education and Research.

The authors would like to thank Anjali Kan-
tharuban, Shun Shao, and Anne Lauscher for an
early discussion of different aspects of this work.
The authors would also like to thank Ji-Ung Lee,
anonymous reviewers and action editors of TACL
for feedback on a draft of this paper.


References

Aakanksha, Arash Ahmadian, Beyza Ermis,
Seraphina Goldfarb-Tarrant, Julia Kreutzer,
Marzieh Fadaee, and Sara Hooker. 2024. The
multilingual alignment prism: Aligning global
and local preferences to reduce harm. In Pro-
ceedings of the 2024 Conference on Empirical
Methods in Natural Language Processing, pages
12027-12049, Miami, Florida, USA. Associa-
tion for Computational Linguistics.

Ahmed Abdelali, Hamdy Mubarak, Younes Samih,
Sabit Hassan, and Kareem Darwish. 2021.
QADI: Arabic dialect identification in the wild.
In Proceedings of the Sixth Arabic Natural Lan-
guage Processing Workshop, pages 1-10, Kyiv,
Ukraine (Virtual). Association for Computa-
tional Linguistics.

Nuredin Ali Abdelkadir, Charles Zhang, Ned
Mayo, and Stevie Chancellor. 2024. Diverse
perspectives, divergent models: Cross-cultural
evaluation of depression detection on Twitter.
In Proceedings of the 2024 Conference of the
North American Chapter of the Association for
Computational Linguistics: Human Language
Technologies (Volume 2: Short Papers), pages
672-680, Mexico City, Mexico. Association for
Computational Linguistics.

Christabel Acquaye, Haozhe An, and Rachel
Rudinger. 2024. Susu box or piggy bank: As-
sessing cultural commonsense knowledge be-
tween Ghana and the US. In Proceedings of the
2024 Conference on Empirical Methods in Nat-
ural Language Processing, pages 9483-9502,
Miami, Florida, USA. Association for Computa-
tional Linguistics.

Muhammad Adilazuarda, Sagnik Mukherjee, Prad-
hyumna Lavania, Siddhant Singh, Alham Aji,
Jacki O’ Neill, Ashutosh Modi, and Monojit
Choudhury. 2024. Towards measuring and mod-
eling “culture” in LLMs: A survey. In Pro-
ceedings of the 2024 Conference on Empirical
Methods in Natural Language Processing, pages
15763-15784, Miami, Florida, USA. Associa-
tion for Computational Linguistics.

Gati V. Aher, Rosa I. Arriaga, and Adam Tauman
Kalai. 2023. Using large language models to
simulate multiple humans and replicate human
subject studies. In International Conference on

Machine Learning, ICML 2023, 23-29 July 2023,
Honolulu, Hawaii, USA, volume 202 of Pro-
ceedings of Machine Learning Research, pages
337-371. PMLR.

Idris Akinade, Jesujoba Alabi, David Adelani,

Clement Odoje, and Dietrich Klakow. 2023.
Varepsilon kt mask: Integrating Yoruba cultural
greetings into machine translation. In Proceed-
ings of the First Workshop on Cross-Cultural
Considerations in NLP (C3NLP), pages 1-7,
Dubrovnik, Croatia. Association for Computa-
tional Linguistics.

Badr AlKhamissi, Muhammad ElNokrashy, Mai

Alkhamissi, and Mona Diab. 2024. Investigat-
ing cultural alignment of large language models.
In Proceedings of the 62nd Annual Meeting of
the Association for Computational Linguistics
(Volume I: Long Papers), pages 12404-12422,
Bangkok, Thailand. Association for Computa-
tional Linguistics.

Zaid Alyafeai, Khalid Almubarak, Ahmed Ashraf,

Deema Alnuhait, Saied Alshahrani, Gubran Ab-
dulrahman, Gamil Ahmed, Qais Gawah, Zead
Saleh, Mustafa Ghaleb, Yousef Ali, and Maged
Al-shaibani. 2024. CIDAR: Culturally relevant
instruction dataset for Arabic. In Findings of the
Association for Computational Linguistics ACL
2024, pages 12878-12901, Bangkok, Thailand
and virtual meeting. Association for Computa-
tional Linguistics.

Nalini Ambady, Jasook Koo, Fiona Lee, and Robert

Rosenthal. 1996. More than words: Linguis-
tic and nonlinguistic politeness in two cultures.
Journal of Personality and Social Psychology,
70(5):996.

Haozhe An, Zongxia Li, Jieyu Zhao, and Rachel

Rudinger. 2023. SODAPOP: Open-ended dis-
covery of social biases in social commonsense
reasoning models. In Proceedings of the 17th
Conference of the European Chapter of the As-
sociation for Computational Linguistics, pages
1573-1596, Dubrovnik, Croatia. Association for
Computational Linguistics.

Alan Ansell, Edoardo Maria Ponti, Jonas Pfeif-

fer, Sebastian Ruder, Goran Glavas, Ivan Vulié,
and Anna Korhonen. 2021. MAD-G: Multi-
lingual adapter generation for efficient cross-
lingual transfer. In Findings of the Association


for Computational Linguistics: EMNLP 2021,
pages 4762-4781, Punta Cana, Dominican Re-
public. Association for Computational Linguis-
tics.

Ayme Arango Monnar, Jorge Perez, Barbara
Poblete, Magdalena Saldafia, and Valentina
Proust. 2022. Resources for multilingual hate
speech detection. In Proceedings of the Sixth
Workshop on Online Abuse and Harms (WOAR),
pages 122-130, Seattle, Washington (Hybrid).
Association for Computational Linguistics.

Lisa P. Argyle, Ethan C. Busby, Nancy Fulda,
Joshua R. Gubler, Christopher Rytting, and
David Wingate. 2023. Out of one, many: Us-
ing language models to simulate human samples.
Political Analysis, 31(3):337-351.

Amanda Askell, Yuntao Bai, Anna Chen, Dawn
Drain, Deep Ganguli, Tom Henighan, Andy
Jones, Nicholas Joseph, Benjamin Mann, Nova
DasSarma, Nelson Elhage, Zac Hatfield-Dodds,
Danny Hernandez, Jackson Kernion, Kamal
Ndousse, Catherine Olsson, Dario Amodei,
Tom B. Brown, Jack Clark, Sam McCandlish,
Chris Olah, and Jared Kaplan. 2021. A general
language assistant as a laboratory for alignment.
ArXiv preprint arXiv:2112.00861v3.

Giuseppe Attanasio, Flor Miriam Plaza del Arco,
Debora Nozza, and Anne Lauscher. 2023. A tale
of pronouns: Interpretability informs gender bias
mitigation for fairer instruction-tuned machine
translation. In Proceedings of the 2023 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 3996-4014, Singapore. Asso-
ciation for Computational Linguistics.

Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda
Askell, Anna Chen, Nova DasSarma, Dawn
Drain, Stanislav Fort, Deep Ganguli, Tom
Henighan, Nicholas Joseph, Saurav Kadavath,
Jackson Kernion, Tom Conerly, Sheer El Showk,
Nelson Elhage, Zac Hatfield-Dodds, Danny Her-
nandez, Tristan Hume, Scott Johnston, Shauna
Kravec, Liane Lovitt, Neel Nanda, Catherine
Olsson, Dario Amodei, Tom B. Brown, Jack
Clark, Sam McCandlish, Chris Olah, Benjamin
Mann, and Jared Kaplan. 2022a. Training a help-
ful and harmless assistant with reinforcement
learning from human feedback. ArXiv preprint
arXiv:2204.05862v1.

Yuntao Bai, Saurav Kadavath, Sandipan Kundu,

Amanda Askell, Jackson Kernion, Andy Jones,
Anna Chen, Anna Goldie, Azalia Mirhoseini,
Cameron McKinnon, Carol Chen, Catherine
Olsson, Christopher Olah, Danny Hernandez,
Dawn Drain, Deep Ganguli, Dustin Li, Eli Tran-
Johnson, Ethan Perez, Jamie Kerr, Jared Mueller,
Jeffrey Ladish, Joshua Landau, Kamal Ndousse,
Kamile Lukosiute, Liane Lovitt, Michael Sell-
itto, Nelson Elhage, Nicholas Schiefer, Noemi
Mercado, Nova DasSarma, Robert Lasenby,
Robin Larson, Sam Ringer, Scott Johnston,
Shauna Kravec, Sheer El Showk, Stanislav
Fort, Tamera Lanham, Timothy Telleen-Lawton,
Tom Conerly, Tom Henighan, Tristan Hume,
Samuel R. Bowman, Zac Hatfield-Dodds, Ben
Mann, Dario Amodei, Nicholas Joseph, Sam Mc-
Candlish, Tom Brown, and Jared Kaplan. 2022b.
Constitutional AI: harmlessness from AI feed-
back. ArXiv preprint arXiv:2212.08073v1.

Manuel Barrera Jr and Felipe Gonzalez Castro.

2006. A heuristic framework for the cultural
adaptation of interventions. Clinical Psychol-
ogy: Science and Practice, 13(4):311-316.

Lisa Bauer, Hanna Tischer, and Mohit Bansal.

2023. Social commonsense for explanation and
cultural bias discovery. In Proceedings of the
17th Conference of the European Chapter of
the Association for Computational Linguistics,
pages 3745-3760, Dubrovnik, Croatia. Associa-
tion for Computational Linguistics.

Tilman Beck, Hendrik Schuff, Anne Lauscher, and

Iryna Gurevych. 2024. Sensitivity, performance,
robustness: Deconstructing the effect of sociode-
mographic prompting. In Proceedings of the
18th Conference of the European Chapter of
the Association for Computational Linguistics
(Volume 1: Long Papers), pages 2589-2615, St.
Julian’s, Malta. Association for Computational
Linguistics.

Guillermo Bernal, Janet Bonilla, and Carmen Bel-

lido. 1995. Ecological validity and cultural sen-
sitivity for outcome research: Issues for the cul-
tural adaptation and development of psychoso-
cial treatments with hispanics. Journal of abnor-
mal child psychology, 23:67-82.

Mehar Bhatia, Sahithya Ravi, Aditya Chinchure,

EunJeong Hwang, and Vered Shwartz. 2024.


From local concepts to universals: Evaluat-
ing the multicultural understanding of vision-
language models. In Proceedings of the 2024
Conference on Empirical Methods in Natural
Language Processing, pages 6763-6782, Miami,
Florida, USA. Association for Computational
Linguistics.

Mehar Bhatia and Vered Shwartz. 2023. GD-
COMET: A geo-diverse commonsense inference
model. In Proceedings of the 2023 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 7993-8001, Singapore. Associa-
tion for Computational Linguistics.

Shaily Bhatt and Fernando Diaz. 2024. Extrinsic
evaluation of cultural competence in large lan-
guage models. In Findings of the Association
for Computational Linguistics: EMNLP 2024,
pages 16055-16074, Miami, Florida, USA. As-
sociation for Computational Linguistics.

Mukul Bhutani, Kevin Robinson, Vinodkumar
Prabhakaran, Shachi Dave, and Sunipa Dev.
2024. SeeGULL multilingual: a dataset of geo-
culturally situated stereotypes. In Proceedings
of the 62nd Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short
Papers), pages 842-854, Bangkok, Thailand. As-
sociation for Computational Linguistics.

Cristina Bicchieri, Ryan Muldoon, and Alessandro
Sontuoso. 2018. Social norms. The Stanford
encyclopedia of philosophy.

Steven Bird. 2020. Decolonising speech and lan-
guage technology. In Proceedings of the 28th
International Conference on Computational Lin-
guistics, pages 3504-3519, Barcelona, Spain
(Online). International Committee on Compu-
tational Linguistics.

Janet Blake. 2000. On defining the cultural her-
itage. International and Comparative Law Quar-
terly, 49(1):61-85.

Emmanuel Blanchard, Ryad Razaki, and Claude
Frasson. 2005. Cross-cultural adaptation of e-
learning contents: A methodology. In E-Learn:
World Conference on E-Learning in Corporate,
Government, Healthcare, and Higher Education,
pages 1895-1902. Association for the Advance-
ment of Computing in Education (AACE).

Verena Blaschke, Christoph Purschke, Hinrich
Schuetze, and Barbara Plank. 2024. What do
dialect speakers want? a survey of attitudes to-
wards language technology for German dialects.
In Proceedings of the 62nd Annual Meeting
of the Association for Computational Linguis-
tics (Volume 2: Short Papers), pages 823-841,
Bangkok, Thailand. Association for Computa-
tional Linguistics.

Shoshana Blum-Kulka and Elite Olshtain. 1984.
Requests and apologies: A cross-cultural study
of speech act realization patterns (CCSARP).
Applied linguistics, 5(3):196—213.

Robert Boyd and Peter J Richerson. 1988. Cul-
ture and the evolutionary process. University of
Chicago press.

Adam Briggle and Carl Mitcham. 2012a. Ethics
and science: An introduction. Cambridge Uni-
versity Press.

Adam Briggle and Carl Mitcham. 2012b. Sci-
ence and ideational culture, Cambridge Applied
Ethics, page 268-289. Cambridge University
Press.

Samuel Cahyawijaya, Holy Lovenia, Fajri Koto,
Rifki Putri, Wawan Cenggoro, Jhonson Lee,
Salsabil Akbar, Emmanuel Dave, Nuurshadieq
Nuurshadieq, Muhammad Mahendra, Rr Putri,
Bryan Wilie, Genta Winata, Alham Aji, Ayu Pur-
warianti, and Pascale Fung. 2024. Cendol: Open
instruction-tuned generative large language mod-
els for Indonesian languages. In Proceedings of
the 62nd Annual Meeting of the Association for
Computational Linguistics (Volume I: Long Pa-
pers), pages 14899-14914, Bangkok, Thailand.
Association for Computational Linguistics.

Niccolé Campolungo, Federico Martelli, Francesco
Saina, and Roberto Navigli. 2022. DiBiMT: A
novel benchmark for measuring Word Sense Dis-
ambiguation biases in Machine Translation. In
Proceedings of the 60th Annual Meeting of the
Association for Computational Linguistics (Vol-
ume I: Long Papers), pages 4331-4352, Dublin,
Ireland. Association for Computational Linguis-
tics.

Yong Cao, Min Chen, and Daniel Hershcovich.
2024a. Bridging cultural nuances in dialogue


agents through cultural value surveys. In Find-
ings of the Association for Computational Lin-
guistics: EACL 2024, pages 929-945, St. Ju-
lian’s, Malta. Association for Computational
Linguistics.

Yong Cao, Yova Kementchedjhieva, Ruixiang Cui,
Antonia Karamolegkou, Li Zhou, Megan Dare,
Lucia Donatelli, and Daniel Hershcovich. 2024b.
Cultural adaptation of recipes. Transactions of
the Association for Computational Linguistics,
12:80-99.

Yong Cao, Li Zhou, Seolhwa Lee, Laura Cabello,
Min Chen, and Daniel Hershcovich. 2023. As-
sessing cross-cultural alignment between Chat-
GPT and human societies: An empirical study.
In Proceedings of the First Workshop on Cross-
Cultural Considerations in NLP (C3NLP), pages
53-67, Dubrovnik, Croatia. Association for
Computational Linguistics.

Silvia Casola, Simona Frenda, Soda Lo, Erhan
Sezerer, Antonio Uva, Valerio Basile, Cristina
Bosco, Alessandro Pedrani, Chiara Rubagotti,
Viviana Patti, and Davide Bernardi. 2024. Mul-
tiPICo: Multilingual perspectivist irony corpus.
In Proceedings of the 62nd Annual Meeting of
the Association for Computational Linguistics
(Volume I: Long Papers), pages 16008-16021,
Bangkok, Thailand. Association for Computa-
tional Linguistics.

Sky CH-Wang, Arkadiy Saakyan, Oliver Li, Zhou
Yu, and Smaranda Muresan. 2023. Sociocultural
norm similarities and differences via situational
alignment and explainable textual entailment. In
Proceedings of the 2023 Conference on Empir-
ical Methods in Natural Language Processing,
pages 3548-3564, Singapore. Association for
Computational Linguistics.

Tuhin Chakrabarty, Arkadiy Saakyan, and
Smaranda Muresan. 2021. Don’t go far off:
An empirical study on neural poetry translation.
In Proceedings of the 2021 Conference on Em-
pirical Methods in Natural Language Process-
ing, pages 7253-7265, Online and Punta Cana,
Dominican Republic. Association for Computa-
tional Linguistics.

Paul F. Christiano, Jan Leike, Tom B. Brown, Mil-

jan Martic, Shane Legg, and Dario Amodei.
2017. Deep reinforcement learning from human

preferences. In Advances in Neural Information
Processing Systems 30: Annual Conference on
Neural Information Processing Systems 2017,
December 4-9, 2017, Long Beach, CA, USA,
pages 4299-4307.

Robert B Cialdini, Carl A Kallgren, and Ray-

mond R Reno. 1991. A focus theory of nor-
mative conduct: A theoretical refinement and
reevaluation of the role of norms in human be-
havior. In Advances in experimental social psy-
chology, volume 24, pages 201-234. Elsevier.

Simone Conia, Daniel Lee, Min Li, Umar Farooq

Minhas, Saloni Potdar, and Yunyao Li. 2024.
Towards cross-cultural machine translation with
retrieval-augmented generation from multilin-
gual knowledge graphs. In Proceedings of the
2024 Conference on Empirical Methods in Natu-
ral Language Processing, pages 16343-16360,
Miami, Florida, USA. Association for Computa-
tional Linguistics.

Ned Cooper, Courtney Heldreth, and Ben Hutchin-

son. 2024. it’s how you do things that matters”:
Attending to process to better serve indigenous
communities with language technologies. In
Proceedings of the 18th Conference of the Eu-
ropean Chapter of the Association for Compu-
tational Linguistics (Volume 2: Short Papers),
pages 204-211, St. Julian’s, Malta. Association
for Computational Linguistics.

Nicholas Deas, Jessica Grieser, Shana Kleiner,

Desmond Patton, Elsbeth Turcan, and Kathleen
McKeown. 2023. Evaluation of African Ameri-
can language bias in natural language generation.
In Proceedings of the 2023 Conference on Empir-
ical Methods in Natural Language Processing,
pages 6805-6824, Singapore. Association for
Computational Linguistics.

Nicholas Deas, Elsbeth Turcan, Ivan Mejia, and

Kathleen McKeown. 2024. MASIVE: Open-
ended affective state identification in English
and Spanish. In Proceedings of the 2024 Con-
ference on Empirical Methods in Natural Lan-
guage Processing, pages 20467-20485, Miami,
Florida, USA. Association for Computational
Linguistics.

Pieter Delobelle, Ewoenam Tokpo, Toon Calders,

and Bettina Berendt. 2022. Measuring fair-
ness with biased rulers: A comparative study


on bias metrics for pre-trained language models.
In Proceedings of the 2022 Conference of the
North American Chapter of the Association for
Computational Linguistics: Human Language
Technologies, pages 1693-1706, Seattle, United
States. Association for Computational Linguis-
tics.

Ameet Deshpande, Vishvak Murahari, Tanmay
Rajpurohit, Ashwin Kalyan, and Karthik
Narasimhan. 2023. Toxicity in chatgpt: Ana-
lyzing persona-assigned language models. In
Findings of the Association for Computational
Linguistics: EMNLP 2023, pages 1236-1270,
Singapore. Association for Computational Lin-
guistics.

Sunipa Dev, Emily Sheng, Jieyu Zhao, Aubrie Am-
stutz, Jiao Sun, Yu Hou, Mattie Sanseverino,
Jiin Kim, Akihiro Nishi, Nanyun Peng, and Kai-
Wei Chang. 2022. On measures of biases and
harms in NLP. In Findings of the Association
for Computational Linguistics: AACL-IJCNLP
2022, pages 246-267, Online only. Association
for Computational Linguistics.

Esin Durmus, Karina Nyugen, Thomas I. Liao,
Nicholas Schiefer, Amanda Askell, Anton
Bakhtin, Carol Chen, Zac Hatfield-Dodds,
Danny Hernandez, Nicholas Joseph, Liane
Lovitt, Sam McCandlish, Orowa Sikder, Alex
Tamkin, Janel Thamkul, Jared Kaplan, Jack
Clark, and Deep Ganguli. 2024. Towards mea-
suring the representation of subjective global
opinions in language models. In First Confer-
ence on Language Modeling.

Ashutosh Dwivedi, Pradhyumna Lavania, and
Ashutosh Modi. 2023. EtiCor: Corpus for an-
alyzing LLMs for etiquettes. In Proceedings
of the 2023 Conference on Empirical Methods
in Natural Language Processing, pages 6921-
6931, Singapore. Association for Computational
Linguistics.

AbdelRahim Elmadany, ElMoatez Billah Nagoudi,

and Muhammad Abdul-Mageed. 2023. ORCA:
A challenging benchmark for Arabic language
understanding. In Findings of the Association
for Computational Linguistics: ACL 2023, pages
9559-9586, Toronto, Canada. Association for
Computational Linguistics.

EVS. 2011.

Denis Emelin, Ronan Le Bras, Jena D. Hwang,

Maxwell Forbes, and Yejin Choi. 2021. Moral
stories: Situated reasoning about norms, intents,
actions, and their consequences. In Proceedings
of the 2021 Conference on Empirical Methods in
Natural Language Processing, pages 698-718,
Online and Punta Cana, Dominican Republic.
Association for Computational Linguistics.

Elena V. Epure, Guillaume Salha, Manuel Mous-

sallam, and Romain Hennequin. 2020. Model-
ing the music genre perception across language-
bound cultures. In Proceedings of the 2020 Con-
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 4765-4779,
Online. Association for Computational Linguis-
tics.

Cristina Espafia-Bonet and Alberto Barr6n-Cedefio.

2022. The (undesired) attenuation of human bi-
ases by multilinguality. In Proceedings of the
2022 Conference on Empirical Methods in Nat-
ural Language Processing, pages 2056-2077,
Abu Dhabi, United Arab Emirates. Association
for Computational Linguistics.

EVS - European Values Study
1981 - integrated dataset. GESIS Datenar-
chiv, K6ln. ZA4438 Datenfile Version 3.0.0,
https://doi.org/10.4232/1.10791.

Fahim Faisal, Orevaoghene Ahia, Aarohi Sri-

vastava, Kabir Ahuja, David Chiang, Yulia
Tsvetkov, and Antonios Anastasopoulos. 2024.
DIALECTBENCH: An NLP benchmark for di-
alects, varieties, and closely-related languages.
In Proceedings of the 62nd Annual Meeting of
the Association for Computational Linguistics
(Volume I: Long Papers), pages 14412-14454,
Bangkok, Thailand. Association for Computa-
tional Linguistics.

Virginia Felkner, Ho-Chun Herbert Chang, Eugene

Jang, and Jonathan May. 2023. WinoQueer:
A community-in-the-loop benchmark for anti-
LGBTQ+ bias in large language models. In Pro-
ceedings of the 61st Annual Meeting of the Asso-
ciation for Computational Linguistics (Volume
I; Long Papers), pages 9126-9140, Toronto,
Canada. Association for Computational Linguis-
tics.

Shangbin Feng, Taylor Sorensen, Yuhan Liu, Jillian

Fisher, Chan Young Park, Yejin Choi, and Yulia


Tsvetkov. 2024. Modular pluralism: Pluralistic
alignment via multi-LLM collaboration. In Pro-
ceedings of the 2024 Conference on Empirical
Methods in Natural Language Processing, pages
4151-4171, Miami, Florida, USA. Association
for Computational Linguistics.

Maxwell Forbes, Jena D. Hwang, Vered Shwartz,
Maarten Sap, and Yejin Choi. 2020. Social
chemistry 101: Learning to reason about social
and moral norms. In Proceedings of the 2020
Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 653-670,
Online. Association for Computational Linguis-
tics.

Simona Frenda, Alessandro Pedrani, Valerio Basile,
Soda Marem Lo, Alessandra Teresa Cignarella,
Raffaella Panizzon, Cristina Marco, Bianca Scar-
lini, Viviana Patti, Cristina Bosco, and Davide
Bernardi. 2023. EPIC: Multi-perspective anno-
tation of a corpus of irony. In Proceedings of the
61st Annual Meeting of the Association for Com-
putational Linguistics (Volume 1: Long Papers),
pages 13844-13857, Toronto, Canada. Associa-
tion for Computational Linguistics.

Felix Friedrich, Wolfgang Stammer, Patrick
Schramowski, and Kristian Kersting. 2023. Re-
vision transformers: Instructing language mod-
els to change their values. In ECAI 2023 - 26th
European Conference on Artificial Intelligence,
September 30 - October 4, 2023, Krakow, Poland
- Including 12th Conference on Prestigious Ap-
plications of Intelligent Systems (PAIS 2023),
volume 372 of Frontiers in Artificial Intelligence
and Applications, pages 756-763. IOS Press.

VA Fromkin, Robert Rodman, and V Hyams. 1998.
An Introduction to Language 6e. Orlando, FL:
Hartcourt Brace College Publishers.

Yi Fung, Tuhin Chakrabarty, Hao Guo, Owen Ram-
bow, Smaranda Muresan, and Heng Ji. 2023.
NORMSAGE: Multi-lingual multi-cultural norm
discovery from conversations on-the-fly. In Pro-
ceedings of the 2023 Conference on Empirical
Methods in Natural Language Processing, pages
15217-15230, Singapore. Association for Com-
putational Linguistics.

Yi Fung, Ruining Zhao, Jae Doo, Chenkai Sun, and
Heng Ji. 2024. Massively multi-cultural knowl-

edge acquisition & LM benchmarking. ArXiv
preprint arXiv:2402.09369v1.

Clifford Geertz. 1973. The interpretation of cul-
tures. Basic books.

Joshua Gert and Bernard Gert. 2025. The Defini-
tion of Morality. In Edward N. Zalta and Uri
Nodelman, editors, The Stanford Encyclopedia
of Philosophy, Spring 2025 edition. Metaphysics
Research Lab, Stanford University.

Erving Goffman. 2023. The presentation of self in
everyday life. In Social theory re-wired, pages
450-459. Routledge.

Suchin Gururangan, Ana Marasovic, Swabha
Swayamdipta, Kyle Lo, Iz Beltagy, Doug
Downey, and Noah A. Smith. 2020. Don’t stop
pretraining: Adapt language models to domains
and tasks. In Proceedings of the 58th Annual
Meeting of the Association for Computational
Linguistics, pages 8342-8360, Online. Associa-
tion for Computational Linguistics.

David Ha, Andrew M. Dai, and Quoc V. Le. 2017.
Hypernetworks. In 5th International Confer-
ence on Learning Representations, ICLR 2017,
Toulon, France, April 24-26, 2017, Conference
Track Proceedings. OpenReview.net.

Thomas Haider, Steffen Eger, Evgeny Kim, Ro-
man Klinger, and Winfried Menninghaus. 2020.
PO-EMO: Conceptualization, annotation, and
modeling of aesthetic emotions in German and
English poetry. In Proceedings of the Twelfth
Language Resources and Evaluation Conference,
pages 1652-1663, Marseille, France. European
Language Resources Association.

Mika Hamilainen, Khalid Alnajjar, Niko Partanen,
and Jack Rueter. 2021. Finnish dialect identi-
fication: The effect of audio and text. In Pro-
ceedings of the 2021 Conference on Empirical
Methods in Natural Language Processing, pages
8777-8783, Online and Punta Cana, Dominican
Republic. Association for Computational Lin-
guistics.

Xiaochuang Han and Jacob Eisenstein. 2019. Un-
supervised domain adaptation of contextualized
embeddings for sequence labeling. In Proceed-
ings of the 2019 Conference on Empirical Meth-
ods in Natural Language Processing and the


9th International Joint Conference on Natural
Language Processing (EMNLP-IJCNLP), pages
4238-4248, Hong Kong, China. Association for
Computational Linguistics.

Einar Haugen. 1966. Dialect, language, nation 1.
American anthropologist, 68(4):922-935.

Shreya Havaldar, Salvatore Giorgi, Sunny Rai,
Thomas Talhelm, Sharath Chandra Guntuku, and
Lyle Ungar. 2024. Building knowledge-guided
lexica to model cultural variation. In Proceed-
ings of the 2024 Conference of the North Amer-
ican Chapter of the Association for Computa-
tional Linguistics: Human Language Technolo-
gies (Volume I: Long Papers), pages 211-226,
Mexico City, Mexico. Association for Computa-
tional Linguistics.

Shreya Havaldar, Matthew Pressimone, Eric Wong,
and Lyle Ungar. 2023a. Comparing styles across
languages. In Proceedings of the 2023 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 6775-6791, Singapore. Asso-
ciation for Computational Linguistics.

Shreya Havaldar, Bhumika Singhal, Sunny Rai,
Langchen Liu, Sharath Chandra Guntuku, and
Lyle Ungar. 2023b. Multilingual language mod-
els are not multicultural: A case study in emo-
tion. In Proceedings of the 13th Workshop on
Computational Approaches to Subjectivity, Senti-
ment, & Social Media Analysis, pages 202-214,
Toronto, Canada. Association for Computational
Linguistics.

Shirley Hayati, Minhwa Lee, Dheeraj Rajagopal,
and Dongyeop Kang. 2024. How far can we
extract diverse perspectives from large language
models? In Proceedings of the 2024 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 5336-5366, Miami, Florida, USA.
Association for Computational Linguistics.

Michael Hechter and Karl-Dieter Opp. 2001. So-
cial norms. Russell Sage Foundation.

William Held, Caleb Ziems, and Diyi Yang. 2023.
TADA : Task agnostic dialect adapters for En-
glish. In Findings of the Association for Compu-
tational Linguistics: ACL 2023, pages 813-824,
Toronto, Canada. Association for Computational
Linguistics.

Dan Hendrycks, Collin Burns, Steven Basart, Andy

Zou, Mantas Mazeika, Dawn Song, and Jacob
Steinhardt. 2021. Measuring massive multitask
language understanding. In 9th International
Conference on Learning Representations, ICLR
2021, Virtual Event, Austria, May 3-7, 2021.
OpenReview.net.

Joseph Henrich, Steven J Heine, and Ara Noren-

zayan. 2010. The weirdest people in the world?
Behavioral and brain sciences, 33(2-3):61—83.

Daniel Hershcovich, Stella Frank, Heather Lent,

Miryam de Lhoneux, Mostafa Abdou, Stephanie
Brandl, Emanuele Bugliarello, Laura Cabello Pi-
queras, Ilias Chalkidis, Ruixiang Cui, Constanza
Fierro, Katerina Margatina, Phillip Rust, and An-
ders S¢gaard. 2022. Challenges and strategies in
cross-cultural NLP. In Proceedings of the 60th
Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers),
pages 6997-7013, Dublin, Ireland. Association
for Computational Linguistics.

Jack Hessel, Ana Marasovic, Jena D. Hwang,

Lillian Lee, Jeff Da, Rowan Zellers, Robert
Mankoff, and Yejin Choi. 2023. Do androids
laugh at electric sheep? humor “understanding”
benchmarks from the new yorker caption con-
test. In Proceedings of the 61st Annual Meeting
of the Association for Computational Linguis-
tics (Volume 1: Long Papers), pages 688-714,
Toronto, Canada. Association for Computational
Linguistics.

David Hobson, Haiqi Zhou, Derek Ruths, and An-

drew Piper. 2024. Story morals: Surfacing value-
driven narrative schemas using large language
models. In Proceedings of the 2024 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 12998-13032, Miami, Florida,
USA. Association for Computational Linguis-
tics.

Valentin Hofmann, Goran Glavas, Nikola Ljubesi¢,

Janet B. Pierrehumbert, and Hinrich Schiitze.
2024a. Geographic adaptation of pretrained lan-
guage models. Transactions of the Association
for Computational Linguistics, 12:411-431.

Valentin Hofmann, Pratyusha Ria Kalluri, Dan Ju-

rafsky, and Sharese King. 2024b. AI generates
covertly racist decisions about people based on
their dialect. Nature, 633(8028):147-154.


G. Hofstede. 1984. Culture’s Consequences: In-
ternational Differences in Work-Related Val-
ues. Cross Cultural Research and Methodology.
SAGE Publications.

Geert Hofstede. 2011. Dimensionalizing cultures:
The hofstede model in context. Online readings
in psychology and culture, 2(1):8.

Xudong Hong, Asad Sayeed, Khushboo Mehra,
Vera Demberg, and Bernt Schiele. 2023. Vi-
sual writing prompts: Character-grounded story
generation with curated image sequences. Trans-
actions of the Association for Computational
Linguistics, 11:565-581.

Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzeb-
ski, Bruna Morrone, Quentin de Laroussilhe, An-
drea Gesmundo, Mona Attariyan, and Sylvain
Gelly. 2019. Parameter-efficient transfer learn-
ing for NLP. In Proceedings of the 36th Interna-
tional Conference on Machine Learning, ICML
2019, 9-15 June 2019, Long Beach, Califor-
nia, USA, volume 97 of Proceedings of Machine
Learning Research, pages 2790-2799. PMLR.

Juliane House. 2005. Politeness in Germany: Po-
liteness in GERMANY? Miultilingual Matters,
Bristol, Blue Ridge Summit.

Juliane House and Gabriele Kasper. 1981. Polite-
ness Markers in English and German, pages 157-
186. De Gruyter Mouton, Berlin, New York.

Dirk Hovy, Federico Bianchi, and Tommaso For-
naciari. 2020. “you sound just like your father”
commercial machine translation systems include
stylistic biases. In Proceedings of the 58th An-
nual Meeting of the Association for Computa-
tional Linguistics, pages 1686-1690, Online. As-
sociation for Computational Linguistics.

Dirk Hovy and Diyi Yang. 2021. The importance
of modeling social factors of language: Theory
and practice. In Proceedings of the 2021 Confer-
ence of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human
Language Technologies, pages 588—602, Online.
Association for Computational Linguistics.

Hsin-Yi Hsieh, Shih-Cheng Huang, and Richard
Tsai. 2024. TWBias: A benchmark for assess-
ing social bias in traditional Chinese large lan-
guage models through a Taiwan cultural lens. In

Findings of the Association for Computational
Linguistics: EMNLP 2024, pages 8688-8704,
Miami, Florida, USA. Association for Computa-
tional Linguistics.

Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan
Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,
and Weizhu Chen. 2022. Lora: Low-rank adap-
tation of large language models. In The Tenth
International Conference on Learning Represen-
tations, ICLR 2022, Virtual Event, April 25-29,
2022. OpenReview.net.

Songbo Hu, Han Zhou, Mete Hergul, Milan Gritta,
Guchun Zhang, Ignacio Iacobacci, Ivan Vuli¢,
and Anna Korhonen. 2023. Multi 3 WOZ:
A multilingual, multi-domain, multi-parallel
dataset for training and evaluating culturally
adapted task-oriented dialog systems. Trans-
actions of the Association for Computational
Linguistics, 11:1396-1415.

Tianyi Hu, Maria Maistro, and Daniel Hershcovich.
2024. Bridging cultures in the kitchen: A frame-
work and benchmark for cross-cultural recipe
retrieval. In Proceedings of the 2024 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 1068-1080, Miami, Florida, USA.
Association for Computational Linguistics.

Jing Huang and Diyi Yang. 2023. Culturally
aware natural language inference. In Findings of
the Association for Computational Linguistics:
EMNLP 2023, pages 7591-7609, Singapore. As-
sociation for Computational Linguistics.

EunJeong Hwang, Bodhisattwa Majumder, and
Niket Tandon. 2023. Aligning language models
to user opinions. In Findings of the Association
for Computational Linguistics: EMNLP 2023,
pages 5906-5919, Singapore. Association for
Computational Linguistics.

Hamish Ivison, Yizhong Wang, Jiacheng Liu, Ze-
qiu Wu, Valentina Pyatkin, Nathan Lambert,
Noah A. Smith, Yejin Choi, and Hanna Ha-
jishirzi. 2024. Unpacking DPO and PPO: disen-
tangling best practices for learning from prefer-
ence feedback. In Advances in Neural Informa-
tion Processing Systems 38: Annual Conference
on Neural Information Processing Systems 2024,
NeurIPS 2024, Vancouver, BC, Canada, Decem-
ber 10 - 15, 2024.


Hamish Ivison, Yizhong Wang, Valentina Pyatkin,
Nathan Lambert, Matthew E. Peters, Pradeep
Dasigi, Joel Jang, David Wadden, Noah A.
Smith, Iz Beltagy, and Hannaneh Hajishirzi.
2023. Camels in a changing climate: Enhanc-
ing LM adaptation with Tulu 2. ArXiv preprint
arXiv:2311.10702v2.

Ray Jackendoff. 1989. What is a concept, that
a person may grasp it? 1. Mind & language,
4(1-2):68-102.

Ray Jackendoff. 2012. What is a concept? In
Frames, Fields, and Contrasts, pages 191-208.
Routledge.

Younghoon Jeong, Juhyun Oh, Jongwon Lee,
Jaimeen Ahn, Jihyung Moon, Sungjoon Park,
and Alice Oh. 2022. KOLD: Korean offensive
language dataset. In Proceedings of the 2022
Conference on Empirical Methods in Natural
Language Processing, pages 10818-10833, Abu
Dhabi, United Arab Emirates. Association for
Computational Linguistics.

Akshita Jha, Aida Mostafazadeh Davani, Chan-
dan K Reddy, Shachi Dave, Vinodkumar Prab-
hakaran, and Sunipa Dev. 2023. SeeGULL: A
stereotype benchmark with broad geo-cultural
coverage leveraging generative models. In Pro-
ceedings of the 61st Annual Meeting of the Asso-
ciation for Computational Linguistics (Volume
I; Long Papers), pages 9851-9870, Toronto,
Canada. Association for Computational Linguis-
tics.

Ming Jiang and Mansi Joshi. 2024. CPopQA:
Ranking cultural concept popularity by LLMs.
In Proceedings of the 2024 Conference of the
North American Chapter of the Association for
Computational Linguistics: Human Language
Technologies (Volume 2: Short Papers), pages
615-630, Mexico City, Mexico. Association for
Computational Linguistics.

Yuchen Eleanor Jiang, Tianyu Liu, Shuming Ma,
Dongdong Zhang, Mrinmaya Sachan, and Ryan
Cotterell. 2023. Discourse-centric evaluation
of document-level machine translation with a
new densely annotated parallel corpus of nov-
els. In Proceedings of the 61st Annual Meeting
of the Association for Computational Linguis-
tics (Volume 1: Long Papers), pages 7853-7872,

Toronto, Canada. Association for Computational
Linguistics.

Jiho Jin, Jiseon Kim, Nayeon Lee, Haneul Yoo, Al-

ice Oh, and Hwaran Lee. 2024. KoBBQ: Korean
bias benchmark for question answering. Trans-
actions of the Association for Computational
Linguistics, 12:507-524.

Rebecca L. Johnson, Giada Pistilli, Natalia

Menédez-Gonzalez, Leslye Denisse Dias Duran,
Enrico Panai, Julija Kalpokiene, and Donald Jay
Bertulfo. 2022. The ghost in the machine has an
american accent: value conflict in GPT-3. ArXiv
preprint arXiv:2203.07785v1.

David Jurgens, Agrima Seth, Jackson Sargent,

Athena Aghighi, and Michael Geraci. 2023.
Your spouse needs professional help: Determin-
ing the contextual appropriateness of messages
through modeling social relationships. In Pro-
ceedings of the 61st Annual Meeting of the Asso-
ciation for Computational Linguistics (Volume
1; Long Papers), pages 10994-11013, Toronto,
Canada. Association for Computational Linguis-
tics.

Anubha Kabra, Emmy Liu, Simran Khanuja, Al-

ham Fikri Aji, Genta Winata, Samuel Cahyaw-
ijaya, Anuoluwapo Aremu, Perez Ogayo, and
Graham Neubig. 2023. Multi-lingual and
multi-cultural figurative language understand-
ing. In Findings of the Association for Computa-
tional Linguistics: ACL 2023, pages 8269-8284,
Toronto, Canada. Association for Computational
Linguistics.

Nora Kassner, Philipp Dufter, and Hinrich Schiitze.

2021. Multilingual LAMA: Investigating knowl-
edge in multilingual pretrained language models.
In Proceedings of the 16th Conference of the
European Chapter of the Association for Compu-
tational Linguistics: Main Volume, pages 3250-
3258, Online. Association for Computational
Linguistics.

Zixuan Ke, Haowei Lin, Yijia Shao, Hu Xu, Lei

Shu, and Bing Liu. 2022. Continual training
of language models for few-shot learning. In
Proceedings of the 2022 Conference on Empir-
ical Methods in Natural Language Processing,
pages 10205-10216, Abu Dhabi, United Arab
Emirates. Association for Computational Lin-
guistics.


Amr Keleg and Walid Magdy. 2023. DLAMA: A
framework for curating culturally diverse facts
for probing the knowledge of pretrained lan-
guage models. In Findings of the Association
for Computational Linguistics: ACL 2023, pages
6245-6266, Toronto, Canada. Association for
Computational Linguistics.

Simran Khanuja, Sathyanarayanan Ramamoorthy,
Yueqi Song, and Graham Neubig. 2024. An im-
age speaks a thousand words, but can everyone
listen? on image transcreation for cultural rele-
vance. In Proceedings of the 2024 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 10258-10279, Miami, Florida,
USA. Association for Computational Linguis-
tics.

Md Tawkat Islam Khondaker, Abdul Waheed,
El Moatez Billah Nagoudi, and Muhammad
Abdul-Mageed. 2023. GPTAraEval: A com-
prehensive evaluation of ChatGPT on Arabic
NLP. In Proceedings of the 2023 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 220-247, Singapore. Association
for Computational Linguistics.

Hyunwoo Kim, Jack Hessel, Liwei Jiang, Peter
West, Ximing Lu, Youngjae Yu, Pei Zhou, Ronan
Bras, Malihe Alikhani, Gunhee Kim, Maarten
Sap, and Yejin Choi. 2023. SODA: Million-
scale dialogue distillation with social common-
sense contextualization. In Proceedings of the
2023 Conference on Empirical Methods in Natu-
ral Language Processing, pages 12930-12949,
Singapore. Association for Computational Lin-
guistics.

Hyunwoo Kim, Youngjae Yu, Liwei Jiang, Xim-
ing Lu, Daniel Khashabi, Gunhee Kim, Yejin
Choi, and Maarten Sap. 2022. ProsocialDia-
log: A prosocial backbone for conversational
agents. In Proceedings of the 2022 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 4005-4029, Abu Dhabi, United
Arab Emirates. Association for Computational
Linguistics.

Jaehong Kim, Chaeyoon Jeong, Seongchan Park,
Meeyoung Cha, and Wonjae Lee. 2024. How do
moral emotions shape political participation? a
cross-cultural analysis of online petitions using
language models. In Findings of the Association

for Computational Linguistics ACL 2024, pages
16274-16289, Bangkok, Thailand and virtual
meeting. Association for Computational Linguis-
tics.

Hannah Rose Kirk, Alexander Whitefield, Paul

Rottger, Andrew M. Bean, Katerina Margatina,
Rafael Mosquera Gomez, Juan Ciro, Max Bar-
tolo, Adina Williams, He He, Bertie Vidgen,
and Scott Hale. 2024. The PRISM alignment
dataset: What participatory, representative and
individualised human feedback reveals about the
subjective and multicultural alignment of large
language models. In Advances in Neural Infor-
mation Processing Systems 38: Annual Confer-
ence on Neural Information Processing Systems
2024, NeurIPS 2024, Vancouver, BC, Canada,
December 10 - 15, 2024.

Bernd Kortmann, Kerstin Lunkenheimer, and

Katharina Ehret, editors. 2020. eWAVE.

Fajri Koto, Nurul Aisyah, Haonan Li, and Tim-

othy Baldwin. 2023. Large language models
only pass primary school exams in Indonesia:
A comprehensive test on IndoMMLU. In Pro-
ceedings of the 2023 Conference on Empirical
Methods in Natural Language Processing, pages
12359-12374, Singapore. Association for Com-
putational Linguistics.

Fajri Koto, Haonan Li, Sara Shatnawi, Jad Dough-

man, Abdelrahman Sadallah, Aisha Alraeesi,
Khalid Almubarak, Zaid Alyafeai, Neha Sen-
gupta, Shady Shehata, Nizar Habash, Preslav
Nakov, and Timothy Baldwin. 2024a.  Ara-
bicMMLU: Assessing massive multitask lan-
guage understanding in Arabic. In Findings of
the Association for Computational Linguistics
ACL 2024, pages 5622-5640, Bangkok, Thai-
land and virtual meeting. Association for Com-
putational Linguistics.

Fajri Koto, Rahmad Mahendra, Nurul Aisyah, and

Timothy Baldwin. 2024b. IndoCulture: Ex-
ploring geographically influenced cultural com-
monsense reasoning across eleven Indonesian
provinces. Transactions of the Association for
Computational Linguistics, 12:1703-1719.

Alfred Louis Kroeber and Clyde Kluckhohn. 1952.

Culture: A critical review of concepts and defini-
tions. Papers. Peabody Museum of Archaeology
& Ethnology, Harvard University.


Julia Kruk, Caleb Ziems, and Diyi Yang. 2023.
Impressions: Visual semiotics and aesthetic im-
pact understanding. In Proceedings of the 2023
Conference on Empirical Methods in Natural
Language Processing, pages 12273-12291, Sin-
gapore. Association for Computational Linguis-
tics.

Olli Kuparinen, Aleksandra Mileti¢é, and Yves
Scherrer. 2023. Dialect-to-standard normaliza-
tion: A large-scale multilingual evaluation. In
Findings of the Association for Computational
Linguistics: EMNLP 2023, pages 13814-13828,
Singapore. Association for Computational Lin-
guistics.

Preethi Lahoti, Nicholas Blumm, Xiao Ma,
Raghavendra Kotikalapudi, Sahitya Potluri, Qi-
jun Tan, Hansa Srinivasan, Ben Packer, Ahmad
Beirami, Alex Beutel, and Jilin Chen. 2023. Im-
proving diversity of demographic representation
in large language models via collective-critiques
and self-voting. In Proceedings of the 2023 Con-
ference on Empirical Methods in Natural Lan-
guage Processing, pages 10383-10405, Singa-
pore. Association for Computational Linguistics.

Viet Lai, Chien Nguyen, Nghia Ngo, Thuat
Nguyen, Franck Dernoncourt, Ryan Rossi, and
Thien Nguyen. 2023. Okapi: Instruction-tuned
large language models in multiple languages
with reinforcement learning from human feed-
back. In Proceedings of the 2023 Conference on
Empirical Methods in Natural Language Pro-
cessing: System Demonstrations, pages 318—
327, Singapore. Association for Computational
Linguistics.

Thang Le and Anh Luu. 2023. A parallel corpus for
Vietnamese central-northern dialect text transfer.
In Findings of the Association for Computational
Linguistics: EMNLP 2023, pages 13839-13855,
Singapore. Association for Computational Lin-
guistics.

Hwaran Lee, Seokhee Hong, Joonsuk Park, Taky-
oung Kim, Gunhee Kim, and Jung-woo Ha.
2023a. KoSBI: A dataset for mitigating social
bias risks towards safer large language model
applications. In Proceedings of the 61st Annual
Meeting of the Association for Computational
Linguistics (Volume 5: Industry Track), pages
208-224, Toronto, Canada. Association for Com-
putational Linguistics.

Jiyoung Lee, Minwoo Kim, Seungho Kim, Jungh-

wan Kim, Seunghyun Won, Hwaran Lee, and
Edward Choi. 2024a. KorNAT: LLM alignment
benchmark for Korean social values and com-
mon knowledge. In Findings of the Association
for Computational Linguistics ACL 2024, pages
11177-11213, Bangkok, Thailand and virtual
meeting. Association for Computational Linguis-
tics.

Nayeon Lee, Chani Jung, Junho Myung, Jiho Jin,

Jose Camacho-Collados, Juho Kim, and Alice
Oh. 2024b. Exploring cross-cultural differences
in English hate speech annotations: From dataset
construction to analysis. In Proceedings of the
2024 Conference of the North American Chapter
of the Association for Computational Linguistics:
Human Language Technologies (Volume 1: Long
Papers), pages 4205—4224, Mexico City, Mexico.
Association for Computational Linguistics.

Nayeon Lee, Chani Jung, and Alice Oh. 2023b.

Hate speech classifiers are culturally insensi-
tive. In Proceedings of the First Workshop on
Cross-Cultural Considerations in NLP (C3NLP),
pages 35—46, Dubrovnik, Croatia. Association
for Computational Linguistics.

Cheng Li, Mengzhuo Chen, Jindong Wang,

Sunayana Sitaram, and Xing Xie. 2024a. Cul-
turellm: Incorporating cultural differences into
large language models. In Advances in Neu-
ral Information Processing Systems 38: Annual
Conference on Neural Information Processing
Systems 2024, NeurIPS 2024, Vancouver, BC,
Canada, December 10 - 15, 2024.

Chengxi Li, Kai Fan, Jiajun Bu, Boxing Chen,

Zhongqiang Huang, and Zhi Yu. 2023a. Trans-
late the beauty in songs: Jointly learning to
align melody and translate lyrics. In Findings of
the Association for Computational Linguistics:
EMNLP 2023, pages 27-39, Singapore. Associa-
tion for Computational Linguistics.

Haonan Li, Yixuan Zhang, Fajri Koto, Yifei Yang,

Hai Zhao, Yeyun Gong, Nan Duan, and Timo-
thy Baldwin. 2024b. CMMLU: Measuring mas-
sive multitask language understanding in Chi-
nese. In Findings of the Association for Com-
putational Linguistics ACL 2024, pages 11260-
11285, Bangkok, Thailand and virtual meeting.
Association for Computational Linguistics.


Oliver Li, Mallika Subramanian, Arkadiy Saakyan,
Sky CH-Wang, and Smaranda Muresan. 2023b.
NormDial: A comparable bilingual synthetic
dialog dataset for modeling social norm adher-
ence and violation. In Proceedings of the 2023
Conference on Empirical Methods in Natural
Language Processing, pages 15732-15744, Sin-
gapore. Association for Computational Linguis-
tics.

Wenyan Li, Crystina Zhang, Jiaang Li, Qiwei Peng,
Raphael Tang, Li Zhou, Weijia Zhang, Guimin
Hu, Yifei Yuan, Anders S¢gaard, Daniel Her-
shcovich, and Desmond Elliott. 2024c. Food-
ieQA: A multimodal dataset for fine-grained un-
derstanding of Chinese food culture. In Pro-
ceedings of the 2024 Conference on Empirical
Methods in Natural Language Processing, pages
19077-19095, Miami, Florida, USA. Associa-
tion for Computational Linguistics.

Zhi Li and Yin Zhang. 2023. Cultural concept adap-
tation on multimodal reasoning. In Proceedings
of the 2023 Conference on Empirical Methods in
Natural Language Processing, pages 262-276,
Singapore. Association for Computational Lin-
guistics.

Chen Liu, Gregor Geigle, Robin Krebs, and Iryna
Gurevych. 2022a. FigMemes: A dataset for
figurative language identification in politically-
opinionated memes. In Proceedings of the 2022
Conference on Empirical Methods in Natural
Language Processing, pages 7069-7086, Abu
Dhabi, United Arab Emirates. Association for
Computational Linguistics.

Chen Liu, Fajri Koto, Timothy Baldwin, and
Iryna Gurevych. 2024a. Are multilingual LLMs
culturally-diverse reasoners? an investigation
into multicultural proverbs and sayings. In Pro-
ceedings of the 2024 Conference of the North
American Chapter of the Association for Com-
putational Linguistics: Human Language Tech-
nologies (Volume 1: Long Papers), pages 2016—
2039, Mexico City, Mexico. Association for
Computational Linguistics.

Chen Liu, Jonas Pfeiffer, Anna Korhonen, Ivan
Vulié, and Iryna Gurevych. 2023a. Delving
deeper into cross-lingual visual question answer-
ing. In Findings of the Association for Compu-
tational Linguistics: EACL 2023, pages 2453-

2468, Dubrovnik, Croatia. Association for Com-
putational Linguistics.

Chen Liu, Jonas Pfeiffer, Ivan Vuli¢, and Iryna
Gurevych. 2024b. FUN with fisher: Improv-
ing generalization of adapter-based cross-lingual
transfer with scheduled unfreezing. In Proceed-
ings of the 2024 Conference of the North Amer-
ican Chapter of the Association for Computa-
tional Linguistics: Human Language Technolo-
gies (Volume 1: Long Papers), pages 1998-2015,
Mexico City, Mexico. Association for Computa-
tional Linguistics.

Fangyu Liu, Emanuele Bugliarello, Edoardo Maria
Ponti, Siva Reddy, Nigel Collier, and Desmond
Elliott. 2021. Visually grounded reasoning
across languages and cultures. In Proceedings
of the 2021 Conference on Empirical Methods
in Natural Language Processing, pages 10467—
10485, Online and Punta Cana, Dominican Re-
public. Association for Computational Linguis-
tics.

Xuelin Liu, Yanfei Zhu, Shucheng Zhu, Pengyuan
Liu, Ying Liu, and Dong Yu. 2024c. Evaluating
moral beliefs across LLMs through a pluralistic
framework. In Findings of the Association for
Computational Linguistics: EMNLP 2024, pages
4740-4760, Miami, Florida, USA. Association
for Computational Linguistics.

Yanchen Liu, William Held, and Diyi Yang. 2023b.
DADA: Dialect adaptation via dynamic aggre-
gation of linguistic rules. In Proceedings of the
2023 Conference on Empirical Methods in Natu-
ral Language Processing, pages 13776-13793,
Singapore. Association for Computational Lin-
guistics.

Zhixuan Liu, Youeun Shin, Beverley-Claire
Okogwu, Youngsik Yun, Lia Coleman, Pe-
ter Schaldenbrand, Jihie Kim, and Jean Oh.
2023c. Towards equitable representation in
text-to-image synthesis models with the cross-
cultural understanding benchmark (CCUB)
dataset. ArXiv preprint arXiv:2301.12073v2.

Zoey Liu, Crystal Richardson, Richard Hatcher,
and Emily Prud’hommeaux. 2022b. Not always
about you: Prioritizing community needs when
developing endangered language technology. In
Proceedings of the 60th Annual Meeting of the


Association for Computational Linguistics (Vol-
ume I: Long Papers), pages 3933-3944, Dublin,
Ireland. Association for Computational Linguis-
tics.

Brandon Lwowski, Paul Rad, and Anthony Rios.
2022. Measuring geographic performance dis-
parities of offensive language classifiers. In
Proceedings of the 29th International Confer-
ence on Computational Linguistics, pages 6600—
6616, Gyeongju, Republic of Korea. Interna-
tional Committee on Computational Linguistics.

Manuel Mager, Elisabeth Mager, Katharina Kann,
and Ngoc Thang Vu. 2023. Ethical considera-
tions for machine translation of indigenous lan-
guages: Giving a voice to the speakers. In Pro-
ceedings of the 61st Annual Meeting of the Asso-
ciation for Computational Linguistics (Volume
I; Long Papers), pages 4871-4897, Toronto,
Canada. Association for Computational Linguis-
tics.

Olga Majewska, Evgeniia Razumovskaia,
Edoardo M. Ponti, Ivan Vuli¢, and Anna
Korhonen. 2023. Cross-lingual dialogue dataset
creation via outline-based generation. Trans-
actions of the Association for Computational
Linguistics, 11:139-156.

Vijit Malik, Sunipa Dev, Akihiro Nishi, Nanyun
Peng, and Kai-Wei Chang. 2022. Socially aware
bias measurements for Hindi language represen-
tations. In Proceedings of the 2022 Conference
of the North American Chapter of the Associa-
tion for Computational Linguistics: Human Lan-
guage Technologies, pages 1041-1052, Seattle,
United States. Association for Computational
Linguistics.

Antonis Maronikolakis, Axel Wisiorek, Leah
Nann, Haris Jabbar, Sahana Udupa, and Hinrich
Schuetze. 2022. Listening to affected communi-
ties to define extreme speech: Dataset and exper-
iments. In Findings of the Association for Com-
putational Linguistics: ACL 2022, pages 1089-—
1104, Dublin, Ireland. Association for Computa-
tional Linguistics.

Reem Masoud, Ziquan Liu, Martin Ferianc,
Philip C. Treleaven, and Miguel Rodrigues Ro-
drigues. 2025. Cultural alignment in large lan-
guage models: An explanatory analysis based on
hofstede‘s cultural dimensions. In Proceedings

of the 31st International Conference on Com-
putational Linguistics, pages 8474-8503, Abu
Dhabi, UAE. Association for Computational Lin-
guistics.

Takahiko Masuda, Richard Gonzalez, Letty Kwan,
and Richard E Nisbett. 2008. Culture and aes-
thetic preference: Comparing the attention to
context of east asians and americans. Personal-
ity and Social Psychology Bulletin, 34(9):1260—
1275.

David Matsumoto and Linda Juang. 1996. Culture
and psychology. Pacific Grove, pages 266-270.

Yoshiko Matsumoto. 1988. Reexamination of the
universality of face: Politeness phenomena in
japanese. Journal of pragmatics, 12(4):403-—
426.

Michael McCloskey and Neal J. Cohen. 1989.
Catastrophic interference in connectionist net-
works: The sequential learning problem. vol-
ume 24 of Psychology of Learning and Motiva-
tion, pages 109-165. Academic Press.

Nicholas Meade, Elinor Poole-Dayan, and Siva
Reddy. 2022. An empirical survey of the effec-
tiveness of debiasing techniques for pre-trained
language models. In Proceedings of the 60th
Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers),
pages 1878-1898, Dublin, Ireland. Association
for Computational Linguistics.

. A. Meaney. 2020. Crossing the line: Where do
demographic variables fit into humor detection?
In Proceedings of the 58th Annual Meeting of
the Association for Computational Linguistics:
Student Research Workshop, pages 176-181, On-
line. Association for Computational Linguistics.

Batja Mesquita, Nico H Frijda, and Klaus R
Scherer. 1997. Culture and emotion. Handbook
of cross-cultural psychology: Basic processes
and human development, 2:255.

George A. Miller. 1992. WordNet: A lexical
database for English. In Speech and Natural
Language: Proceedings of a Workshop Held at
Harriman, New York, February 23-26, 1992.

Farhad Moghimifar, Shilin Qu, Tongtong Wu,
Yuan-Fang Li, and Gholamreza Haffari. 2023.
NormMark: A weakly supervised Markov model


for socio-cultural norm discovery. In Findings of
the Association for Computational Linguistics:
ACL 2023, pages 5081-5089, Toronto, Canada.
Association for Computational Linguistics.

Youssef Mohamed, Mohamed Abdelfattah, Shyma
Alhuwaider, Feifan Li, Xiangliang Zhang, Ken-
neth Church, and Mohamed Elhoseiny. 2022.
ArtELingo: A million emotion annotations of
WikiArt with emphasis on diversity over lan-
guage and culture. In Proceedings of the 2022
Conference on Empirical Methods in Natural
Language Processing, pages 8770-8785, Abu
Dhabi, United Arab Emirates. Association for
Computational Linguistics.

Youssef Mohamed, Runjia Li, Ibrahim Ahmad,
Kilichbek Haydarov, Philip Torr, Kenneth
Church, and Mohamed Elhoseiny. 2024. No
culture left behind: ArtELingo-28, a benchmark
of WikiArt with captions in 28 languages. In
Proceedings of the 2024 Conference on Empir-
ical Methods in Natural Language Processing,
pages 20939-20962, Miami, Florida, USA. As-
sociation for Computational Linguistics.

Aida Mostafazadeh Davani, Mark Diaz, Dylan
Baker, and Vinodkumar Prabhakaran. 2024.
D3CODE: Disentangling disagreements in data
across cultures on offensiveness detection and
evaluation. In Proceedings of the 2024 Con-
ference on Empirical Methods in Natural Lan-
guage Processing, pages 18511-18526, Miami,
Florida, USA. Association for Computational
Linguistics.

Anjishnu Mukherjee, Aylin Caliskan, Ziwei Zhu,
and Antonios Anastasopoulos. 2024. Global
gallery: The fine art of painting culture por-
traits through multilingual instruction tuning.
In Proceedings of the 2024 Conference of the
North American Chapter of the Association for
Computational Linguistics: Human Language
Technologies (Volume 1: Long Papers), pages
6398-6415, Mexico City, Mexico. Association
for Computational Linguistics.

Anjishnu Mukherjee, Chahat Raj, Ziwei Zhu, and
Antonios Anastasopoulos. 2023. Global Voices,
local biases: Socio-cultural prejudices across
languages. In Proceedings of the 2023 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 15828-15845, Singapore. As-
sociation for Computational Linguistics.

George Peter Murdock. 1940.

The cross-
cultural survey. American Sociological Review,
5(3):361-370.

Maria Nadejde, Anna Currey, Benjamin Hsu, Xing

Niu, Marcello Federico, and Georgiana Dinu.
2022. CoCoA-MT: A dataset and benchmark
for contrastive controlled MT with application
to formality. In Findings of the Association for
Computational Linguistics: NAACL 2022, pages
616-632, Seattle, United States. Association for
Computational Linguistics.

Nikita Nangia, Clara Vania, Rasika Bhalerao, and

Samuel R. Bowman. 2020. CrowS-pairs: A
challenge dataset for measuring social biases
in masked language models. In Proceedings of
the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP), pages
1953-1967, Online. Association for Computa-
tional Linguistics.

Tarek Naous, Michael Ryan, Alan Ritter, and Wei

Xu. 2024. Having beer after prayer? measuring
cultural bias in large language models. In Pro-
ceedings of the 62nd Annual Meeting of the As-
sociation for Computational Linguistics (Volume
1: Long Papers), pages 16366-16393, Bangkok,
Thailand. Association for Computational Lin-
guistics.

Shravan Nayak, Kanishk Jain, Rabiul Awal, Siva

Reddy, Sjoerd Van Steenkiste, Lisa Anne
Hendricks, Karolina Stanczak, and Aishwarya
Agrawal. 2024. Benchmarking vision language
models for cultural understanding. In Proceed-
ings of the 2024 Conference on Empirical Meth-
ods in Natural Language Processing, pages
5769-5790, Miami, Florida, USA. Association
for Computational Linguistics.

Aurélie Névéol, Yoann Dupont, Julien Bezangon,

and Karén Fort. 2022. French CrowS-pairs: Ex-
tending a challenge dataset for measuring social
bias in masked language models to a language
other than English. In Proceedings of the 60th
Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers),
pages 8521-8531, Dublin, Ireland. Association
for Computational Linguistics.

Tuan-Phong Nguyen, Simon Razniewski, Aparna S.

Varde, and Gerhard Weikum. 2023. Extracting
cultural commonsense knowledge at scale. In


Proceedings of the ACM Web Conference 2023,
WWW 2023, Austin, TX, USA, 30 April 2023 - 4
May 2023, pages 1907-1917. ACM.

Tuan-Phong Nguyen, Simon Razniewski, and Ger-
hard Weikum. 2024. Cultural commonsense
knowledge for intercultural dialogues. In Pro-
ceedings of the 33rd ACM International Confer-
ence on Information and Knowledge Manage-
ment, CIKM ’24, page 1774-1784, New York,
NY, USA. Association for Computing Machin-
ery.

Minako O’hagan and Carmen Mangiron. 2013.
Game Localization: Translating for the global
digital entertainment industry, volume 106.
John Benjamins Publishing.

Longshen Ou, Xichu Ma, Min-Yen Kan, and
Ye Wang. 2023. Songs across borders: Singable
and controllable neural lyric translation. In Pro-
ceedings of the 61st Annual Meeting of the Asso-
ciation for Computational Linguistics (Volume I:
Long Papers), pages 447-467, Toronto, Canada.
Association for Computational Linguistics.

Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo
Almeida, Carroll L. Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Kata-
rina Slama, Alex Ray, John Schulman, Jacob
Hilton, Fraser Kelton, Luke Miller, Maddie
Simens, Amanda Askell, Peter Welinder, Paul F.
Christiano, Jan Leike, and Ryan Lowe. 2022.
Training language models to follow instructions
with human feedback. In Advances in Neural In-
formation Processing Systems 35: Annual Con-
ference on Neural Information Processing Sys-
tems 2022, NeurIPS 2022, New Orleans, LA,
USA, November 28 - December 9, 2022.

Shramay Palta and Rachel Rudinger. 2023. FORK:
A bite-sized test set for probing culinary cul-
tural biases in commonsense reasoning mod-
els. In Findings of the Association for Computa-
tional Linguistics: ACL 2023, pages 9952-9962,
Toronto, Canada. Association for Computational
Linguistics.

Claudio Paonessa, Yanick Schraner, Jan Deriu,
Manuela Hiirlimann, Manfred Vogel, and Mark
Cieliebak. 2023. Dialect transfer for Swiss Ger-
man speech translation. In Findings of the Asso-
ciation for Computational Linguistics: EMNLP

2023, pages 15240-15254, Singapore. Associa-
tion for Computational Linguistics.

Joon Sung Park, Lindsay Popowski, Carrie J.
Cai, Meredith Ringel Morris, Percy Liang, and
Michael S. Bernstein. 2022. Social simulacra:
Creating populated prototypes for social comput-
ing systems. In The 35th Annual ACM Sympo-
sium on User Interface Software and Technology,
UIST 2022, Bend, OR, USA, 29 October 2022 -
2 November 2022, pages 74:1—74:18. ACM.

Jiaxin Pei and David Jurgens. 2023. When do an-
notator demographics matter? measuring the
influence of annotator demographics with the
POPQUORN dataset. In Proceedings of the 17th
Linguistic Annotation Workshop (LAW-XVII),
pages 252-265, Toronto, Canada. Association
for Computational Linguistics.

Zoé Pettit. 2009. 3: Connecting Cultures: Cultural
Transfer in Subtitling and Dubbing, pages 44—
57. Multilingual Matters, Bristol, Blue Ridge
Summit.

Jonas Pfeiffer, Ivan Vuli¢, Iryna Gurevych, and
Sebastian Ruder. 2020. MAD-X: An Adapter-
Based Framework for Multi-Task Cross-Lingual
Transfer. In Proceedings of the 2020 Confer-
ence on Empirical Methods in Natural Language
Processing (EMNLP), pages 7654-7673, Online.
Association for Computational Linguistics.

Michel Pliiss, Jan Deriu, Yanick Schraner, Clau-
dio Paonessa, Julia Hartmann, Larissa Schmidt,
Christian Scheller, Manuela Hiirlimann, Tanja
Samardzi¢, Manfred Vogel, and Mark Cieliebak.
2023. STT4SG-350: A speech corpus for all
Swiss German dialect regions. In Proceedings
of the 61st Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short
Papers), pages 1763-1772, Toronto, Canada. As-
sociation for Computational Linguistics.

Edoardo Maria Ponti, Goran GlavaS, Olga Majew-
ska, Qianchu Liu, Ivan Vuli¢é, and Anna Korho-
nen. 2020. XCOPA: A multilingual dataset for
causal commonsense reasoning. In Proceedings
of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP), pages
2362-2376, Online. Association for Computa-
tional Linguistics.


Rifki Putri, Faiz Haznitrama, Dea Adhista, and Al-
ice Oh. 2024. Can LLM generate culturally rel-
evant commonsense QA data? case study in In-
donesian and Sundanese. In Proceedings of the
2024 Conference on Empirical Methods in Natu-
ral Language Processing, pages 20571-20590,
Miami, Florida, USA. Association for Computa-
tional Linguistics.

Valentina Pyatkin, Jena D. Hwang, Vivek Sriku-
mar, Ximing Lu, Liwei Jiang, Yejin Choi, and
Chandra Bhagavatula. 2023. ClarifyDelphi: Re-
inforced clarification questions with defeasibility
rewards for social and moral situations. In Pro-
ceedings of the 61st Annual Meeting of the Asso-
ciation for Computational Linguistics (Volume
1; Long Papers), pages 11253-11271, Toronto,
Canada. Association for Computational Linguis-
tics.

Rafael Rafailov, Archit Sharma, Eric Mitchell,
Christopher D. Manning, Stefano Ermon, and
Chelsea Finn. 2023. Direct preference opti-
mization: Your language model is secretly a
reward model. In Advances in Neural Informa-
tion Processing Systems 36: Annual Conference
on Neural Information Processing Systems 2023,
NeurIPS 2023, New Orleans, LA, USA, Decem-
ber 10 - 16, 2023.

Aida Ramezani and Yang Xu. 2023. Knowledge
of cultural moral norms in large language mod-
els. In Proceedings of the 61st Annual Meeting
of the Association for Computational Linguis-
tics (Volume 1: Long Papers), pages 428-446,
Toronto, Canada. Association for Computational
Linguistics.

Kavel Rao, Liwei Jiang, Valentina Pyatkin, Yuling
Gu, Niket Tandon, Nouha Dziri, Faeze Brahman,
and Yejin Choi. 2023. What makes it ok to set a
fire? iterative self-distillation of contexts and ra-
tionales for disambiguating defeasible social and
moral situations. In Findings of the Association
for Computational Linguistics: EMNLP 2023,
pages 12140-12159, Singapore. Association for
Computational Linguistics.

Ken Resnicow, Tom Baranowski, Jasjit S.
Ahluwalia, and Ronald L. Braithwaite. 1999.
Cultural sensitivity in public health: Defined and
demystified. Ethnicity & Disease, 9(1):10—21.

Dor Ringel, Gal Lavee, Ido Guy, and Kira Radin-

sky. 2019. Cross-cultural transfer learning for
text classification. In Proceedings of the 2019
Conference on Empirical Methods in Natural
Language Processing and the 9th International
Joint Conference on Natural Language Process-
ing (EMNLP-IJCNLP), pages 3873-3883, Hong
Kong, China. Association for Computational
Linguistics.

William Gaviria Rojas, Sudnya Frederick Diamos,

Keertan Kini, David Kanter, Vijay Janapa Reddi,
and Cody Coleman. 2022. The dollar street
dataset: Images representing the geographic and
socioeconomic diversity of the world. In Ad-
vances in Neural Information Processing Sys-
tems 35: Annual Conference on Neural Infor-
mation Processing Systems 2022, NeurIPS 2022,
New Orleans, LA, USA, November 28 - Decem-
ber 9, 2022.

Nihar Sahoo, Pranamya Kulkarni, Arif Ahmad,

Tanu Goyal, Narjis Asad, Aparna Garimella,
and Pushpak Bhattacharyya. 2024. IndiBias: A
benchmark dataset to measure social biases in
language models for Indian context. In Proceed-
ings of the 2024 Conference of the North Amer-
ican Chapter of the Association for Computa-
tional Linguistics: Human Language Technolo-
gies (Volume 1: Long Papers), pages 8786-8806,
Mexico City, Mexico. Association for Computa-
tional Linguistics.

Nihar Sahoo, Niteesh Mallela, and Pushpak Bhat-

tacharyya. 2023. With prejudice to none: A few-
shot, multilingual transfer learning approach to
detect social bias in low resource languages. In
Findings of the Association for Computational
Linguistics: ACL 2023, pages 13316-13330,
Toronto, Canada. Association for Computational
Linguistics.

Mohammad Salameh, Houda Bouamor, and Nizar

Habash. 2018. Fine-grained Arabic dialect iden-
tification. In Proceedings of the 27th Interna-
tional Conference on Computational Linguistics,
pages 1332-1344, Santa Fe, New Mexico, USA.
Association for Computational Linguistics.

Nithya Sambasivan, Erin Arnesen, Ben Hutchinson,

Tulsee Doshi, and Vinodkumar Prabhakaran.
2021. Re-imagining algorithmic fairness in in-
dia and beyond. In FAccT ’21: 2021 ACM Con-


ference on Fairness, Accountability, and Trans-
parency, Virtual Event / Toronto, Canada, March
3-10, 2021, pages 315-328. ACM.

Sandra Sandoval, Jieyu Zhao, Marine Carpuat, and
Hal Daumé III. 2023. A rose by any other name
would not smell as sweet: Social bias in names
mistranslation. In Proceedings of the 2023 Con-
ference on Empirical Methods in Natural Lan-
guage Processing, pages 3933-3945, Singapore.
Association for Computational Linguistics.

Shibani Santurkar, Esin Durmus, Faisal Lad-
hak, Cinoo Lee, Percy Liang, and Tatsunori
Hashimoto. 2023. Whose opinions do language
models reflect? In International Conference on
Machine Learning, ICML 2023, 23-29 July 2023,
Honolulu, Hawaii, USA, volume 202 of Pro-
ceedings of Machine Learning Research, pages
29971-30004. PMLR.

Sebastin Santy, Jenny Liang, Ronan Le Bras,
Katharina Reinecke, and Maarten Sap. 2023.
NLPositionality: Characterizing design biases
of datasets and models. In Proceedings of the
61st Annual Meeting of the Association for Com-
putational Linguistics (Volume 1: Long Papers),
pages 9080-9102, Toronto, Canada. Association
for Computational Linguistics.

Maarten Sap, Swabha Swayamdipta, Laura Vianna,
Xuhui Zhou, Yejin Choi, and Noah A. Smith.
2022. Annotators with attitudes: How annotator
beliefs and identities bias toxic language detec-
tion. In Proceedings of the 2022 Conference
of the North American Chapter of the Associa-
tion for Computational Linguistics: Human Lan-
guage Technologies, pages 5884-5906, Seattle,
United States. Association for Computational
Linguistics.

Beatrice Savoldi, Marco Gaido, Luisa Bentivogli,
Matteo Negri, and Marco Turchi. 2021. Gen-
der bias in machine translation. Transactions of
the Association for Computational Linguistics,
9:845-874.

Modeling cross-cultural pragmatic inference
with codenames duet. In Findings of the Associ-
ation for Computational Linguistics: ACL 2023,
pages 6550-6569, Toronto, Canada. Association
for Computational Linguistics.

Chhavi Sharma, Deepesh Bhageria, William

Scott, Srinivas PYKL, Amitava Das, Tanmoy
Chakraborty, Viswanath Pulabaigari, and Bjorn
Gambiack. 2020. SemEval-2020 task 8: Mem-
otion analysis- the visuo-lingual metaphor! In
Proceedings of the Fourteenth Workshop on Se-
mantic Evaluation, pages 759-773, Barcelona
(online). International Committee for Computa-
tional Linguistics.

Shuaijie She, Wei Zou, Shujian Huang, Wen-

hao Zhu, Xiang Liu, Xiang Geng, and Jia-
jun Chen. 2024. MAPO: Advancing multilin-
gual reasoning through multilingual-alignment-
as-preference optimization. In Proceedings of
the 62nd Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Pa-
pers), pages 10015-10027, Bangkok, Thailand.
Association for Computational Linguistics.

Ravi Shekhar, Mladen Karan, and Matthew Purver.

2022. CoRAL: a context-aware Croatian abusive
language dataset. In Findings of the Association
for Computational Linguistics: AACL-IJCNLP
2022, pages 217-225, Online only. Association
for Computational Linguistics.

Weiyan Shi, Ryan Li, Yutong Zhang, Caleb Ziems,

Sunny Yu, Raya Horesh, Rogério Paula, and
Diyi Yang. 2024. CultureBank: An online
community-driven knowledge base towards cul-
turally aware language technologies. In Findings
of the Association for Computational Linguis-
tics: EMNLP 2024, pages 4996-5025, Miami,
Florida, USA. Association for Computational
Linguistics.

Vered Shwartz. 2022. Good night at 4 pm?! time

expressions in different cultures. In Findings of
the Association for Computational Linguistics:
ACL 2022, pages 2842-2853, Dublin, Ireland.

Shalom H Schwartz. 1992. Universals in the con-
tent and structure of values: Theoretical ad-
vances and empirical tests in 20 countries. In
Advances in experimental social psychology, vol-
ume 25, pages 1-65. Elsevier.

Association for Computational Linguistics.

Linda Tuhiwai Smith. 2021. Decolonizing method-
ologfies: Research and indigenous peoples.
Bloomsbury Publishing.

Omar Shaikh, Caleb Ziems, William Held, Aryan
Pariani, Fred Morstatter, and Diyi Yang. 2023.

Guin Son, Hanwool Lee, Sungdong Kim, Seun-
gone Kim, Niklas Muennighoff, Taekyoon Choi,


Cheonbok Park, Kang Min Yoo, and Stella Bider-
man. 2024. KMMLU: measuring massive mul-
titask language understanding in korean. ArXiv
preprint arXiv:2402.11548v2.

Taylor Sorensen, Jared Moore, Jillian Fisher,
Mitchell L. Gordon, Niloofar Mireshghallah,
Christopher Michael Rytting, Andre Ye, Liwei
Jiang, Ximing Lu, Nouha Dziri, Tim Althoff,
and Yejin Choi. 2024. Position: A roadmap
to pluralistic alignment. In Forty-first Interna-
tional Conference on Machine Learning, ICML
2024, Vienna, Austria, July 21-27, 2024. Open-
Review.net.

Robyn Speer, Joshua Chin, and Catherine Havasi.
2017. Conceptnet 5.5: An open multilingual
graph of general knowledge. In Proceedings of
the Thirty-First AAAI Conference on Artificial
Intelligence, February 4-9, 2017, San Francisco,
California, USA, pages 4444-4451. AAAI Press.

Maximilian Splieth6ver, Sai Nikhil Menon, and
Henning Wachsmuth. 2024. Disentangling di-
alect from social bias via multitask learning to
improve fairness. In Findings of the Association
for Computational Linguistics: ACL 2024, pages
9294-9313, Bangkok, Thailand. Association for
Computational Linguistics.

Anirudh Srinivasan and Eunsol Choi. 2022. TyDiP:
A dataset for politeness classification in nine ty-
pologically diverse languages. In Findings of
the Association for Computational Linguistics:
EMNLP 2022, pages 5723-5738, Abu Dhabi,
United Arab Emirates. Association for Compu-
tational Linguistics.

Gabriel Stanovsky, Noah A. Smith, and Luke
Zettlemoyer. 2019. Evaluating gender bias in
machine translation. In Proceedings of the 57th
Annual Meeting of the Association for Computa-
tional Linguistics, pages 1679-1684, Florence,
Italy. Association for Computational Linguistics.

Ian Stewart and Rada Mihalcea. 2024. Whose wife
is it anyway? assessing bias against same-gender
relationships in machine translation. In Proceed-
ings of the 5th Workshop on Gender Bias in
Natural Language Processing (GeBNLP), pages
365-375, Bangkok, Thailand. Association for
Computational Linguistics.

Hao Sun, Zhexin Zhang, Fei Mi, Yasheng Wang,
Wei Liu, Jianwei Cui, Bin Wang, Qun Liu, and

Minlie Huang. 2023. MoralDial: A framework
to train and evaluate moral dialogue systems via
moral discussions. In Proceedings of the 61st
Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers),
pages 2213-2230, Toronto, Canada. Association
for Computational Linguistics.

Tony Sun, Andrew Gaut, Shirlyn Tang, Yuxin

Huang, Mai ElSherief, Jieyu Zhao, Diba
Mirza, Elizabeth Belding, Kai-Wei Chang, and
William Yang Wang. 2019. Mitigating gender
bias in natural language processing: Literature
review. In Proceedings of the 57th Annual Meet-
ing of the Association for Computational Lin-
guistics, pages 1630-1640, Florence, Italy. As-
sociation for Computational Linguistics.

Zhewei Sun and Yang Xu. 2022. Tracing semantic

variation in slang. In Proceedings of the 2022
Conference on Empirical Methods in Natural
Language Processing, pages 1299-1313, Abu
Dhabi, United Arab Emirates. Association for
Computational Linguistics.

Nir Sweed and Dafna Shahaf. 2021. Catchphrase:

Automatic detection of cultural references. In
Proceedings of the 59th Annual Meeting of the
Association for Computational Linguistics and
the 11th International Joint Conference on Nat-
ural Language Processing (Volume 2: Short Pa-
pers), pages 1-7, Online. Association for Com-
putational Linguistics.

Yi Tay, Donovan Ong, Jie Fu, Alvin Chan, Nancy

Chen, Anh Tuan Luu, and Chris Pal. 2020.
Would you rather? a new benchmark for learn-
ing machine alignment with cultural values and
social preferences. In Proceedings of the 58th
Annual Meeting of the Association for Compu-
tational Linguistics, pages 5369-5373, Online.
Association for Computational Linguistics.

Katherine Thai, Marzena Karpinska, Kalpesh Kr-

ishna, Bill Ray, Moira Inghilleri, John Wieting,
and Mohit Lyyer. 2022. Exploring document-
level literary machine translation with paral-
lel paragraphs from world literature. In Pro-
ceedings of the 2022 Conference on Empirical
Methods in Natural Language Processing, pages
9882-9902, Abu Dhabi, United Arab Emirates.
Association for Computational Linguistics.


Ashish V. Thapliyal, Jordi Pont Tuset, Xi Chen,
and Radu Soricut. 2022. Crossmodal-3600: A
massively multilingual multimodal evaluation
dataset. In Proceedings of the 2022 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 715-729, Abu Dhabi, United
Arab Emirates. Association for Computational
Linguistics.

Peter Trudgill. 2000. Sociolinguistics: An intro-
duction to language and society. Penguin UK.

Edward Burnett Tylor. 1871. Primitive culture:
Researches into the development of mythology,
Dhilosophy, religion, art and custom, volume 2.
J. Murray.

UNESCO. 1982. World conference on cultural
policies, mexico city, final report.

Ahmet Ustiin, Arianna Bisazza, Gosse Bouma, and
Gertjan van Noord. 2020. UDapter: Language
adaptation for truly Universal Dependency pars-
ing. In Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Pro-
cessing (EMNLP), pages 2302-2315, Online.
Association for Computational Linguistics.

Karina Vida, Judith Simon, and Anne Lauscher.
2023. Values, ethics, morals? on the use of
moral concepts in NLP research. In Findings of
the Association for Computational Linguistics:
EMNLP 2023, pages 5534-5554, Singapore. As-
sociation for Computational Linguistics.

Anvesh Rao Vijjini, Rakesh R Menon, Jiayi Fu,
Shashank Srivastava, and Snigdha Chaturvedi.
2024. SocialGaze: Improving the integration of
human social norms in large language models.
In Findings of the Association for Computational
Linguistics: EMNLP 2024, pages 16487-16506,
Miami, Florida, USA. Association for Computa-
tional Linguistics.

Alex Wang, Amanpreet Singh, Julian Michael, Fe-
lix Hill, Omer Levy, and Samuel R. Bowman.
2019. GLUE: A multi-task benchmark and anal-
ysis platform for natural language understand-
ing. In 7th International Conference on Learn-
ing Representations, ICLR 2019, New Orleans,
LA, USA, May 6-9, 2019. OpenReview.net.

Bin Wang, Geyu Lin, Zhengyuan Liu, Chengwei
Wei, and Nancy Chen. 2024a. CRAFT: Extract-
ing and tuning cultural instructions from the wild.

In Proceedings of the 2nd Workshop on Cross-
Cultural Considerations in NLP, pages 42-47,
Bangkok, Thailand. Association for Computa-
tional Linguistics.

Bin Wang, Zhengyuan Liu, Xin Huang, Fangkai
Jiao, Yang Ding, AiTi Aw, and Nancy Chen.
2024b. SeaEval for multilingual foundation
models: From cross-lingual alignment to cul-
tural reasoning. In Proceedings of the 2024 Con-
ference of the North American Chapter of the
Association for Computational Linguistics: Hu-
man Language Technologies (Volume 1: Long
Papers), pages 370-390, Mexico City, Mexico.
Association for Computational Linguistics.

Ruize Wang, Duyu Tang, Nan Duan, Zhongyu
Wei, Xuanjing Huang, Jianshu Ji, Guihong Cao,
Daxin Jiang, and Ming Zhou. 2021. K-Adapter:
Infusing Knowledge into Pre-Trained Models
with Adapters. In Findings of the Association
for Computational Linguistics: ACL-IJCNLP
2021, pages 1405-1418, Online. Association for
Computational Linguistics.

Wenxuan Wang, Wenxiang Jiao, Jingyuan Huang,
Ruyi Dai, Jen-tse Huang, Zhaopeng Tu, and
Michael Lyu. 2024c. Not all countries celebrate
thanksgiving: On the cultural dominance in large
language models. In Proceedings of the 62nd
Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers),
pages 6349-6384, Bangkok, Thailand. Associa-
tion for Computational Linguistics.

Ronald Wardhaugh and Janet M Fuller. 2021. An
introduction to sociolinguistics. John Wiley &
Sons.

Isadora White, Sashrika Pandey, and Michelle Pan.
2024. Communicate to play: Pragmatic reason-
ing for efficient cross-cultural communication.
In Findings of the Association for Computational
Linguistics: EMNLP 2024, pages 12201-12216,
Miami, Florida, USA. Association for Computa-
tional Linguistics.

Leslie A White. 1959. The concept of culture.
American anthropologist, 61(2):227-251.

Andrew Whiten, Robert A Hinde, Kevin N
Laland, and Christopher B Stringer. 2011.
Culture evolves. Philosophical Transactions
of the Royal Society B: Biological Sciences,
366(1567):938-948.


Anna Wierzbicka. 1992.

Haryo Wibowo, Erland Fuadi, Made Nityasya,
Radityo Eko Prasojo, and Alham Aji. 2024.
COPAL-ID: Indonesian language reasoning with
local culture and nuances. In Proceedings of the
2024 Conference of the North American Chapter
of the Association for Computational Linguis-
tics: Human Language Technologies (Volume 1:
Long Papers), pages 1404-1422, Mexico City,
Mexico. Association for Computational Linguis-
tics.

Semantics, culture,
and cognition: Universal human concepts in
culture-specific configurations. Oxford Univer-
sity Press.

Zedian Xiao, William Held, Yanchen Liu, and Diyi
Yang. 2023. Task-agnostic low-rank adapters for
unseen English dialects. In Proceedings of the
2023 Conference on Empirical Methods in Nat-
ural Language Processing, pages 7857-7870,
Singapore. Association for Computational Lin-
guistics.

Hu Xu, Bing Liu, Lei Shu, and Philip Yu. 2019.
BERT post-training for review reading compre-
hension and aspect-based sentiment analysis. In
Proceedings of the 2019 Conference of the North
American Chapter of the Association for Com-
putational Linguistics: Human Language Tech-
nologies, Volume I (Long and Short Papers),
pages 2324-2335, Minneapolis, Minnesota. As-
sociation for Computational Linguistics.

Ying Xu, Dakuo Wang, Mo Yu, Daniel Ritchie,
Bingsheng Yao, Tongshuang Wu, Zheng Zhang,
Toby Li, Nora Bradford, Branda Sun, Tran
Hoang, Yisi Sang, Yufang Hou, Xiaojuan Ma,
Diyi Yang, Nanyun Peng, Zhou Yu, and Mark
Warschauer. 2022. Fantastic questions and
where to find them: FairytaleQA — an authentic
dataset for narrative comprehension. In Proceed-
ings of the 60th Annual Meeting of the Associ-
ation for Computational Linguistics (Volume 1:
Long Papers), pages 447-460, Dublin, Ireland.
Association for Computational Linguistics.

Linting Xue, Noah Constant, Adam Roberts, Mihir
Kale, Rami Al-Rfou, Aditya Siddhant, Aditya
Barua, and Colin Raffel. 2021. mT5: A mas-
sively multilingual pre-trained text-to-text trans-
former. In Proceedings of the 2021 Conference
of the North American Chapter of the Associ-
ation for Computational Linguistics: Human

Language Technologies, pages 483-498, Online.
Association for Computational Linguistics.

Diyi Yang. 2019. Computational Social Roles.

Ph.D. thesis, Carnegie Mellon University Pitts-
burgh, PA, USA.

Zhichao Yang, Pengshan Cai, Yansong Feng, Fei

Li, Weijiang Feng, Elena Suet-Ying Chiu, and
Hong Yu. 2019. Generating classical Chinese
poems from vernacular Chinese. In Proceed-
ings of the 2019 Conference on Empirical Meth-
ods in Natural Language Processing and the
9th International Joint Conference on Natural
Language Processing (EMNLP-IJCNLP), pages
6155-6164, Hong Kong, China. Association for
Computational Linguistics.

Binwei Yao, Ming Jiang, Tara Bobinac, Diyi Yang,

and Junjie Hu. 2024a. Benchmarking machine
translation with cultural awareness. In Findings
of the Association for Computational Linguis-
tics: EMNLP 2024, pages 13078-13096, Miami,
Florida, USA. Association for Computational
Linguistics.

Jing Yao, Xiaoyuan Yi, Yifan Gong, Xiting Wang,

and Xing Xie. 2024b. Value FULCRA: Mapping
large language models to the multidimensional
spectrum of basic human value. In Proceed-
ings of the 2024 Conference of the North Amer-
ican Chapter of the Association for Computa-
tional Linguistics: Human Language Technolo-
gies (Volume 1: Long Papers), pages 8762-8785,
Mexico City, Mexico. Association for Computa-
tional Linguistics.

Da Yin, Hritik Bansal, Masoud Monajatipoor, Liu-

nian Harold Li, and Kai-Wei Chang. 2022. Ge-
oMLAMA: Geo-diverse commonsense probing
on multilingual pre-trained language models. In
Proceedings of the 2022 Conference on Empir-
ical Methods in Natural Language Processing,
pages 2039-2055, Abu Dhabi, United Arab Emi-
rates. Association for Computational Linguis-
tics.

Da Yin, Liunian Harold Li, Ziniu Hu, Nanyun Peng,

and Kai-Wei Chang. 2021. Broaden the vision:
Geo-diverse visual commonsense reasoning. In
Proceedings of the 2021 Conference on Em-
pirical Methods in Natural Language Process-
ing, pages 2115-2129, Online and Punta Cana,


Dominican Republic. Association for Computa-
tional Linguistics.

Linhao Yu, Yongqi Leng, Yufei Huang, Shang Wu,
Haixin Liu, Xinmeng Ji, Jiahui Zhao, Jinwang
Song, Tingting Cui, Xiaoqing Cheng, Liutao Li-
utao, and Deyi Xiong. 2024. CMoralEval: A
moral evaluation benchmark for Chinese large
language models. In Findings of the Association
for Computational Linguistics ACL 2024, pages
11817-11837, Bangkok, Thailand and virtual
meeting. Association for Computational Linguis-
tics.

Ye Yuan, Kexin Tang, Jianhao Shen, Ming Zhang,
and Chenguang Wang. 2024. Measuring social
norms of large language models. In Findings
of the Association for Computational Linguis-
tics: NAACL 2024, pages 650-699, Mexico City,
Mexico. Association for Computational Linguis-
tics.

Mahmoud Yusuf, Marwan Torki, and Nagwa EI-
Makky. 2022. Arabic dialect identification with
a few labeled examples using generative adver-
sarial networks. In Proceedings of the 2nd Con-
ference of the Asia-Pacific Chapter of the Asso-
ciation for Computational Linguistics and the
12th International Joint Conference on Natural
Language Processing (Volume 1: Long Papers),
pages 196-204, Online only. Association for
Computational Linguistics.

Haolan Zhan, Zhuang Li, Xiaoxi Kang, Tao Feng,
Yuncheng Hua, Lizhen Qu, Yi Ying, Mei Rianto
Chandra, Kelly Rosalin, Jureynolds Jureynolds,
Suraj Sharma, Shilin Qu, Linhao Luo, Ingrid
Zukerman, Lay-Ki Soon, Zhaleh Semnani Azad,
and Reza Haf. 2024. RENOVI: A benchmark
towards remediating norm violations in socio-
cultural conversations. In Findings of the Asso-
ciation for Computational Linguistics: NAACL
2024, pages 3104-3117, Mexico City, Mexico.
Association for Computational Linguistics.

Haolan Zhan, Zhuang Li, Yufei Wang, Linhao Luo,
Tao Feng, Xiaoxi Kang, Yuncheng Hua, Lizhen
Qu, Lay-Ki Soon, Suraj Sharma, Ingrid Zuker-
man, Zhaleh Semnani-Azad, and Gholamreza
Haffari. 2023. Socialdial: A benchmark for
socially-aware dialogue systems. In Proceed-
ings of the 46th International ACM SIGIR Con-
ference on Research and Development in Infor-

mation Retrieval, SIGIR 2023, Taipei, Taiwan,
July 23-27, 2023, pages 2712-2722. ACM.

Jiaxu Zhao, Meng Fang, Zijing Shi, Yitong Li, Ling

Chen, and Mykola Pechenizkiy. 2023. CHBias:
Bias evaluation and mitigation of Chinese con-
versational language models. In Proceedings
of the 61st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long
Papers), pages 13538-13556, Toronto, Canada.
Association for Computational Linguistics.

Jingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li,

Yasheng Wang, Minlie Huang, Xin Jiang, Qun
Liu, and Helen Meng. 2022. Towards identify-
ing social bias in dialog systems: Framework,
dataset, and benchmark. In Findings of the Asso-
ciation for Computational Linguistics: EMNLP
2022, pages 3576-3591, Abu Dhabi, United
Arab Emirates. Association for Computational
Linguistics.

Li Zhou, Laura Cabello, Yong Cao, and Daniel Her-

shcovich. 2023a. Cross-cultural transfer learn-
ing for Chinese offensive language detection.
In Proceedings of the First Workshop on Cross-
Cultural Considerations in NLP (C3NLP), pages
8-15, Dubrovnik, Croatia. Association for Com-
putational Linguistics.

Li Zhou, Antonia Karamolegkou, Wenyu Chen,

and Daniel Hershcovich. 2023b. Cultural com-
pass: Predicting transfer learning success in of-
fensive language detection with cultural features.
In Findings of the Association for Computational
Linguistics: EMNLP 2023, pages 12684-12702,
Singapore. Association for Computational Lin-
guistics.

Li Zhou, Taelin Karidi, Nicolas Garneau, Yong

Cao, Wanlong Liu, Wenyu Chen, and Daniel Her-
shcovich. 2024. Does mapo tofu contain coffee?
probing Ilms for food-related cultural knowledge.
ArXiv preprint arXiv:2404.06833Vv1.

Caleb Ziems, Jiaao Chen, Camille Harris, Jessica

Anderson, and Diyi Yang. 2022a. VALUE: Un-
derstanding dialect disparity in NLU. In Pro-
ceedings of the 60th Annual Meeting of the Asso-
ciation for Computational Linguistics (Volume 1:
Long Papers), pages 3701-3720, Dublin, Ireland.
Association for Computational Linguistics.

Caleb Ziems, Jane Dwivedi-Yu, Yi-Chia Wang,

Alon Halevy, and Diyi Yang. 2023a. NormBank:


A knowledge bank of situational social norms.
In Proceedings of the 61st Annual Meeting of
the Association for Computational Linguistics
(Volume I; Long Papers), pages 7756-7776,
Toronto, Canada. Association for Computational
Linguistics.

Caleb Ziems, William Held, Jingfeng Yang, Jwala
Dhamala, Rahul Gupta, and Diyi Yang. 2023b.
Multi- VALUE: A framework for cross-dialectal
English NLP. In Proceedings of the 61st Annual
Meeting of the Association for Computational
Linguistics (Volume I: Long Papers), pages 744—
768, Toronto, Canada. Association for Computa-
tional Linguistics.

Caleb Ziems, Jane Yu, Yi-Chia Wang, Alon Halevy,
and Diyi Yang. 2022b. The moral integrity cor-
pus: A benchmark for ethical dialogue systems.
In Proceedings of the 60th Annual Meeting of the
Association for Computational Linguistics (Vol-
ume I: Long Papers), pages 3755-3773, Dublin,
Ireland. Association for Computational Linguis-
tics.


A Method

We examine the main and findings papers from
the leading *CL venues, including: ACL, EMNLP,
AACL, EACL, NAACL and TACL published since
2020 (5-year span). The initial set of papers was
identified using the following search terms: “cul-
ture”, “cultural”, “geo-diverse’’, “socio”, “social”,
“moral”, “norms” in the title and abstract. Initially,
we collected 336 papers, using human verification
to exclude papers that did not consider cultural
variations, as well as papers that solely focus on
analysis and probing (as they are beyond the scope
of our survey). The final paper count is 127. For
more on probing and analysis, please refer to the
recent surveys like Adilazuarda et al. (2024). We
further acknowledge the limitation of missing rele-
vant papers from other sources and papers without
explicitly mentioning any of the search keywords.
However, our goal is not to conduct a systematic
review, but to propose a taxonomy and understand
the progress in NLP for this research area and iden-
tify research gaps. We believe that focusing on *CL
venues is an appropriate choice for this purpose.

B_ Additional Examples of Use Cases for
the Taxonomy.

Another example of applying this taxonomy is the
development of culturally aware conversational
AI for educational purposes. Such development
should be informed, at a minimum, by relevant
Knowledge (e.g., Facts), appropriate Style, under-
standing of the Communicative Goals (e.g., that of
teaching) and consideration of Relationships (e.g.,
that of a teacher and student). These are merely
example elements and applications to consider.

Communicate in the same | age as the target
culture

z Surface
Recognize and understand

different cultural elements
through explicit assessments

Behave as a
member of a
particular cultural
community Deep

Figure 3: An illustration of surface versus deep cultur-
ally adapted NLP model.


Liu et al. (2021)

Thapliyal et al. (2022)
Felkner et al. (2023)

Koto et al. (2024b)

Lee et al. (2024b)

Majewska et al. (2023)
Koto et al. (2023)
Hu et al. (2023)

Nguyen et al. (2023)
Fung et al. (2023)
Fung et al. (2024)

Putri et al. (2024)

Ziems et al. (2023a)
CH-Wang et al. (2023)
Liu et al. (2024a)
Bhutani et al. (2024)

Held et al. (2023)
Xiao et al. (2023)

Figure 4: Categorization of the methods for resource acquisitions with representative examples.

Automatic: Models
and Pipelines

Semi-Automatic:
Model-in-the-loop;
Structured Resources



Figure 5: Categorization of the adaptation modelling methods and examples in each category.
