arX1v:2510.09536v1 [cs.CL] 10 Oct 2025

Evaluating Robustness of Large Language Models
Against Multilingual Typographical Errors

Yihong Liu!*", Raoyuan Zhao!*”", Lena Altinger',
Hinrich Schiitze!”, and Michael A. Hedderich!”

‘Center for Information and Language Processing, LMU Munich
?Munich Center for Machine Learning (MCML)
{yihong, rzhao, hedderich}@cis.1lmu.de

Abstract

Large language models (LLMs) are increas-
ingly deployed in multilingual, real-world ap-
plications with user inputs — naturally intro-
ducing typographical errors (typos). Yet most
benchmarks assume clean input, leaving the ro-
bustness of LLMs to typos across languages
largely underexplored. To address this gap,
we introduce MULTYPO, a multilingual typo
generation algorithm that simulates human-like
errors based on language-specific keyboard lay-
outs and typing behavior. We evaluate 18 open-
source LLMs across three model families and
five downstream tasks spanning language infer-
ence, multi-choice question answering, math-
ematical reasoning, and machine translation
tasks. Our results show that typos consistently
degrade performance, particularly in genera-
tive tasks and those requiring reasoning — while
the natural language inference task is compara-
tively more robust. Instruction tuning improves
clean-input performance but may increase brit-
tleness under noise. We also observe language-
dependent robustness: high-resource languages
are generally more robust than low-resource
ones, and translation from English is more ro-
bust than translation into English. Our find-
ings underscore the need for noise-aware train-
ing and multilingual robustness evaluation. We
make our code and data publicly available.!

1 Introduction

LLMs are increasingly deployed in real-world ap-
plications such as chatbots, translation tools, and
search engines (Dam et al., 2024; Naveed et al.,
2024; Raza et al., 2025), where users input text via
keyboards in a wide range of languages. In such
settings, typographical errors (typos) are a natural
part of user input — arising from slips, fast typing,
or unfamiliarity with keyboard layouts (Wengelin,
2007; Conijn et al., 2019; Shi et al., 2025). Despite

“Equal contribution.
‘https://github.com/mainlp/Multypo-Eval

= @..— —
Cre7 Pees 562)
Ter ai ca
o!M> OLMo-2-1124-7B-Instruct
AL
(a Bereateinvienstas ) H- —-----— » So,
| FISIB auf das Brett... ein | |Poppy [B@ solving ... the | Ig@parmentos patnalocanocell
Drittel der vervieibenden | (eemainieg piecrs... | [cnoxutb?
——— Tele. Se _____L OS - - - E
Ek EE EET EE] da | ie an FEEEEEEEE
«PEE Ee TE = ‘fi a it | EEE ET EE EE
EP EE EE ET PEELE LEEEETEEE EY)
Mg- — iMg- —>
Of 500% OF S00 Of 5008)
en “S ; ~~ ——. Brionnn cobupaet naan |

Poppy lést ein 7” Poppy is solving a

{ s000-tele-Puzzle. Sie | diane Hea puzzle. \ { 1000 chparmertos. Oxa

legt ein Viertel der Teile She places a quarter of the | | eopatier ice te aeee
| auf das Brett, dann legt | pieces on the board, then | | ae oe a :

ihre Mama ein Drittel der | ' her mom places a third of | eenmeccrnens
ocTasuinxca cpparmeHtos. ||
Ckonbko cbparmeHToB }
/ “nasna octanocb cnoxKuTbY

\
cknagbiBaeT YeTBEpTb |
|
|
|

verbleibenden Teile. Wie | ! the remaining pieces. How | |
| viele Puzzleteile miissen i] | many jigsaw pieces are left | |
_\noch gelegt werden? J \to be placed?
‘Ss _ S

Figure 1: Illustration of the impact of real-world typo-
graphical errors. Humans often make typos on language-
specific keyboard layouts, and once such errors are in-
troduced, models can fail across languages. In this
example, the model cannot generate the correct answer
("500") under typos in English, German, and Russian.

this, most LLM evaluations assume clean, error-
free input and report only a single aggregate statis-
tic on a held-out set, thereby overlooking this ubiq-
uitous source of noise (Sun et al., 2020; Moradi and
Samwald, 2021; Wang et al., 2024) and often over-
estimating real-world performance (Ribeiro et al.,
2020; Hedderich et al., 2022; Zhao et al., 2024)
Robustness to typos is not just a usability concern;
it is essential for ensuring reliable model behavior,
maintaining user trust, and delivering consistent
downstream performance in practical deployments.

Prior work on robustness evaluation has largely
focused on adversarial or synthetic perturbations in
an English-centric manner (Gao et al., 2018; Wang
et al., 2023; Gan et al., 2024; Zhu et al., 2024;
Zhang et al., 2025). As a result, we know little
about how robust LLMs are against realistic typos
in a multilingual context. Models can generate
wrong answers with simple input textual perturba-
tions across languages, as shown in Figure 1. More-
over, these approaches often rely on edit-distance


Error Example Sentence

None Colorless green ideas smell furiously.
Replacement Colorless green ideaa smell furiously.
Insertion Colorless greenm ideas smell furiously.
Deletion Coorless green ideas smell furiously.
Transposition Colorless green ideas smell furioulsy.

Table 1: Examples of four different typographical errors.

heuristics or character-level noise, with little regard
for typing behavior (e.g., /0-finger typing conven-
tion) based on language-specific keyboard layouts.

To address these gaps, we first introduce MUL-
TYPO, a multilingual typo generation algorithm
grounded in empirical modeling of typing behavior.
Unlike prior work, MULT YPO simulates realistic
typos based on actual language-specific keyboard
layouts and constraints, allowing us to generate
noise that better reflects real-world user patterns
across languages. Crucially, we validate typo real-
ism through human evaluation, ensuring our per-
turbations reflect actual typing behavior. Relying
on MULTYPO, we conduct a comprehensive ro-
bustness evaluation of 18 open-source LLMs, span-
ning three major model families: Gemma, Qwen,
and OLMo, using both base models and their
instruction-tuned versions, across diverse down-
stream tasks. Moreover, we assess the model ro-
bustness under varying levels of typo corruption,
and under both zero- and few-shot prompting.

Our experiments yield several key findings. First,
typographical errors consistently degrade model
performance, particularly on generative tasks and
those requiring reasoning (§5.1). Second, model
size does not guarantee robustness: both small and
large models exhibit noticeable performance drops
under typos (§5.2). Third, instruction tuning im-
proves clean-input performance but may also in-
crease vulnerability under noise (§5.3). Fourth,
increasing the number of examples in few-shot set-
tings does not improve the robustness against ty-
pos (86.1). Lastly, robustness varies substantially
across languages and scripts: for instance, trans-
lation from English tends to be more robust than
translation into English (§6.2).

Our contributions are summarized as follows. (i)
We propose MULTYPO, a multilingual typo gener-
ation algorithm that simulates realistic human-like
errors grounded in language-specific keyboard lay-
outs and typing patterns, and validate its realism
through human evaluation. (ii) We conduct a com-
prehensive robustness evaluation suite spanning 18
open-source LLMs from three families (Gemma,

Qwen, OLMo), across five downstream tasks. (iii)
We evaluate robustness under both zero-shot and
few-shot prompting, and under varying levels of ty-
pographical corruption, enabling fine-grained anal-
ysis of model behavior. (iv) We will release our
code to facilitate further research on multilingual
robustness under typographical errors.

2 Background and Related Work
2.1 Typographical Errors

Typographical errors are among the most common
forms of natural noise in user-generated text, typi-
cally resulting from accidental keystrokes during
typing. Early studies (Gardner, 1992; Lisbach and
Meyer, 2013) have identified four core types of ty-
pos: replacement, insertion, deletion, and trans-
position. Replacement errors occur when the in-
tended key is substituted with another, typically
an adjacent key. Insertion errors arise from unin-
tentionally pressing an adjacent key alongside the
intended one, while deletion errors involve acci-
dentally omitting a character. Transposition errors,
frequently attributed to asynchronous hand move-
ments, swap two adjacent characters, particularly
those typed by different hands. Examples are illus-
trated in Table 1. These four categories have been
widely adopted and extended in subsequent work
on noise modeling and robustness evaluation (Gao
et al., 2018; Pruthi et al., 2019; Zhang et al., 2022;
Gan et al., 2024). They also form the foundation of
our multilingual typo simulation algorithm MUL-
Typo (cf. §3),” which extends this line of work by
incorporating language-specific keyboard layouts.

2.2 Related Work

Input Text Perturbations Recent advances in
LLMs have sparked growing interest in evaluat-
ing their robustness to noisy or manipulated input.
A large body of work focuses on input corrup-
tions, which aim to degrade model performance
by perturbing the input text at various granularities.
These include character-level modifications such as
misspellings and typographical errors (Gao et al.,
2018; Li et al., 2019; Pruthi et al., 2019; Gan et al.,
2024), word-level attacks like synonym substitu-
tion or word shuffling (Garg and Ramakrishnan,
2020; Jin et al., 2020; Moradi and Samwald, 2021;

>For comparison, we implement a naive baseline that ap-
plies the same operations without layout constraints, in line
with prior approaches. We show that our typos better resem-
ble human errors (cf. §3.2) and that models exhibit different
robustness to our typos versus the naive ones (cf. §D).


(E] Input Text

ae
“One of our number will carry
out your instructions minutely.

000

Typo Rate: 0.1

®D oan na nawnx HOMepoB
OyfeT HOCKOHaNnbHO
BbINONHATb Balu MHCTpyKLUMN.

©. AMiLaglad Audits » gins LUI) Gye Saal y Agi

4a JS

Selected Words

VHCTpYyKLMU

e Output Text

(Transpose)

PIA
3 aietructions aogg Fone of our number will carry
© “Position Samping out your instrcutions
ey g

minutely.
(Insert)
pW Ogun v3 Hawux Homepos

OyfeT HOCKOHaNnbHO

BbINONHATb Balun
WHCTPKLYyUN.
UglS Clilaglad Lyatty 6 gin Luld) yo Saal y
Typo Operations: ey
Replace, .

(Replace)
Insert,Delete, Transpose

Figure 2: Illustration of the pipeline of MULT YPO: Given an input text and a user-defined typo rate, the algorithm (i)
samples words with probability proportional to the square root of the word length, (ii) samples character positions
using a position-aware distribution, and (iii) samples one of four typo operations: replace, insert, delete, or transpose.
Then the algorithm produces a noised text that simulates human-like errors.

Zhou et al., 2024), and sentence-level perturbations
through paraphrasing or irrelevant context inser-
tions (Shi et al., 2023a; Lanham et al., 2023; Xu
et al., 2024). Even minor punctuation noise can
affect LLMs’ performance (Abedin et al., 2025).
However, most of this research is conducted in
English-centric settings, leaving it unclear how ty-
pos influence LLMs’ robustness across different
languages — a gap our work directly addresses.

Multilingual Robustness Evaluation Another
line of work has examined the robustness of
multilingual models (Cooper Stickland et al.,
2023; Aliakbarzadeh et al., 2025). For example,
Cooper Stickland et al. (2023) investigated how
real-world noise influences encoder-only models
such as XLM-R (Conneau et al., 2020) and mBERT
(Devlin et al., 2019), and proposed data augmen-
tation with a contrastive loss for pretraining more
robust multilingual models. More recently, Aliak-
barzadeh et al. (2025) extended this line of inves-
tigation to larger multilingual models, demonstrat-
ing that performance deteriorates when inputs are
corrupted by real-world noise in language under-
standing tasks. In contrast to them, we explore
typographical errors directly by introducing a mul-
tilingual, keyboard-aware typo generation algo-
rithm that enables realistic and extensible simu-
lation across diverse languages. Additionally, our
systematic evaluation covers a broader range of
tasks beyond language understanding.

3 MULTYPO

This section introduces MULT YPO, a multilingual
typo generation algorithm designed to simulate
realistic, human-like typos based on language-
specific keyboard layouts. Given a clean input

text, MULTYPO injects character-level perturba-
tions that mimic natural typing mistakes, producing
corrupted outputs that maintain the overall coher-
ence of the original text. We describe the algorith-
mic design in §3.1, followed by a human evaluation
in §3.2 that evaluates how well the generated typos
reflect real human typing behavior.

3.1 Algorithm Design

To reflect the real typing behavior of users of dif-
ferent languages, we leverage a keyboard layout
database.* When inserting typos, special symbols
(e.g., punctuation marks or modifier keys such as
Enter) are excluded. For determining which hand
types a specific key, we rely on the standard /0-
finger typing convention for QWERTY English
keyboards, according to which characters such as
“STGB” are assigned to the left hand and “6YHN”
to the right hand (Logan et al., 2016). For other lan-
guages, we adopt the same keyboard-relative hand
separation (i.e., left vs. right half, based on key
positions) — a common implicit assumption in mul-
tilingual layout design — though we validate its ap-
propriateness empirically in our human evaluation.
The overall pipeline of MULT YPO is illustrated in
Figure 2. Below, we describe the key components
in detail, and the description of MULT YPO.

Typo Types We consider four types of typos
based on existing literature, as introduced in §2.1:
replacement, insertion, deletion, and transposition.

* Replacement: A single character in a word is
replaced by a neighboring key based on the
language-specific keyboard layout.

3https ://kbdlayout. info/


¢ Insertion: A randomly selected additional
character is inserted immediately after a cor-
rectly typed character, simulating accidental
simultaneous keystrokes.

* Deletion: A single character in a word is ran-
domly deleted from the word, simulating the
common case where a keypress is missed.

¢ Transposition: Two adjacent characters are
swapped. We constrain this to occur only be-
tween characters typed with different hands,
based on the 10-finger typing convention.

Ignoring String Sets To avoid corrupting tokens
that are critical for downstream understanding, es-
pecially numbers, we define a language-specific set
of strings to ignore during typo insertion. These
sets include numerical expressions commonly used
across languages — both in digit form (e.g., 1, 2, 3)
and in word form (e.g., “three’’, “hundred”, “‘mil-
lion’) (see Figure 8 in §A). During typo generation,
any word that matches or contains a string in the
set is excluded from being inserted with typos.

Length-Aware Sampling Probability Rather
than treating all words equally, we assign each
word a sampling probability proportional to the
Viwl
Cw Viel

over all words in a given text), reflecting the ten-
dency for longer words to attract more typos (Peter-
son, 1986; Kukich, 1992). In addition, when select-
ing a specific character position within a word to in-
sert or modify, we also consider position-dependent
weights. Following observations from Lisbach and
Meyer (2013), which show that errors are more
likely to occur toward the middle or end of a word,
we assign a non-uniform probability distribution
over character indices, with details provided in $A.

square root of its length: (normalized

Algorithm Description Given an input sequence
S = {wi, w2,...,Wn} of n words, our algorithm
begins by computing the number of typos to in-
sert, determined by a user-defined corruption ratio
T € [0, 1] and the total number of words n, rounded
to the nearest integer. Each word w) is assigned a
sampling probability proportional to the square root
of its character length J|ul , as described earlier,
and candidates are sampled accordingly. For each

4While this makes the noise slightly less realistic, it ensures
that benchmark results reflect robustness to typos rather than
being skewed by altered numeric values in the prompt.

Language Multypo (avg.) Naive (avg.) Significance
German 8.93 a2 sd
English 10.00 4.79 aia
Russian 9.67 7.67 ak
Hindi 9.40 6.67 ad
French 9.60 6.67 sd
Greek 8.07 5.93 *
Arabic 6.00 6.60

Table 2: Average number of sentences judged as “nat-
ural” out of 15 corrupted sentences per system, with
significance from paired t-tests. Stars denote the signifi-
cance levels: * p < 0.05, ** p < 0.01, *** p < 0.001.

selected word, we sample one of four typo opera-
tions: replace, insert, delete, or transpose. The spe-
cific character position within the word is sampled
based on a length-aware, position-dependent distri-
bution that favors later positions. Once the position
in a word is determined, the algorithm applies the
selected typo operation to that position. After each
successful typo insertion, the corresponding word’s
sampling weight is halved to encourage distribu-
tional diversity. The algorithm proceeds iteratively
until either the target number of typos is reached
or a maximum retry threshold is exceeded. The
pipeline of MULT YPO is illustrated in Figure 2.

3.2. Human Evaluation on Typo Naturalness

To further assess the realism of MULT YPO-
generated typos, we conduct a human evaluation
comparing MULT YPO against a naive baseline that
applies the same four operations (insertion, dele-
tion, substitution, transposition) but without con-
sidering keyboard layout constraints. For each lan-
guage, we sample 30 sentences from Flores200
(NLLB Team et al., 2022), split into two equal
halves: 15 sentences corrupted by MULT YPO and
15 by the naive baseline. Within each set, we bal-
anced the number of sentences across 3 corruption
levels (0.1, 0.4, and 0.7; five sentences per level),
while ensuring that sentence length distributions
remained comparable across the two conditions. At
least 15 participants in each language were asked to
judge whether the typos in each sentence appeared
natural or unnatural. This binary judgment pro-
vides a direct measure of how human-like the errors
appear. We collected annotations across seven lan-
guages: Arabic, German, Greek, English, French,
Hindi, and Russian (details provided in §B).

Table 2 summarizes the results across languages.
In six of the seven cases, MULT YPO is judged sig-
nificantly more natural than the random baseline in
the paired t-test (at least p < 0.05). Arabic is the
only exception, where ratings slightly favored the


Qwen Gemma

Belebele — 10% typo rate

Flores200

OLMo

— 10% typo rate Belebele

30 40 50 |yny

Figure 3: Performance under different typo rates (0, 0.1, 0.4, and, 0.7) averaged across languages for each task.

baseline, but without statistical significance. We
include it in our further experiments for complete-
ness, though results might need to be interpreted
with caution. Taken together, this human evaluation
confirms that MULTYPO can generally generate ty-
pos perceived as more human-like across languages
than a naive baseline process that does not consider
keyboard layout constraints. In §D, we also show
that models exhibit different robustness to our ty-
pos versus the naive ones: models are more robust
to typos generated by MULT YPO, possibly due to
the exposure of similar typos — real-world human
typos — in the pretraining phase.

4 Experimental Setup

This section outlines our evaluation setup, where
we apply MULT YPO to inject human-like typos into
diverse downstream tasks and assess the robustness
of different LLMs to these perturbations.

4.1 Languages

We consider 12 languages spanning 7 language
families and written in 7 different scripts, with a fo-
cus on alphabet-based writing systems where typos
are primarily influenced by keyboard layout. The
set of supported languages by MULT YPO includes
Arabic (ara_Arab), Armenian (hye_Armn),
Bengali (ben_Beng), English (eng_Latn),
French (fra_Latn), Georgian (Kat_Geor),
German (deu_Latn), Greek (ell_Grek), He-
brew (heb_Hebr), Hindi (hin_Deva), Russian
(rus_Cyrl), and Tamil (tam_Taml).

4.2 Models

We evaluate 18 decoder-only language models
from 3 model families: Gemma (Gemma Team
et al., 2025), Qwen (Yang et al., 2025), and
OLMo (Team OLMo et al., 2025). Models from
the first two families are pretrained on highly

multilingual corpora, while OLMo is pretrained
on English-centric data. For the Gemma fam-
ily, we consider gemma-3-1b-pt, gemma-3-4b-pt,
and gemma-3-12b-pt. For the Qwen family, we
consider Qwen3-1.7B-Base, Qwen3-4B-Base, and
Qwen3-8B-Base. Finally for the OLMo family,
we consider OLMo-2-@425-1B, OLMo-2-1124-7B,
and OLMo-2-1124-13B. For each model above, we
also consider its corresponding instruction-tuned
version, aiming to systematically investigate the
robustness against multilingual typos of models
across size, family, and training strategies.

4.3 Dataset

To evaluate robustness under multilingual ty-
pos, we use six datasets spanning four task
types: natural language inference (XNLI (Con-
neau et al., 2018)), multiple-choice questions an-
swering (Belebele (Bandarkar et al., 2024) and
MMMLU (Hendrycks et al., 2021)), mathematical
reasoning (MGSM (Shi et al., 2023b), along with
Arabic and Hindi adaptations of GSM8K (Cobbe
et al., 2021; Gumma et al., 2024; Omartificial-
Intelligence-Space, 2025)), and machine transla-
tion (FLORES200 (NLLB Team et al., 2022)).
These datasets are selected to cover diverse tasks
and our target languages. Note that the typos are
only injected into the dataset instances, but not
into other components of the prompt, such as task
instructions, to ensure that we are evaluating ro-
bustness to input corruption rather than altering the
task specification itself. Further details, including
language coverage of each dataset and used prompt
templates, are provided in §C.

5 Results and Discussion

In this section, we present the results of injecting
typos into different datasets. By default, we use 3-
shot prompting to ensure a reasonable performance


XNLI

Belebele

MMMLU

— Gemma (0%)
== Gemma (10%)
60 | —— Qwen (0%)

== Qwen (10%) =
— OLMo (0%)
501 —— OLMo (10%)

— Gemma (0%)
== Gemma (10%)
— Qwen (0%)
== Qwen (10%)
— OLMo (0%)
60 —— OLMo (10%)

Avg Score
Avg Score

30

551 —— Gemma (0%) 2
== Gemma (10%)
501 —— Qwen (0%)
== Qwen (10%)
— OLMo (0%)

small Medium Large small

Model Size

MGSM

Medium large Small

Medium Large
Model Size

Flores200

—— Gemma (0%)
60-1 —— Gemma (10%)
— Qwen (0%)
== Qwen (10%)
— 01Mo (0%) gor
== OLMo (10%)

Avg Score

30 | —— Gemma (0%)
== Gemma (10%)
— Qwen (0%)
== Qwen (10%)
— 0LMo (0%)
5 207 —= OLMo (10%)

ee

Small Medium Large

Model Size

Small Medium Large

Model Size

Figure 4: Impact of model size (Small, Medium, Large) on multilingual robustness across five tasks. A different
color represents each model family, and two lines are plotted per family: performance on clean input (0%) and input
with a 10% typo rate. Larger models generally perform better but also exhibit performance drops under noise.

(we further analyze the effect of example-count on
robustness in §6.1). In the following parts, we aim
to investigate three research questions: (1) Does
performance degrade when typographical errors
are introduced, and if so, how much? (§5.1); (2)
Do larger models present better robustness against
typographical errors compared to smaller ones?
(§5.2); and (3) Does instruction-tuning improve the
robustness of the models? (§5.3).

5.1 Performance Drop under Typos

Figure 3 presents the average performance of three
model families - Gemma, Qwen, and OLMo —
across five multilingual tasks, under varying levels
of typographical corruption (0%, 10%, 40%, 70%).
Results are aggregated over instruction-tuned mod-
els and all supported languages within each task.
Typos consistently degrade performance
across all models. Across all families and tasks,
even minor typographical noise largely impairs
model performance. For example, Qwen achieves
over 50 on Belebele in the clean setting, but drops
to around 45 with just a 10% typo rate. As noise
increases, performance declines continuously. This
pattern holds across families and tasks, underscor-
ing a general vulnerability to surface-level pertur-
bations. These findings echo prior monolingual
results (Moradi and Samwald, 2021; Wang et al.,
2025), and extend them to a multilingual setting.
Robustness varies substantially by task. Typo
sensitivity is not uniform across tasks. For in-
stance, XNLI exhibits good robustness: Qwen’s
performance remains nearly unchanged under 10%
noise. Even the OLMo models — despite being pri-

Family Small Medium Large
Gemma 21.46 (-9.9%) 48.50 (-5.7%) 59.11 (-3.7%)
OLMo 16.30 (-9.5%) 29.16 (-7.9%) 36.82 (-4.3%)
Qwen 27.86 (-5.7%) 44.50 (-8.2%) 47.19 (-5.7%)

Table 3: Each cell reports the average score of a model
family under a 10% typo rate, with the relative perfor-
mance drop from clean input shown in parentheses.

marily monolingual — sustain less than a 10-point
absolute drop at the highest noise level. In con-
trast, tasks involving generative reasoning (e.g.,
MGSM) are highly susceptible. Qwen’s accuracy
on MGSM plummets from around 40 (clean) to
around 27 (70% noise), suggesting that token-level
corruption disrupts multi-step reasoning more than
classification-based understanding. These results
support earlier, monolingual claims that noisy in-
puts affect complex reasoning (Gan et al., 2024).

Takeaway. While LLMs can often infer intended
meaning from noisy input in simpler classification
tasks (e.g., natural language inference), reasoning
tasks amplify the fragility introduced by typos.

5.2 Model Size Impact on Robustness

Figure 4 presents the average performance when
fed with clean inputs and with a small typo rate
(10%). We group the models in each model family
into different scales (Small, Medium, and Large).
Results are averaged across tasks and supported
languages, focusing on instruction-tuned models.
Larger models consistently outperform
smaller ones, with mild gains in robustness.
While larger models consistently outperform
smaller ones, also under typo noise, models of all


XNLI

Belebele

MMMLU

— 10%
— 40% 60

[= Base

— 10%
— 40%
— 70%
[= Base

— 10%
— 40%
— 10%
= Base

SF instrudt

Instruct =finstrect

Avg Score

Avg Score

Gemma Qwen OLMo Gemma

Qwen OLMo

Gemma Qwen OLMo

Flores200

— 10%
— 40%
— 70%
5) Base

=F Instruct

Avg Score

10

0

— 10%
— 40%
20 — 70%
[3 Base
Instruct

Avg Score

|

5

Gemma Qwen OLMo

Gemma Qwen OLMo

Figure 5: Impact of Instruction-tuning on multilingual robustness. Instruction-tuned models improve the perfor-
mance, but do not seem to improve the robustness against typos, especially with higher typo rates.

Gemma Family

Qwen Family

OLMo Family

39
33
36
30
x
fo)
a)
a
30 D24
<=
=e 0% Typos 21

—e 10% Typos ze
—e 40% Typos
2 70% Typos 15

Avg Score

N
ey

ci
Avg Score
Ss .8

N
R

N
x

oe
se} 2.

—e 0% Typos 16
—e 10% Typos
-e 40% Typos
—e- 70% Typos

© 0% Typos
© 10% Typos
© 40% Typos
© 70% Typos

oO 1 5

°

3 1
Shot Count

3
Shot Count

5 ) 1 5

3
Shot Count

Figure 6: Performance of different model families under different numbers of shots. Increasing the demonstrations
slightly improves the performance but does not improve the robustness against typos.

sizes suffer from input perturbations, as shown in
Figure 4. To further analyze the effect of model
scale on robustness, we compute the relative
degradation under a 10% typo rate (A,
As reported in Table 3, larger models show smaller
drops — particularly within the Gemma and OLMo
families. E.g., Gemma’s relative drop decreases
from 9.9% (Small) to 3.7% (Large), suggesting that

greater model capacity enables better robustness.

Takeaways. Scaling the model improves task per-
formance under typo noise, but larger models are
not immune to noise as well. However, larger mod-
els present improved robustness under typos.

5.3. Base vs. Instruction-Tuned Models

Figure 5 presents the performance of pretrained
based models and their instruction-tuned versions
under varying levels of typographical corruption
(0%, 10%, 40%, 70%). Results are averaged over
all supported languages within each task.
Instruction-tuned models outperform
base models but remain brittle under typos.
Instruction-tuning improves overall performance,
aligning with prior work (Liu et al., 2023; Chung
et al., 2024), which shows that instruction-tuning
enhances task-specific multi-step reasoning.

Despite clear performance benefits under clean
input, instruction-tuned models remain vulnerable
to typos. In many cases, the absolute degradation
under 10% or 40% noise is as severe as or
even worse than their base counterparts. For
instance, on MGSM, Gemma’s instruction-tuned
models drop from around 48 to 33 under 40%
corruption. Similar degradation is seen across
other families and tasks. This suggests that while
instruction-tuned models are better at following
complex prompts, they remain equally brittle under
surface-level input corruption.

Takeaways. Instruction-tuning boosts perfor-
mance but does not improve robustness. Current
tuning methods prioritize clean prompts and may
underprepare models for noisy real-world input.

6 Complementary Analysis

6.1 Does Example Counts Affect Robustness?

Few-shot prompting is known to enhance model
performance by providing clearer task formula-
tions and patterns (Brown et al., 2020; Schick and
Schiitze, 2022). This naturally raises the question:
Can increasing the number of examples also im-
prove robustness against typos? To explore this,
we vary the number of examples in the prompt — 0,


Gemma: Translation Robustness

BLEU Score

Direction / Typo Rate
From English
_E3 To English
—-— 10%
j=» 40%
|. wi 70% - |
< Kes RA »
& e o Ss
57
oe’ we’ & Se

Figure 7: Robustness of Gemma models on Flores200 under different levels of typographical noise. Translation
from English seems to be more robust compared to translation to English.

Family ara_Arab ben_Beng deu_Latn ell_Grek eng_Latn fra_Latn hin_Deva rus_Cyrl

51.3 47.3 53.0 55:3 56.4 53.6 45.6 573
Gemma 46.3 42.3 52.2 55.4 575 52.1 41.3 50.5
9.7% 10.6% 15%  -0.2% -2.0% 2.8% 9.4% 11.9%
47.2 38.3 52.9 47.6 62.3 54.8 41.0 55.0
Qwen 44.6 31.6 50.8 44.5 58.8 53.0 36.9 52.4
5.5% 17.5% 4.0% 6.5% 5.6% 3.3% 10.0% 4.7%
30.6 20.3 40.9 39.1 57.5 46.3 26.9 41.9
OLMo 28.5 19.1 38.3 Si 55.8 43.4 24.6 35.3
6.9% 5.9% 6.4% 5.1% 3.0% 6.3% 8.6% 15.8%

Table 4: Performance when fed with clean input (top
row) and with a 10% typo rate (bottom row), aggregated
across all tasks and datasets, by language. Only lan-
guages supported by at least 3 datasets are considered.

1, 3, and 5 — and evaluate instruction-tuned models
across different typo rates, tasks, and languages.
Figure 6 presents the aggregated results.

Across the multilingual models (Gemma and
Qwen), increasing the number of examples in few-
shot settings leads to consistent performance gains
until 3 shots. However, the robustness gap, i.e.,
the performance drop from clean to noisy inputs,
remains nearly unchanged regardless of shot count.
For the OLMo family, adding more examples does
not seem to help and occasionally harms perfor-
mance, likely due to its limited multilingual cov-
erage and confusion introduced by prompts in lan-
guages that OLMo does not support well. These
findings suggest that while demonstrations im-
prove overall performance, they do not inher-
ently enhance robustness against typos.

6.2. Which Language is More Sensitive?

We hypothesize that model robustness to typos is
not uniform across languages, particularly due to
data availability. To investigate this, we analyze
performance degradation across eight languages
that are each supported by at least three datasets.
Table 4 presents results aggregated over all tasks.
Additionally, we analyze Flores200 separately to
examine how translation direction interacts with
typo robustness. Specifically, we compare the per-
formance of Gemma models when translating from

English vs. into English, as shown in Figure 7.
Across all three model families, English consis-
tently exhibits the highest robustness — its relative
drop is among the lowest. Other languages that
use the Latin script, such as German and French,
also show relatively small degradations. In contrast,
languages with underrepresented scripts, including
Arabic, Hindi, and Bengali, tend to exhibit larger
drops. Interestingly, even Russian, despite being
high-resource, suffers from sharp degradation (e.g.,
11.9% for Gemma). This suggests that models
are more robust in languages with both high
data availability and orthographic familiarity
(e.g., Latin script). Furthermore, Figure 7 shows
that translations from English are more robust than
those into English, reinforcing the idea that ty-
pos in lower-resourced or structurally differ-
ent input languages more severely impair both
crosslingual understanding and generation.

7 Conclusion

We present a comprehensive study on the multi-
lingual robustness of LLMs under simulated, re-
alistic typographical errors. To this end, we intro-
duce MULT YPO, a multilingual typo generation
algorithm grounded in language-specific keyboard
layouts and human typing behavior. Through ex-
tensive evaluation of 18 models across five tasks
and three model families, we find that even mod-
est levels of noise can impair model performance
— particularly in reasoning-heavy tasks. While
larger models and instruction tuning improve per-
formance on clean inputs, they do not necessar-
ily confer greater robustness. Moreover, we iden-
tify language-specific sensitivity: models are more
resilient in high-resource, Latin-script languages.
These findings highlight critical blind spots in cur-
rent LLM evaluation and motivate future work on
noise-aware multilingual pretraining, evaluation,
and human-centric error modeling.


Limitations

While our work provides a first step toward mul-
tilingual robustness evaluation under human-like
typographical errors, we acknowledge that several
limitations remain.

First, MULTYPO currently supports a diverse but
limited set of typologically diverse languages. To
incorporate a new language, one needs to manu-
ally specify the corresponding keyboard layout and
typing conventions.

Second, our algorithm does not yet support lo-
gographic or syllabic writing systems, such as Chi-
nese. This limitation stems from the fundamen-
tal differences in input methods — e.g., Chinese
characters are typically typed via phonetic systems
like Pinyin rather than direct keypresses. Model-
ing such input pipelines requires a fundamentally
different corruption strategy. Future work could ex-
tend MULT YPO to accommodate these languages
by simulating common typing errors in the inter-
mediate input stages (e.g., Pinyin mistyping or can-
didate misselection).

Third, our human evaluation provides important
validation of the realism of MULT YPO, covering
multiple languages. However, results for Arabic
did not show significant improvements over the
naive baseline, suggesting that our typo simulation
algorithm MULTYPO may not capture all language-
specific properties equally well. However, this does
not overshadow the findings that LLMs are not
robust to multilingual textual perturbations.

Finally, we focus exclusively on physical key-
boards (e.g., QWERTY), while ignoring other in-
put modalities such as touchscreen keyboards on
mobile devices. Typing behaviors, error distribu-
tions, and auto-correct interference vary substan-
tially across modalities (Jokinen et al., 2021; Shi
et al., 2025). Evaluating robustness under such
device-dependent noise would further enrich our
understanding of LLM performance in real-world
settings, which we leave for future work.

Acknowledgments

This research was supported by the Munich Center
for Machine Learning (MCML) and German Re-
search Foundation (DFG, grant SCHU 2246/14-1).

Ethical Considerations

Data Annotation Before conducting the human
evaluation, all participants were clearly informed
about the purpose, procedure, and voluntary nature

of the study, and provided their informed consent.
For most languages, annotators were recruited via
Prolific and compensated fairly at a rate equivalent
to approximately £6 per hour (about £1 per com-
pleted annotation set) (details are provided in §B).
A small portion of participants (around 10%) were
personal contacts who volunteered without com-
pensation. No personally identifiable information
was collected, and all demographic data (e.g., age,
gender) was provided optionally.

Use of AI Assistants The authors acknowledge
the use of ChatGPT exclusively for grammar cor-
rection, improving the clarity and coherence of the
draft, and assisting with code implementation.»

References

Zain Ul Abedin, Shahzeb Qamar, Lucie Flek, and Akbar
Karimi. 2025. Arithmattack: Evaluating robustness
of Ilms to noisy context in math problem solving.
Preprint, arXiv:2501.08203.

Amirhossein Aliakbarzadeh, Lucie Flek, and Akbar
Karimi. 2025. Exploring robustness of multilin-
gual Ilms on real-world noisy data. Preprint,
arXiv:2501.08322.

Yukino Baba and Hisami Suzuki. 2012. How are
spelling errors generated and corrected? a study
of corrected and uncorrected spelling errors using
keystroke logs. In Proceedings of the 50th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 2: Short Papers), pages 373-377,
Jeju Island, Korea. Association for Computational
Linguistics.

Lucas Bandarkar, Davis Liang, Benjamin Muller, Mikel
Artetxe, Satya Narayan Shukla, Donald Husa, Naman
Goyal, Abhinandan Krishnan, Luke Zettlemoyer, and
Madian Khabsa. 2024. The belebele benchmark: a
parallel reading comprehension dataset in 122 lan-
guage variants. In Proceedings of the 62nd Annual
Meeting of the Association for Computational Lin-
guistics (Volume I: Long Papers), pages 749-775,
Bangkok, Thailand. Association for Computational
Linguistics.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
Clemens Winter, and 12 others. 2020. Language
models are few-shot learners. In Advances in Neural
Information Processing Systems 33: Annual Confer-
ence on Neural Information Processing Systems 2020,
NeurIPS 2020, December 6-12, 2020, virtual.

Shttps://chatgpt.com/


Hyung Won Chung, Le Hou, Shayne Longpre, Barret
Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi
Wang, Mostafa Dehghani, Siddhartha Brahma, Albert
Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac
Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex
Castro-Ros, Marie Pellat, Kevin Robinson, and 16
others. 2024. Scaling instruction-finetuned language
models. J. Mach. Learn. Res., 25:70:1—70:53.

Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,
Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias
Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
Nakano, Christopher Hesse, and John Schulman.
2021. Training Verifiers to Solve Math Word Prob-
lems. CoRR, abs/2110.14168.

Rianne Conijn, Menno Van Zaanen, Mariélle Leijten,
and Luuk Van Waes. 2019. How to typo? building a
process-based model of typographic error revisions.
Journal of Writing Analytics, 3:69-95.

Alexis Conneau, Kartikay Khandelwal, Naman Goyal,
Vishrav Chaudhary, Guillaume Wenzek, Francisco
Guzman, Edouard Grave, Myle Ott, Luke Zettle-
moyer, and Veselin Stoyanov. 2020. Unsupervised
cross-lingual representation learning at scale. In Pro-
ceedings of the 58th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 8440-—
8451, Online. Association for Computational Lin-
guistics.

Alexis Conneau, Ruty Rinott, Guillaume Lample, Adina
Williams, Samuel Bowman, Holger Schwenk, and
Veselin Stoyanov. 2018. XNLI: Evaluating cross-
lingual sentence representations. In Proceedings of
the 2018 Conference on Empirical Methods in Nat-
ural Language Processing, pages 2475-2485, Brus-
sels, Belgium. Association for Computational Lin-
guistics.

Asa Cooper Stickland, Sailik Sengupta, Jason Krone,
Saab Mansour, and He He. 2023. Robustification of
multilingual language models to real-world noise in
crosslingual zero-shot settings with robust contrastive
pretraining. In Proceedings of the 17th Conference
of the European Chapter of the Association for Com-
putational Linguistics, pages 1375-1391, Dubrovnik,
Croatia. Association for Computational Linguistics.

Sumit Kumar Dam, Choong Seon Hong, Yu Qiao, and
Chaoning Zhang. 2024. A complete survey on Ilm-
based ai chatbots. Preprint, arXiv:2406.16937.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. BERT: Pre-training of
deep bidirectional transformers for language under-
standing. In Proceedings of the 2019 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Volume I (Long and Short Papers), pages
4171-4186, Minneapolis, Minnesota. Association for
Computational Linguistics.

Esther Gan, Yiran Zhao, Liying Cheng, Mao Yancan,
Anirudh Goyal, Kenji Kawaguchi, Min-Yen Kan, and

Michael Shieh. 2024. Reasoning robustness of LLMs
to adversarial typographical errors. In Proceedings
of the 2024 Conference on Empirical Methods in
Natural Language Processing, pages 10449-10459,
Miami, Florida, USA. Association for Computational
Linguistics.

Ji Gao, Jack Lanchantin, Mary Lou Soffa, and Yan-
jun Qi. 2018. Black-Box Generation of Adversarial
Text Sequences to Evade Deep Learning Classifiers.
In 2018 IEEE Security and Privacy Workshops, SP
Workshops 2018, San Francisco, CA, USA, May 24,
2018, pages 50-56. IEEE Computer Society.

Sylvia A. Gardner. 1992. Spelling Errors in On-
line Databases: What the Technical Communicator
Should Know. Technical Communication, 39(1):50—
53.

Siddhant Garg and Goutham Ramakrishnan. 2020.
BAE: BERT-based adversarial examples for text clas-
sification. In Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 6174-6181, Online. Association for
Computational Linguistics.

Gemma Team, Aishwarya Kamath, Johan Ferret, Shreya
Pathak, Nino Vieillard, Ramona Merhej, Sarah Per-
rin, Tatiana Matejovicova, Alexandre Ramé, Mor-
gane Riviére, Louis Rouillard, Thomas Mesnard, Ge-
offrey Cideron, Jean bastien Grill, Sabela Ramos,
Edouard Yvinec, Michelle Casbon, Etienne Pot, Ivo
Penchev, and 25 others. 2025. Gemma 3 technical
report. Preprint, arXiv:2503.19786.

Varun Gumma, Pranjal A. Chitale, and Kalika Bali.
2024. Towards Inducing Document-Level Abilities
in Standard Multilingual Neural Machine Translation
Models. Preprint, arXiv:2408.11382.

Michael A. Hedderich, Jonas Fischer, Dietrich Klakow,
and Jilles Vreeken. 2022. Label-descriptive patterns
and their application to characterizing classification
errors. In International Conference on Machine
Learning, ICML 2022, 17-23 July 2022, Baltimore,
Maryland, USA, volume 162 of Proceedings of Ma-
chine Learning Research, pages 8691-8707. PMLR.

Dan Hendrycks, Collin Burns, Steven Basart, Andy
Zou, Mantas Mazeika, Dawn Song, and Jacob Stein-
hardt. 2021. Measuring massive multitask language
understanding. In 9th International Conference on
Learning Representations, ICLR 2021, Virtual Event,
Austria, May 3-7, 2021. OpenReview.net.

Di Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter
Szolovits. 2020. Is BERT really robust? A strong
baseline for natural language attack on text classifi-
cation and entailment. In The Thirty-Fourth AAAI
Conference on Artificial Intelligence, AAAI 2020, The
Thirty-Second Innovative Applications of Artificial
Intelligence Conference, IAAI 2020, The Tenth AAAI
Symposium on Educational Advances in Artificial In-
telligence, EAAI 2020, New York, NY, USA, February
7-12, 2020, pages 8018-8025. AAAI Press.


Jussi Jokinen, Aditya Acharya, Mohammad Uzair, Xin-
hui Jiang, and Antti Oulasvirta. 2021. Touchscreen
typing as optimal supervisory control. In CHT ’2/:
CHI Conference on Human Factors in Computing
Systems, Virtual Event / Yokohama, Japan, May 8-13,
2021, pages 720:1—720:14. ACM.

Karen Kukich. 1992. Techniques for automatically
correcting words in text. ACM computing surveys
(CSUR), 24(4):377-439.

Tamera Lanham, Anna Chen, Ansh Radhakrishnan,
Benoit Steiner, Carson Denison, Danny Hernandez,
Dustin Li, Esin Durmus, Evan Hubinger, Jackson
Kernion, Kamilé LukoSiité, Karina Nguyen, Newton
Cheng, Nicholas Joseph, Nicholas Schiefer, Oliver
Rausch, Robin Larson, Sam McCandlish, Sandi-
pan Kundu, and 11 others. 2023. Measuring faith-
fulness in chain-of-thought reasoning. Preprint,
arXiv:2307.13702.

Jinfeng Li, Shouling Ji, Tianyu Du, Bo Li, and Ting
Wang. 2019. Textbugger: Generating adversarial
text against real-world applications. In 26th Annual
Network and Distributed System Security Symposium,
NDSS 2019, San Diego, California, USA, February
24-27, 2019. The Internet Society.

Bertrand Lisbach and Victoria Meyer. 2013. Linguistic
Identity Matching. Springer.

Hanmeng Liu, Zhiyang Teng, Leyang Cui, Chaoli
Zhang, Qiji Zhou, and Yue Zhang. 2023. LogiCoT:
Logical chain-of-thought instruction tuning. In Find-
ings of the Association for Computational Linguis-
tics: EMNLP 2023, pages 2908-2921, Singapore.
Association for Computational Linguistics.

Gordon D Logan, Jana E Ulrich, and Dakota RB Lind-
sey. 2016. Different (key) strokes for different
folks: How standard and nonstandard typists balance
fitts’ law and hick’s law. Journal of Experimental
Psychology: Human Perception and Performance,
42(12):2084.

Peter F MacNeilage. 1964. Typing errors as clues to
serial ordering mechanisms in language behaviour.
Language and speech, 7(3):144-159.

Milad Moradi and Matthias Samwald. 2021. Evaluating
the robustness of neural language models to input
perturbations. In Proceedings of the 2021 Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 1558-1570, Online and Punta Cana,
Dominican Republic. Association for Computational
Linguistics.

Humza Naveed, Asad Ullah Khan, Shi Qiu, Muhammad
Saqib, Saeed Anwar, Muhammad Usman, Naveed
Akhtar, Nick Barnes, and Ajmal Mian. 2024. A
comprehensive overview of large language models.
Preprint, arXiv:2307.06435.

NLLB Team, Marta R. Costa-jussa, James Cross, Onur
Celebi, Maha Elbayad, Kenneth Heafield, Kevin Hef-
fernan, Elahe Kalbassi, Janice Lam, Daniel Licht,

Jean Maillard, Anna Sun, Skyler Wang, Guillaume
Wenzek, Al Youngblood, Bapi Akula, Loic Barrault,
Gabriel Mejia Gonzalez, Prangthip Hansanti, and
20 others. 2022. No language left behind: Scal-
ing human-centered machine translation. Preprint,
arXiv:2207.04672.

Omartificial-Intelligence-Space. 2025. Ara-
bic GSM8K: Arabic Grade School Math
Dataset. https: //huggingface.co/datasets/
Omartificial-Intelligence-Space/
Arabic-gsm8k.

James L Peterson. 1986. A note on undetected typing
errors. Communications of the ACM, 29(7):633-637.

Danish Pruthi, Bhuwan Dhingra, and Zachary C. Lip-
ton. 2019. Combating adversarial misspellings with
robust word recognition. In Proceedings of the 57th
Annual Meeting of the Association for Computational
Linguistics, pages 5582-5591, Florence, Italy. Asso-
ciation for Computational Linguistics.

Mubashar Raza, Zarmina Jahangir, Muhammad Bi-
lal Riaz, Muhammad Jasim Saeed, and Muham-
mad Awais Sattar. 2025. Industrial applications
of large language models. Scientific Reports,
15(1):13755.

Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin,
and Sameer Singh. 2020. Beyond accuracy: Be-
havioral testing of NLP models with CheckList. In
Proceedings of the 58th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 4902-
4912, Online. Association for Computational Lin-
guistics.

Timo Schick and Hinrich Schiitze. 2022. True few-shot
learning with Prompts—A real-world perspective.
Transactions of the Association for Computational
Linguistics, 10:716-731.

Danqing Shi, Yujun Zhu, Francisco Erivaldo Fernan-
des Junior, Shumin Zhai, and Antti Oulasvirta. 2025.
Simulating errors in touchscreen typing. In Proceed-
ings of the 2025 CHI Conference on Human Factors
in Computing Systems, CHI 2025, YokohamaJapan,
26 April 2025- 1 May 2025, pages 1086:1—1086:13.
ACM.

Freda Shi, Xinyun Chen, Kanishka Misra, Nathan
Scales, David Dohan, Ed H. Chi, Nathanael Scharli,
and Denny Zhou. 2023a. Large language models can
be easily distracted by irrelevant context. In Interna-
tional Conference on Machine Learning, ICML 2023,
23-29 July 2023, Honolulu, Hawaii, USA, volume
202 of Proceedings of Machine Learning Research,
pages 31210-31227. PMLR.

Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang,
Suraj Srivats, Soroush Vosoughi, Hyung Won Chung,
Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das,
and Jason Wei. 2023b. Language models are multi-
lingual chain-of-thought reasoners. In The Eleventh
International Conference on Learning Representa-
tions, ICLR 2023, Kigali, Rwanda, May 1-5, 2023.
OpenReview.net.


Lichao Sun, Kazuma Hashimoto, Wenpeng Yin, Akari
Asai, Jia Li, Philip Yu, and Caiming Xiong. 2020.
Ady-bert: Bert is not robust on misspellings! gener-
ating nature adversarial samples on bert. Preprint,
arXiv:2003.04985.

Team OLMo, Pete Walsh, Luca Soldaini, Dirk Groen-
eveld, Kyle Lo, Shane Arora, Akshita Bhagia, Yuling
Gu, Shengyi Huang, Matt Jordan, Nathan Lambert,
Dustin Schwenk, Oyvind Tafjord, Taira Anderson,
David Atkinson, Faeze Brahman, Christopher Clark,
Pradeep Dasigi, Nouha Dziri, and 21 others. 2025. 2
olmo 2 furious. Preprint, arXiv:2501.00656.

Bin Wang, Chengwei Wei, Zhengyuan Liu, Geyu Lin,
and Nancy F. Chen. 2024. Resilience of large lan-
guage models for noisy instructions. In Findings
of the Association for Computational Linguistics:
EMNLP 2024, pages 11939-11950, Miami, Florida,
USA. Association for Computational Linguistics.

Haoyu Wang, Guozheng Ma, Cong Yu, Ning Gui, Linrui
Zhang, Zhiqi Huang, Suwei Ma, Yongzhe Chang,
Sen Zhang, Li Shen, Xueqian Wang, Peilin Zhao,
and Dacheng Tao. 2025. Are large language models
really robust to word-level perturbations? Trans.
Mach. Learn. Res., 2025.

Jindong Wang, Xixu Hu, Wenxin Hou, Hao Chen,
Runkai Zheng, Yidong Wang, Linyi Yang, Haojun
Huang, Wei Ye, Xiubo Geng, Binxin Jiao, Yue Zhang,
and Xing Xie. 2023. On the robustness of chatgpt:
An adversarial and out-of-distribution perspective.
Preprint, arXiv:2302.12095.

Asa Wengelin. 2007. The word-level focus in text pro-
duction by adults with reading and writing difficulties.
In Writing and cognition, pages 67-82. Brill.

Xilie Xu, Keyi Kong, Ning Liu, Lizhen Cui, Di Wang,
Jingfeng Zhang, and Mohan S. Kankanhalli. 2024.
An LLM can fool itself: A prompt-based adversar-
ial attack. In The Twelfth International Conference
on Learning Representations, ICLR 2024, Vienna,
Austria, May 7-11, 2024. OpenReview.net.

An Yang, Anfeng Li, Baosong Yang, Beichen Zhang,
Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao,
Chengen Huang, Chenxu Lv, Chujie Zheng, Day-
iheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao
Ge, Haoran Wei, Huan Lin, Jialong Tang, and 41
others. 2025. Qwen3 technical report. Preprint,
arXiv:2505.09388.

Kun Zhang, Le Wu, Kui Yu, Guangyi Lv, and Dacao
Zhang. 2025. Evaluating and improving robustness
in large language models: A survey and future direc-
tions. Preprint, arXiv:2506.11111.

Yunxiang Zhang, Liangming Pan, Samson Tan, and Min-
Yen Kan. 2022. Interpreting the robustness of neural
NLP models to textual perturbations. In Findings of
the Association for Computational Linguistics: ACL
2022, pages 3993-4007, Dublin, Ireland. Association
for Computational Linguistics.

Raoyuan Zhao, Abdullatif Koksal, Yihong Liu, Leonie
Weissweiler, Anna Korhonen, and Hinrich Schuetze.
2024. SynthEval: Hybrid behavioral testing of NLP
models with synthetic CheckLists. In Findings of the
Association for Computational Linguistics: EMNLP
2024, pages 7017-7034, Miami, Florida, USA. Asso-
ciation for Computational Linguistics.

Zihao Zhou, Qiufeng Wang, Mingyu Jin, Jie Yao, Jianan
Ye, Wei Liu, Wei Wang, Xiaowei Huang, and Kaizhu
Huang. 2024. Mathattack: Attacking large language
models towards math solving ability. In Thirty-
Eighth AAAI Conference on Artificial Intelligence,
AAAI 2024, Thirty-Sixth Conference on Innovative
Applications of Artificial Intelligence, IAAI 2024,
Fourteenth Symposium on Educational Advances
in Artificial Intelligence, EAAI 2014, February 20-
27, 2024, Vancouver, Canada, pages 19750-19758.
AAAT Press.

Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang,
Hao Chen, Yidong Wang, Linyi Yang, Wei Ye, Yue
Zhang, Neil Gong, and Xing Xie. 2024. Promptro-
bust: Towards evaluating the robustness of large
language models on adversarial prompts. In Pro-
ceedings of the Ist ACM Workshop on Large AI Sys-
tems and Models with Privacy and Safety Analysis,
LAMPS 2024, Salt Lake City, UT, USA, October 14-
18, 2024, pages 57-68. ACM.

A Additional Details of MULTYPO

Neighbors of Keys In our work, we define a char-
acter’s neighbors (which are used in typo operation
replace and insert) as the keys that are immediately
adjacent to it on the same row of the keyboard —
specifically, the key to its left and the key to its
right, based on the empirical findings that horizon-
tal neighbor errors are more common (MacNeilage,
1964).° Keys corresponding to non-alphabetic sym-
bols or function keys (such as Enter or Tab) are not
considered, and characters that are absent from the
specified keyboard layout simply have no neigh-
bors. This definition provides a consistent notion of
adjacency across languages and platforms, avoid-
ing complications introduced by layout-specific
variations in the placement of special characters
(e.g., brackets on Windows vs. macOS).

Ignoring String Sets As described in §3.1, we
exclude several words from being selected as the
candidates to insert typos. These words are mainly
commonly used numerical expressions across lan-
guages. We exclude them since they are typically

®To reflect the real typing behavior of users of differ-
ent languages, we leverage a keyboard layout database from
https: //kbdlayout.info/, which uses data sourced from
Windows version 10.0.27729.1000


‘zero’, ‘one’, ‘two’, ‘three’, four’,

‘five’, 'six’, ‘seven’, ‘eight, ‘nine’ Wy) on aah ale Heuer ay Je uCU ‘
Her clever ict iirteen Ae, GT, “AIST, (CTs, Veta Ste ae rete
English: ‘fifteen’, ‘twenty’, ‘thirty’, ‘forty’, cup ‘Sir, ‘SPT ‘err, A Baca unin, ETEB, wu fun, .
. ‘ify, hundred’, thousand’ foes’, “TAT, “Amore, rmentian: FEE LTD latte TUL
‘simone, ‘STSTS', TG", "TS", hunt’, ‘Upipwinn’, "ényne’, Uby',
‘eH, WoH', DEES, ‘AT, ‘inp’, ‘hhuq’,
Ae ee, Ee oe 42", '3', "4, 59, °6', "75 8 '91, "0"
Bengali: ‘aon, "RAIA, ‘OR, COA,
German: ‘zwanzig’, 'sechzig’, 'siebzig', Se ht, gh te, NG fa! Arabic:
‘hundert’, 'tausend', ‘million’, Ty ot ete recipes .
aa 'e!, ‘a’, 10's #lang-intem
oon ae ee ee numbers onlyif theyare on
Hb 2S AN'5, G77, 85. 0 enptern
Be AN a bd Ge a on a
‘ago’, 'go', ‘oghsdgh0',
Tngdgh@qd0', '8380", Ago~@o',
E h ‘onze’, 'douze’, 'treize', ‘quatorze', gogo emong a ;
rench: ‘quinze’, ‘seize’, 'vingt’, 'trente’, Saas {G64s', 'sbo, '‘nobo', ‘neorbIgH0'
feteren ‘ey eohentel cont Georgian: ee
‘mille’, ‘million’, ‘milliard’ 1G50960,, 'wbyHIAH0', ByIWO',
1172131, 4546, 7.8, 9). 0°
‘ed, ‘ewéa, ‘déKa’, 'undév',
‘éva’, ‘tptavta’, ‘tpia’, 'sikoot’,
‘eKard’, 'é6, ‘nevtivta’, ‘6U0', “oe nom inn yen “ent
‘mévte', 'oKtw', '‘EvteKa’, ‘oySovta’, . ;
Greek: ‘téagepa’, ‘dwWOEKa’, ‘sveviivta’, Hebrew:
‘enrd’, ‘eBdoprivta’, ‘oapavta’,
‘evra’, ‘xiAta’, ‘ekatoppUpio’,
‘StoekatoppUpio’, a
Hy2i) aia’, 5116),'7),78', 9,0" Hindi:
Beau amg oc:
‘wecTHaguate’, ‘ABecTu', . HMM, ‘asin:
‘uereipe', ‘copox’, 'ea', ‘Tou, ae SIEUTLIBY, “J, “BIDUY,
‘wecre’, ‘ceme’, 'munnnapa’, Tamil: ee Bo SPE ci,
Russian: ‘neces’, ‘neBaTHaguaTe’, amit. or retry 5.
‘yeTbIPHaguaTb’, 'CTO', ‘AeBATb', ‘Use ooihs, a is),
‘qpeHaquate’, 'OAUH', ‘Us |co_G, ‘Lyesluud', ‘LOLs,
‘nATHaguaTe’, ThICAa’, ‘NATE, SUE Lpemee, oe fe
'mMunnvoH', 'ceMHaguate', ‘DeocOwiesr

41, '2', '3','4','5', '6,'7', 8", '9', 10"

Ber ac § 4 ‘S, 6, 7, 8, 9, 0

Figure 8: Ignoring String Sets across all languages that are considered in MULT YPO.

critical for downstream understanding. The set for
each language is visualized in Figure 8.

Sampling In MULTYPO, there are three places
where we introduce randomness by sampling: word
sampling, position sampling, and typo operation
sampling. We introduce the details of each sam-
pling process in the following.

¢ Word Sampling: We assign each word a sam-
pling probability proportional to the square
root of its length: J|wl . We then normalize
the probability by dividing the sum over all
words: >>, J|wl . This probability reflects
the empirically observed tendency for longer
words to attract more typos.

* Position Sampling: When selecting a spe-
cific character position within a word to insert
or modify a character, we consider position-
dependent weights: the first character is as-
signed a weight of 0 and is never selected; the
second character receives a weight of 0.1; the
final character receives 0.2; and all intermedi-
ate positions are linearly interpolated between
these values. This empirical setup is based on
findings from Lisbach and Meyer (2013) that
word-initial errors are rare. The probability of
each position is then its normalized weight.

* Typo Operation Sampling: Insertion op-
erations are sampled with a probability of

15.25%, while replacement, deletion, and
transposition are each assigned a probability
of 28.25%. This skewed distribution reflects
empirical observations that insertion errors
are less common than the other three error
types according to the findings from Baba and
Suzuki (2012).

Validating Operation In our implementation, in-
stead of sampling all candidate words at once, we
iteratively select a word at a time and insert a typo
into it, guaranteeing an adequate number of ty-
pos according to the user specification (typo rate).
Therefore, when inserting a typo into a word, we
perform a validity check before applying each op-
eration. Because errors are introduced iteratively,
unconstrained edits could yield implausible out-
comes — for example, replacing the initial w in
word with e to obtain eord, and then replacing e
back with w, which would be counted as two errors
despite leaving the word unchanged. The validity
check prevents such contradictions and filters out
unlikely multi-step substitutions, ensuring that the
final set of typos is consistent with natural typing
patterns.

Special Cases and Strategies We handle several
edge cases to keep the typographical errors mean-
ingful and realistic:

¢ If the selected word is only one character
long, or if it contains an item of the prede-


fined Ignoring String Sets, another word will
be selected.

¢ If the transpose operation is selected and the
word is not the final word in the sentence, a
whitespace character is appended to the end
of the word. This is done to facilitate the de-
tection of cross-hand key pairs, as previously
described, unless the whitespace has already
been appended in an earlier iteration.

¢ If the typo operation is deemed invalid or if
the modified word is identical to the original
(indicating no actual change occurred), an-
other typo function is selected for the same
word.

B Details of Human Evaluation

Overview We designed a lightweight web inter-
face to collect judgments of typo naturalness. Par-
ticipants first selected their evaluation language
(English, German, French, Greek, Russian, Ara-
bic, Hindi), filled in basic demographic informa-
tion (age, gender, nationality, fluency in the se-
lected language),’ , as shown in Figure 9 and then
completed 30 annotation trials. Each trial displayed
a single corrupted sentence from Flores200 (NLLB
Team et al., 2022), and participants judged whether
the typos appeared natural or unnatural, as shown
in Figure 10. At the end of the evaluation, the par-
ticipant needed to provide a confidence rating (1-5)
(the higher, the more confident).

Task Setup. In total, 30 sentences were sampled
from Flores200, with 15 corrupted by MULT YPO
and 15 by the random baseline (5 sentences at 10%,
40%, and 70% typo rates for each system). Sen-
tences were balanced for length across the two con-
ditions. The order of the sentences is randomized
for each participant to avoid a systematic learning
effect while going through the sentences. Partici-
pants completed the annotation in ~5-8 minutes.
Participants were recruited through personal con-
tacts (~10%, mainly for English and German), ex-
tended through recruitment on Prolific. We com-
pensated crowdworkers at a rate equivalent to about
£6 per hour, which corresponds to roughly £1 per
annotation set (30 sentences).

THowever, providing this information is completely volun-
tary. We did not store any personally identifiable information
except for fluency (for ensuring the quality).

Shttps ://www.prolific.com/

Multilingual Typo Evaluation

This annotation task will show you texts containing typographical errors (typos). Each text may contain multiple
typos. Your job is to decide whether the typos look natural or unnatural overall for each text, based on your own
judgment.

By natural, we mean typos that resemble mistakes people might realistically make when typing on a physical
keyboard in that language (e.g. errors influenced by the keyboard layout or adjacent keys). In contrast, some
typos may look unlikely or artificial.

There are in total 30 texts, and the time estimate will be around 5-8 minutes.

Select Language:

Before we start

Please provide a bit of background information. Providing this information is completely voluntary. We will
not store any personally identifiable information (such as IP addresses or e-mail) along with your
submission.

Age group: | — Select — v)

Gender: |-- Select -- v

Nationality: [Enter your nationality | C Prefer not to say

Fluency in selected language:(~Selec’- 4

| Begin Task

Figure 9: Screenshot of the annotation interface.

Progress: 1/30

Etant donné que les plumes de dinosaure n'ont pas une tife entigremen tdéveloppée, que
l'on appelle rachis, mzis montrent cependant d'aures caractéristiuges propres aux plumes —
barbes et barbulers — lesq chercheurs en ont déduit que | erachis était probablement un
développement évolutif ultérieur 4 ces autres caraxtéristiques.

| Looks Natural Looks Unnatural

| Back

| Submit All

Figure 10: Example of annotating one sentence.

Participants. We collected at least 15 valid re-
sponses per language.” Table 5 summarizes the
fluency levels and self-reported confidence across
languages. Table 6 and Table 7 summarize the dis-
tribution of age and gender, respectively. Overall,
the pool covered a balanced mix of native, near-
native, and non-native speakers, with most partici-
pants being native or near-native and reporting high
confidence (4-5).

Findings. Extending on the results reported in
§3.2, we also observe a clear effect of corruption
level (cf. Figure 11): across all languages, higher
typo rates lead to substantially lower “naturalness”
judgments, aligning with the intuition that dense er-
ror patterns are less plausible as real-world human
mistakes. Importantly, we observe that even under
severe corruption (i.e., 40% and 70%), MULTYPO
maintains a naturalness advantage over the naive
baseline, highlighting that modeling human-typing
behavior provides a better simulation of real-world
typos.

°For each language, we enabled Prolific’s auto-filtering fea-
ture, which excluded responses completed in under 3 minutes
as likely invalid.


Human Judgments for Arabic

Human Judgments for German

100 100
—®- Multypo —® Multypo
—® Naive —® Naive
] 804 w 804
c c
me | fe j
r=] r=]
oO ©
= 604 = 604
w wu
o o
a a
Y 404 Y 404
ne} me}
Re a
S204 x 204
o+— : : ot, : :
10% 40% 70% 10% 40% 70%
Typo Rate Typo Rate
ii Human Judgments for Greek 7 Human Judgments for English
1 1
—®- Multypo —® Multypo
—® Naive —® Naive
% 807 % 8074
£ £
_ =
vw wv
o oO
= 604 = 604
Ww w
o oO
o a
Y 404 Y 404
To me}
= —
Ss 204 x 204
o+— ‘ ; ot, + ;
10% 40% 70% 10% 40% 70%
Typo Rate Typo Rate
0 Human Judgments for French oo Human Judgments for Hindi
1 1
—®- Multypo —@®- Multypo
—® Naive —® Naive
% 807 % 804
£ £
r= | aS
r=] r=]
o ©
= 604 = 604
w w
o oO
a a
Y 404 Y 404
me} me}
- —
S 204 xe 204
o+— ; ; ot, + +
10% 40% 70% 10% 40% 70%
Typo Rate Typo Rate
00 Human Judgments for Russian
1
—@® Multypo
—® Naive
% 8074
ps
=
Fa
©
Z 604
u
oO
a
Y 404
Ee |
=
x 204

10%

40%
Typo Rate

70%

Figure 11: Human evaluation results grouped by the three considered typo rates (10%, 40%, 70%) across seven
languages. Across all languages, higher typo rates reduce perceived naturalness, yet MULT YPO consistently yields
more human-like typos than the naive baseline, even under higher corruption rates.


Language Native Near-native Non-native Avg. Confidence (1-5)
Arabic 7 4 4 4.1
German 6 6 3 4.0
Greek 8 3 4 3.8
English 10 13 5 3.9
French 7 4 4 39
Hindi 8 8 4 4.0
Russian 7 4 4 4.0

Table 5: Participant language fluency by language: num-
ber of native/near-native (very fluent)/non-native (basic)
speakers and average self-reported confidence.

Language 18-24 25-34 35-44 45-54 55+ Prefer not
Arabic 5 6 3 1
German
Greek
English
French
Hindi
Russian

1
1
3

Ll nreon !l

2 =e

KF WnAaA Ke
NODO He
an tvd NW
NP wWwWNdhH 1] Ww

Table 6: Annotator age distribution across languages.
Dashes indicate that no participant reported the corre-
sponding category.

C_ Details of Downstream Tasks

C.1_ Dataset Statistics

Language Coverage MULTYPO supports 12 lan-
guages at the current stage. Each downstream task
covers a slightly different set of languages, and
therefore, we only evaluate on languages that are
supported by MULT YPO for each dataset. Table 8
presents the languages supported in each dataset.

Instance Selection To ensure a fair and balanced
evaluation, we cap each dataset at a maximum of
1,000 instances across languages where possible.
Belebele contains roughly 900 instances by design
and requires no further reduction. For Flores200,
we selected 500 instances per translating direction
(translating into and from English), yielding 1,000
prompts in total. MGSM and its Arabic and Hindi
adaptations are limited to 250 examples each to
maintain consistency. For XNLI and MMMLU,
we subsample 1,000 instances while preserving
original label (XNLD and subject-area (MMMLU)
distributions. The sampling is consistently applied
in each parallel dataset to ensure comparability
across languages.

C.2. Prompt Templates

For each dataset, prompts are constructed in a stan-
dardized format to ensure consistency across exper-
iments. If typographical errors are injected, only
the instances of the dataset, denoted in curly brack-
ets {} ({language} in Flores200 is an exception),
are affected. All other components of the prompt re-

Language Male Female Prefer not Unspecified
Arabic 6 9 - -
German 4 5 6 —
Greek 8 6 1 —
English 9 13 6 =
French 8 5 - 2
Hindi 7 8 - =
Russian 6 8 - 1

Table 7: Annotator gender distribution across languages.
“Unspecified” refers to missing or null responses.

main unchanged. The prompt templates are shown
as follows.

Classify the relationship between the premise and hypothe-
sis as (O) Entailment, (1) Neutral, or (2) Contradiction.
Premise: {premise}

Hypothesis: {hypothesis}

Label:

Given the following passage, query, and answer choices,
output the letter of the correct answer.
HHH

Passage:

{flores_passage}

HHH

Query:

{question}

HHH

Choices:

(A) {mc_answer1 }

(B) {mc_answer2}

(C) {mc_answer3}

(D) {mc_answer4}

HHH

Answer:

The following are multiple choice questions (with answers)
about {Subject}.

{Question}

(A) {A} (B) {B} (C) {C} (D) {D}

Answer:

Question: {question} Let’s think step by step.
Step-by-Step Answer:

Translate the following sentence from {language} to En-
glish.

{language}: <BOS>{ sentence }<EOS>

English: <BOS>

Translate the following sentence from English to
{language}.

English: <BOS>{ sentence }<EOS>

{language}: <BOS>


Dataset ara_Arab ben_Beng deu

Latn ell_Grek eng_Latn fra_Latn heb_Hebr hin_Deva hye_Armn kat_Geor rus_Cyrl tam_Taml

xX

MK RK OM

xX xX

xX xX xX xX xX x
xX
xX XxX

xX x xX x xX x

Table 8: Supported languages for each dataset in our evaluation.

XNLI x x x x
Belebele x x x x x
MMMLU x x x x
MGSM x x x x
FLORES200 x x x x x
Task 10% 40% 710%
XNLI 0.665 0.621 0.768
Belebele  0.001*** 0.029* 0.000***
MMMLU 0.133 0.170 0.168
MGSM 0.002**  0.001** 0.001***
Flores200 0.213 0.071 0.000***

Table 9: Significance of performance differences be-
tween MULT YPO and random baseline under 3-shot
setup. Each cell shows the p-value with significance
stars (* p < 0.05, ** p < 0.01, *** p < 0.001).

Few-Shot Setup For each shot setting, we sam-
ple a fixed set of support examples per language
and introduce typographical noise according to the
specified corruption level. To preserve a consistent
supervision signal, the correct answers in the exem-
plars are left unaltered, allowing the model to learn
correct associations even under noisy contexts. The
same exemplars are used across all evaluations to
ensure comparability. Whenever possible, exam-
ples are drawn from the training or development
splits; otherwise, the first instances from the test
split are selected. The remaining data points serve
as independent queries during evaluation.

D_ Performance Comparison with
Random Typo Baseline

We examine performance differences when input
text is perturbed by MULT YPO — which simulates
human typing behavior — versus a random typo
baseline that applies the same four operations de-
scribed in §3.1 but disregards keyboard layout con-
straints. For this evaluation, we use Qwen3-4B
(instruction-tuned) across all five tasks.

As shown in Figure 12, performance under ran-
dom perturbations is consistently lower than with
MULTYPO. This suggests that models are more ro-
bust to MULT YPO typos, likely because they better
approximate realistic human typing errors, some
of which may already be represented in pretrain-
ing corpora. Table 9 further confirms these trends:
(1) For natural language understanding tasks (e.g.,
XNLI), the performance gap is small and not sta-

tistically significant. (2) For generation tasks — par-
ticularly those requiring reasoning — the random
baseline leads to significantly larger degradation
compared to MULT YPO.

E Complementary Results on Translation

We also compare the performance of Qwen and
OLMo models when translating from English vs.
into English, as shown in Figure 13 and Figure 14.
In general, we observe the same trend as in Fig-
ure 7. That is, translations from English are more
robust than those into English. This trend is typi-
cally noticeable when involving low-resource lan-
guages that are written in non-Latin scripts, such
as hye_Armn and kat_Geor. To sum up, these find-
ings further support our claim that typos in lower-
resource input languages might severely impair the
understanding and, therefore, result in bad transla-
tion quality.

F Experimental Environment and
Hyperparameters

All experiments are conducted on NVIDIA RTX
A6000 GPUs. We use vLLM to process the
prompts and obtain the response for each prompt. !°
The default sampling parameters (top-k, top-p, etc.)
of VLLM are used. We set the different maximum
generation tokens for each dataset: 5 for XNLI,
100 for Belebele, 5 for MMMLU, 200 for MGSM,
and 100 for Flores200, based on preliminary exper-
imental results.

https: //docs.vllm.ai/en/va.7.3/


72
Mg MulTypo
64 M8 Baseline
56
48
L
§ 40
wn
D 32
>
=
24
16
8
{e)

we.
So LY hol so ooo a teh oo aN iio wip wip WS aN WS aN VS oe oS sof At ec si

Tasks (with Typo Rate)

Figure 12: Performance comparison of MULT YPO and random baseline under different typo rates (10%, 40%, 70%)
in the 3-shot setting. Bars show average performance across all languages for each task.

Qwen: Translation Robustness

cS
o

Direction / Typo Rate
[5 From English

| [9 To English
‘| —= 10%

| —- 40%

| sees 70%

|

| 5

Sa x oe & \
© eo es o>) eS
o/

7 cs & “

w
a

BLEU Score
a e N N Ww
u oOo ul fo} wu lo}

°

Figure 13: Robustness of Qwen models on Flores200 under different levels of typographical noise. Translation
from English seems to be more robust compared to translation to English.

OLMo: Translation Robustness

254 Direction / Typo Rate
From English
w 205 G3 To English
5 == 10%
A —- 40%
wis 9
a) = 70%
=I 104
‘ i
0 ——
& ss ~ 2
O7 Pid 7 a Bo y 7 & 7
e wv © Ag »

Figure 14: Robustness of OLMo models on Flores200 under different levels of typographical noise. Translation
from English seems to be more robust compared to translation to English.
