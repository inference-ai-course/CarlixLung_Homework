arXiv:2510.09782v1 [cs.AI] 10 Oct 2025

The Geometry of Reasoning: Flowing Logics in
Representation Space

Yufa Zhou”, Yixiao Wang”, Xunjian Yin*, Shuyan Zhou, Anru R. Zhang

Duke University
{yufa.zhou,yixiao.wang,xunjian.yin, shuyan.zhou, anru. zhang}@duke. edu
*Equal contribution.

We study how large language models (LLMs) “think” through their representation space. We propose a novel
geometric framework that models an LLM’s reasoning as flows—embedding trajectories evolving where logic goes.
We disentangle logical structure from semantics by employing the same natural deduction propositions with
varied semantic carriers, allowing us to test whether LLMs internalize logic beyond surface form. This perspective
connects reasoning with geometric quantities such as position, velocity, and curvature, enabling formal analysis in
representation and concept spaces. Our theory establishes: (1) LLM reasoning corresponds to smooth flows in
representation space, and (2) logical statements act as local controllers of these flows’ velocities. Using learned
representation proxies, we design controlled experiments to visualize and quantify reasoning flows, providing
empirical validation of our theoretical framework. Our work serves as both a conceptual foundation and practical
tools for studying reasoning phenomenon, offering a new lens for interpretability and formal analysis of LLMs’
behavior.

€) Code: https: //github.com/MasterZhou1/Reasoning-Flow
& Dataset: https: //huggingface.co/datasets/MasterZhou/Reasoning-Flow

“Reasoning is nothing but reckoning.”

— Thomas Hobbes

1. Introduction

The geometry of concept space, i.e., the idea that meaning can be represented as positions in a structured geometric
space, has long served as a unifying perspective across Al, cognitive science, and linguistic philosophy [15, 59, 16].
Early work in this tradition was limited by the absence of precise and scalable semantic representations. With the
rise of large language models (LLMs) [28, 52, 19, 21, 75], we revisit this geometric lens: pretrained embeddings
now offer high-dimensional vector representations of words, sentences, and concepts [44, 49, 79, 35, 34], enabling
geometric analysis of semantic and cognitive phenomena at scale.

A seminal recent work [46] formalizes the notion that learned representations in LLMs lie on low-dimensional
concept manifolds. Building on this view, we hypothesize that reasoning unfolds as a trajectory, potentially a flow,
along such manifolds. To explore this idea, we draw on classical tools from differential geometry [42, 25, 20, 9] and
propose a novel geometric framework for analyzing reasoning dynamics in language models. Concretely, we view
reasoning as a context-cumulative trajectory in embedding space: at each step, the reasoning prefix is extended,
and the model’s representation is recorded to trace the evolving flow (Figures 1a and 1b). Our results suggest that
LLM reasoning is not merely a random walk on graphs [67, 45]. At the isolated embedding level, trajectories exhibit
stochasticity reminiscent of graph-based views; however, when viewed cumulatively, a structured flow emerges
on a low-dimensional concept manifold, where local velocities are governed by logical operations. To the best of
our knowledge, this is the first work to formalize and empirically validate such a dynamical perspective, offering
quantitative evidence together with broad insights and implications. We further rigorously define and formalize


The Geometry of Reasoning: Flowing Logics in Representation Space

Reasoning flows (PCA 3D) xX
® Ss ‘Top: “sown view (PC1 vs PC2) T WU
ne 4 Pe 2 Curves(C) A=W¥or”, Curves(R)
m="  F € oF 4 i
e < .
ee a y Fe DR
?
Pc2 ee a Le seve CH sees Sons ene > Lrep

(a) Reasoning flows visualized using PCA (b) Reasoning flows visualized using PCA (c) Schematic illustration of mappings be-
in 3 dimensions. in 2 dimensions. tween spaces.

Figure 1: Reasoning Flow. (a-b) Visualizations on a selected problem from MATH500 with six distinct answers. (c)
Our geometric framework of mapping relationships among input space 1’, concept space C, logic space £, and
representation space R. See Section 4 for more details.

concept, logic, and representation spaces (Figure 1c), and relate them through carefully designed experiments.

From Aristotle’s syllogistics to Frege’s predicate calculus and modern math foundations [4, 8, 11], formal logic
isolates validity as form independent of content. Wittgenstein’s Tractatus sharpened this view—“the world is
the totality of facts, not of things” [72]—underscoring logical form as the substrate of language and reality. In
this spirit, we treat logic as a carrier-invariant skeleton of reasoning and test whether LLMs, trained on massive
corpora, have internalized such structural invariants on the embedding manifold, effectively rediscovering in data
the universal logic that took humans two millennia to formalize. We deliberately construct a dataset that isolates
formal logic from its semantic carriers (e.g., topics and languages) to validate our geometric perspective.

Our experiments, conducted with Qwen3 [75] hidden states on our newly constructed dataset, reveal that LLMs
exhibit structured logical behavior. In the original (0-order) representation space, semantic properties dominate,
with sentences on the same topic clustering together. However, when we analyze differences (1- and 2-order
representations), logical structure emerges as the dominant factor. Specifically, we find that velocity similarity and
Menger curvature similarity remain highly consistent between flows sharing the same logical skeleton, even across
unrelated topics and languages. In contrast, flows with different logical structures exhibit lower similarity, even
when they share the same semantic carrier. These findings provide quantifiable evidence for our hypothesis that
logic governs the velocity of reasoning flows.

While interpretability research on LLMs has made substantial empirical progress [1, 58, 48, 61, 40, 13], rigorous
theoretical understanding remains comparatively limited, with only a few recent efforts in this direction [31, 54, 46,
55]. Our work contributes to this emerging line by introducing a mathematically grounded framework with formal
definitions and analytic tools for quantifying and analyzing how LLMs behave and reason. We hope our theory and
empirical evidence open a new perspective for interpretability community and spark practical applications. Our
contributions are:

¢ We introduce a geometric perspective that models LLM reasoning as flows, providing formal definitions and
analytic tools to study reasoning dynamics.

¢ We design a formal logic dataset that disentangles logical structure from semantic surface, enabling direct tests
of whether LLMs internalize logic beyond semantics.

¢ We empirically validate our framework through experiments and analysis, demonstrating its utility and offering
practical insights.


The Geometry of Reasoning: Flowing Logics in Representation Space

2. Related Work

Concept Space Geometry. The Linear Representation Hypothesis (LRH) proposes that concepts align with
linear directions in embedding space, a view supported by theoretical analyses and empirically validated in
categorical, hierarchical, and truth-false settings [54, 32, 55, 31, 41]. However, strict linearity is limited: features
may be multi-dimensional or manifold-like, as seen in concepts like colors, years, dates, and antonym pairs.
[12, 46, 34]. Other works emphasize compositionality, showing that concepts require explicit constraints or
algebraic subspace operations to compose meaningfully [63, 70]. At a broader scale, hidden-state geometry follows
expansion—contraction patterns across layers and exhibits training trajectories whose sharp shifts coincide with
emergent capabilities and grokking [65, 53, 39]. Sparse autoencoders further reveal multi-scale structure, from
analogy-like “crystals” to anisotropic spectra [36]. Collectively, these results suggest that concept spaces are locally
linear yet globally curved, compositional, and dynamic, motivating our perspective of reasoning as flows on such
manifolds.

Mechanistic Interpretability. LLMs have exhibited unprecedented intelligence ever since their debut [51]. Yet
the underlying mechanisms remain opaque, as transformers are neural networks not readily interpretable by
humans—motivating efforts to uncover why such capabilities emerge [61, 40]. Mechanistic Interpretability (MI)
pursues this goal by reverse-engineering transformer internals into circuits, features, and algorithms [58, 13,
3]. The Transformer Circuits program at Anthropic exemplifies this agenda, systematically cataloging reusable
computational subroutines [1]. Empirical studies reveal concrete algorithmic mechanisms: grokking progresses
along Fourier-like structures [48], training can yield divergent solutions for the same task (Clock vs. Pizza) [81],
arithmetic emerges via trigonometric embeddings on helical manifolds [33], and spatiotemporal structure is
encoded through identifiable neurons [22]. Beyond circuits, in-context learning and fine-tuning yield distinct
representational geometries despite comparable performance [10], while safety studies reveal polysemantic
vulnerabilities where small-model interventions transfer to larger LLMs [18].

Understanding Reasoning Phenomenon. LLMs benefit from test-time scaling, where allocating more inference
compute boosts accuracy on hard tasks [62]. Explanations span expressivity—CoT enabling serial computation [37],
reasoning as superposed trajectories [82], and hidden planning in scratch-trained math models [78]—to inductive
biases, where small initialization favors deeper chains [77]. Structural analyses view reasoning as path aggregation
or graph dynamics with small-world properties [67, 45], while attribution highlights key “thought anchors” [5].
Empirical work shows inverted-U performance with CoT length and quantifiable reasoning boundaries [73, 6],
and embedding-trajectory geometry supports OOD detection [68]. Moving beyond text, latent-reasoning methods
scale compute through recurrent depth, continuous “soft thinking,” and latent CoT for branch exploration and
self-evaluation [80, 17, 23, 69]. Applications exploit these insights for steering and efficiency: steering vectors and
calibration shape thought processes [66, 7], manifold steering mitigates overthinking [27], and adaptive indices
enable early exit [14].

Formal Logic with LLMs. Recent work links transformer computation directly to logic. Log-precision transformers
are expressible in first-order logic with majority quantifiers, providing an upper bound on expressivity [43], while
temporal counting logic compiles into softmax-attention architectures, giving a constructive lower bound [76].
Beyond these characterizations, pre-pretraining on formal languages with hierarchical structure (e.g., Dyck) imparts
syntactic inductive biases and improves efficiency [26]. Synthetic logic corpora and proof-generation frameworks
further strengthen reasoning, though benefits diminish as proofs lengthen [47, 74]. Systematic evaluations,
including LogicBench and surveys, highlight persistent failures on negation and inductive reasoning, despite partial
gains from “thinking” models and rejection finetuning [56, 30, 38]. In contrast, our work employs formal logic not
as an end task, but as a tool to validate our geometric framework in LLMs’ representation space, distinguishing our
contribution from prior lines of work.


The Geometry of Reasoning: Flowing Logics in Representation Space

3. Preliminaries

3.1. Large Language Models

Let V denote a finite vocabulary of tokens, and let 6 denote the parameters of a large language model (LLM). An
LLM defines a conditional probability distribution po(u; | we:,P), we € V, where uz := (uy1,...,U¢_-1) is the
prefix of previously generated tokens and P € Y” is the tokenized problem prompt. At each step t, inference
proceeds by sampling uz ~ po(- | uct, P).

Definition 3.1 (Chain-of-Thought Reasoning). Given a prompt P © V", Chain-of-Thought (CoT) reasoning is
an iterative stochastic process that generates a sequence U = (uj,U2,...,ur), Ut € V, via recursive sampling

To enable geometric analysis of reasoning, we need a mapping from discrete token sequences into continuous
vectors, a transformation that modern LLMs naturally provide.

Definition 3.2 (Representation Operator). A Representation Operator is a mapping € : V* x I — R¢, where
uv = (1,...,%n) € V* is a token sequence and u € T is an index specifying the representation type (e.g., a token
position, a prefix, a pooling rule, or an internal layer state). The output €(x,1) € R® is the embedding/representaion
of s under the selection rule v. For notational simplicity, we omit the index 1 unless explicitly required.

The range of this operator defines the ambient space of reasoning:

Definition 3.3 (Representation Space). Given an representation operator €, the representation space is R := {E(x) :
x € V*} C R®. Elements of R are continuous embeddings of discrete language inputs, serving as the foundation and
empirical proxy for our geometric analysis of reasoning.

In practice, € may be instantiated by a pretrained encoder such as Qwen3 Embedding [79] or OpenAl’s
text-embedding-3-large [49], or by extracting hidden states directly from an LLM. Typical choices of « include
mean pooling, the hidden state of the final token, or a specific layer—position pair within the model [79, 35, 24, 50].
We interpret € as projecting discrete language sequences into a continuous semantic space, potentially lying on a
low-dimensional manifold embedded in R®@ [46, 12, 34].

3.2. Menger Curvature

We adopt Menger curvature [42] to quantitatively capture the geometric structure of reasoning flows. As a metric-
based notion of curvature, Menger curvature simultaneously reflects both angular deviation and distance variation,
making it particularly suitable for reasoning trajectories represented as discrete embeddings. We leave more details
to Appendix C.2.

Definition 3.4 (Menger Curvature). Let x1, 22,23 € R” be three distinct points. The Menger curvature of the triple
(41, £2, x3) is defined as the reciprocal of the radius R(x , x2, x3) of the unique circle passing through the three points:

_ 1
c(x1, @2,; x3) => R(@i.t2,83)"

4. Reasoning as Geometric Flows in Representation Space

We formalize the view that LLMs reason by tracing trajectories in their representation space. A central question is
whether LLMs exhibit intrinsic control over these flows, mirroring the human perspective. We hypothesize semantic
content as a curve on a concept manifold, and logical structure acts as a local controller of the trajectory. In this
section, we introduce the spaces, maps, and geometric quantities that underpin the paper. We then rigorously
formalize this construction and establish the correspondence between the LLM’s representation space and the
human concept space.


The Geometry of Reasoning: Flowing Logics in Representation Space

4.1. Concept Space and Semantic Trajectories

Definition 4.1 (Concept Space). The concept space C is an abstract semantic space that models human-level cognitive
structures such as ideas, reasoning states, and problem-solving subtasks.

We assume C is endowed with a smooth geometric structure, allowing continuous trajectories to represent the
evolution of conceptual content. This assumption can be traced back to the classical insight of William James
[29], who famously argued that consciousness does not appear to itself “chopped up in bits.” Chains or trains of
thought are, in his words, inadequate metaphors; instead, “it is nothing jointed; it flows. A river or a stream are
the metaphors by which it is most naturally described.”

Definition 4.2 (Semantic Subspace as Cognitive Trajectories). Let MM C C denote a semantic subspace corresponding
to a coherent domain of meaning (e.g., temporal concepts, colors, or causal relations). Let X* denote the set of all finite
input sequences over XV. We introduce a trajectory map

T: X&* > Curves(M), Xx,
that assigns each sentence Xp = (a#1,...,a7) to a continuous curve yx within M. Formally,
yx :[0,1]} 3M, 81H yx(s),

where s € [0,1] is a continuous progress parameter along the reasoning flow. For each discrete prefix (11,...,Xt),
we align it with the point yx (4) on the curve. The curve 7x thus traces the gradual unfolding of semantic content,
formalizing the view that human cognition operates as a continuous flow of concepts rather than as a sequence of
isolated symbols.

We then define the logic space that mirrors the human view of logic.

Definition 4.3 (Formal Logical Space). The formal logical space £ is an abstract domain that captures structural
dynamics of reasoning (natural deduction [64, 57]; see Definition 5.1). Define the flow operator

Fo: Curves(C) + Leorm,

which maps a semantic trajectory to its formal counterpart. Semantically different expressions that correspond to the
same natural-deduction proposition map to the same element in Lyorm-

4.2. Representation Space

We use LLM representations/embeddings as proxies to study human cognition and to investigate why LLMs exhibit
reasoning phenomenon. We build on the multidimensional linear representation hypothesis [46], which posits that
representations decompose linearly into a superposition of features. Each feature corresponds to a basis direction
within a feature-specific subspace of the embedding space, weighted by a non-negative activation coefficient
encoding its salience.

Hypothesis 4.4 (Multidimensional Linear Representation Hypothesis [46]). Let X denote the input space (e.g.,
natural language sentences). Let F be a set of semantic features. For each feature f € F, let Wy C R® denote a
feature-specific subspace of the embedding space.

Then the representation map V : ¥ — R¢ of an input x € X is assumed to take the form
U(2)= So ps(w)w4(z),
feF (2)

where F(x) =<{f € F : pp(x) > O} is the set of active features in x, p(x) € Ro is a non-negative scaling coefficient
encoding the intensity or salience of feature f in x, wy (x) € Wy is a unit vector (||wf(x)||2 = 1) specifying the direction
of feature f within its subspace Wy.


The Geometry of Reasoning: Flowing Logics in Representation Space

Algorithm 1: Get Context Cumulative Reasoning Trajectory
V: vocabulary space; P € Y”: tokenized problem prompt; T: number of reasoning steps; x, € V*: tokens
for step t; € : V* — R¢: representation operator; y, € R?: embedding at step t.
Input: Pe V"; X = [x1,..., v7] with x, € Y*
Output: Y = [y,..., yr] € R&*?
Yel) S0<(P)
for t + 1 to T do
St + Concat(S;_1, 7); // Concatenate with previous context
yt <— E(S:); // Get embedding of current step
Append y, to Y;

return Y;

Building on this compositional picture, we now move from single inputs to growing contexts. As a model reasons,
its internal representation evolves. The next definition formalizes this evolution as a cumulative flow in embedding
space.

Definition 4.5 (Reasoning Trajectory / Context Cumulative Flow). Let be the input space, and V : ¥ — R¢ the
representation map from finite input sequences to the embedding space defined in Hypothesis 4.4. Given a prompt
P € X anda Chain-of-Thought sequence Xp = (x1,...,@7) with x, € X, define

St = (P,a1,...,Xt), He = V(S,) € RY, t=1,...,T.
When focusing solely on the reasoning process (ignoring the prompt), we set
yw = U(X, eR’, t=1,...,T.
The sequence Y = [y1,..., yr] € R®" is called the context cumulative flow. The construction of Y follows Algorithm 1.
The embeddings we observe along a sentence are discrete, while reasoning itself is naturally understood to

unfold as a continuous process. It is therefore natural to posit an underlying smooth curve from which these
discrete points arise as samples, thereby enabling the use of geometric tools such as velocity and curvature.

Hypothesis 4.6 (Smooth Representation Trajectory). The discrete representations {y,}7_, produced by context
accumulation intrinsically lie on a C' curve W : [0,1] + R¢ satisfying

U(s:)=y for an increasing schedule s; <+-- < sr.

In other words, the sequence is not merely fitted by a smooth curve, but should be regarded as samples from an
underlying smooth trajectory. This assumption is reasonable: in Appendix C.1 we show an explicit construction of
such a C! trajectory via a relaxed prefix-mask mechanism.

Once a smooth trajectory exists, we can canonically align symbolic progress (e.g., “how far along the derivation
we are”) with geometric progress in representation space. The following corollary formalizes this alignment on
domains where the symbolic schedule is well-behaved.

Corollary 4.7 (Canonical Alignment). On a domain where I is injective and W is defined, there exists a canonical
alignment _
A: Curves(C) > Curves(R), A:=Wolr".


The Geometry of Reasoning: Flowing Logics in Representation Space

4.3. Logic as Differential Constraints on Flow

We now turn from the structural hypotheses of representation trajectories to their dynamical regulation. In particular,
we view logic not as an external add-on, but as a set of differential constraints shaping how embeddings evolve
step by step. This perspective enables us to couple discrete reasoning structure with continuous semantic motion.

Definition 4.8 (Representation-Logic Space). Given a representation trajectory Y = (y1,..., yr) defined in Defini-
tion 4.5, define local increments Ay, := y; — yz-1 for t > 2. The representation-logic space is

Lrep = { (Ayo,..., Ayr) | Y a context-cumulative trajectory }.

The above constructs a discrete object: a sequence of increments capturing how representations change from
one reasoning step to the next. To connect this discrete view with a continuous account of semantic evolution, we
next introduce the notion of velocity along embedding trajectories.

Definition 4.9 (Flow Velocity). Let WU : [0, 1] + R¢ be the continuous embedding trajectory associated with a sentence.
The flow velocity at progress s is defined as v(s) = £W(s), which captures the instantaneous rate of change of the

embedding w.r.t. the unfolding of the sentence.

By relating local increments in representation space (Definition 3.3) to the derivative of a continuous trajectory,
we can interpret each discrete reasoning step as an integrated outcome of infinitesimal semantic motion.

Proposition 4.10 (Logic as Integrated Thought). By the fundamental theorem of calculus, the cumulative semantic
shift between two successive reasoning steps s; and 544, is

St+1 ~
/ v(s)ds = W(st41) — U(st) = Yori — ye = Ayes.
St

Thus, we could view each representation—logic step as the integration of local semantic velocity, which aggregates
infinitesimal variations of meaning into a discrete reasoning transition. Definition 4.9 captures the central principle that
semantic representations evolve continuously, whereas logical steps are inherently discrete: logic acts as the controller
of semantic velocity, governing both its magnitude and its direction.

Having established this continuous—discrete correspondence, we can now ask: what properties of reasoning
flows should persist across changes in surface semantics? We posit that reasoning instances sharing the same
natural-deduction skeleton but differing in semantic carriers (¢.g., topics or languages) should yield reasoning flows
whose trajectories exhibit highly correlated curvature (Definition 3.4). If logic governs flow velocity (magnitude
and direction) then flows instantiated with different carriers may undergo translations or rotations, reflecting
dominant semantic components of the original space. Nevertheless, their overall curvature should remain invariant.
A more detailed discussion of curvature is provided in Appendix C.2. Such correlation would indicate that the
accumulation of semantic variation produces turning points aligned with both LLM reasoning and human logical
thought. This directly corresponds to the central research objective of this paper, namely clarifying the relationship
between the two logical spaces Ljorm and Lyep as illustrated in Figure 1c. Empirical evidence for this claim will be
provided later, where we demonstrate cross-carrier similarity in both first-order differences and curvature.

In summary, logic functions as the differential regulator of semantic flow, discretizing continuous variations
into meaningful steps. For clarity and reference, all mappings and derivational relationships introduced in this
subsection are systematically summarized in Appendix B.

5. Formal Logic with Semantic Carriers

5.1. Logic and Natural Deduction System

We construct a dataset of reasoning tasks that instantiate the fundamental logical patterns formalized in Defi-
nition 5.1. Each task is presented step by step in both formal symbolic notation and natural language. To test


The Geometry of Reasoning: Flowing Logics in Representation Space

Table 1: Comparison of reasoning-flow similarities across 4 models. We report mean cosine similarity (position,
velocity) and Pearson correlation (curvature) under 3 grouping criteria: logic, topic, and language. Results show
that position similarity is dominated by surface carriers, while velocity and curvature highlight logical structure as
the primary invariant. See Section 6 for more.

Model Position Similarity Velocity Similarity Curvature Similarity

Logic Topic Lang. Logic Topic Lang. Logic Topic Lang.

Qwen3 0.6B 0.26 0.30 0.85 0.17 0.07 0.08 0.53 O.11 0.13
Qwen3 1.7B 0.44 0.46 0.89 0.19 0.08 0.09 0.46 0.13 0.15
Qwen3 4B 0.33 0.35 0.86 0.16 0.07 0.08 0.53 0.11 0.13
LLaMA3 8B (0.31) =—(0.34S (0.74 «0.15 :0.06S «0.07, ss«O0.58)—SO0.13s(0.17

whether reasoning relies on surface content or underlying structure, we express the same logical skeletons across
diverse carriers, e.g., topics such as weather, education, and sports, as well as multiple languages (en, zh, de). This

design disentangles logics from linguistic surface and provides a controlled setting for analyzing how reasoning
flows behave under varying contexts.

Definition 5.1 (Natural Deduction System [64, 57]). A natural deduction system is a pair ND = (F, R) where:

¢ F: a formal language of formulas (e.g., propositional or first-order logic),
¢ R: a finite set of inference rules with introduction and elimination rules for each logical constant.

A derivation (or proof) in ND is a tree whose nodes are judgements of the form “a formula is derivable” and whose edges
follow inference rules from R. Temporary assumptions may be introduced in sub-derivations and are discharged by

certain rules (e.g., + I, =I). Each connective is governed by paired introduction and elimination rules, which together
determine its proof-theoretic meaning.

5.2. Data Design

To test whether LLM reasoning trajectories are governed by logical structure rather than semantic content, we
generates parallel reasoning tasks that maintain identical logical scaffolding while systematically varying superficial
characteristics, specifically topical domain and linguistic realization.

Our dataset construction employs a principled two-stage generation pipeline using GPT-5 [52]. It proceeds as
follows: (i) abstract logical templates are first constructed, followed by (ii) domain-specific and language-specific
rewriting. Our final dataset comprises 30 distinct logical structures, each containing between 8 and 16 reasoning
steps. Each logical structure is instantiated across 20 topical domains and realized in four languages (English,
Chinese, German, and Japanese), yielding a total corpus of 2,430 reasoning sequences. This controlled design
enables direct comparison of trajectories across logical forms and surface carriers, isolating the role of logical
structure in embedding dynamics. Full generation prompts and sampled data cases are provided in Appendix D.

6. Play with LLMs

6.1. Experimental Setup

We employ the Qwen3 [75] family models and LLaMA3 [19]. From the final transformer layer (before the LM
head), we extract context-dependent hidden states {rh}, where ne) € R¢ denotes the representation at layer L
and position i. Each reasoning step x; is a set of tokens indexed by S;, and its step-level embedding is defined

by mean pooling: y%, = Sl ics, ne), yt € R¢. The resulting sequence Y = (y1,...,y7) forms the reasoning
trajectory in representation space.


The Geometry of Reasoning: Flowing Logics in Representation Space

~02

(a) Position Similarity. (b) Velocity Similarity. (c) Curvature Similarity.

Figure 2: Similarity of reasoning flows on Qwen3 0.6B. Blocks correspond to logic templates (L:A-E) instantiated
with different topics and languages. (a) Position similarity (mean cosine): diagonals correspond to topics (e.g.,
Network Security), showing that positions are dominated by surface semantics. (b) Velocity similarity (mean
cosine): semantic effects diminish, and flows with the same logical skeleton align while differing logics diverge. (€)
Curvature similarity (Pearson): separation is further amplified, with logic emerging as the principal invariant and
revealing close similarity between logics B and C. See Section 6 for more details.

6.2. Results Analysis

We evaluate four models (Qwen3 0.6B, 1.7B, 4B, and LLaMA3 8B) by extracting hidden states across our dataset
(Section 5) and computing similarities under three criteria: (i) Logic, grouping by deduction skeleton and averaging
across topics and languages; (ii) Topic; and (iii) Language, both capturing surface carriers. This yields position,
velocity, and curvature similarities (Table 1). Results show that logical similarity is low at zeroth order (position)
but becomes dominant at first and second order (velocity and curvature), validating our hypothesis. Topic and
language exhibit low velocity similarity, suggesting they might occupy orthogonal subspaces; by contrast, the high
logical similarity at first and second order breaks this orthogonality, indicating that logical structure transcends
surface carriers.

For visualization, we also analyze Qwen3 0.6B on a subset of our dataset (Figure 2). At the position level,
embeddings cluster by topic and language. First-order differences reveal logical control: flows sharing the same
skeleton align, while differing logics diverge even with identical carriers. Second-order curvature further amplifies
this separation, and its strong cross-carrier consistency directly supports Proposition 4.10, confirming that logic
governs reasoning velocity. Additional experiments across broader model families are presented in Appendix A.

Together, these results show that LLMs internalize latent logical structure beyond surface form. They are
not mere stochastic parrots [2]: whereas humans formalized logic only in the 20th century [4], LLMs acquire it
emergently from large-scale data—a hallmark of genuine intelligence.

7. Discussion

Contrast with Graph Perspective. Prior works have modeled chain-of-thought reasoning as a graph structure
[45, 67]. While this provides a useful perspective, its predictive power is limited: graphs naturally suggest random
walks between discrete nodes, which fits the noisy behavior of isolated embeddings but fails to capture the smooth,
directed dynamics we observe under cumulative context. Our results in Section 6 show that well-trained LLMs
learn flows governed by logical structure, transcending the surface semantics of language. Such continuity and
logic-driven trajectories cannot be explained within a purely graph-based framework, but arise naturally in our
differential-geometric view.


The Geometry of Reasoning: Flowing Logics in Representation Space

Other Components in Learned Representation. Beyond logical structure, learned representations also encode
a wide spectrum of factors such as semantic objects, discourse tone, natural language identity, and even signals
of higher-level cognitive behavior. Extending our framework to systematically isolate these components and
characterize their interactions presents a major challenge for future work. A promising direction is to develop
methods that disentangle additional attributes, enabling finer-grained insights into how language components
co-evolve in representation space.

Practical Implications. Our results suggest that reasoning in LLMs unfolds as continuous flows, opening multiple
directions. First, trajectory-level control offers principled tools for steering, alignment, and safety, extending vector-
based interventions to flow dynamics [66, 7, 18, 27, 3]. Second, our geometric view provides a formal framework
to study abstract language concepts, enabling first-principle analyses of reasoning efficiency, stability, and failure
modes. Third, it motivates new approaches to retrieval and representation, where embeddings respect reasoning
flows rather than mere similarity, potentially improving RAG, reranking, and search [71]. Finally, it hints at
architectural advances, as models parameterizing latent flows may enable more efficient reasoning [23, 17, 80, 60].

8. Conclusion

We introduced a novel geometric framework that models LLM reasoning as smooth flows in representation space,
with logic acting as a controller of local velocities. By disentangling logical structure from semantic carriers through
a controlled dataset, we showed that velocity and curvature invariants reveal logic as the principal organizing
factor of reasoning trajectories, beyond surface form. Our theory and experiments provide both a conceptual
foundation and practical tools for analyzing reasoning, opening new avenues for interpretability.

Acknowledgment

ARZ was partially supported by NSF Grant CAREER-2203741.

References

[1] Anthropic. Transformer circuits. https: //transformer-circuits.pub/, 2021.

[2] Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. On the dangers of
stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM conference on fairness,
accountability, and transparency, pages 610-623, 2021.

[3

faa

Leonard F. Bereska and Efstratios Gavves. Mechanistic interpretability for ai safety — a review. TMLR, April
2024.

[4
[5

a

Joseph M Bochenski and Ivo Thomas. A history of formal logic. 1961.

ia)

Paul C Bogdan, Uzay Macar, Neel Nanda, and Arthur Conmy. Thought anchors: Which Ilm reasoning steps
matter? arXiv preprint arXiv:2506.19143, 2025.

[6

oa

Qiguang Chen, Libo Qin, Jiaqi Wang, Jingxuan Zhou, and Wanxiang Che. Unlocking the capabilities of
thought: A reasoning boundary framework to quantify and optimize chain-of-thought. Advances in Neural
Information Processing Systems, 37:54872-54904, 2024.

L7

—

Runjin Chen, Zhenyu Zhang, Junyuan Hong, Souvik Kundu, and Zhangyang Wang. Seal: Steerable reasoning
calibration of large language models for free. arXiv preprint arXiv:2504.07986, 2025.

[8
[9

oa

Irving M Copi, Carl Cohen, and Kenneth McMahon. Introduction to logic. Routledge, 2016.

—

Manfredo P Do Carmo. Differential geometry of curves and surfaces: revised and updated second edition. Courier
Dover Publications, 2016.

10


[10]

[11]

[12]

[13]

[14]

[15]

[16]

[17]

[18]

[19]

[20]

[21]

[22]

[23]

[24]
[25]
[26]

[27]

[28]

[29]

The Geometry of Reasoning: Flowing Logics in Representation Space

Diego Doimo, Alessandro Serra, Alessio Ansuini, and Alberto Cazzaniga. The representation landscape
of few-shot learning and fine-tuning in large language models. Advances in Neural Information Processing
Systems, 37:18122-18165, 2024.

Herbert B Enderton. A mathematical introduction to logic. Elsevier, 2001.

Joshua Engels, Eric J Michaud, Isaac Liao, Wes Gurnee, and Max Tegmark. Not all language model features
are one-dimensionally linear. In The Thirteenth International Conference on Learning Representations, 2025.
URL https: //openreview. net/forum?id=d63a4AM4hb.

Javier Ferrando, Gabriele Sarti, Arianna Bisazza, and Marta R Costa-Jussa. A primer on the inner workings
of transformer-based language models. arXiv preprint arXiv:2405.00208, 2024.

Yichao Fu, Junda Chen, Siqi Zhu, Zheyu Fu, Zhongdongming Dai, Yonghao Zhuang, Yian Ma, Aurick
Qiao, Tajana Rosing, Ion Stoica, et al. Efficiently scaling Ilm reasoning with certaindex. arXiv preprint
arXiv:2412.20993, 2024.

Peter Gardenfors. Conceptual spaces: The geometry of thought. MIT press, 2004.
Peter Gardenfors. The geometry of meaning: Semantics based on conceptual spaces. MIT press, 2014.

Jonas Geiping, Sean McLeish, Neel Jain, John Kirchenbauer, Siddharth Singh, Brian R Bartoldson, Bhavya
Kailkhura, Abhinav Bhatele, and Tom Goldstein. Scaling up test-time compute with latent reasoning: A
recurrent depth approach. arXiv preprint arXiv:2502.05171, 2025.

Bofan Gong, Shiyang Lai, and Dawn Song. Probing the vulnerability of large language models to polysemantic
interventions. arXiv preprint arXiv:2505.11611, 2025.

Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle,
Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, et al. The llama 3 herd of models. arXiv e-prints,
pages arXiv—2407, 2024.

Heinrich W Guggenheimer. Differential geometry. Courier Corporation, 2012.

Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma,
Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning.
arXiv preprint arXiv:2501.12948, 2025.

Wes Gurnee and Max Tegmark. Language models represent space and time. In The Twelfth International
Conference on Learning Representations, 2024. URL https: //openreview.net/forum?id=jE8xbmvFin.

Shibo Hao, Sainbayar Sukhbaatar, DiJia Su, Xian Li, Zhiting Hu, Jason Weston, and Yuandong Tian. Training
large language models to reason in a continuous latent space. arXiv preprint arXiv:2412.06769, 2024.

Hesam Sheikh Hessani. Llm embeddings explained: A visual and intuitive guide, 2025.
Noel J Hicks. Notes on differential geometry, volume 1. van Nostrand Princeton, 1965.

Michael Y Hu, Jackson Petty, Chuan Shi, William Merrill, and Tal Linzen. Between circuits and chomsky:
Pre-pretraining on formal languages imparts linguistic biases. arXiv preprint arXiv:2502.19249, 2025.

Yao Huang, Huanran Chen, Shouwei Ruan, Yichi Zhang, Xingxing Wei, and Yinpeng Dong. Mitigating
overthinking in large reasoning models via manifold steering. arXiv preprint arXiv:2505.22411, 2025.

Aaron Hurst, Adam Lerer, Adam P Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila
Welihinda, Alan Hayes, Alec Radford, et al. Gpt-40 system card. arXiv preprint arXiv:2410.21276, 2024.

William James, Frederick Burkhardt, Fredson Bowers, and Kestutis Skrupskelis. The principles of psychology,
volume 1. Macmillan London, 1890.

11


[30]

[31]

[32]

[33]

[34]

[35]

[36]

[37]

[38]

[39]

[40]

[41]

[42]

[43]

[44]

[45]

[46]

The Geometry of Reasoning: Flowing Logics in Representation Space

Jin Jiang, Jianing Wang, Yuchen Yan, Yang Liu, Jianhua Zhu, Mengdi Zhang, Xunliang Cai, and Liangcai
Gao. Do large language models excel in complex logical reasoning with formal language? arXiv preprint
arXiv:2505.16998, 2025.

Yibo Jiang, Bryon Aragam, and Victor Veitch. Uncovering meanings of embeddings via partial orthogonality.
Advances in Neural Information Processing Systems, 36:31988-32005, 2023.

Yibo Jiang, Goutham Rajendran, Pradeep Kumar Ravikumar, Bryon Aragam, and Victor Veitch. On the origins
of linear representations in large language models. In Forty-first International Conference on Machine Learning,
2024. URL https: //openreview.net/forum?id=otuTw4Mghk.

Subhash Kantamneni and Max Tegmark. Language models use trigonometry to do addition. arXiv preprint
arXiv:2502.00873, 2025.

Austin C Kozlowski, Callin Dai, and Andrei Boutyline. Semantic structure in large language model embeddings.
arXiv preprint arXtv:2508.10003, 2025.

Jinhyuk Lee, Feiyang Chen, Sahil Dua, Daniel Cer, Madhuri Shanbhogue, Iftekhar Naim, Gustavo Hernandez
Abrego, Zhe Li, Kaifeng Chen, Henrique Schechter Vera, et al. Gemini embedding: Generalizable embeddings
from gemini. arXiv preprint arXiv:2503.07891, 2025.

Yuxiao Li, Eric J Michaud, David D Baek, Joshua Engels, Xiaoqing Sun, and Max Tegmark. The geometry of
concepts: Sparse autoencoder feature structure. Entropy, 27(4):344, 2025.

Zhiyuan Li, Hong Liu, Denny Zhou, and Tengyu Ma. Chain of thought empowers transformers to solve
inherently serial problems. In The Twelfth International Conference on Learning Representations, 2024. URL
https: //openreview.net/forum?id=3EWTEyOMIM.

Hanmeng Liu, Zhizhang Fu, Mengru Ding, Ruoxi Ning, Chaoli Zhang, Xiaozhang Liu, and Yue Zhang. Logical
reasoning in large language models: A survey. arXiv preprint arXiv:2502.09100, 2025.

Ziming Liu, Ouail Kitouni, Niklas S Nolte, Eric Michaud, Max Tegmark, and Mike Williams. Towards
understanding grokking: An effective theory of representation learning. Advances in Neural Information
Processing Systems, 35:34651-34663, 2022.

Andreas Madsen, Himabindu Lakkaraju, Siva Reddy, and Sarath Chandar. Interpretability needs a new
paradigm. arXiv preprint arXiv:2405.05386, 2024.

Samuel Marks and Max Tegmark. The geometry of truth: Emergent linear structure in large language
model representations of true/false datasets. In First Conference on Language Modeling, 2024. URL https:
//openreview.net/forum?id=aajyHYjjsk.

Karl Menger. Untersuchungen tiber allgemeine metrik. Mathematische Annalen, 100(1):75-163, 1928.

William Merrill and Ashish Sabharwal. A logic for expressing log-precision transformers. Advances in neural
information processing systems, 36:52453-52463, 2023.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in
vector space. In ICLR, 2013.

Gouki Minegishi, Hiroki Furuta, Takeshi Kojima, Yusuke Iwasawa, and Yutaka Matsuo. Topology of reasoning:
Understanding large reasoning models through reasoning graph properties. arXiv preprint arXiv:2506.05744,
2025.

Alexander Modell, Patrick Rubin-Delanchy, and Nick Whiteley. The origins of representation manifolds in
large language models. arXiv preprint arXiv:2505.18235, 2025.

12


[47]

[48]

[49]

[50]

[51]
[52]
[53]

[54]

[55]

[56]

[57]

[58]

[59]

[60]

[61]

[62]

The Geometry of Reasoning: Flowing Logics in Representation Space

Terufumi Morishita, Gaku Morio, Atsuki Yamaguchi, and Yasuhiro Sogawa. Enhancing reasoning capabilities of
Ilms via principled synthetic logic corpus. Advances in Neural Information Processing Systems, 37:73572-73604,
2024.

Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, and Jacob Steinhardt. Progress measures for
grokking via mechanistic interpretability. In The Eleventh International Conference on Learning Representations,
2023. URL https: //openreview.net/forum?id=9XFSbDPmdW.

Arvind Neelakantan, Tao Xu, Raul Puri, Alec Radford, Jesse Michael Han, Jerry Tworek, Qiming Yuan, Nikolas
Tezak, Jong Wook Kim, Chris Hallacy, et al. Text and code embeddings by contrastive pre-training. arXiv
preprint arXiv:2201.10005, 2022.

Zhijie Nie, Zhangchi Feng, Mingxin Li, Cunwang Zhang, Yanzhao Zhang, Dingkun Long, and Richong Zhang.
When text embedding meets large language model: a comprehensive survey. arXiv preprint arXiv:2412.09165,
2024.

OpenAl. Introducing chatgpt. https: //openai.com/index/chatgpt/, 2022.
OpenAlI. Gpt-5 system card. Technical report, OpenAl, August 2025.

Core Francisco Park, Maya Okawa, Andrew Lee, Ekdeep S Lubana, and Hidenori Tanaka. Emergence of
hidden capabilities: Exploring learning dynamics in concept space. Advances in Neural Information Processing
Systems, 37:84698-84729, 2024.

Kiho Park, Yo Joong Choe, and Victor Veitch. The linear representation hypothesis and the geometry of
large language models. In Forty-first International Conference on Machine Learning, 2024. URL https:
//openreview.net/forum?id=UGpGkLzwpP.

Kiho Park, Yo Joong Choe, Yibo Jiang, and Victor Veitch. The geometry of categorical and hierarchical
concepts in large language models. In The Thirteenth International Conference on Learning Representations,
2025. URL https: //openreview.net/forum?id=bVTM2QKYuA.

Mihir Parmar, Nisarg Patel, Neeraj Varshney, Mutsumi Nakamura, Man Luo, Santosh Mashetty, Arindam
Mitra, and Chitta Baral. Logicbench: Towards systematic evaluation of logical reasoning ability of large
language models. In 62nd Annual Meeting of the Association for Computational Linguistics, ACL 2024, pages
13679-13707. Association for Computational Linguistics (ACL), 2024.

Francis Jeffry Pelletier and Allen Hazen. Natural Deduction Systems in Logic. In Edward N. Zalta and Uri
Nodelman, editors, The Stanford Encyclopedia of Philosophy. Metaphysics Research Lab, Stanford University,
Spring 2024 edition, 2024.

Daking Rai, Yilun Zhou, Shi Feng, Abulhair Saparov, and Ziyu Yao. A practical review of mechanistic
interpretability for transformer-based language models. arXiv preprint arXiv:2407.02646, 2024.

John T Rickard. A concept geometry for conceptual spaces. Fuzzy optimization and decision making, 5:
311-329, 2006.

Xuan Shen, Yizhou Wang, Xiangxi Shi, Yanzhi Wang, Pu Zhao, and Jiuxiang Gu. Efficient reasoning with
hidden thinking. arXiv preprint arXiv:2501.19201, 2025.

Chandan Singh, Jeevana Priya Inala, Michel Galley, Rich Caruana, and Jianfeng Gao. Rethinking inter-
pretability in the era of large language models. arXiv preprint arXiv:2402.01761, 2024.

Charlie Victor Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. Scaling LLM test-time compute optimally
can be more effective than scaling parameters for reasoning. In The Thirteenth International Conference on
Learning Representations, 2025. URL https: //openreview.net/forum?id=4FWAwZtd2n.

13


[63]

[64]

[65]

[66]

[67]

[68]

[69]

[70]

[71]

[72]
[73]

[74]

[75]

[76]

[77]

[78]

The Geometry of Reasoning: Flowing Logics in Representation Space

Adam Stein, Aaditya Naik, Yinjun Wu, Mayur Naik, and Eric Wong. Towards compositionality in concept
learning. In Forty-first International Conference on Machine Learning, 2024. URL https://openreview.
net/forum? id=up08FUwf 92.

A. S. Troelstra and Helmut Schwichtenberg. Basic Proof Theory. Cambridge University Press, 2nd edition,
2000.

Lucrezia Valeriani, Diego Doimo, Francesca Cuturello, Alessandro Laio, Alessio Ansuini, and Alberto Cazzaniga.
The geometry of hidden representations of large transformer models. Advances in Neural Information Processing
Systems, 36:51234-51252, 2023.

Constantin Venhoff, Ivan Arcuschin, Philip Torr, Arthur Conmy, and Neel Nanda. Understanding reasoning in
thinking language models via steering vectors. In Workshop on Reasoning and Planning for Large Language
Models, 2025. URL https: //openreview.net/forum?id=OwhVWNOBcz.

Xinyi Wang, Alfonso Amayuelas, Kexun Zhang, Liangming Pan, Wenhu Chen, and William Yang Wang.
Understanding reasoning ability of language models from the perspective of reasoning paths aggregation. In
International Conference on Machine Learning, pages 50026-50042. PMLR, 2024.

Yiming Wang, Pei Zhang, Baosong Yang, Derek Wong, Zhuosheng Zhang, and Rui Wang. Embedding trajectory
for out-of-distribution detection in mathematical reasoning. Advances in Neural Information Processing Systems,
37:42965-42999, 2024.

Yiming Wang, Pei Zhang, Baosong Yang, Derek F. Wong, and Rui Wang. Latent space chain-of-embedding
enables output-free LLM self-evaluation. In The Thirteenth International Conference on Learning Representations,
2025. URL https: //openreview.net/forum?id=jxo070B9fQo.

Zihao Wang, Lin Gui, Jeffrey Negrea, and Victor Veitch. Concept algebra for (score-based) text-controlled
generative models. Advances in Neural Information Processing Systems, 36:35331-35349, 2023.

Orion Weller, Michael Boratko, Iftekhar Naim, and Jinhyuk Lee. On the theoretical limitations of embedding-
based retrieval. arXiv preprint arXiv:2508.21038, 2025.

Ludwig Wittgenstein. Tractatus Logico-Philosophicus. Kegan Paul, Trench, Trubner & Co., Ltd., London, 1922.

Yuyang Wu, Yifei Wang, Ziyu Ye, Tianqi Du, Stefanie Jegelka, and Yisen Wang. When more is less: Under-
standing chain-of-thought length in Ilms. arXiv preprint arXiv:2502.07266, 2025.

Yuan Xia, Akanksha Atrey, Fadoua Khmaissia, and Kedar S Namjoshi. Can large language models learn formal
logic? a data-driven training and evaluation framework. arXiv preprint arXiv:2504.20213, 2025.

An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen
Huang, Chenxu Ly, et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388, 2025.

Andy Yang and David Chiang. Counting like transformers: Compiling temporal counting logic into softmax
transformers. In First Conference on Language Modeling, 2024. URL https: //openreview.net/forum?
id=FmhPg4UJ9OK.

Junjie Yao, Zhongwang Zhang, and Zhi-Qin John Xu. An analysis for reasoning bias of language models
with small initialization. In Forty-second International Conference on Machine Learning, 2025. URLhttps:
//openreview.net/forum?id=4HQaMUYWAT.

Tian Ye, Zicheng Xu, Yuanzhi Li, and Zeyuan Allen-Zhu. Physics of language models: Part 2.1, grade-school
math and the hidden reasoning process. In The Thirteenth International Conference on Learning Representations,
2025.

14


The Geometry of Reasoning: Flowing Logics in Representation Space

[79] Yanzhao Zhang, Mingxin Li, Dingkun Long, Xin Zhang, Huan Lin, Baosong Yang, Pengjun Xie, An Yang,
Dayiheng Liu, Junyang Lin, et al. Qwen3 embedding: Advancing text embedding and reranking through
foundation models. arXiv preprint arXiv:2506.05176, 2025.

[80] Zhen Zhang, Xuehai He, Weixiang Yan, Ao Shen, Chenyang Zhao, Shuohang Wang, Yelong Shen, and Xin Eric
Wang. Soft thinking: Unlocking the reasoning potential of llms in continuous concept space. arXiv preprint
arXiv:2505.15778, 2025.

[81] Ziqian Zhong, Ziming Liu, Max Tegmark, and Jacob Andreas. The clock and the pizza: Two stories in
mechanistic explanation of neural networks. Advances in neural information processing systems, 36:27223-
27250, 2023.

[82] Hanlin Zhu, Shibo Hao, Zhiting Hu, Jiantao Jiao, Stuart Russell, and Yuandong Tian. Reasoning by su-
perposition: A theoretical perspective on chain of continuous thought. arXiv preprint arXiv:2505.12514,
2025.

15


The Geometry of Reasoning: Flowing Logics in Representation Space

Contents

1 Introduction
2 Related Work

3 Preliminaries
3.1 Large Language Models .. 1... . ee

3:2 MengerCurvature 2.sew ewe eee bee Ee EEE ew EHH Ee eG

4 Reasoning as Geometric Flows in Representation Space
4.1 Concept Space and Semantic Trajectories... 2... 2. ee
4.2, Representation Spact@« sc eee coe ob EERE ERR R RRR HR EE

4.3 Logic as Differential Constraints on Flow ......... 0.2 ee

5 Formal Logic with Semantic Carriers
5.1 Logic and Natural Deduction System . 2... 1... ee
5.2 DataDesign... 2... ee

6 Play with LLMs
6.1 Experimental Setup... 2... ee
62, Restilts Analysis seus enw ew ete e tees eee HHH HR HOWE EMO eR eee ES

7 Discussion

KR OA

N uw ws

N

Conclusion
Additional Experiments

Symbolic Glossary and Mapping Relations

B.1 Spaces...
B.2 Primarymaps .......... 2,-0.0 eee ee ee
B.3. Reasoning increments and curvature ...........0 00 eee eeee

B.4 Roadmap diagram .... 2... 2.2...

Geometric Foundations of Reasoning Trajectories

C.1 Continuity of Representation Trajectories. .............-.-.-008-

C.2 Menger Curvature .. 1... . ee ee

Data Generation

10

18

18
18
19
20
20

20
21
23

26

16


The Geometry of Reasoning: Flowing Logics in Representation Space

D.1 Prompts for Data Generation. . 2... 2. ee

D.2 Data Examples

17


The Geometry of Reasoning: Flowing Logics in Representation Space
Appendix

A. Additional Experiments

We additionally evaluate LLaMA3 [19] and more Qwen3 [75] models (1.7B, 4B) to test robustness under the same
experimental settings as in Section 6. The results (Figures 3, 4 and 5) confirm that our findings generalize across
model sizes and families.

topic: Network Security

L: By

L:C.

L:D

EE L:D Lc EB LA IE LD Lc LB LA

(a) Position Similarity. (b) Velocity Similarity. (c) Curvature Similarity.

Figure 3: Similarity of reasoning flows on Qwen3 1.7B.

lopic: Network Security

L: B.

LeG:

LE LD Lc LB LA

(a) Position Similarity. (b) Velocity Similarity. (c) Curvature Similarity.

Figure 4: Similarity of reasoning flows on Qwen3 4B.

B. Symbolic Glossary and Mapping Relations

This section is a standalone roadmap that summarizes the spaces, maps, and commutative structure underlying
our geometric view of reasoning.

B.1. Spaces

¢ Input space 7 (often specialized to a vocabulary V): discrete tokens/sentences.

18


The Geometry of Reasoning: Flowing Logics in Representation Space

gylopic: Network Security

L: A:

L: B.

Li

L:D

LE LD Lc LB LA KEE L:D L:c L:B LA leek L:D Lc L:B LA

(a) Position Similarity. (b) Velocity Similarity. (c) Curvature Similarity.

Figure 5: Similarity of reasoning flows on Llama3 8B.

* Concept space C: abstract semantic space. A sentence X is represented by a smooth semantic trajectory

where M is a semantic submanifold for a coherent domain of meaning.
* Representation space R C R*@: the model’s embedding space. Each prefix X; yields

sampling a continuous representation trajectory V : [0,1] = R¢.

Formal logical space £4.;:.: symbolic/human logic governed by a natural deduction system ND = (F,R),
with formulas F and rules R. Judgements [+ » and rule-based derivations live here.
Representation-based logical space C,,.,,: the space of reasoning increments in the embedding space, defined
by local variations of the trajectory, Ay; := y:+1 — yz. Geometric descriptors such as the Menger curvature kK;
are evaluated here. This space is non-symbolic, and serves as the model’s internal analogue of logic.

B.2. Primary maps

¢ Semantic interpretation:
[: X > Curves(C), XH x.

Neural representation:
UW: X > Curves(R),

realized by token embeddings € and a contextual encoder ®, producing the continuous trajectory V and
sampled states Y = (y1,..., yr).
Canonical Alignment.

Definition B.1 (Canonical alignment map). Assume S and W are injective on the domain of interest. Define
A:=WoI™!: Curves(C) > Curves(R).

Then A is a bijection between semantic curves and representation trajectories, and the top-level diagram commutes
exactly:
AoT=VW,

19


The Geometry of Reasoning: Flowing Logics in Representation Space

Flow vs. differential to logic. We distinguish a human flow operator on concepts from a differential operator on
representations:

Fe : y+ (human reasoning flowin C) € Leorm, Dr: UK (Ay) € Lreps

The left operator Fe is not a discrete difference; it encodes how a semantic trajectory induces formal reasoning
steps under ND. The right operator Dz extracts local increments from the representation trajectory.

B.3. Reasoning increments and curvature

¢ Formal side (concepts). Human reasoning flow is captured at the semantic level by Fc, which maps a
semantic curve y into a sequence of formally valid steps in Lorn per the rules ND.

¢ Representation side (vectors). The local increment Ay; = y:11 — yz encodes a step of representation flow
I Lreps

¢ Curvature as geometric intensity. For three consecutive states (y:_1, ¥:, ¥z+1), the Menger curvature

2,/1 — CosSim(u, v)?
Vera — Ye—all

couples angular change with scale, providing a geometry-aware proxy for the “strength” of a reasoning step
in the representation.

Ke = Cm (Yt-1, Yt, Yeti) = > Ui= Ye — Ye-1, V = Yt41 — Ye,

B.4. Roadmap diagram

The overall structure can be read from the commutative roadmap below. Here 4 sits at the center; semantic and
representation curves live to the left and right; formal and representation-based logics sit below. The top arrow is
strict by definition of A; the vertical arrows express how each curve induces its respective notion of reasoning.

x
i wv
Curves(C) i > Curves(R)
Fe Dr
Liorm Lrep

Reading guide. (1) Input sequences branch into a semantic curve (left) and a representation curve (right). (2)
The canonical alignment A = Uo S~! identifies the two curves one-to-one. (3) The semantic curve induces human,
rule-constrained steps in Lform via Fe, while the representation curve induces vector increments in L,., via Dr.
(4) Curvature in £,., quantifies the geometric intensity of reasoning transitions and can be related back to formal
steps under appropriate correspondences established elsewhere in the paper.

C. Geometric Foundations of Reasoning Trajectories

In this section, we establish the geometric foundations for analyzing reasoning as smooth flows in representation
space. We first construct representation trajectories as C! curves via a relaxed prefix-mask mechanism, thereby
justifying smoothness as a working principle. Then, we introduce Menger curvature as a computable descriptor
that couples angular deviation with distance variation, providing a principled measure of the intensity of reasoning
turns.

20


The Geometry of Reasoning: Flowing Logics in Representation Space

C.1. Continuity of Representation Trajectories

In this section, we provide a rigorous and explicit construction of a C' trajectory using a relaxed prefix-mask
mechanism. This construction justifies our working assumption that representation trajectories are C'. Note that
the symbol Z (Definition 3.2) is defined with a slight variation compared to main paper: here it is specialized to
encode positional information, while the remaining complexities of the model architecture are subsumed into a
single mapping ®.

Definition C.1 (Neural Encoding View of Sentence Representation). Let x = (u1,..., Un) be a sentence with tokens
u; drawn from a vocabulary space V. Define an embedding map

E: VOR, uj > E(us),

which assigns each token a d-dimensional vector. Augmenting E(u;) with positional information yields the input
sequence
zo = (E(u), E(u2),-.-,E(un)) € (R*)”.

Let ® : (R?)" x Z — R®@ denote a contextual encoder that maps a sequence of token embeddings together with
positional information to a global sentence-level representation, where T is the positional encoding space and T,, C T
denotes the set of encodings for the first n positions. For a fixed t = (t1,...,4n) € In, we define

U(x) := O(20,in) = B(E(ur),...,E(un), +) € R*

In this view, WV subsumes both the static token embeddings and the contextual transformations carried out by the
neural network.

Hence the hidden state y, = V(.S;) in Definition 4.5 should be interpreted not merely as a sum of embeddings, but
as the outcome of the full encoding process applied to the prefix S;.

Mask-aware realization (for later use). Fix a maximum length N > n and consider the mask-aware realization of the
same encoder,
®, : (R®)* x In x {0,1}% > R¢,

such that for any length n < N,

®n ((E(ur), ...,E(Un),0,...,0,6), Lyi<n}) = ®(E(u1), ...,E(Un), (Lricn}li)nei)-
When the mask is all ones on {1,...,n}, this coincides with the above definition; when we pass a mask explicitly we
will write ®(-, M).

Hypothesis C.2 (Smooth Trajectory Hypothesis). The sequence of representations y, = U(X;) generated during a
reasoning process lies on a smooth, differentiable trajectory in the embedding space.

Definition C.3 (Relaxed-Mask Sentence Representation). Let each sentence in Hypothesis 4.4 be x, = (ui,1,---, Ut,nz)
fort =1,...,T7, and let the full token stream be

Ui:n = (u1j1, oe) U1ynq) U2,15+++5U2n25+++, UT I++ UT np)

t

with total length N = yy nz and cumulative lengths N; = >7,

s € [0, 1] and a relaxed prefix mask

~1 2j- Introduce a continuous progress parameter

m,:{1,...,N}— [0,1],
which specifies the fractional inclusion of each token at progress s.

Using the embedding map € and positional information Ty from Definition C.1, define the masked input sequence
at progress s by

z= (ms(i)E(ui)) 4, = (ms(i) us)

21


The Geometry of Reasoning: Flowing Logics in Representation Space

and the associated hard mask
M,(i) = Lim. @=1}) 7=1,...,N.

Let k(s) := [sN], denote the number of tokens included at progress s. The truncated masked sequences are then defined
as

2fS*) = (z,(1),...,25(k(s))) € (RY*, u8(S*) s— (48(1),...,08(k(s))) € ZF).

With the mask-aware encoder ®,,, : (R“)N x ZN x {0,1}% — R? introduced above, the continuous representation
trajectory is defined by

U(s) := ®m(z5,0°, Ms) € R¢, where ®,,(z5,1°, Ms) = B(2{S"), ge(Sk))

At sentence boundaries s; := N,/N, the hard prefix mask is recovered exactly by choosing a smooth function with
flat tails (ee Proposition C.4); consequently,
yr = U(S;) = (25,0, My,) = U(s:),  t=1,...,T.
Proposition C.4 (Continuity of the Relaxed-Mask Trajectory). Suppose the relaxed mask takes the form
ms(t) = g(sN — 4),
where g € C™(R) satisfies g(x) = 0 for x < —6, g(x) = 1 for x > 6, with some 0 < 6 < $ (ie., a smoothstep/bump

with flat tails). Assume the encoder ® is C+. Then the mapping W : [0,1] > R@ defines a C! trajectory in embedding
space. Moreover, the discrete sentence embeddings (y;)/_, are exactly samples of this trajectory at s; = N;/N:

ys = V(s), t=1,...,T.

Proof. For each token U;, we define the masked embedding and positional encoding as

Since g is C™ and both €(U;) and v; are constant in s, each coordinate pair (z,(7), v°(i)) varies smoothly with s.
Hence the entire masked sequence

(z.,0°) = (z5(1),---,2s8(V); u°(1),...,e°(N))

is a smooth trajectory with respect to s. The mask M,(i) = 14, (:)=1; is piecewise constant in s and equals the
all-ones indicator on indices where sN — i > 6, and zeros where sN — i < —6; in particular, it is locally constant
on neighborhoods that avoid the transition band |sN — i| < 6.

By assumption, ® is a composition of affine maps, matrix multiplications, LayerNorm, residual connections,
softmax attention, and smooth pointwise nonlinearities. As a function of its inputs, such a network is smooth; thus,
on any interval where M, is fixed, the composite map

U(s) = ®(z.,0°, Ms)
is C! by the chain rule.

At sentence boundaries s; = N;/N, choose 6 < $ so that g(N; — i) = 1 fori < NM; and g(N; — 2) = 0 for
i> N, +1. Hence ms,(z) € {0,1} exactly and M,,(i) = 1,;<y,}. Substituting into the definition,

U(s:) = ®((E(U1),.-.,E(Uw;),0,---,0,0), Len.) = U(St) = ye,

which shows that the discrete embeddings (y,)!_, are precisely samples of the continuous trajectory (s).

22


The Geometry of Reasoning: Flowing Logics in Representation Space

Remark C.5. Since ®(-) implemented with affine maps, matrix multiplications, LayerNorm, residual connections,
softmax attention, and smooth pointwise nonlinearities (e.g., GELU/SiLU/Swish), it’s reasonable to assume that is C’.
If ReLU activations (or other piecewise smooth nonlinearities) are used instead of smooth ones, the mapping WV remains
continuous and is differentiable almost everywhere. Since this does not affect the manifold-level geometric reasoning,
we idealize ® as smooth throughout our discussion.

The construction above is merely one possible realization of a continuous and C! trajectory V(s). In fact, many
alternative constructions are possible. This abundance of realizations justifies our assumption that the sentence U(X 7),
through its step-by-step variations, can be viewed as T points lying on a smooth, differentiable curve. On this basis, we
can consistently define the notion of flow velocity in Definition 4.9.

C.2. Menger Curvature

Definition C.6 (Menger Curvature). Let 71, 72,73 € R” be three distinct points. The Menger curvature of the triple
(a1, £2, x3) is defined as the reciprocal of the radius R(x1, x2, x3) of the unique circle passing through the three points:

1

9 |

Proposition C.7 (Computation Formula). Let a = ||x2 — x3||, b = ||a1 — ||, and c = ||a1 — x2]. Denote by
A(a1,%2, x3) the area of the triangle spanned by the three points. Then the circumradius R and the Menger curvature
c(@1,%2, v3) are given by

abc 4A (a1, 22,23)

R(x, 22,23) =
Proof. The formula follows from classical Euclidean geometry: for a triangle with side lengths a,b,c and area A,

the circumradius satisfies R = he Taking the reciprocal yields the Menger curvature.

Figure 6: Circumcircle through three points x), x2, #3, with radius R and Menger curvature 1/R.

Proposition C.8 (Menger curvature from three consecutive states). Let y—1, y, yr+1 € R@ be three distinct points
and set

U := Yt — Yt-1, VU S= Yt+1 — Yt-

Write the side lengths

a=|ull, b=llel], ¢= llo— ull = lycra — yea

23


The Geometry of Reasoning: Flowing Logics in Representation Space

s

1 Center’ \

I
t
t
1
i) \
1
1
\

t
‘ Center
1
1
1

Figure 7: Two circumcircles through {y:-1, yz, ys} and {yz-1, Yt; yr}, with radii R and R’. Here yi? and yi?
lie on the same ray from 1.

The Menger curvature of the triple (y:—1, yz, Ye+1) equals

4 A(Yt—15 Yi Yera) _ 2,/1 — CosSim(u, v)?
abe Yer — Ye—-all

CM (Yt—-15 Yt» Yer) =

3

where CosSim(u, v) := a (If the three points are collinear, cyy := 0.)

Proof. By classical Euclidean geometry, for a triangle with side lengths a, b,c and area A, the circumradius satisfies
b 4A
R=—~< The Menger curvature is the reciprocal cy; = 1/R = —.
4A abc
It remains to express A in terms of u and v. The (unsigned) area of the triangle spanned by u and v can be
written in a dimension-independent way via the Gram determinant:

A = Flurl = jae seas) = gw MPTP = (eso

speed . 4A,
Substituting a = ||ul|, b = ||v||, ¢ = ||v — ul] into cv = abe BIVes
abc

_ 2y/|lullPllell? = (u,v)?

lull [lel lo — eI

CM

(u,v)
lel ell

Divide the numerator and denominator by ||u|| ||v|| and denote s := CosSim(u, v) =

24


The Geometry of Reasoning: Flowing Logics in Representation Space

2/1 — s _ 2sind

— |v-ull oe

CM

?

where 6 is the angle between wu and v (so sin@ = V1 — s?). If the three points are collinear, A = 0 and hence
cv = 0, consistent with the convention. This proves the claim.

Remark C.9. As illustrated in Figure 7, using the Menger curvature instead of cosine similarity is significant. Cosine
similarity only depends on the angle at y:, so the two triples {y:—1, yt, yer} and {y1-1, Yt; ys} would look identical.
In contrast, their circumradii R and R’ are different, hence the Menger curvatures distinguish two different curvature
regimes. This demonstrates how Menger curvature captures both angle and length information, enabling discrimination
that cosine similarity alone cannot provide.

25


The Geometry of Reasoning: Flowing Logics in Representation Space

D. Data Generation

We provide the exact prompt templates and the representative sampled data instances used in our data generation
process. The two-stage pipeline is run with GPT-5.

D.1. Prompts for Data Generation

The following prompts are used for abstract logical templates construction and domain-specific and language-specific
rewriting.

Prompt for Logic Pattern Generation

You are a formal logic pattern generator.

Goal: Create an abstract, domain-agnostic reasoning sequence of exactly N steps, written in symbolic form,
using standard propositional/first-order logic notation.

Strict output format:

e Exactly N lines, each line starts with a bracketed index and a single formula or conclusion, e.g.:

[1] A ->B

[2] B->C

[3] © -> D

[4] (D& E) >> F

[5] forall x(H(x) -> J(x))

[6] A

[7] E

[8] H(a)

[9] D (from [1-3] and [6])

[10] F & J(a) (from [4],[7],[5],[8],1[9])

Use only symbols from: =, A, V,—,<,V, i, parentheses, predicate letters with uppercase (A,B,C.,...)
and predicate symbols like H(x), J(x).

You may include brief justifications at the end of lines in parentheses referencing earlier step indices
(e.g., (from [2] and [5])).

The sequence must be internally coherent (later steps can be derived from earlier ones), but no proof
of a fixed target is required.

No extra commentary before or after the lines. No natural-language sentences.

Parameters (provided by caller):

¢ N: number of steps to output.
¢ logic: a label for this abstract logic (optional).

N = {N}
logic = {logic}
Now produce exactly N lines.

26


The Geometry of Reasoning: Flowing Logics in Representation Space

Prompt for Reasoning Rewriter

You are a reasoning rewriter.

Task: Given an abstract N-step reasoning scaffold (formal symbolic lines) and a target topic, rewrite the
scaffold into a topic-specific natural-language reasoning sequence with exactly the same number of steps
and the same dependency structure.

Inputs (provided by caller):

¢ Topic: the target domain (.g., weather, software).
* Abstract Steps (1..N): the neutral scaffold, numbered 1..N.
¢ N: the total number of steps.

Output requirements:

* Produce exactly N steps, each line begins with the same bracketed index as the abstract: [1]
[N]
Keep step count and ordering identical to the abstract. Do not merge, split, add, or remove steps.
Preserve the logical dependencies: if abstract step k enables k+1, your rewrite must preserve that
relationship in the topic.
Use concrete domain terms appropriate to the topic, but keep sentences concise and precise.
No extra commentary before or after the steps.

Multilingual mode (when Languages: are specified by the caller):

¢ Create a separate section for each requested language code.

¢ Each section starts with a header line === <code> === (€.g., === en ===).

* Under each header, write the N steps with bracketed indices [1] ..  [N] in that language.
¢ Keep the content aligned across languages (same meaning per step index).

Inputs you will receive:

Topic: {topic}

Abstract Steps (1..N): {ABSTRACT STEPS}
N = {N}

Now perform the rewrite.

D.2. Data Examples

Table 2 presents a 9-step logical scaffold from our dataset. We illustrate its instantiation in two distinct domains,
weather and finance, providing the corresponding statements in both English (EN) and German (DE).

27


The Geometry of Reasoning: Flowing Logics in Representation Space

Table 2: Logic Example (9-Step) with Weather and Finance Topics in English and German

Abstract Logic Topic: Weather Topic: Finance
[lJ A> B EN: If moisture converges over the city, then __ EN: If the firm’s interest coverage ratio exceeds 3.0x,
thunderclouds develop. then the firm is deemed able to meet interest
DE: Wenn tiber der Stadt Feuchte obligations.
konvergiert, dann bilden sich DE: Wenn die Zinsdeckungskennzahl des
Gewitterwolken. Unternehmens iiber 3,0x liegt, dann gilt das
Unternehmen als fahig, Zinszahlungen zu leisten.
[2] BoC EN: If thunderclouds develop, then heavy EN: If the firm is deemed able to meet interest
rain occurs. obligations, then the bank will approve a new term
DE: Wenn sich Gewitterwolken bilden, dann loan.
tritt starker Regen auf. DE: Wenn das Unternehmen als fahig gilt,
Zinszahlungen zu leisten, dann wird die Bank ein
neues Laufzeitdarlehen genehmigen.
[3] Vx(H (x) > EN: For any location x, if a cold front passes _ EN: For any security x, if x is a U.S. Treasury, then x is
J(x)) x, then temperatures drop at x. acceptable as repo collateral.
DE: Fir jeden Ort x gilt: Wenn eine Kaltfront DE: Fiir jedes Wertpapier x gilt: Wenn x eine
x tiberquert, dann sinkt dort die Temperatur. US-Staatsanleihe ist, dann ist x als Repo-Sicherheit
zulassig.
4| H(a) EN: A cold front is passing the airport. EN: Bond A is a U.S. Treasury.
DE: Eine Kaltfront tiberquert den Flughafen. DE: Anleihe A ist eine US-Staatsanleihe.
5] A EN: Moisture is converging over the city. EN: The firm’s interest coverage ratio exceeds 3.0x.
DE: Uber der Stadt herrscht DE: Die Zinsdeckungskennzahl des Unternehmens
Feuchtekonvergenz. liegt tiber 3,0x.
6] B (from [1], [5]) | EN: From [1] and [5], thunderclouds EN: The firm is deemed able to meet interest
develop. obligations (from [1] and [5]).

DE: Aus [1] und [5] folgt, dass sich
Gewitterwolken bilden.

DE: Daher gilt das Unternehmen als fahig,
Zinszahlungen zu leisten (aus [1] und [5]).

[7] C (from [2], [6])

EN: From [2] and [6], heavy rain occurs.
DE: Aus [2] und [6] folgt, dass starker Regen
auftritt.

EN: The bank will approve a new term loan (from [2]
and [6]).

DE: Daher wird die Bank ein neues Laufzeitdarlehen
genehmigen (aus [2] und [6]).

[8] J(a) Grom [3], [4])

EN: From [3] and [4], temperatures drop at
the airport.

DE: Aus [3] und [4] folgt, dass am Flughafen
die Temperatur sinkt.

EN: Bond A is acceptable as repo collateral (from [3]
and [4]).

DE: Daher ist Anleihe A als Repo-Sicherheit zulassig
(aus [3] und [4]).

[I]CA
J(a) (from [7], [8])

EN: From [7] and [8], heavy rain occurs and
temperatures drop at the airport.

DE: Aus [7] und [8] folgt: Es tritt starker
Regen auf und am Flughafen sinkt die
Temperatur.

EN: The bank will approve a new term loan and Bond
A is acceptable as repo collateral (from [7] and [8]).
DE: Somit wird die Bank ein neues Laufzeitdarlehen
genehmigen und Anleihe A ist als Repo-Sicherheit
zulassig (aus [7] und [8]).

28
