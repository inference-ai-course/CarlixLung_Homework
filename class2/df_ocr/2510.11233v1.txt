arXiv:2510.11233v1 [cs.CL] 13 Oct 2025

CNSocialDepress: A Chinese Social Media Dataset for Depression Risk
Detection and Structured Analysis

Jinyuan XU!", Tian LAN?", Xintao YU*, Xue HE**, Hezhi ZHANG?, Ying WANG‘,
Pierre Magistry', Mathieu Valette!, Lei LI’*"

' Ertim Inalco, * Milkuya Studio, ? Sorbonne Université, * IRD Lab
> Faculty of Psychology, Peking University
® Faculty of Psychology and Cognitive Science, Beijing Normal University
7 University of Washington, ® VitaSight

Abstract

Depression is a pressing global public health
issue, yet publicly available Chinese-language
resources for risk detection remain scarce and
are mostly limited to binary classification. To
address this limitation, we release CNSocialDe-
press, a benchmark dataset for depression risk
detection from Chinese social media posts. The
dataset contains 44,178 texts from 233 users,
within which psychological experts annotated
10,306 depression-related segments. CNSo-
cialDepress provides binary risk labels together
with structured multi-dimensional psycholog-
ical attributes, enabling interpretable and fine-
grained analysis of depressive signals. Exper-
imental results demonstrate its utility across
a wide range of NLP tasks, including struc-
tured psychological profiling and fine-tuning
of large language models for depression de-
tection. Comprehensive evaluations highlight
the dataset’s effectiveness and practical value
for depression risk identification and psycho-
logical analysis, thereby providing insights to
mental health applications tailored for Chinese-
speaking populations.

1 Introduction

Depressive disorders are among the most common
mental health conditions worldwide, characterized
by persistent low mood or loss of interest in daily
activities. According to a 2023 report! by the
World Health Organization (WHO), approximately
280 million people globally suffer from depression.
In China, a 2024 survey by the Chinese Center
for Disease Control and Prevention (Wang et al.,
2024a) estimates that around 95 million individuals
are affected by depression, and out of the 280,000
suicides reported annually, 40% are linked to de-
pressive disorders. Moreover, research (Wang et al.,
--* These authors contributed equally to this work.
+ Corresponding Author.

‘https ://www.who. int/news-room/fact-sheets/
detail/depression

2024a) shows that depression strongly correlates
with both suicidal and non-suicidal self-injurious
deaths.

Motivated by the urgent need for the detection of
depression, researchers increasingly apply machine
learning (ML) and natural language processing
(NLP) methods for automated analysis of depres-
sion risk (Squires et al., 2023; Hasib et al., 2023;
Aleem et al., 2022). While early efforts have shown
promising results, they are heavily constrained by
the limitations of existing datasets. Traditional de-
pression detection studies often rely on clinical
data(Bittar et al., 2019; Fernandes et al., 2018), or
on transcripts from medical or psychological inter-
views resources (Shen et al., 2022; Li et al., 2022)
that are are expensive to collect, limited in size and
diversity, and may not reflect the informal, emo-
tionally nuanced expressions typical of real-world
online environments.

To overcome these limitations, recent research
has shifted toward leveraging user-generated con-
tent on social media platforms? (Harrigian et al.,
2021), which provides rich linguistic signals and
greater availability. Such data are also more eas-
ily anonymized, alleviating some privacy concerns.
Beyond these methodological advantages, social
media itself has become an emotional outlet for
many individuals, especially in East Asian contexts
(Yang and Li, 2009; Zhou et al., 2023), where per-
sonal emotions are more freely expressed online
rather than in face to face settings. Social media
serves as a critical outlet for emotional expression,
potentially offering richer and more authentic lin-
guistic data for depression analysis.

However, most existing datasets are in English
and focus solely on classification with binary or
multi-class labels, lacking structured psychologi-
cal insight or professional validation. (Cai et al.,

*https://github.com/bucuram/
depression-datasets-nlp


2023; Wang et al., 2020; Li et al., 2020). Moreover,
with the emergence of generative models applied
to mental health (Hu et al., 2024; Xu et al., 2024;
Lai et al., 2023; Yang et al., 2024), many scholars
in psychology and computational linguistics now
emphasize the need for datasets combining risk
labels with structured analyses, such as user pro-
files or survey-based explanations. Such datasets
align more closely with real-world settings, where
multi-faceted insights are helpful for clinical inter-
vention.

Some recent efforts have introduced summariza-
tion style datasets for depression, leveraging infor-
mation extraction and automated summarization
techniques (Sotudeh et al., 2022, 2021). However,
these datasets usually rely on model generated con-
tent validated by automatic metrics (e.g., ROUGE
(Lin, 2004)) and typically lack professional mental
health annotation, raising concerns about domain-
specific reliability and accuracy.

To address these challenges, we introduce
(CNSocialDepress, the first publicly available
Chinese-language dataset for depression risk de-
tection that integrates binary risk labels with struc-
tured psychological analyses. All annotations are
drafted and validated by certified mental health
experts, ensuring both domain relevance and anno-
tation quality. CNSD is designed to support multi-
ple task paradigms, including binary classification,
generation of structured analyses, summarization,
and fine-tuning of large language models (LLMs)
for psychological reasoning.

Our contributions are fourfold:

e We construct a high-quality Chinese dataset
that bridges the gap between classification and
interpretable analysis in depression detection,
and supports a wide range of tasks including
binary classification, generation of structured
psychological analyses, summarization, and
fine-tuning of large language models.

¢ We design a robust annotation and generation
pipeline involving professional experts and
structured templates;

e We conduct extensive experiments demon-
strating that CNSD enables effective training
and evaluation of LLM-based methods across
diverse depression-related tasks.

¢ We propose and validate a robust pipeline for
generating structured psychological analyses
in the context of depression risk (Section 4).

2 Related Work

2.1 Existing Datasets for Depression Detection

Current depression detection datasets primarily
come from English-language social media plat-
forms like Twitter, Reddit, Facebook, and Insta-
gram (Shen et al., 2017; Parapar et al., 2022; Zhang
et al., 2021; Raihan et al., 2024). Annotation meth-
ods include self-disclosure identification (Yates
et al., 2017; Bathina et al., 2021; Islam et al.,
2018), manual coding by clinical raters (Almouzini
et al., 2019; Yazdavar et al., 2020; Alhamed et al.,
2024), and symptom mapping (Seabrook et al.,
2018; Aldarwish and Ahmad, 2017; Zhang et al.,
2022) based on DSM (American Psychiatric As-
sociation et al., 2000) and PHQ (Kroenke et al.,
2001). While most datasets use binary classifica-
tion, others incorporate severity scales or symptom-
specific tagging (Zhang et al., 2022; Mowery et al.,
2017). Multilingual resources for depression de-
tection exist for Spanish (Romero et al., 2024),
Arabic (Maghraby and Ali, 2022), Russian (Stanke-
vich et al., 2020), Portuguese (Santos et al., 2024),
Japanese (Yuka Niimi, 2021), and Thai (Hamalai-
nen et al., 2021). For Chinese, Sina Weibo is the
primary source (Li et al., 2020; Shen et al., 2018;
Li et al., 2023; Guo et al., 2023; Yang et al., 2021),
with datasets like WU3D (Wang et al., 2020) and
SWDD (Cai et al., 2023) commonly used.

2.2 Methodological Advancements

Early methods in depression detection used statisti-
cal approaches like TF-IDF and feature engineer-
ing (Yang et al., 2020) along with traditional ma-
chine learning classifiers (Cortes, 1995; Li, 2024;
Breiman, 2001; McCallum et al., 1998; Dreiseitl
and Ohno-Machado, 2002; Li et al., 2024; Shi et al.,
2024). With the rise of neural networks (Schmidhu-
ber, 2015), deep learning models such as Word2Vec
(Mikolov et al., 2013), LSTM (Sak et al., 2014),
CNN (Kim, 2014), Transformer (Vaswani, 2017),
and BERT (Devlin et al., 2019) improved the de-
tection of depression. Recently, large language
models (LLMs) have been applied to depression
detection tasks due to their ability to generate la-
bels and provide interpretable analyses (Lan et al.,
2024; Hu et al., 2024; Xin Yan, 2023; Lai et al.,
2023). These models enhance explainability in
mental health analysis (Wang et al., 2024c; Yang
et al., 2024; Xu et al., 2024; Yang et al., 2023; Hu
et al., 2024; Xu et al., 2024).


Selection of user

a>

SWDD Dataset (binary label)

Negative Users

Annotation process

Positive Users (self-reported)

Annotation Guideline we) oe

Selection of user

=>

116 Positive Users 117 Negative Users

Our summarization Cross Validation i
Dataset with 6 Dim Update Annotation Guideline Psychological Experts

Figure 1: Dataset Construction Process: During the data annotation process, we used a subset of the original SWDD
dataset for labeling, which included 116 Positive (Depressive) users and 117 Negative users. Psychologists used
rating scales based on the DSM-5 and the statistical results of the dataset’s text to formulate an initial labeling
guideline. Then, during the psychologists’ labeling process, random sampling was continuously performed for cross
validation, and the labeling standards were continuously updated based on the annotation outcomes. Ultimately, the
labeled gold-standard data was obtained, with each user containing a six-dimensional structural analyses summary.

2.3. Summary and Gaps

Despite existing efforts, current datasets rarely in-
clude structured psychological analysis, especially
for non-English social media content. Furthermore,
available resources often lack professional mental-
health annotation, limiting their practical utility.
This study addresses these limitations by presenting
the first expert-validated Chinese-language dataset
featuring detailed structured annotations, thereby
providing richer resources for depression-risk de-
tection and analysis.

3 Construction of Dataset

Our raw data are derived from the SWDD dataset
(Cai et al., 2023), a user-level dataset collected
from Sina Weibo, the world’s largest Chinese-
language social media platform. This dataset com-
prises two categories of users (depressed and non-
depressed), each user has between dozens and hun-
dreds of Weibo posts. The dataset, which is labeled
as either depressed or non-depressed, also contains
user-level depression feature annotations provided
by experts in accordance with the DSM-5* (Ameri-
can Psychiatric Association et al., 2000) reference
standards.

From this SWDD dataset, we have 116 self-
reported depressed (positive) users and 117 non-
depressed (negative) users to form the candidate

3https://www.psychiatry.org/psychiatrists/
practice/dsm/educational-resources/
dsm-5-fact-sheets

samples for our dataset. Each selected user has at
least 60 posts, and the total token count for each
user’s posts is no fewer than 3,000 tokens’.

To guide the annotation process, a group of psy-
chology experts formulated a preliminary annota-
tion standard based on the DSM-5 diagnostic cri-
teria, the PHQ-9 scale (Kroenke et al., 2001), and
prior research on linguistic features indicative of
depression in online texts (Mothe et al., 2022).

Criteria involving objective factual statements
(e.g., clinical symptoms, medical records, self-
reports) with stronger diagnostic specificity are
designated as Primary Criteria, while criteria based
on subjective linguistic or emotional expressions
(e.g., negative phrasing, emotional intensity) with
weaker specificity are designated as lower-weight
Secondary Criteria, and the hierarchical classifi-
cation follows clinical diagnostic principles that
prioritize objective symptoms over subjective per-
ceptions. This standard comprises six depression
dimensions:

¢ Dimension 1: Depressive Psychological
State (primary criterion). At its core, this
category reflects a loss of self-worth, over-
whelming guilt, and suicidal ideation. Rep-
resentative semantic segments include Inferi-
ority, Sorry, Death, Self-harm, Wrist cutting,
Suicide, etc.

¢ Dimension 2: Depression-Related Medical

4Qwen2.5’s tokenizer


Expressions (primary criterion). Focusing
on expressions linked to medication usage and
psychological diagnoses, this category cov-
ers terms such as Take medication, Venlafax-
ine, Side effects, Depression, Anxiety disorder,
Hospital, Doctor, Disease, etc.

Dimension 3: Depression-Related Clinical
Symptoms (primary criterion). Address-
ing physiological and somatic alterations, in-
cluding changes in weight or appetite, dis-
turbed sleep patterns, fatigue, and various
forms of physical pain, this dimension in-
cludes semantic segments such as Appetite,
Insomnia, Sleeping pills, Nightmare, Tired,
Headache, Stomachache, among others.

¢ Dimension 4: Negative Emotions (sec-
ondary criterion). Encompassing a broad
array of adverse emotional states, this part
presents examples such as Torment, Abyss,
Hell, Sad, Grieve, Anxious, Depressed,
Lonely, Despair, etc.

¢ Dimension 5: Potential External Causes of
Depression (secondary criterion). Highlight-
ing possible triggers like marital or intimate
relationship issues, family conflicts, signifi-
cant social events, and everyday stressors, this
segment comprises semantic units including
Divorce, Parents, College entrance examina-
tion, School, Teacher, Poor, Drop out, etc.

¢ Dimension 6: Depression-Related Patterns
of Language Use (secondary criterion). Em-
phasizing particular linguistic patterns, such
as negations, interrogatives, and derogatory
expressions. This category includes illustra-
tive semantic segments like J don’t know, I
don’t like me, I really don’t want to, I can’t do
it, why, and what should I do?, among others.

The annotation work was carried out by four
senior researchers, each with substantial research
experience in psychology, specializing in depres-
sion scales. Using an internally developed anno-
tation platform, they identified specific depression
dimensions present in each post, along with the
corresponding semantic segments. Throughout this
process, the annotators periodically performed ran-
dom cross-validation to ensure reliability and con-
sistency. Because this annotation task relies on
qualitative rather than quantitative metrics, the an-
notation schema was updated as needed, informed

Data Sample

User id: user 192

User posts:
GST 1: "RAM T", WHS 2: "ARAB T " ....
post1: 'I lost my job’, post2: 'I want to die’ ....

Label:
FB Depressed

Dim 1:

Bat: "FEDS BRS (MamiRA"
Overall Assessment: ‘Significant self-destructive
tendencies and loss of self-worth'

FBAMAX: post28 [X47 TARAAE], post48 (SAA
Post Selections: post28 [despair about life], post48
[today is sad] ...

Dim 6:

BAT: "Sehr Bers awn"
Overall Assessment: 'Frequent use of oxymoronic
rhetoricand self-deprecation'

FBAMA: post4[AB/)\92], postSs[HARBE]...
Post Selections: post4 [coward], post58 [self-
denial] ...

Figure 2: Example entry from the CNSD-Gold dataset

by real-time feedback from the annotated texts and
discussions among experts. During the annotation
process, the expert annotators did not refer to the bi-
nary labels from the original dataset, consequently,
some of the depression risk labels may differ from
those in the original data set.

This rigorous process produced the CNSD Gold
dataset (100 positive and 100 negative users) and
the CNSD Test dataset (16 positive and 17 negative
users). The dataset construction process can be
referenced in Figure 1.

Each entry as shown in Figure 2 comprises two
parts: a binary depression label and a detailed,
dimension-specific analysis. For each dimension,
the analysis includes an overall assessment and a
list of post numbers with brief justifications for
their selection.

The overall statistics are presented in Table 1,
with a total of 10,306 dimension-level annotations
summarized in Table 2.

4 Automated Dataset Generation Pipeline

Due to the substantial human effort and profes-
sional psychological expertise required for dataset
annotation, user-level depression risk datasets


Positive Negative
(Depressive) (Non-depressive)
Number of Users 116 117
Number of Texts 20,360 23,818
Number of Tokens 1,024,978 1,115,951

Table 1: Dataset Statistics.

Dimension Negative User Positive User
Dim! 117 2127
Dim2 2 555
Dim3 126 768
Dim4 514 2933
Dim5 193 863
Dim6 231 1877
Total 1183 9123

Table 2: Dimension Annotation Statistics for Negative
and Positive Users: This table shows the statistics of
depression repeated segments marked by psychological
experts across different dimensions. A text may contain
multiple depression repeated segments.

based on social media remain scarce in the Chinese
domain. To address this gap, we developed an au-
tomated dataset generation pipeline. This pipeline
was used to create the CNSD Silver dataset by pro-
cessing the SWDD binary classification dataset,
leveraging insights from the manually annotated
CNSD Gold dataset (described in Section 3). For
the construction of CNSD Silver, we randomly
selected 100 positive (depressive risk) users and
100 negative (non-depressive risk) users from the
SWDD dataset. Each user contributed between sev-
eral dozen and several hundred posts, totaling more
than 3,000 tokens per user.
The pipeline consists of two main modules:

4.1 Module I: Dimension-Wise Automatic
Labeling

This module uses a smaller model (Qwen2.5-14B
(Bai et al., 2023)) to automatically annotate texts
across six depression-related dimensions (D =
{Di, D2,...,De}). The model is first fine-tuned
on carefully curated text-level data derived from
the positive users in CNSD Gold, enabling it to
assign each individual text to one or more of these
six dimensions.

Data Preparation for Fine-tuning Module I
Model:

1. Texts from positive users in CNSD Gold con-
taining depression-related semantic segments
for each dimension D;, were extracted, form-
ing sets Sz.

2. The dimension with the fewest samples
(Mmin = 442, corresponding to "depression-
related medical expressions") was identified:

min

Np = 442
kE{1,2,...,6}

min =

3. To balance data across dimensions, texts for
each dimension D;, were downsampled to
Nmin if NZ > Nmin, forming balanced sets ae

gt — {a if Nx = Nmin,

k RandomSubset(.S;,, min), if m_ > Mmin-
This resulted in 6 x 442 labeled positive texts.
Each text is annotated in the format: “This
text segment belongs to [category] because
it references [feature],’ supplemented by 20
randomly generated expressions sharing the
same meaning (see Appendix A.2).

4. For negative data, posts from negative users
in CNSD Gold were split, and texts with
any depression-related dimension were fil-
tered out. From the remaining unlabeled texts,
6 x 442 were uniformly sampled and assigned
one of 20 distinct label expressions indicat-
ing absence of negative emotions (details in
Appendix A.3).

5. The Module I model (Qwen?2.5-14B) was then
fine-tuned using LoRA (Hu et al., 2022) on
this combined set of 2 x (6 x 442) texts for
1 epoch at a learning rate of 5e-05 (details in
Appendix A.4).

4.2 Module II: Automatic Verification and
Summarization

In the second module, we applied the fine-tuned
model from Module I to label every text for
each user, extracting all texts that contain any
depression-related semantics. We then leveraged
the Deepseek R1 671B model (DeepSeek-AI et al.,
2025) to verify the correctness of both labels and
texts on a case-by-case basis. Following this ver-
ification step, we employed a few-shot approach
to summarize the extracted texts. In the few-shot
setting, we instruct the model to assume the role of
experts in psychology and text sentiment analysis.
Additionally, we provide the model with detailed
task requirements and exemplary gold-standard an-
swer samples. Details are in the Appendix 3.


5 Experiments

We design our experiments around two central re-
search questions. First , how effectively our data
generation pipeline in producing high-quality struc-
tured annotations? Second , how well do various
large language models (LLMs) perform on tasks
involving user-level depression risk summarization
and structured psychological analysis?

Based on these questions, our experiments aim
to:

1. To assess the quality of text generated for six-
dimensional depression analysis by models
fine-tuned on CNSD Gold and CNSD Silver,
comparing them against baseline models and
few-shot approaches.

2. To evaluate the performance of these fine-
tuned models on the downstream task of user-
level depression risk classification.

3. To benchmark the performance of various
leading LLMs on a structured depression anal-
ysis summarization task using our CNSD
Gold dataset.

Additionally, as shown in the Appendix 5.5, we
demonstrate the use of the CNSD Gold dataset as
the test set for the binary depression classification
task, further illustrating the dataset’s versatility.

5.1 Baseline Models

In the following experiments, we employ
DeepSeek-R1 Distill-14B (DeepSeek-AI et al.,
2025), Qwen2.5-14B (QwenTeam, 2024), GPT-40
5, GPT-40-Mini®, DeepSeek-R1-671B’ (DeepSeek-
AI et al., 2025), and Llama3-8B-Chinese-Chat
(Wang et al., 2024b) as our generative baseline
models. We summarize the key characteristics of
each model on A.1.

5.2 Experimental Setup

For our experiments, we used NVIDIA A800 80G
and A100 80G GPUs. Unless otherwise specified,
all generation experiments were conducted with a
temperature setting of 0.7. All fine-tuning exper-
iments were conducted using the LLama Factory
framework (Zheng et al., 2024), employing the

Shttps://openai.com/index/hello-GPT-40/
Shttps://openai.com/index/

GPT-40-mini-advancing-cost-efficient-intelligence/

Thttps://www.deepseek.com/

LoRA method (Hu et al., 2022) for one epoch with
a learning rate of 5e-5.

Our experiments consist of two main parts. The
first part evaluates the performance of our pipeline
on data generation, while the second part presents
benchmarks on CNSD Gold dataset for Structured
Summarization and Analysis Generation.

In our classification tasks, we use accuracy, re-
call, precision, and Fl-score as evaluation metrics.
For text generation experiments, we employ BLEU
(Papineni et al., 2002), ROUGE-1 (Lin, 2004), and
BERTScore(Zhang et al., 2020) for performance
assessment.

5.3. Task I: Data Generation

In this section, we conducted multiple experiments
on the CNSD Test dataset. We primarily evalu-
ated the Qwen2.5 14B models fine-tuned on CNSD
Gold and CNSD Silver:

* Qwen2.5 14B Gold: Fine-tuned using the
CNSD Gold.

* Qwen2.5 14B Silver: Fine-tuned using the
CNSD Silver. which was generated by ap-
plying the pipeline described in Section 4 to
100 randomly selected positive users and 100
randomly selected negative users from the
SWDD binary classification dataset.

We compared the performance of these models
with other baselines in two aspects:

1. The performance of the depression risk classi-
fication.

2. The quality of the generated text in the six-
dimensional analyses section (including text
hallucinations).

Throughout these experiments, unless noted other-
wise, we employed a user-level generation strategy.
This approach involves providing the complete set
of a user’s Weibo posts along with an instruction
that requires the model to directly output the user’s
depression label along with the corresponding jus-
tification.

5.3.1 Six-Dimensional Analysis of Depression
task

Research has demonstrated that structured know!I-

edge enhances the benefits of integrating structured

data into LLMs (Moiseev et al., 2022), thereby im-

proving output quality. CNSD Gold and CNSD


Strategy BERTScore ROUGE-1 BLEU
Pipeline 0.791 0.478 0.288
FS:Qwen2.5 14B 0.649 0.076 0.075
FS:GPT-40 0.678 0.269 0.094
FS:GPT-40 Mini 0.674 0.170 0.070
FS:DeepSeek R1 671B 0.678 0.301 0.054
FS:DeepSeek R1 Distill -14B 0.6756 0.191 0.073

Table 3: Comparison of Generation Strategies on Text
Quality: In the table, FS stands for Few-Shot, and
Pipeline is based on the Automated Dataset Generation
Pipeline we proposed in Section 4 and our proposed
dataset in Section 3. The prompt used in this experi-
ment can be found in Appendix A.6. The purpose is to
demonstrate that, using the same prompt, our pipeline
achieves the highest text generation quality that meets
our task requirements.

Silver are datasets with fine-grained structured an-
notations across six dimensions to summarize and
analyze social media users. Fine-tuning on these
datasets should reduces textual hallucinations and
achieves text generation quality comparable to the
other much larger model.

Table 3 shows the comparisons between different
generation strategies in terms of the quality of the
produced text. Notably, our Pipeline achieves the
highest scores across all three metrics: BERTScore
(0.791), ROUGE-1 (0.478), and BLEU (0.288), in-
dicating superior semantic alignment, lexical over-
lap, and n-gram precision, respectively. In con-
trast, with the FS (few-shot) strategies, all models:
Qwen2.5 14B, GPT-40, and DeepSeek R1 671B,
yield comparatively lower performance on each
metric. Even the large-scale DeepSeek R1 671B
model does not surpass the Pipeline approach, sug-
gesting that the proposed Pipeline method effec-
tively leverages its generation procedure to produce
higher-quality text that more closely matches the
reference, outperforming both smaller and larger
models under the few-shot setting.

Additionally, we also report the comparison
of generation quality between the original model,
Qwen?2.5 14B Gold, and Qwen?2.5 14B Silver. (Ta-
ble 5)

For automatic metrics, the original model
achieved a Bert-Score of 0.649, which increased
to 0.764 for Gold (+16.9%) and 0.787 for Sil-
ver (+21.5%), showing stronger semantic align-
ment. Rouge-1 rose from 0.076 to 0.217 for Gold
(+172%) and 0.218 for Silver (4172%), indicat-
ing improved lexical overlap. Bleu increased from
0.075 to 0.186 for Gold (+149%) and 0.237 for
Silver (+218%), reflecting better n-gram precision

and structural quality.

The human evaluation was conducted by two lin-
guistic experts across accuracy, coverage, and hal-
lucination. Compared to the original Qwen2.5 14B,
both Silver and Gold showed clear improvements.
Silver improved by about 33.4% in accuracy, 37.1%
in coverage, and 15.5% in hallucination. Gold
achieved even stronger gains, with 42.9% in ac-
curacy, 58.0% in coverage, and 26.8% in halluci-
nation. Overall, Gold performed best in human
evaluation, while Silver, though slightly behind,
still showed significant gains over the original and
reached levels close to Gold.

In summary, Gold achieved the strongest results
in human evaluation, while Silver performed better
in automatic metrics. Both models clearly outper-
formed the original, showing that fine-tuning with
our dataset or pipeline can significantly enhance
generation quality at semantic, lexical, and struc-
tural levels.

5.3.2 Classification task

In the depression classification task, Qwen2.5 14B
Silver achieves the best performance compared to
other models, with an accuracy of 0.944 and an
F1 score of 0.941, even surpassing Qwen2.5 14B
Gold, which was fine-tuned on human-annotated
data. Furthermore, it outperforms large-scale mod-
els such as GPT-40 (accuracy = 0.917, F1 score =
0.923) and DeepSeek R1 671B (accuracy = 0.861,
F1 score = 0.872). This result provides evidence
for the effectiveness of our generation pipeline and
the high quality of the data produced through this
pipeline. The details of the experimental results are
in the Table 6.

5.4 Task II: Structured Summarization and
Analysis Generation

The proposed dataset effectively supports research
on generative models in the field of internet de-
pression risk analyses, demonstrating particular
value for user depressive mental state summariza-
tion tasks. Due to the absence of comparable open-
source datasets, we conducted preliminary evalua-
tions on mainstream generative models using our
annotated dataset containing 233 user-level sam-
ples. The detailed results are demonstrated in the
table 7. We used the basic prompt as follows:
Please carefully read the following multiple texts
and then answer the question: Based on these texts,
does this user exhibit a depressive mood? If the
user exhibits depressive mood, answer ’Yes’; if the


Model/Test Dataset

RoBERTa Chinese (trained by swdd origin)
RoBERTa Chinese (trained by wu3d)

Bert based Chinese (trained by swdd origin)
Bert based Chinese (trained by wu3d)
StructBERT-mental (trained by swdd origin)
StructBERT-mental (trained by wu3d)
Llama3-8b

Glm4-9b-chat

Qwen2.5 7b

GPT-40-Mini

GPT-40

DeepSeek-R1 671b

Swdd Origin Wu3d Ours (Gold)
Ace Fl Ace Fl Ace Fl

0.89 0.90 | 0.76 0.80 | 0.88 0.87
0.88 0.87 0.90 0.91 | 0.82 0.78
0.89 0.90 | 0.76 0.80 | 0.85 0.82
0.88 0.87 | 0.90 0.91 | 0.83 0.80
0.81 0.84 | 0.69 0.76 | 0.85 0.86
0.85 0.85 | 0.92 0.92 | 0.83 0.80
0.86 0.86 | 0.79 0.79 | 0.60 0.63
0.76 0.81 0.77 0.81 | 0.79 0.82
0.88 0.89 | 0.84 0.85 | 0.94 0.94
0.65 0.74 | 0.65 0.74 | 0.53 0.68
0.92 0.92 0.91 0.92 | 0.83 0.86
0.86 0.87 | 0.89 0.90 | 0.81 0.84

Table 4: Model Classification Performance Comparison on Different Test Datasets.

Model Bert-Score Rougel Bleu Hacc H.cov H.hallu
Qwen2.5 14B 0.649 0.076 0.075 0.583 0.574 = 0.657
Qwen2.5 14B Silver 0.787 0.218 =0.237) 0.778 = 0.787 ~~ 0.759
Qwen?2.5 14B Gold 0.764 0.217 = =0.186 §=0.833 0.907 = 0.833

Table 5: Comparison of text quality across different models. *Qwen2.5 14B Gold’ denotes the model fine-tuned
on our proposed dataset, while *Qwen2.5 14B Silver’ denotes the model fine-tuned using data generated from the
pipeline strategy described in Table 3, with further details in Section 4. The table reports three human evaluation
metrics: acc (accuracy of the generated text), cov (content coverage), and hallu (hallucination). Higher values across

all metrics indicate better generation performance.

Model Accuracy Recall Precision F1

Qwen?2.5 14B 0.889 0.944 0.850 0.894
Qwen2.5 14B_FT_Silver 0.944 0.889 1.000 0.941
Qwen2.5 14B_FT_Gold 0.861 0.889 0.842 0.864
GPT-40 0.917 1.000 0.857 0.923
GPT-40 Mini 0.667 1.000 0.600 0.750
DeepSeek R1 671B 0.861 0.944 0.801 0.872
DeepSeek R1 Distill-14B 0.889 1.000 0.818 0.900

Table 6: Comparison of Models for Generated Dataset
Quality: Application to Classification Tasks.

user does not exhibit depressive mood, answer ’No’.
Then, provide your step-by-step analysis process.

Model Bert-Score Rougel Bleu

Llama3-8b 0.654 0.194 0.122
Glm4-9b-chat 0.694 0.208 0.140
Qwen?2.5-7b 0.680 0.208 0.093
DeepSeek-R1-671B 0.698 0.454 0.125
GPT-40-mini 0.696 0.166 0.126
GPT-40 0.710 0.346 0.152

Table 7: Performance Comparison on Depression Risk
Analysis Summarization Generation Task.

The results reveal variations across models in
the task of risk analysis summarization generation:
Bert-Score: Narrow range (0.65-0.71) with
GPT-4o0 leading at 0.71, indicating superior seman-

tic understanding. Rougel: DeepSeek-R1-671B
achieves remarkable 0.45 score, suggesting 10%
improvement over second-best performer. Bleu:
Maximum 15.17 from GPT-40 vs minimum 9.36
from Qwen2.5-7b, reflecting lexical alignment dif-
ferences.

5.5 Task III: Classification Experimentations

In the depression risk binary classification task, we
used three datasets, including the original SWDD
dataset (Cai et al., 2023) and the WU3D dataset
(Wang et al., 2020). Both of these datasets were
randomly sampled with 200 negative users and 200
positive users for the experiment. Details provided
in the table 4.

In the classification experiments, in addition to
the generative models mentioned in the section A.1,
we also used models based on the BERT architec-
ture with the details on A.7.

6 Conclusion

We introduced CNSocialDepress, a new dataset for
depression risk analysis using Chinese social me-
dia texts. Uniquely, it is the first dataset to include
both user-level and text-level labels, combining
binary depression indicators with fine-grained six-
dimensional analysis annotated by mental health


professionals. We also developed an automated
data generation pipeline to ease manual annotation
and support language model fine-tuning for classifi-
cation and summarization tasks. We believe CNSo-
cialDepress will prove valuable across a range of
applications, advancing early detection and inter-
vention strategies in mental health.

7 Limitations

While CNSocialDepress provides a valuable re-
source for depression risk analyses in Chinese so-
cial media, several limitations should be noted.
First, the dataset is sourced exclusively from Weibo,
potentially introducing platform-specific demo-
graphic biases (e.g., underrepresentation of rural or
elderly populations).

Second, linguistic diversity, including dialectal
variations and metaphorical expressions common
in Chinese depressive discourse, remains insuffi-
ciently captured and may limit cross-regional gen-
eralizability. Third, although manual expert anno-
tation ensures high quality, it constrains scalability,
resulting in a relatively limited dataset size.

Additionally, the current structured analysis fo-
cus primarily on depressive symptoms, omitting
comorbid mental health conditions (e.g., anxiety)
and contextual social factors. Future work will
expand data collection to multi-platform sources,
integrate dynamic lexicon updates for emerging
expressions, and adopt hybrid annotation frame-
works (e.g., expert-guided crowdsourcing) to en-
hance coverage and efficiency. Privacy-preserving
techniques and longitudinal data tracking will fur-
ther strengthen ethical and practical utility.

8 Ethic Statement

This dataset is built upon the SWDD (Cai et al.,
2023) benchmark released in early 2023. The orig-
inal data comes from user-level text on the Weibo
platform and was annotated by a team of psychol-
ogy experts according to the DSM-5 symptom stan-
dards.

During our work on the re-annotation process,
we applied a second round of deep anonymiza-
tion to meet privacy requirements. This involved
systematically removing personal information, geo-
graphic locations, and potential identifiers from the
original text, ensuring compliance with data protec-
tion protocols Benton et al. (2017) and GDPR (Gen-
eral Data Protection Regulation’). We also invited

SEUR-Lex GDPR Regulation

experienced researchers specializing in depression-
related psychology to provide professional annota-
tions based on their expertise.

This dataset is mainly used for building early-
warning models for depression risk. Through multi-
dimensional feature analysis, it detects potential
risk signals and can be used to automatically gen-
erate structured psychological assessment reports,
offering technical support for digital mental health
services. It is important to note that this study is
strictly limited to the realm of mental health assis-
tance, and any results should only serve as refer-
ences for professional diagnosis or as a digital tool
for self-assessment.

At present, none of the algorithmic models can
replace in-person psychiatric evaluations or deliver
pathological diagnoses. If a system built using
this dataset flags high-risk cases, or if individuals
already show persistent mood disturbances or im-
paired social functioning, they should seek profes-
sional medical attention promptly. Mental health
issues require clinical expertise, and any online
self-assessment tool cannot substitute for in-person
medical diagnosis.

References

Maryam Mohammed Aldarwish and Hafiz Farooq Ah-
mad. 2017. Predicting depression levels using social
media posts. In 2017 IEEE 13th international Sympo-
sium on Autonomous decentralized system (ISADS),
pages 277-280. IEEE.

Shumaila Aleem, Noor ul Huda, Rashid Amin, Samina
Khalid, Sultan S Alshamrani, and Abdullah Alshehri.
2022. Machine learning algorithms for depression:
diagnosis, insights, and research directions. Electron-
ics, 11(7):1111.

Falwah Alhamed, Julia Ive, and Lucia Specia. 2024.
Classifying social media users before and after de-
pression diagnosis via their language usage: A
dataset and study. In Proceedings of the 2024 Joint
International Conference on Computational Linguis-
tics, Language Resources and Evaluation (LREC-
COLING 2024), pages 3250-3260, Torino, Italia.
ELRA and ICCL.

Salma Almouzini, Asem Alageel, et al. 2019. Detecting
arabic depressed users from twitter data. Procedia
Computer Science, 163:257-265.

American Psychiatric Association et al. 2000. Diagnos-
tic and statistical manual of mental disorders. Text
revision.

Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang,
Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei


Huang, et al. 2023. Qwen technical report. arXiv
preprint arXiv:2309. 16609.

Krishna C Bathina, Marijn Ten Thij, Lorenzo Lorenzo-
Luaces, Lauren A Rutter, and Johan Bollen. 2021.
Individuals with depression express more distorted
thinking on social media. Nature human behaviour,
5(4):458—466.

Adrian Benton, Glen Coppersmith, and Mark Dredze.
2017. Ethical research protocols for social media
health research. In Proceedings of the First ACL
Workshop on Ethics in Natural Language Process-
ing, pages 94-102, Valencia, Spain. Association for
Computational Linguistics.

André Bittar, Sumithra Velupillai, Angus Roberts, and
Rina Dutta. 2019. Text classification to inform sui-
cide risk assessment in electronic health records. In
MEDINFO 2019: Health and Wellbeing e-Networks
for All, pages 40-44. IOS Press.

Leo Breiman. 2001. Random forests. Machine learning,
45:5-372.

Yicheng Cai, Haizhou Wang, Huali Ye, Yanwen Jin,
and Wei Gao. 2023. Depression detection on online
social network with multivariate time series feature
of user depressive symptoms. Expert Systems with
Applications, 217:119538.

Corinna Cortes. 1995. Support-vector networks. Ma-
chine Learning.

Yiming Cui, Wanxiang Che, Ting Liu, Bing Qin, Ziqing
Yang, Shijin Wang, and Guoping Hu. 2019. Pre-
training with whole word masking for chinese bert.
arXiv preprint arXiv: 1906.08101.

DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang,
Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu,
Shirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang,
Xingkai Yu, Yu Wu, Z. F. Wu, Zhibin Gou, Zhihong
Shao, Zhuoshu Li, Ziyi Gao, Aixin Liu, Bing Xue,
Bingxuan Wang, Bochao Wu, Bei Feng, Chengda Lu,
Chenggang Zhao, Chengqi Deng, Chenyu Zhang,
Chong Ruan, Damai Dai, Deli Chen, Dongjie Ji,
Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo,
Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang,
Han Bao, Hanwei Xu, Haocheng Wang, Honghui
Ding, Huajian Xin, Huazuo Gao, Hui Qu, Hui Li,
Jianzhong Guo, Jiashi Li, Jiawei Wang, Jingchang
Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, J. L.
Cai, Jiaqi Ni, Jian Liang, Jin Chen, Kai Dong, Kai
Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai
Yu, Lean Wang, Lecong Zhang, Liang Zhao, Litong
Wang, Liyue Zhang, Lei Xu, Leyi Xia, Mingchuan
Zhang, Minghua Zhang, Minghui Tang, Meng Li,
Miaojun Wang, Mingming Li, Ning Tian, Panpan
Huang, Peng Zhang, Qiancheng Wang, Qinyu Chen,
Qiushi Du, Ruigi Ge, Ruisong Zhang, Ruizhe Pan,
Runji Wang, R. J. Chen, R. L. Jin, Ruyi Chen,
Shanghao Lu, Shangyan Zhou, Shanhuang Chen,
Shengfeng Ye, Shiyu Wang, Shuiping Yu, Shunfeng
Zhou, Shuting Pan, S. S. Li, Shuang Zhou, Shaoqing

Wu, Shengfeng Ye, Tao Yun, Tian Pei, Tianyu Sun,
T. Wang, Wangding Zeng, Wanjia Zhao, Wen Liu,
Wenfeng Liang, Wenjun Gao, Wenqin Yu, Wentao
Zhang, W. L. Xiao, Wei An, Xiaodong Liu, Xiaohan
Wang, Xiaokang Chen, Xiaotao Nie, Xin Cheng, Xin
Liu, Xin Xie, Xingchao Liu, Xinyu Yang, Xinyuan Li,
Xuecheng Su, Xuheng Lin, X. Q. Li, Xiangyue Jin,
Xiaojin Shen, Xiaosha Chen, Xiaowen Sun, Xiaoxi-
ang Wang, Xinnan Song, Xinyi Zhou, Xianzu Wang,
Xinxia Shan, Y. K. Li, Y. Q. Wang, Y. X. Wei, Yang
Zhang, Yanhong Xu, Yao Li, Yao Zhao, Yaofeng
Sun, Yaohui Wang, Yi Yu, Yichao Zhang, Yifan Shi,
Yiliang Xiong, Ying He, Yishi Piao, Yisong Wang,
Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang Guo,
Yuan Ou, Yuduan Wang, Yue Gong, Yuheng Zou, Yu-
jia He, Yunfan Xiong, Yuxiang Luo, Yuxiang You,
Yuxuan Liu, Yuyang Zhou, Y. X. Zhu, Yanhong Xu,
Yanping Huang, Yaohui Li, Yi Zheng, Yuchen Zhu,
Yunxian Ma, Ying Tang, Yukun Zha, Yuting Yan,
Z. Z. Ren, Zehui Ren, Zhangli Sha, Zhe Fu, Zhean
Xu, Zhenda Xie, Zhengyan Zhang, Zhewen Hao,
Zhicheng Ma, Zhigang Yan, Zhiyu Wu, Zihui Gu, Zi-
jia Zhu, Zijun Liu, Zilin Li, Ziwei Xie, Ziyang Song,
Zizheng Pan, Zhen Huang, Zhipeng Xu, Zhongyu
Zhang, and Zhen Zhang. 2025. Deepseek-r1: Incen-
tivizing reasoning capability in Ilms via reinforce-
ment learning. Preprint, arXiv:2501.12948.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. BERT: Pre-training of
deep bidirectional transformers for language under-
standing. In Proceedings of the 2019 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Volume I (Long and Short Papers), pages
4171-4186, Minneapolis, Minnesota. Association for
Computational Linguistics.

Stephan Dreiseitl and Lucila Ohno-Machado. 2002. Lo-
gistic regression and artificial neural network classi-
fication models: a methodology review. Journal of
biomedical informatics, 35(5-6):352-359.

Andrea C Fernandes, Rina Dutta, Sumithra Velupillai,
Jyoti Sanyal, Robert Stewart, and David Chandran.
2018. Identifying suicide ideation and suicidal at-
tempts in a psychiatric clinical research database us-
ing natural language processing. Scientific reports,
8(1):7426.

Zhihua Guo, Nengneng Ding, Minyu Zhai, Zhenwen
Zhang, and Zepeng Li. 2023. Leveraging domain
knowledge to improve depression detection on chi-
nese social media. IEEE Transactions on Computa-
tional Social Systems, 10(4):1528-1536.

Mika Hamialainen, Pattama Patpong, Khalid Alnajjar,
Niko Partanen, and Jack Rueter. 2021. Detecting de-
pression in Thai blog posts: a dataset and a baseline.
In Proceedings of the Seventh Workshop on Noisy
User-generated Text (W-NUT 2021), pages 20-25,
Online. Association for Computational Linguistics.

Keith Harrigian, Carlos Aguirre, and Mark Dredze.
2021. On the state of social media data for men-
tal health research. In Proceedings of the Seventh


Workshop on Computational Linguistics and Clinical
Psychology: Improving Access, pages 15-24, Online.
Association for Computational Linguistics.

Khan Md Hasib, Md Rafiqul Islam, Shadman Sakib,
Md Ali Akbar, Imran Razzak, and Moham-
mad Shafiul Alam. 2023. Depression detection from
social networks data based on machine learning and
deep learning techniques: An interrogative survey.
IEEE Transactions on Computational Social Systems,
10(4): 1568-1586.

Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan
Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and
Weizhu Chen. 2022. LoRA: Low-rank adaptation of
large language models. In International Conference
on Learning Representations.

Jinpeng Hu, Tengteng Dong, Luo Gang, Hui Ma,
Peng Zou, Xiao Sun, Dan Guo, and Meng Wang.
2024.  Psycollm: Enhancing Ilm for psycho-
logical understanding and evaluation. Preprint,
arXiv:2407.05721.

Md Rafigqul Islam, Muhammad Ashad Kabir, Ashir
Ahmed, Abu Raihan M Kamal, Hua Wang, and An-
waar Ulhaq. 2018. Depression detection from so-
cial network data using machine learning techniques.
Health information science and systems, 6:1—12.

Yoon Kim. 2014. Convolutional neural networks
for sentence classification. In Proceedings of the
2014 Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 1746-1751,
Doha, Qatar. Association for Computational Linguis-
tics.

Kurt Kroenke, Robert L Spitzer, and Janet BW Williams.
2001. The phq-9: validity of a brief depression sever-
ity measure. Journal of general internal medicine,

16(9):606-613.

Tin Lai, Yukun Shi, Zicong Du, Jiajie Wu, Ken Fu,
Yichao Dou, and Zigi Wang. 2023. Psy-Ilm: Scal-
ing up global mental health psychological services
with ai-based large language models. arXiv preprint
arXiv:2307.11991.

Xiaochong Lan, Yiming Cheng, Li Sheng, Chen Gao,
and Yong Li. 2024. Depression detection on social
media with large language models. arXiv preprint
arXiv:2403. 10750.

Genghao Li, Bing Li, Langlin Huang, Sibing Hou,
et al. 2020. Automatic construction of a depression-
domain lexicon based on microblogs: text mining
study. JMIR medical informatics, 8(6):e17650.

Lei Li. 2024. Cpseg: Finer-grained image semantic seg-
mentation via chain-of-thought language prompting.
In Proceedings of the IEEE/CVF Winter Conference
on Applications of Computer Vision, pages 513-522.

Lei Li, Sen Jia, Wang Jianhao, Zhongyu Jiang, Feng
Zhou, Ju Dai, Tianfang Zhang, Wu Zongkai, and
Jeng-Neng Hwang. 2024. Human motion instruction
tuning. arXiv preprint arXiv:2411,16805.

Mingzheng Li, Haojie Xu, Weifeng Liu, and Jiangwei
Liu. 2022. Bidirectional lstm and attention for de-
pression detection on clinical interview transcripts.
In 2022 IEEE 10th International Conference on In-
formation, Communication and Networks (ICICN),
pages 638-643. IEEE.

Zepeng Li, Zhengyi An, Wenchuan Cheng, Jiawei Zhou,
Fang Zheng, and Bin Hu. 2023. Mha: a multimodal
hierarchical attention model for depression detection
in social media. Health information science and
systems, 11(1):6.

Chin- Yew Lin. 2004. ROUGE: A package for auto-
matic evaluation of summaries. In Text Summariza-
tion Branches Out, pages 74-81, Barcelona, Spain.
Association for Computational Linguistics.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-
dar Joshi, Dangi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Roberta: A robustly optimized bert pretraining ap-
proach. Preprint, arXiv:1907.11692.

Ashwag Maghraby and Hosnia Ali. 2022. Modern stan-
dard arabic mood changing and depression dataset.
Data in Brief, 41:107999.

Andrew McCallum, Kamal Nigam, et al. 1998. A com-
parison of event models for naive bayes text classi-
fication. In AAAI-98 workshop on learning for text
categorization, volume 752, pages 41-48. Madison,
WI.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient estimation of word representa-
tions in vector space. Preprint, arXiv:1301.3781.

Fedor Moiseev, Zhe Dong, Enrique Alfonseca, and Mar-
tin Jaggi. 2022. SKILL: Structured knowledge infu-
sion for large language models. In Proceedings of
the 2022 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, pages 1581-1588,
Seattle, United States. Association for Computational
Linguistics.

Josiane Mothe, Faneva Ramiandrisoa, and Md Zia Ul-
lah. 2022. Comparison of machine learning models
for early depression detection from users’ posts. In
Early Detection of Mental Health Disorders by So-
cial Media Monitoring: The First Five Years of the
eRisk Project, volume 1018 of Studies in Computa-
tional Intelligence book series (SCI), pages 111-139.
Springer International Publishing.

Danielle Mowery, Hilary Smith, Tyler Cheney, Greg
Stoddard, Glen Coppersmith, Craig Bryan, Mike
Conway, et al. 2017. Understanding depressive symp-
toms and psychosocial stressors on twitter: a corpus-
based study. Journal of medical Internet research,

19(2):e6895.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic evalu-
ation of machine translation. In Proceedings of the


40th Annual Meeting of the Association for Compu-
tational Linguistics, pages 311-318, Philadelphia,
Pennsylvania, USA. Association for Computational
Linguistics.

Javier Parapar, Patricia Martin-Rodilla, David E.
Losada, and Fabio Crestani. 2022. Overview of erisk
at clef 2022: Early risk prediction on the internet
(extended overview). In CLEF 2022: Conference
and Labs of the Evaluation Forum, September 5-6,
2022, Bologna, Italy, Bologna, Italy. CEUR Work-
shop Proceedings. CC BY 4.0; ISSN: 1613-0073.

QwenTeam. 2024. Qwen2.5: A party of foundation
models.

Nishat Raihan, Sadiya Sayara Chowdhury Puspo,
Shafkat Farabi, Ana-Maria Bucur, Tharindu Ranas-
inghe, and Marcos Zampieri. 2024. MentalHelp:
A multi-task dataset for mental health in social me-
dia. In Proceedings of the 2024 Joint International
Conference on Computational Linguistics, Language
Resources and Evaluation (LREC-COLING 2024),
pages 11196-11203, Torino, Italia. ELRA and ICCL.

Alba M Marmol Romero, Adrian Moreno Mufioz, Flor
Miriam Plaza Del Arco, M Dolores Molina-Gonzalez,
Maria Teresa Martin Valdivia, L Alfonso Urena
Lopez, and Arturo Montejo Radez. 2024. Mental-
riskes: A new corpus for early detection of mental
disorders in spanish. In Proceedings of the 2024 Joint
International Conference on Computational Linguis-
tics, Language Resources and Evaluation (LREC-
COLING 2024), pages 11204-11214.

Hasim Sak, Andrew Senior, and Francoise Beaufays.
2014. Long short-term memory based recurrent neu-
ral network architectures for large vocabulary speech
recognition. arXiv preprint arXiv: 1402.1128.

Wesley Ramos dos Santos, Rafael Lage de Oliveira, and
Ivandré Paraboni. 2024. Setembrobr: a social media
corpus for depression and anxiety disorder prediction.
Language Resources and Evaluation, 58(1):273-300.

Jiirgen Schmidhuber. 2015. Deep learning in neural net-
works: An overview. Neural Networks, 61:85—117.

Elizabeth M Seabrook, Margaret L Kern, Ben D Fulcher,
and Nikki S Rickard. 2018. Predicting depression
from language-based emotion dynamics: longitudi-
nal analysis of facebook and twitter status updates.
Journal of medical Internet research, 20(5):e168.

Guangyao Shen, Jia Jia, Liqiang Nie, Fuli Feng, Cunjun
Zhang, Tianrui Hu, Tat-Seng Chua, Wenwu Zhu, et al.
2017. Depression detection via harvesting social
media: A multimodal dictionary learning solution.
In IJCAT, pages 3838-3844.

Tiancheng Shen, Jia Jia, Guangyao Shen, Fuli Feng,
Xiangnan He, Huanbo Luan, Jie Tang, Thanassis
Tiropanis, Tat Seng Chua, and Wendy Hall. 2018.
Cross-domain depression detection via harvesting so-
cial media. In Proceedings of the International Joint
Conference on Artificial Intelligence. International
Joint Conferences on Artificial Intelligence.

Ying Shen, Huiyu Yang, and Lin Lin. 2022. Automatic
depression detection: An emotional audio-textual
corpus and a gru/bilstm-based model. In ICASSP
2022-2022 IEEE International Conference on Acous-
tics, Speech and Signal Processing (ICASSP), pages
6247-6251. IEEE.

Jingzhe Shi, Jialuo Li, Qinwei Ma, Zaiwen Yang, Huan
Ma, and Lei Li. 2024. Chops: Chat with customer
profile systems for customer service with llms. arXiv
preprint arXiv:2404.01343.

Sajad Sotudeh, Hanieh Deilamsalehy, Franck Dernon-
court, and Nazli Goharian. 2021. TLDR9+: A large
scale resource for extreme summarization of social
media posts. In Proceedings of the Third Workshop
on New Frontiers in Summarization, pages 142-151,
Online and in Dominican Republic. Association for
Computational Linguistics.

Sajad Sotudeh, Nazli Goharian, and Zachary Young.
2022. MentSum: A resource for exploring summa-
rization of mental health online posts. In Proceedings
of the Thirteenth Language Resources and Evalua-
tion Conference, pages 2682-2692, Marseille, France.
European Language Resources Association.

Matthew Squires, Xiaohui Tao, Soman Elangovan, Raj
Gururajan, Xujuan Zhou, U Rajendra Acharya, and
Yuefeng Li. 2023. Deep learning and machine learn-
ing in psychiatry: a survey of current progress in
depression detection, diagnosis and treatment. Brain
Informatics, 10(1):10.

Maxim Stankevich, Ivan Smirnov, Natalia Kiselnikova,
and Anastasia Ushakova. 2020. Depression detection
from social media profiles. In Data Analytics and
Management in Data Intensive Domains: 21st Inter-
national Conference, DAMDID/RCDL 2019, Kazan,
Russia, October 15—18, 2019, Revised Selected Pa-
pers 21, pages 181-194. Springer.

A Vaswani. 2017. Attention is all you need. Advances
in Neural Information Processing Systems.

Jifei Wang, Zhenping Zhao, Jing Yang, Limin Wang,
Mei Zhang, and Maigeng Zhou. 2024a. The associa-
tion between depression and all-cause, cause-specific
mortality in the chinese population—china, 2010-
2022. China CDC Weekly, 6(40): 1022.

Shenzhi Wang, Yaowei Zheng, Guoyin Wang, Shiji
Song, and Gao Huang. 2024b. Llama3-8b-chinese-
chat (revision 6622423).

Wei Wang, Bin Bi, Ming Yan, Chen Wu, Zuyi Bao,
Jiangnan Xia, Liwei Peng, and Luo Si. 2019. Struct-
bert: Incorporating language structures into pre-
training for deep language understanding. arXiv
preprint arXiv: 1908.04577.

Yiding Wang, Zhenyi Wang, Chenghao Li, Yilin Zhang,
and Haizhou Wang. 2020. A multimodal feature
fusion-based method for individual depression detec-
tion on sina weibo. In 2020 IEEE 39th International
Performance Computing and Communications Con-

ference (IPCCC), pages 1-8.


Yuxi Wang, Diana Inkpen, and Prasadith Kirinde
Gamaarachchige. 2024c. Explainable depression de-
tection using large language models on social me-
dia data. In Proceedings of the 9th Workshop on
Computational Linguistics and Clinical Psychology
(CLPsych 2024), pages 108-126.

Dong Xue* Xin Yan. 2023. Mindchat: Psychologi-
cal large language model. https://github.com/
X-D-Lab/MindChat.

Xuhai Xu, Bingsheng Yao, Yuanzhe Dong, Saadia
Gabriel, Hong Yu, James Hendler, Marzyeh Ghas-
semi, Anind K Dey, and Dakuo Wang. 2024. Mental-
Ilm: Leveraging large language models for mental
health prediction via online text data. Proceedings
of the ACM on Interactive, Mobile, Wearable and
Ubiquitous Technologies, 8(1):1-32.

Juhua Yang and Lulu Li. 2009. Intergenerational dy-
namics and family solidarity: A comparative study
of mainland china, japan, korea and taiwan. Socio-
logical Studies, 3:26—-53.

Kailai Yang, Shaoxiong Ji, Tianlin Zhang, Qianqian
Xie, Ziyan Kuang, and Sophia Ananiadou. 2023. To-
wards interpretable mental health analysis with large
language models. In Proceedings of the 2023 Con-
ference on Empirical Methods in Natural Language
Processing, pages 6056-6077, Singapore. Associa-
tion for Computational Linguistics.

Kailai Yang, Tianlin Zhang, Ziyan Kuang, Qianqian Xie,
Jimin Huang, and Sophia Ananiadou. 2024. Mental-
lama: interpretable mental health analysis on social
media with large language models. In Proceedings
of the ACM on Web Conference 2024, pages 4489-
4500.

Tingting Yang, Fei Li, Donghong Ji, Xiaohui Liang,
Tian Xie, Shuwan Tian, Bobo Li, and Peitong Liang.
2021. Fine-grained depression analysis based on
chinese micro-blog reviews. Information Processing
& Management, 58(6):102681.

Xingwei Yang, Rhonda McEwen, Liza Robee Ong, and
Morteza Zihayat. 2020. A big data analytics frame-
work for detecting user-level depression from social
networks. International Journal of Information Man-
agement, 54:102141.

Andrew Yates, Arman Cohan, and Nazli Goharian. 2017.
Depression and self-harm risk assessment in online
forums. In Proceedings of the 2017 Conference on
Empirical Methods in Natural Language Processing,
pages 2968-2978, Copenhagen, Denmark. Associa-
tion for Computational Linguistics.

Amir Hossein Yazdavar, Mohammad Saeid Mah-
davinejad, Goonmeet Bajaj, William Romine, Amit
Sheth, Amir Hassan Monadjemi, Krishnaprasad
Thirunarayan, John M Meddar, Annie Myers, Jyotish-
man Pathak, et al. 2020. Multimodal mental health
analysis in social media. Plos one, 15(4):e0226248.

Yutaka Miyaji Yuka Niimi. 2021. Machine learning
approach for depression detection in Japanese. In
Proceedings of the 35th Pacific Asia Conference on
Language, Information and Computation, pages 346—
353, Shanghai, China. Association for Computational
Lingustics.

Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.
Weinberger, and Yoav Artzi. 2020. Bertscore: Evalu-
ating text generation with BERT. In 8th International
Conference on Learning Representations, ICLR 2020,
Addis Ababa, Ethiopia, April 26-30, 2020. OpenRe-
view.net.

Yipeng Zhang, Hanjia Lyu, Yubao Liu, Xiyang Zhang,
Yu Wang, and Jiebo Luo. 2021. Monitoring de-
pression trends on twitter during the covid-19 pan-
demic: observational study. JMIR infodemiology,
1(1):e26769.

Zhiling Zhang, Siyuan Chen, Mengyue Wu, and Kenny
Zhu. 2022. Symptom identification for interpretable
detection of multiple mental disorders on social me-
dia. In Proceedings of the 2022 Conference on Em-
pirical Methods in Natural Language Processing,
pages 9970-9985, Abu Dhabi, United Arab Emirates.
Association for Computational Linguistics.

Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan
Ye, Zheyan Luo, Zhangchi Feng, and Yongqiang Ma.
2024. Llamafactory: Unified efficient fine-tuning
of 100+ language models. In Proceedings of the
62nd Annual Meeting of the Association for Compu-
tational Linguistics (Volume 3: System Demonstra-
tions), Bangkok, Thailand. Association for Computa-
tional Linguistics.

Han-yu Zhou, Wen-qi Zhu, Wen-yi Xiao, Ya-ting
Huang, Kang Ju, Hong Zheng, and Chao Yan. 2023.
Feeling unloved is the most robust sign of adolescent
depression linking to family communication patterns.
Journal of Research on Adolescence, 33(2):418—430.


A Appendix
A.1l_ Baseline Models

¢ DeepSeek-R1 is a large-scale model special-
ized in logical reasoning, This model excels in
complex reasoning tasks such as mathematics
and programming while maintaining strong
overall performance on general tasks. Chosen
for its specialized excellence in complex log-
ical reasoning while maintaining strong gen-
eral task performance, potentially beneficial
for in-depth structured psychological analysis
and nuanced depression risk detection.

DeepSeek R1 Distill-14B is a lightweight
reasoning model derived from Qwen2.5-14B
through Knowledge Distillation. Chosen for
its lightweight reasoning capabilities, aiming
to retain the advantages of larger models in
complex tasks while reducing computational
cost, making it suitable for efficient depres-
sion risk analysis.

Qwenz2.5-14B is part of Alibaba’s Qwen se-
ries of large language models. Chosen for its
strong performance in long-form text gener-
ation and instruction-following, relevant for
generating structured psychological analyses
from Chinese social media posts.

GPT-4o is a multimodal large language model
released by OpenAI. Chosen for its state-of-
the-art multimodal and multilingual process-
ing capabilities, including Chinese, and its
improved overall performance and response
speed, making it a powerful baseline for de-
pression detection and psychological analysis.

GPT-40-Mini is a lightweight AI model de-
veloped by OpenAI to provide an efficient
and cost-effective AI solution. Chosen as a
resource- and cost-efficient model with robust
text understanding and generation, suitable
for less computationally demanding depres-
sion risk identification and basic psychologi-
cal analysis tasks.

Llama3-8B-Chinese-Chat, derived from
Meta-Llama-3-8B, is an instruction-tuned
model optimized for Chinese dialogue tasks.
It has been fine-tuned to process both Chinese
and English inputs. Chosen for its optimiza-
tion for Chinese dialogue tasks and ability
to handle extended conversations, making it

A.2

well-suited for analyzing conversational social
media posts for depression risk and generating
coherent psychological insights in Chinese.

20 Randomly Generated Expression for
the Positive Users

. Carefully read the complete user Weibo text

below and extract key information across six
specified dimensions according to the content.
Also pay attention to the user’ s depressive
state, ensuring that each dimension’ s expla-
nation is consistent with this state.

[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - For each dimension,
if evidence exists in the text, provide the text
index (e.g., text_xx, SC AX_xx) and a brief note
(e.g., text_xx[sad]). - If no evidence is found
for a dimension, state clearly that no relevant
evidence was found.

Note: Only output text index and explanation,
not the actual text.

. Read the entire user Weibo text below and,

based on its content, extract core information
under the following six dimensions. Also con-
sider the user’ s depressive status, ensuring
that each dimension’ s description matches
this state.

[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - For each dimension,
if relevant information is detected, provide the
text index (e.g., text_xx, MC AX_xx) and a short
note (e.g., text_xx[unhappy]). - For dimen-
sions without evidence, explicitly state no rel-
evant evidence found.

Note: Output should include only text index
and explanation, not the actual text.

. Read through the complete user Weibo text

below and extract key information across six
dimensions based on its content. Pay close at-
tention to the user’ s depressive state, ensur-
ing that the explanations are consistent with
it.

[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - If relevant evidence
is found in a dimension, provide the text index
(e.g., text_Xxx, SC AX_xx) and a short note (e.g.,
text_xx[sorrow]). - If no evidence is found,
indicate explicitly.



Note: Provide only indices and explanations,
not the original content.

. Carefully read the full Weibo text below and
extract key evidence across six dimensions
according to the text. At the same time, take
into account the user’ s depressive state, en-
suring that explanations for each dimension
align with this state.

[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - For each dimension,
if there is corresponding evidence, output the
text index (e.g., text_xx, MC AK_xx) and a re-
lated note (e.g., text_xx[frustrated]). - If no
evidence is found, state that no evidence ex-
ists.

Note: Only provide text indices and notes, not
the raw text.

. Please read the full Weibo text below and ex-
tract key information from six dimensions. At
the same time, pay attention to the user’ s de-
pressive state, ensuring that your explanations
match this state.

[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - For each dimension,
if evidence is detected, output the text index
(e.g., text_xx, MC AX_xx) and a short descrip-
tion (e.g., text_xx[sadness]). - If no evidence
is found, specify that no evidence was found.
Note: Only output text indices and explana-
tions, not the original text.

. Read the complete Weibo text below carefully
and extract key information across six dimen-
sions based on the text. Pay attention to the
user’ s depressive state and ensure that your
descriptions are consistent with it.

[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - If relevant evi-
dence is found, provide the text index (e.g.,
text_xx, MC 7X_xx) and a brief description
(e.g., text_xx[low mood]). - If no evidence
is found, clearly state that no evidence exists.
Note: Only provide text indices and explana-
tions, not the original text.

. Please read through the complete user Weibo
text below and extract key information across
six dimensions based on its content. Pay atten-

10.

tion to the user’ s depressive state, ensuring
that each explanation is aligned with this state.
[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - For each dimen-
sion, if evidence exists, provide the text in-
dex (e.g., text_xx, SC AX_xx) and a short note
(e.g., text_xx[loss]). - If no evidence is found,
clearly state no relevant evidence.

Note: Only provide text indices and notes, not
the original text.

. Read the Weibo text below and extract key

evidence across six dimensions according to
the content, while considering the user’ s de-
pressive state to ensure explanations are con-
sistent.

[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - If a dimension con-
tains relevant evidence, provide the text index
(e.g., text_Xxx, SC AX_xx) and a short note (e.g.,
text_xx[low mood)]). - If no evidence is found,
state explicitly that no evidence exists.

Note: Output only text indices and explana-
tions, not the original text.

. Read the complete Weibo text carefully and

extract key evidence across six dimensions
based on the text. Pay attention to the user’ s
depressive state, ensuring that explanations
match this state.

[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - For each dimension,
if relevant evidence is found, output the text
index (e.g., text_xx, SC AX_xx) and a brief ex-
planation (e.g., text_xx[depressed]). - If no
evidence is found, state explicitly that there is
none.

Note: Provide only text indices and notes, not
the original text.

Read through the entire Weibo text and ex-
tract core information across six dimensions
according to the content. Pay attention to the
user’ s depressive state and ensure that the
descriptions are consistent with this state.
[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - For each dimension,
if relevant evidence exists, output the text in-
dex (e.g., text_xx, MC AK_xx) and a short ex-



11.

12.

13.

14.

planation (e.g., text_xx[pessimistic]). - If no
evidence is found, state clearly that no evi-
dence exists.

Note: Only output text indices and explana-
tions, not the original content.

Please read the user Weibo text below com-
pletely and extract essential information
across six dimensions. Ensure that the ex-
planations for each dimension align with the
depressive state given.

[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - If relevant evi-
dence is detected, list the text index (e.g.,
text_xx, 3M AK_xx) and a short description
(e.g., text_xx[melancholy]). - If no evidence is
found, specify that no evidence was detected.
Note: Output should only contain indices and
notes, not the actual text.

Read carefully the full Weibo text provided
and extract key evidence from six dimensions.
Pay attention to the user’ s depressive state,
ensuring that outputs remain consistent with
this state.

[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - If a dimension con-
tains evidence, output the text index (e.g.,
text_xx, 7X_xx) and a concise note (e.g.,
text_xx[disheartened]). - If no evidence ex-
ists, specify so.

Note: Output indices and explanations only,
not original content.

Please go through the complete Weibo text
below and identify critical information across
six dimensions. Ensure the notes correspond
with the user’ s depressive condition.
[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - Where evidence
is found, list the text index (e.g., text_xx,
Me ZX_xx) with a short explanation (e.g.,
text_xx[downhearted]). - If no evidence is
detected, indicate explicitly.

Note: Provide only text indices and notes, ex-
cluding original text.

Read carefully the following Weibo text and
extract evidence across six preset dimensions.
Make sure the explanation for each aligns with

15.

16.

17.

18.

the depressive state.

[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - If evidence exists
for a dimension, output the text index (e.g.,
text_xx, SC 7X_xx) and a short remark (e.g.,
text_xx[low mood)]). - If no evidence is found,
specify clearly.

Note: Output only indices and remarks, not
the raw text.

Read through the following Weibo text and
extract major evidence across six given dimen-
sions. Ensure the output is consistent with the
depressive state specified.

[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - If evidence is found,
provide the text index (e.g., text_xx, SCAN_xx)
with a brief note (e.g., text_xx[hopeless]). - If
no evidence appears, state clearly.

Note: Only provide indices and notes, not
original text.

Please carefully review the Weibo text below
and extract key information from six preset
dimensions. All notes must align with the de-
pressive condition of the user.

[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - If there is evidence,
output the corresponding text index (e.g.,
text_xx, SC 7X_xx) and a short remark (e.g.,
text_xx[emotional slump]). - If not found,
specify clearly that none exists.

Note: Only include indices and notes, no orig-
inal content.

Please go through the complete Weibo text
and extract the critical information across six
given dimensions. Make sure your notes are
consistent with the depressive state provided.
[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - For each dimension,
if evidence is found, provide the text index
(e.g., text_xx, 3M AR_xx) with a concise ex-
planation (e.g., text_xx[feeling low]). - If no
evidence exists, indicate so.

Note: Only output indices and explanations,
not actual text.

Carefully read the Weibo text provided and ex-


19.

20.

A.3

tract important evidence across six specified
dimensions. Keep the explanations aligned
with the depressive state.

[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - If a dimension
contains evidence, state the text index (e.g.,
text_xx, SC 7X_xx) and a short remark (e. g.,
text_xx[upset]). - If not, state that no evidence
is found.

Note: Output only indices and remarks, not
text.

Read the Weibo text completely and extract
relevant evidence from six dimensions. En-
sure each dimension’ s note is consistent
with the depressive state given.

[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - If relevant evi-
dence is detected, provide the text index (e.g.,
text_xx, CAX_xx) and short description (e.g.,
text_xx[distressed]). - If not found, state
clearly no evidence.

Note: Only indices and notes, exclude text
itself.

Please read through the following full Weibo
text and extract essential evidence across six
preset dimensions. Ensure all notes are con-
sistent with the depressive state.

[Input] User depressive state: {label}, Full
Weibo text: {text}.

[Output requirements] - If evidence is found,
provide the text index (e.g., text_xx, SC AXN_xx)
and a short explanation (e.g., text_xx[worry]).
- If no evidence is detected, state that explic-
itly.

Note: Only indices and explanations, not orig-
inal text.

20 Distinct Label Expressions for the
Negative Users

. "This text does not contain any expressions

of negative emotions, nor does it involve any
dimensions of depression."

. "There are no descriptions related to negative

emotions in the text, so it does not fit any
depression-related dimensions."

. "This text does not include expressions of neg-

ative emotions, and therefore it is not classi-
fied under any depression dimensions."

10.

11.

12.

13.

14.

15.

16.

17.

"The content does not reflect negative emo-
tions and does not belong to any depression
indicators."

"This passage contains no expressions of neg-
ative emotions and is not applicable to any
depression dimensions."

"There are no descriptions of negative emo-
tions in the text, so it is not classified under
any depression-related dimensions."

. "This content does not exhibit negative emo-

tions and therefore does not involve any de-
pression dimensions."

. "The text does not contain any expressions

related to negative emotions, nor does it meet
the criteria for depression dimensions."

"There are no signs of negative emotions in
this text, so it does not belong to any depres-
sion dimension."

"The text does not describe negative emotions
and does not cover any depression-related di-
mensions."

"This passage does not contain any expres-
sions related to negative emotions and is not
within the scope of depression dimensions."

"The content does not include expressions of
negative emotions, so it does not fall into any
depression dimensions."

"There are no expressions of negative emo-
tions in the text, nor does it meet the criteria
for depression dimensions."

"This text does not exhibit any negative emo-
tions and does not involve any depression di-
mensions."

"This content does not include descriptions of
negative emotions and therefore is not classi-
fied under any dimensions of depression."

"The text does not show any negative emo-
tions and is not applicable to depression-
related dimensions."

"No expressions of negative emotions are seen
in this passage, so it does not meet any depres-
sion dimension standards."


18.

19.

20.

A

"There are no expressions of negative emo-
tions in the text, so it does not belong to any
depression dimension."

"This text does not display any expressions re-
lated to negative emotions and does not cover
the dimensions of depression."

"The content lacks descriptions of negative
emotions and is therefore not classified under
any depression dimensions."

Instructions for the Fine-Tuning Process

Complete Instruction = Task Instruction +
Supplementary Instruction

Task Instruction:
This task involves the following 6 dimensions of
depression:

Potential External Causes of Depression (Sec-
ondary Judgment Criterion)

Depression-Related Clinical Symptoms (Pri-
mary Judgment Criterion)

Depression-Related Language Expression Pat-
terns (Secondary Judgment Criterion)

Depression-Related Medical Expressions (Pri-
mary Judgment Criterion)

Depressive Psychological State (Primary
Judgment Criterion)

Negative Emotions (Secondary Judgment Cri-
terion)

Supplementary Instructions (randomly select
one):

1.

"Please read the following text segment and
determine whether it contains any of the above
6 expressions of depressive emotion, and pro-
vide a brief explanation; if none is present,
please indicate that the text does not belong
to any depression dimension."

"Read the following text and analyze whether
it demonstrates any one of the aforementioned
6 depressive emotion expression dimensions,
and provide a brief explanation; if such ex-
pression is absent, please indicate that the text
does not correspond to any dimension."

10.

. "Please carefully read the following text seg-

ment and confirm whether any one of the 6 de-
pressive emotion expression dimensions men-
tioned above exists, and include a brief expla-
nation; if not, please state that the text does
not belong to any dimension."

"Please read the following content and de-
termine whether it embodies any one of the
above 6 depressive emotion expression dimen-
sions, and provide a brief explanation; if not,
please indicate that the text does not cover any
depression dimension."

. "Read the following text segment and deter-

mine whether it contains any one of the 6
depressive emotion expressions mentioned
above, and provide a concise explanation; if
not, please state that the text does not belong
to any depression dimension."

"Please read the following text and determine
whether any one of the above 6 depressive
emotion expression dimensions appears, and
include a brief explanation; if not, please in-
dicate that the text does not meet any dimen-
sion."

. "Read the following text and check whether

any one of the above 6 depressive emotion ex-
pression dimensions is presented, and provide
a brief explanation; if not, please state that the
text does not belong to any dimension."

"Please review the following text segment and
determine whether any one of the above 6
depressive emotion expression dimensions ex-
ists, and provide a brief explanation; if not,
then indicate that the text does not belong to
any dimension."

"Read the following text and confirm whether
any one of the above 6 depressive emotion
expression dimensions is embodied, and pro-
vide a brief explanation; if not, please state
that the text does not involve any depression
dimension."

"Please read the following content and deter-
mine whether it contains any one of the 6 de-
pressive emotion expression dimensions men-
tioned earlier, and provide a brief explanation;
if not, please indicate that the text does not
belong to any dimension."


11.

12.

13.

14.

15.

16.

17.

18.

"Read the following text segment and verify
whether it demonstrates any one of the above
6 depressive emotion expression dimensions,
and include a brief explanation; if not, please
state that the text does not meet any dimen-
sion."

"Please read the following text and check
whether it exhibits any one of the above 6 de-
pressive emotion expression dimensions, and
provide a brief explanation; if not, please in-
dicate that the text does not cover any depres-
sion dimension."

"Read the following text and confirm whether
any one of the 6 depressive emotion expres-
sions mentioned above exists, and include a
brief explanation; if such a feature is absent,
please state that the text does not belong to
any dimension."

"Please carefully read the following text seg-
ment and determine whether it embodies any
one of the above 6 depressive emotion expres-
sion dimensions, and provide a concise expla-
nation; if not, please indicate that the text does
not correspond to any dimension."

"Read the following text segment and confirm
whether it contains any one of the above 6 de-
pressive emotion expression dimensions, and
provide a brief explanation; if not, please state
that the text does not involve any depression
dimension."

"Please read the following text segment and
determine whether any one of the 6 depressive
emotion expression dimensions mentioned
above appears in the text, and include a brief
explanation; if not, please indicate that the
text does not belong to any dimension."

"Read the following content and check
whether it contains any one of the above 6 de-
pressive emotion expression dimensions, and
provide a brief explanation; if not, please state
that the text does not belong to any depression
dimension."

"Please read the following content and deter-
mine whether any one of the above 6 depres-
sive emotion expression dimensions exists,
and provide a brief explanation; if not, please
indicate that the text does not involve any di-
mension."

19.

20.

"Read the following text segment and confirm
whether it demonstrates any one of the above
6 depressive emotion expression dimensions
mentioned above, and provide a brief explana-
tion; if not, please state that the text does not
meet any dimension."

"Please read the following text and determine
whether it contains any one of the above 6 de-
pressive emotion expression dimensions, and
provide a concise explanation; if not, please
indicate that the text does not belong to any
depression dimension."


A.5 Module II Prompt

You are a professional psychologist and text sentiment analysis expert. Below is a set of sentence-by-
sentence analysis results generated by a smaller model concerning all of the user's Weibo posts, each result
presented in the format “Text Label: Analysis Content.” Please use your professional knowledge to review,
filter, and correct these analysis contents, and then produce a final comprehensive analysis report.

[Task Requirements]

1, Review and filter the sentence-by-sentence analysis provided by the small model, selecting those text
entries that are useful for generating the final report.

2. Check whether there is any classification error within these entries. If you discover that the small model has
incorrectly assigned certain texts to an incorrect dimension (for example, classifying “unhappy” incorrectly
under depression-related medical expressions), please correct it based on the actual semantics and
psychological knowledge, reassign it to a more reasonable dimension, or exclude that erroneous information
from the final report.

3. The user's depression status is [already known depression label]. Please ensure that the final comprehensive
analysis report is consistent with this label:

o If the label is “depressed,” each dimension in the report should fully reflect evidence related to
depression;

o If the label is “non-depressed,” then the report should not contain extensive mentions of depressive
features.

4. In your descriptions, please avoid using specific time quantifiers (such as ">2 weeks"), and instead use a
neutral description such as “multiple occurrences.”

5. The final report should be organized under the following six dimensions:

Negative emotions (secondary judgment criterion)

Depressive psychological state (primary judgment criterion)

Depressive clinical symptoms (primary judgment criterion)

Potential external causes of depression (secondary judgment criterion)
Depression-related medical expressions (primary judgment criterion)
Depression-related language expression patterns (secondary judgment criterion)

In each dimension, please cite the corresponding text label and provide a concise explanation, ensuring that
all classifications in the final report are your corrected judgments. The output must not contain any
references to internal corrections (such as “already removed" or “already fixed") or references to specific
error rates.

[Reference Gold Standard Answers Example]
[Positive Example]
{positive_example}

[Negative Example]
{negative_example}

[Sample Input Data]
User's known depression label: [{label}]
Small model's sentence-by-sentence analysis results:

Please, based on the requirements above, review, filter, and correct the sentence-by-sentence analysis provided
by the small model, and then produce a final comprehensive analysis report. The report must be organized under
six dimensions, and in each dimension, please cite the corresponding text label along with a concise explanation.
Ensure that the final report, after your corrections, is consistent with the user's known label [[already known
depression label]] , and that it directly reflects the corrected chain of evidence and judgment conclusions,
without including internal correction statements or specific time descriptors.

Now, please produce the final comprehensive analysis report.

Figure 3: Module II Prompt.


A.6 Prompt for Table 3 On Section 5.3.1

Prompt is as follows: You are a professional in
psychology and text sentiment analysis. Please
determine whether the user is at risk of depression
based on the following six dimensions:

¢ Negative emotions (secondary criterion)

¢ Depressive psychological state (primary crite-
rion)

¢ Depression-related clinical symptoms (pri-
mary criterion)

¢ Potential external factors causing depression
(secondary criterion)

¢ Depression-related medical expressions (pri-
mary criterion)

¢ Depression-related language expression pat-
terns (secondary criterion)

For each dimension, please cite the corre-
sponding text reference and provide a concise
explanation.

[Output Data Example]
¢ Answer: “Yes” or “No.”

¢ Briefly explain the manifestations in each of
the six dimensions, and cite the correspond-
ing text reference.

¢ In conclusion, “The user is at risk of depres-
sion” or “The user is not at risk of depres-
sion.”

A.7_ Bert type models

BERT-base-chinese’ is built on the BERT-Base
architecture (Devlin et al., 2019) and is pre-trained
on extensive Chinese corpora. It adopts masked
language modeling (MLM) and next sentence
prediction (NSP) to learn deep bidirectional
representations of Chinese text at the character
level.

Chinese-RoBERTa-wwm-ext (Cui et al.,
2019) leverages RoBERTa (Liu et al., 2019)
with a whole word masking (WWM) approach.
Instead of masking individual characters, it
masks entire words during MLM, leading to a

https: //huggingface.co/google-BERT/
BERT-base-chinese

richer understanding of context. The extended
pre-training (ext) on large Chinese corpora further
refines its effectiveness in various NLP tasks.

StructBERT-mental (Wang et al., 2019) is
based on StructBERT, which incorporates linguis-
tic structures into its pre-training. By focusing on
word and sentence structure, and adding specific
pre-training for mental health texts, it improves
performance in identifying and categorizing mental
health-related content.
