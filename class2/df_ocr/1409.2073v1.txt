arXiv:1409.2073v1 [cs.CL] 7 Sep 2014

(U) Universitat Bremen

Fachbereich 3: Mathematik und Informatik

Bachelor Report

An NLP Assistant for Clide

Tobias Kortkamp

Matriculation No. 2491982

Monday 26t* May, 2014

First reviewer: Prof. Dr. Rolf Drechsler
Second reviewer: Dr. Berthold Hoffmann

Additional advisors: Dr. Mathias Soeken and Dipl.-Inf. Martin Ring




Selbststandigkeitserklarung

Hiermit erklare ich, dass ich die vorliegende Arbeit selbststandig angefertigt, nicht anderweitig zu
Priifungszwecken vorgelegt und keine anderen als die angegebenen Hilfsmittel verwendet habe.
Samtliche wissentlich verwendete Textausschnitte, Zitate oder Inhalte anderer Verfasser wurden

ausdrticklich als solche gekennzeichnet.

Bremen, den 26.05.2014

Tobias Kortkamp




Contents

1 Introduction

2 Basics
2.1 Clojure. 2.
2.1.1 Logic programming with corelogic ..........0.20.00 20000000 |
2.1.2 Tawny-OWL .. 2... 2...
252 COFENGP . 2: nee ete skew ER Ye ek Ew Ee we

3 Approach
3.1 ATCHICGGUUTG 2 cme se tes eR EM EMMY EE Rew ERE ew ew
3.2 Reconciler 2... ee
3.2.1 Chunking .... 2... 0.200200. 000. ee
3.2.2 Incorporating text changes ... 2... 2 ee
32:3 ‘Chunk annotations «: a sisi ee eee HER ERE RHE ERE ER
3.3 Integration of CoreNLP ..........0. 00.0000 ee ee
3.3.1 Accessing sentences of a text ©... 0... ee
3.3.2 Word maps .... 2... 2.0. ee
3.3.3 Coreferences . 2...
3.4 Building an NLP knowledge base ...........0..0.2. 02000000005
3.5 Clide annotations . 2...
3.5.1 Annotation streams .. 2...
3.5.2 Annotation levels... 2...

3.5.3 Annotations provided by clide-nlp . 2... 0... ee

4 Triples
4.1 Triple builders: s 22s: wie 8 i WERE BEER EER Ew EG mw ER
4.2 Reifying triples 2... 2. 2. ee
4.3. Exporting an OWL ontology... 2... 2 2 ee

5 Use case: Graph creation from a natural language specification
5.1 Triple walks...

5.2 Implementation... 0...

6 Conclusion


Contents

A Part of Speech Tags
B_ Installation notes
List of Figures

Bibliography

& A EB

gE


1. Introduction

While developing software or hardware natural language texts are part of the process and used
to record or specify the system requirements. The problem is to automatically extract the
information contained in these texts and make them available for processing. There are some tools
that support developers who want to work with and extract information from these specifications.
We are missing an approachable way to define simple rules to automatically extract and use

information from a text, that is not written in a severely restricted subset of English.

Some tools like e.g. Cucumbef!] a behavior-driven development framework, solve this by only
supporting a DSLPIIt provides a DSL called Gherkin, which allows users to write test scenarios
that both computers and humans can understand. Scenarios consist of steps and each step is
parsed using a user provided regular expression [22]. As a consequence a step’s regular expression
is coupled with the specific phrasing that is used in the step definition. A slight variation in
its phrasing without updating the corresponding regular expression or adding a new regular
expression, might break the scenario because the provided regular expression does not match the
step anymore. Ideally, we would like for two steps, with slightly different phrasing but the same

information content, to yield the same output and not break the scenario.

Defining and refining these extraction rules is not a solitary activity, but a collaborative one. By
integrating such a system with Clidef?] a development environment with collaboration baked in,

we support this aspect from the start.

Clide is a project that was developed as part of Martin Ring’s diploma thesis in 2013 at the
University of Bremen. It was originally intended to be a web-based development environment
for Isabelld’| only {14) [T9]. In contrast with previous Isabelle interfaces, it provides better visu-
alization of the prover’s results than traditional and sequential REPI}}based interfaces through
leveraging Web technologies like HTML5 and JavaScript [19]. It has since undergone further
development and has evolved to facilitate collaborative editing of documents with support for

other languages besides Isabelle [20].

Clide documents are annotated by assistants. It uses an approach called Universal Collaboration
where an assistant is seen as just an additional collaborator by the system [20]. While Clzde is
distributive and asynchronous in nature, it provides an interface that can be used to implement

assistants “in a simple, synchronous manner” [20].

' Available at http: //cukes.info/

?Domain Specific Language
3 Available at

https: //github.com/martinring/clide2
“An interactive theorem prover, available at http://isabelle.in.tum.de/

®Read Eval Print Loop



A Clide assistant is informed about state changes of Clide’s environment, be it newly opened
documents or edits of a document. It can provide domain specific annotations for any parts of

a document’s text.

This report describes clide-nip, an NLA} assistant for Clide. The assistant has the following

goals:
e Create a framework for extracting ontologies from a text, by
— creating an NLP knowledge base (see Chapter 3), and

— using simple queries on that knowledge base to extract useful information from the

text (see Chapter [4).

e Provide annotations for interacting with a text to assist in developing of the queries, in-

cluding showing
— the semantic graph of a sentence (see Figure [1.1p,
— the coreferenced’| of the text, and
— the ontology extracted from the text (see Figure[1.2).

e Work in the collaborative environment that Clide provides and keep the ontology and

annotations up to date and in sync with text changes.

e Being one of the first Clide assistants not developed by Clide’s author, clide-nlp should
also be seen as a test of the limits of Clide’s current API for developing assistants. Clide’s

development continues in parallel with the work on this report.

Chapter [3] introduces the components that constitute clide-nlp and how they interact with each
other. Section [3.1] and Section [3.5] discuss how clide-nlp is integrated into Clide.

Because of Clide’s interactive and collaborative nature, clide-nlp has to contend with continu-
ously changing text. Section discusses a model for providing support for incorporating text
changes into clide-nlp’s internal model. The provided annotations need to reflect these changes

immediately, or as fast as possible.

clide-nlp uses the CoreNLP framework by the Stanford University’s NLP group that provides
access to several NLP tools, including a coreference resolution system, which groups related
entities in a text together, and a dependency parser, that describes the relations between sentence

parts. Section [3.3] and Section describe how we can build an NLP knowledge base based on

these tools.

Chapter |4]shows how we can leverage the knowledge base to extract an ontology through a series
of simple queries. The queries are described in detail in Section Section [4.2] describes how
the queries’ results are used to create an ontology. Section [4.3] discusses one possible way of how
the ontology can be exported to an owl ontology.

°Natural Language Processing
“Groups of related entities in a text
8Web Ontology Language


1. Introduction 9

example.txt >
Files oo] Edge Test goes to node End and starts at node Start.
Ca
B example.txt
Collaboration a |
One other collaborator is participating in
this project
& nip | online |

@ chunk-separators

® coref-clusters

® draw

@® draw-warning-highlights
@® draw-warnings

® grouped-triples

® reified-name

® reified-triples

@ same-as It is 15 cm long. Node Noname and node Start have a distance of 2 cm.

ti re Node Start and node End are connected as are node Start and node Noname.
(RSET eI Edge Test is 4 cm long.
® triples

& invite a collaborator...

Chat Output EE *

Figure 1.1.: The clide-nlp annotation semantic-graph showing the semantic graph for the current
sentence (highlighted in blue).

In Chapter |5] we describe an example application that uses the extracted ontology. We ex-
tend clide-nlp to create graphs from natural language specifications by leveraging the ontology.
Figure [1.3] shows an example graph.


10

draw.txt >

Files o B| Edge Test goes to node End and starts at node Start.
It is 15 cm long.

& Node Noname and node Start have a distance of 10 cm.
Node Start and node End are connected as are node Start and
node Noname. Edge Test is 4 cm long.

Ib 00-README txt
edge-test-@ zat node-start-®
i draw.txt cm-@ zbe num-4-@
cm-1 :be num-15-@
ration a | cm-2 :be num-10-@
llaborator is participating in edge-test-@ tbe long-1
edge-test-@ be long-@
edge-test-@ :be be-1
@ np | online| edge-test-@  :be be-@
@ chunk-separators edge-test-@  :be start-@
® coref-clusters edge-test-@  :be go-@
& draw long-@ tbe cm-1
% draw ning-highlights long-1 sbe cm-0
Hc node-noname-@ :be have-@
ee node-start-@ :be have-@

. ; end-node-@ :connect node-start-@
Sn tt node-noname-@ :connect node-start-@
ete cane node-start-@ connect node-noname-@
@ reified-triples node-start-@ :connect end-node-@
% same-as edge-test-@  :go end-node-@
@® semantic-graph node-noname-@ :have distance-@
® triples node-start-@ have distance-@

distance-@ :0F cm-2
edge-test-@ :start node-start-@
& invite a collaborator edge-test-@  :to end-node-@
View
vy) Show Line Numbers
_ ae Chat Output Bl ‘

Figure 1.2.: The clide-nlp annotation reified-triples showing the triples that are found for the given
text and the annotation same-as highlighting all words that are detected as belonging
together in red. The highlighted words are part of the group Edge-Test-it-0.


1. Introduction

11

draw.tet

Edge Test goes to node End and starts at node Start.

It is 2 cm long.

Node Noname and node Start have a distance of 2 cm.

Node Start and node End are connected as are node Start and
node Noname. Edge Test is 4 cm long.

Noname (su)

Edge « est-@ is specified multiple times

Suggestions
e Check the sentences below

Affected words

t-@ has no length

e Add a sentence like Edge 8 is 5 cm long. OF Node A and Node B have a distance of 2 cm

Affected words

Chat Output [Ej

v

v
*

Figure 1.3.: Showing all annotation from the example application draw, draw-warnings and draw-
warning-highlights that draws the graph specified in the text and highlights potential

problems and ambiguous values in the text.




13

2. Basics

This chapter introduces some of the concepts needed to understand this report.

clide-nlp is implemented in Clojure. We first give a short overview of Clojure and its logic
programming library core.logic. We conclude this chapter with a short introduction of CoreNLP,
the NLP framework used by clide-nlp.

2.1. Clojure

Clojure is a functional programming language and has several features that make it a good fit

for NLP applications.

Clojure provides a REPL which allows us to patch in new code into a running system, enabling

a small “thought-code-feedback loop” [7].

It provides built-in persistent data structures with their own reader syntax, that are immutable

and have clear and intuitive value equality semantics (1 is 1 and |1 2 3} is {1 2 3)).

Clojure is built on top of the JVM and has good interoperability support with Java libraries.
This allows us to leverage all existing Java NLP libraries [6] [21].

Clojure’s macros can be used to extend the language when needed. This is used heavily by

core.logic, which adds logic programming to Clojure.

The following table summarizes the aspects of Clojure’s syntax that is important for reading this

report:

Type Example Description

Function definition | (defn f |a y| ...) | defn defines a function. Here we define the function f
that takes 2 arguments x and y.

Function call (f x) Clojure is a Lisp and uses prefix notation. Here we
call the function f with argument 2.

Keyword ‘a Keywords are often used as keys in a map, because
they evaluate to themselves and can be used as func-
tions that look themselves up in the associative data
structures (e.g. a map) that is passed to them as their
first argument.

Map {:a "Hello" :b 0} | A map with the key-value pairs (:a, "Hello") and (:b,
0)

Vector [1 2 "Hello"| A vector with the elements 1, 2 and "Hello"

There is no special interoperability support for interfacing with Scala libraries, like e.g. Clide.


14 2.1. Clojure

Interfacing with Scala directly from Java is already challenging, and interfacing with Scala from
Clojure adds an additional complication. The work around is to write the components that use

Clide directly in Scala and use Clojure’s runtime interface to call into Clojure code from Scala.
More information on Clojure is available in [6} [7].

2.1.1. Logic programming with core.logic

core.logiq?] adds logic programming capabilities to Clojure. It is based on miniKanren, a logic
programming library for Scheme, developed by William E. Byrd as part of his PhD thesis [2].

Because core.logic is a library for Clojure, we can mix functional and logic programming freely,
dropping down to core.logic when we need it and use Clojure functional programming aspects
otherwise [21].

We summarize the most important functions and macros of core.logic here:

Type Example Description
Run a query (run* [q) ...) Runs a core.logic query by trying to unify a
value with q. Returns a list of all possible
values for q
Create logic variables (fresh [a b] ...) Creates two unbound logic variables a and
b
Unnamed logic variable | (Ivar) Returns a new logic variable
Logical disjunction cond® Tries all branches consecutively
[<branch1>|
[<branch2>|
Soft cut (cond® ...) Like cond® but stops the search as soon as
a branch succeeds
Feature extraction featurec Extracts features from maps. The exam-
{:a 4 :b 5} ple binds the logic variable g to 4.
{:a g}
Unify (= q 4) Unifies the logic variable q with 4.
Never unify (# q 4) Adds a constraint to the logic variable q
that it can never be 4.
List membership ‘member® q |1 2 3}) A goal that succeeds if q is bound to value
that is in the vector [1 2 3]
Extract a logic (project |q| ...) Extracts the value that is bound to the
variable’s value inside a logic variable g. While in scope of a project
query qis aregular Clojure value and we can use
regular Clojure functions with it.
Domain constraint (in q (interval 1 10)) Makes sure that q is bound to a value in
the interval {1, 10}.

° Available at https://github.com/clojure/core. logic


o FW NH Ff

a

2. Basics 15

The presentation of the core.logic code shown here is based on the code presentation in [2} {8}.

Presentation | Actual code

<x>° <x>0 A goal is written with a suffix o to distinguish it from
already defined functions on the functional programming
side, while making clear that they have the same outcome

in both paradigms [2]. E.g. cons° in core.logic and cons

in Clojure
run* run*
cond® conde The branching macros have an added suffix to
cond® conda distinguish them from the built-in cond.

Z '-
The Reasoned Schemer provides a good introduction to miniKanren and in extension also

core.logic|™|

Example. We create a new knowledge base and populate it with three facts about animals.

Relation | Kind | Name

animal cat Felix

animal cat Mittens

animal dog Waldo

Using this knowledge base, we can define a new goal that succeeds iff an animal is a cat or a dog.
We make use of the predefined goal member® to check if the value of a logic variable is inside of

a collection.

(defn cat-or-dog® |name q|
(fresh [t)
(animal t name)
(member® t {"cat" "dog" )
(= t q)))

We can then build a query to check what kind of an animal Waldo is:

(run* [q|
(cat-or-dog® "Waldo" q))

=> ("dog")

Waldo is a dog! And Benjamin?

(run* |q|

(cat-or-dog® "Benjamin" q) )

‘°Their differences are described on core.logic’s Wiki available at https: //github.com/clojure/core.logic/
wiki/Differences-from-The-Reasoned-Schemer



16 2.2. CoreNLP

=> ()

Benjamin does not exist in the knowledge base, so the query returns no result.

We can run the query in reverse to get all cats:

(run® |q|
(cat-or-dog® q "cat"))

=> ("Felix" "Mittens" )

While core.logic supports relational programming, our usage of several non-relation goals, like

cond® or project, makes all of our core.logic usage effectively non-relational.

2.1.2. Tawny-OWL

Tawny-OWL|"] is a Clojure library that provides a domain specific language for building OWL
ontologies [13].

clide-nlp uses Tawny-OWL for building OWL ontologies out of its custom ontologies it extracts
from texts (see Section |4.3). Exporting OWL ontologies allows us to make use of the existing
OWL tools, like e.g. querying them via SparQL [iO].

2.2. CoreNLP

CoreNLP is an NLP framework that was created by the NLP group at Stanford University|?] It
includes several components that facilitate developing NLP applications or algorithms. clide-nlp

uses CoreNLP’s dependency parser and its coreference resolution system.

The dependency parser makes the underlying structures of sentences visible in the form of gram-
matical relations between sentence parts [4]. The output of this component can be modeled
as a graph, where the grammatical relations are the graph’s edges and the nodes are the sen-
tence parts. We call this graph semantic graph in this report. Examples of semantic graphs are
available in Section and Section The grammatical relations are described in [5]. The
dependency parser can collapse prepositions and coordinations into grammatical relations [4] {5}.

clide-nlp uses this feature to simplify the resulting semantic graphs.

The dependency parser makes use of CoreNLP’s part-of-speech (POS) tagger. Its tagset is based
on the POS tagset used by the Penn Treebank, described in [15]. Because semantic graphs
contain POS tags and clide-nlp makes heavy use of semantic graphs, Table provides an

overview over some of the tags provided by CoreNLP.

The deterministic coreference resolution system is used to identify entities refer to each other
(also called mentions). It was introduced in [18]. It competed in the CoNLL Shared
Task 2011, where it achieved the highest score in both the closed and open tracks [12].

Section [3.3.3] goes into more detail and shows an example coreference cluster.

11 Available at
12 Available at

https://github.com/phillord/tawny-owl
http://nlp.stanford.edu



17

3. Approach

This chapter introduces the components that constitute clide-nlp and how they interact with
each other. We first describe how data flows between the components by giving a high-level
architecture overview in Section [3.1] We then delve deeper into the implementation.

clide-nlp receives a continuous stream of events (text operations, cursor movements, and anno-
tation requests) from Clide that need to be integrated with clide-nlp’s underlying computation
model. Section [3.2] describes this model and how we integrate changes into it.

In Section [3.3] we continue with a description of how CoreNLP is integrated into the system by
revealing some pitfalls that occur when using the diverse data structures provided by CoreNLP
and how we can avoid them. In Section we then build a knowledge base from the data
provided by CoreNLP which we can use with core.logic and that forms the basis for the remaining

chapters.

We conclude this chapter with Section[3.5}and explain the user-facing side of clide-nlp by showing
what annotations are provided and what caveats apply given the current annotation model of

Clide.

3.1. Architecture

Figure [3.1] shows how data flows between the components in clide-nlp.

Clide assistants need to provide a subclass of AssistantServer. AssistantServer has support
for connecting and receiving messages from Clide built-in and abstracts away the underlying

Akka implementation.

clide-nlp calls its AssistantServer subclass AsyncAssistantServer. It receives events for file

changes and cursor movements.

All file changes are passed to the reconciler, which uses referentially transparent functions. We
pass them the current state of a file and it returns an updated version of that state. The
AsyncAssistantServer instance is responsible for storing that state and retrieving it when

needed.

The AsyncAssistantServer enqueues the reconciler state and the cursor position of the change

in a queue that is used by the annotation-loop.

The annotation-loop reads one element (state and position) at a time from the queue and prepares
Clide annotations based on it. See Section for a list of provided annotations.

The annotations are not computed in the annotation-loop, but are sent to the assistant-loop,


18 3.2. Reconciler

e Keeps track and updates e Keeps track of wanted annotations”)
the reconciler states of all e Wraps Clide’s AssistantControl
open files and converts between Scala and

e Receives file changes and Clojure data structures
cursor movements e sends annotations to Clide

updates / initializes

AsyncAssistantServer

returns updated state

when a file changed or the

cursor moved, enqueues an

annotation request for the file,

providing

e the file in which the change
or cursor movement

it
e Adds lazy NLP annotations
(semantic graphs, triples, ...) to
text files
e Merges any file changes and
reannotates all changed text parts

uses

occurred

e the cursor or change
position

e the file’s reconciler state

Y

| Annotators }#———H+ annotation-loop assistant-loop
| |
it 1

Prepares annotator e Realizes all annotations that at >
execution by building least one user requested

a lazy map of all e Sends all realized annotations to
possible annotations Clide

Data flows from A to B.
[A}>[B] Data flows from A to B and from B to A.

Data is sent from A and is queued at B (asynchronously).

Figure 3.1.: High-level architecture overview showing the data flow between clide-nlp’s compo-
nents

which is responsible for realizing only those annotations that the users of clide-nlp want to see

and then sending them to Clide.
The annotators that create Clide annotations make use of the reconciler’s lazy NLP annota-

tions (see Section |3.2). The combination of lazy Clide annotations and lazy NLP annotations

guarantees that clide-nlp only does work when it really has to.

3.2. Reconciler

Clide is a collaborative editing environment. Multiple users may change the current file’s text
at any time. As such clide-nlp needs a way to incorporate those text changes into its own data

model.

In traditional IDEs the process which incorporates changes into its data models is called rec-
onciliation. Clide itself does not provide built-in support for reconciling yet. clide-nlp has to

provide that support itself.


3. Approach 19

The reconciler has several related tasks, which are performed in the following order:
1. Split the input text into separate chunks
2. Replay Clide deltas to incorporate text changes and mark all chunks that have changed

3. Compute NLP annotations for each changed chunk

3.2.1. Chunking

clide-nlp splits an input text into several parts to keep the time needed for (re-)computing the

NLP annotations to a minimum and to make testing easier.
In the implementation provided with this report, clide-nlp splits an input text at the string

Oh yan",

Example. The following text

The cat eats the mouse.

The mouse is dead.

is split into 3 chunks:
1. The cat eats the mouse.
2. ----
3. The mouse is dead.

Each chunk has an associated span. A span is the offset interval from the beginning of the text.

In the example above, Chunk 1 has a span of [0, 25) and Chunk 2 is called a chunk separator.

Because a chunk is just a slice of an input text, more complicated chunkers are possible, and
indeed would be more useful and realistic than the very simplistic chunker currently imple-

mented.

We could e.g. treat comment blocks in a Java file as a chunk and the code in between blocks as
chunk separators. CoreNLP might not understand tokens or characters used in Java comments
and as a consequence, we would need to remove them first. If we replace them with whitespace
before passing the comment to CoreNLP, we make sure that we can map to the original text in

an easy way by mirroring the spans inside the original text and inside the replacement text |]

'3CoreNLP does something similar in its cleanxml annotator to remove XML tags from an input text before
parsing it.


20 3.2. Reconciler

Example. The Java comment

{rr

* This is a comment
*h
can be written as

S = "/*«\nux This yisyaycomment\n*/"

The substring

T = "This,jis,ja,;comment"

has the span [7,24) in S. If we replace all special characters not understood by CoreNLP with

spaces, we would get the string

oO = "un \n Thisyisya, comment \ nu"

The span of T in S’ is still [7, 24).

3.2.2. Incorporating text changes

In Clide text changes are described as a list of operations that describe the steps needed to
transform an old version of a text into a new version. There are three operations :

e Retain(n)

e Insert(s)

e Delete(n)

Since Clide is written in Scala Retain, Insert and Delete are implemented using Scala case
classes|"4] While it is possible to work with theses classes in Clojure, it is easier to translate them

to use Clojure’s data structures instead.

The translation is straightforward. For each operation, replace

Retain(n) with  [:retain n]
Insert(s) with  [:insert s]
Delete(n) with [:delete n]

Example. The operations [Retain(5), Insert("hallo") , Retain(15)] are translated into the
Clojure data [[:retain 5] [insert "hallo"] [:retain 15]].

To apply the operations we need to maintain a cursor position starting at 0. The cursor’s position
is the position in the original text, not the edited text. The original text is immutable and is

not changed. The edited text is built by applying each operation sequentially:

e [:retain n] moves the cursor n characters ahead and inserts them in the edited text.

Case classes are algebraic data type constructors and allow pattern matching.


3. Approach 21

e [:insert s] inserts the string s at the current cursor position in the edited text. This will

not move the cursor, because it is relative to the original text.

e [:delete n] deletes the next n characters at the current cursor position and moves the cursor

nm characters ahead.

Example. Given the input text "Thisyisyautest." and the operations |[:retain 9] [:insert "the"]

[:delete 1] [:retain 6]], we get the text "This,is,jthe,test." after applying them.

As the reconciler splits a text into several chunks there are some more concerns to address.
The changes to a text can be

1. inside a chunk separator, i.e. between two chunks A and Ain which case there are two

possible scenarios:

a. A remains unchanged and the spans of B and of all chunks that follow it have to be

updated.

b. A and B have to be merged together because the chunk separator is not valid anymore.

This would also change the spans and indices of all chunks that follow A and B.

2. inside one chunk C, in which case C’s span (end offset) and the span of all chunks that
follow C' must be updated to reflect the changes.

In the actual reconciler implementation changes between two chunks are detected after applying
the edit operations and rechunking the text. If the number of chunks changed, the reconciler
is simply reinitialized. This greatly simplifies the implementation, but all NLP annotations are

lost and need to be rebuilt. An ideal implementation would have to follow all scenarios above.
3.2.3. Chunk annotations

Each chunk has associated annotations that are updated when a chunk changes. The annotations
are added to a Clojure map with lazy evaluation semantics. This model allows the reconciler to
remain fast even when there are continuous changes. The chunk annotations are only realized,

and thus computed, outside of the reconciler.

The graph in Figure [3.2] shows how the annotations depend on each other. Note that graph is
the central nexus of clide-nip that pulls all of its parts together. As such every aspect of clide-nlp

is mirrored in it.

The annotations have the following meaning:

:text, :corenlp-pipeline The graph’s inputs are a previously constructed CoreNLP pipelind™|
and the chunk’s text.

:corenlp-annotation A CoreNLP annotation is created based on the input text. The annotation
provides access to all primitive NLP constructs we need (which includes the coreference

chain, the semantic graphs, all split sentences, and information about each token).

®Chunk B follows chunk A.
16The pipeline needs to be setup to use CoreNLP’s depedency parser and its coreference resolution system.


22 3.2. Reconciler

:corenlp-pipeline :text

\

:corenlp-annotation

a |

:coref-chain-map :semantic-graphs :sentences

\_Z

:>knowledge-base

“|

‘triples :grouped-triples

|

:reified-triples

/

‘ontology _:reified-triples-knowledge-base

|

:draw

Figure 3.2.: Chunk annotation dependency graph

:semantic-graphs Extracts all semantic graphs from the annotation and creates a Clojure rep-
resentations of them. In CoreNLP the class that represents nodes in a semantic graph is

called IndexedWord. All IndexedWord instances are mapped to a word map for later use

(see Section |3.3.2).
:coref-chain-map Extracts all coreference clusters from the CoreNLP annotation (see Section|3.3.3).

‘sentences Extracts information about each of the input text’s sentences from the annotation

and builds a list of sentence maps (see Section |3.3.1).

:knowledge-base Builds a knowledge base for use with core.logic out of the coref chain map and
semantic graphs. The process is described in Section [3.4]

:triples Runs triple builders on the knowledge base that extract useful information gathered
from the semantic graphs and builds a list of triples. The triple’s subject, predicate, and
object only refers to a node in the semantic graph of one sentence. See Chapter [4] for more
details.

:grouped-triples Runs triple builders on the knowledge base and groups the triples’ subjects


3. Approach 23

and objects by their coreference cluster. A group is a list of coreferent or otherwise related
words. In contrast with the triples extracted by :triples, the grouped triple’s subject and
object are a list of related words that can span multiple sentences (the whole text) instead
of only one sentence. See Section [4.2] for more details.

:reified-triples Multiple grouped triples can all have the same subject or object groups. :reified-triples

assigns a unique name to each group i.e. the groups are made real (reified) by giving them
a name (see Section |4.2).

:reified-triples-knowledge-base Adds the reified triples to the knowledge base for use by appli-

cations that don’t want to search the triples sequentially.

‘draw An annotation that is introduced in detail in Chapter [5] It tries to draw a graph specified

in the input text and to warn about simple ambiguous sentences.

‘ontology Builds an OWL ontology (see Section [4.3).

An annotation is only realized when it is directly needed or used by a dependent annotation. As
a result, clide-nilp does not always have to compute all annotations if the text changed and only

does work if it is really needed.

Example. If a client accesses the :knowledge-base annotation only the following annotations are

realized: :semantic-graphs, :coref-chain-map, :corenlp-annotation, text [1]

3.3. Integration of CoreNLP

clide-nlp tries to not rely on CoreNLP’s data structures, because the data structures need to
participate in core.logic unification. Due to the mutable nature of CoreNLP’s data structures

extending them to reliably support unification is problematic.

Additionally, there are inconsistencies in the usages of 0- or 1-based indices in CoreNLP’s data
structures. This is corrected when constructing clide-nlp data structures and allows for easier

matching up of the different data structures based on sentence and token indices.

All data structures are implemented using Clojure records. Records are reified maps, which
compile down to Java classes. They implement the correct interfaces, so that they can be

treated as maps, which we will do from this point on.
We introduce each record by
e giving a short description of its use in clide-nlp,
e by listing its available keys with a description of the content of their values,

e and by showing examples with actual data.

lNote that :text is the input to the graph and as such always realized.


24 3.3. Integration of CoreNLP

3.3.1. Accessing sentences of a text

While accessing individual sentences of a text is not important for the core task of clide-nlp
(extracting an ontology from a text), we need them to create Clide annotations that refer to a

whole sentence (see Section |3.5).
Sentence maps have the following keys:

‘index The index of the sentence starting at 0.
‘span. The 0-based character index span [a,b) of the sentence. The sentence starts
at offset a and goes up to offset b.

‘text The text of the sentence.

Example. The text "Felix is a cat. Waldo is a dog. Tweety is a bird." results in the following
sentence maps{!§]

‘index 0 ‘index 1 ‘index 2
‘span =‘ [0, 15) ‘span =: [16, 31) ‘span =: [32, 49)
‘text —- Felix is a cat. ‘text Waldo is a dog. ‘text Tweety is a bird.

3.3.2. Word maps

Semantic graph nodes are an integral part of the triple builders introduced in Chapter [4]

The semantic graph node class in CoreNLP is called IndexedWord. The information that an
IndexedWord object provides, is used to create a word map with the following keys:
:sentence The sentence index this word map refers to. This matches the sentence maps’
:index value.
:index The index of the word’s token starting at 1. CoreNLP consistently starts at 1

when counting tokens.

‘span The 0-based character index span [a, b) of the word map.
‘tag The word’s part-of-speech tag.

:lemma The word’s lemma.

:token The word’s token.

'8When checking the spans do not forget to include the spaces between the sentences!


3. Approach

25

Example. The semantic graph for the input text "Felix is a cat." has the following word maps:

sentence
‘index
‘span
‘tag
‘lemma

:token

0
1
[0, 5)
NNP
Felix
Felix

sentence
sindex
‘span
:tag
lemma

:token

0

2

[6, 8)
VBZ
be

is

sentence
sindex
‘span
‘tag
‘lemma

:token

0
3

(9, 10)
DT

a

a

sentence
sindex
‘span
‘tag
‘lemma

:token

0

4

[11, 14)
NN

cat

cat

3.3.3. Coreferences

clide-nlp uses CoreNLP’s coreference resolution system to identify which entities in a text are

similar to other entities in a text. Coreferences are grouped in clusters. A cluster is made up of

mentions and we map them to mention maps with the following keys:

:cluster-id

‘sentence

:index-span

‘text

The coreference cluster id the mention map is a part of.

The index of the sentence that contains this mention map. The indices in

CoreNLP start at 1 here. We correct them to be 0-based, and as a consequence

match a sentence map’s :index and a word map’s ‘sentence value.

The index span [a, b) refers to the tokens starting at the word map with index

a and ends before the word map with index b. The indices are 1-based again,

but we do not need to adjust them here, because the token indices of word

maps are 1-based, too.

A clear text representation of the mention map.

CoreNLP’s coreference system provides additional information about each mention. Information

about a mention’s gender, its animacy or its number (plural or singular), is however currently

unused by clide-nip.

Example. The text "Felix is a cat." has the following coreference cluster and associated mention

maps:

Felix [0:1-2

We see that the coreference resolution system in CoreNLP identified Felix to have the same

a cat [0:3-5

meaning as a Cat.

:cluster-id

:sentence
:index-span

‘text

1
0
(1,2)
Felix

:cluster-id 1

:sentence
:index-span

‘text

0
[3, 5)

a cat



26 3.4. Building an NLP knowledge base

3.4. Building an NLP knowledge base

This section describes how the data structures introduced in Section are inserted into a

core.logic database.
Chapter [4] makes extensive use of the knowledge base and provides usage examples.

We first need to define the relations that we want to provide. They are described in further

detail later. clide-nlp’s knowledge base provides the following relations:

(word-map w) provides access to word maps (semantic graph nodes).
(depends dep reln gov) provides access to semantic graph edges.
(same-as wy We) succeeds iff the word maps w, and wz can be treated as referring to

the same word.
Next we need to insert facts into the knowledge base. Given an input text,

1. for every word map w of a semantic graph of a sentence of the text, insert the fact

(word-map w).
2. for every semantic graph edge e = (dep, reln, gov) of a semantic graph of a sentence of the

text, insert the fact (depends dep reln gov).

3. for the word maps w, and wz and using word-map, depends and coreference cluster mentions,
determine if w, and we can be treated as referring to the same word, then insert the facts

(same-as w, we) and (same-as w2 w}).

(word-map w)

word-map provides access to the word map w. It is a unary relation. To unify with information

from a word map, it needs to be used in conjunction with core.logic’s feature extraction goal

featurec (see Section |2.1.1).

Example. Using core.logic’s featurec goal, we can limit a query to only succeed with maps with
specific features. The following query returns all word maps which have a tag NN and an index

0.

(run® (q)
(word-map q)
(featurec q {:tag "NN" sindex 0}))

Because matching a specific set of part of speech tags is used heavily by the triple builders
introduced in Chapter [4] the following helper goals are defined:



oo FW DY FR

rw N

3. Approach 27

tag° w tags) suceeds iff w has one of the tags in the vector tags.

verb° w) succeeds iff w is a verb, i.e. if it has one of the tags VB, VBD, VBG,
VBN, VBP or VBZ.
‘noun® w) succeeds iff w is a noun or pronoun, i.e. if it has one of the tags NNP,

NN, NNS. PRP or PRPS.
wh-word® w) succeeds iff w is a wh-word))] i.e. if it has one of the tags WDT, WP,
WPS or WRB.

tag° is the basis of the implementations of all of these goals. tag° can be defined in the following

way:

(defn tag?
iw tags|
(fresh [tag]
(word-map w)
(featurec w {:tag tag})
(member® tag tags)))

(depends dependent relation governor)

While word-map provides access to semantic graph nodes, depends provides access to semantic

graph edges.

An edge goes from the word map governor to the word map dependent with the grammatical
relation relation. We insert every edge of every semantic graph of every sentence of a text into

the knowledge base.

relation can be either a string containing a typed dependency relation (see [5]) or if the relation
is a collapsed relation, a vector of the first and second part of the relation (e.g. if the relation in
the semantic graph was prep_ of, it gets split into the vector |"prep", "of"|). Splitting a collapsed
dependency in that way keeps core.logic queries simple by making use of its native support for
unifying vectors. This allows searching for specific prepositions or all prepositions in a simple

Manner.

Example. The following query returns the governor and dependent word maps of all edges with

a prepositional relation (e.g. prep of or prep_in) from every semantic graph of a text.

(run* [q|
(fresh [dep gov p|
(depends dep |"prep" p| gov)
(= q [dep gov])))

(same-as wy, we)

same-as asserts that the word map wy, is the same as the word map we and that we can treat



28 3.4. Building an NLP knowledge base

the words as being instances of the same word group.

same-as should be commutative, so that the order of w or wg does not matter. If (same-as w , we)

succeeds, (Same-as we wy 1) succeeds, too.

Because w 1 and we are instances of the same word group and we like the word groups to be
about a concrete thing, we want to limited them to only include pronouns, nouns, or determiners.
Including adjectives e.g. does not make sense because they are properties of word groups. Verbs

are used between two or more word groups.

same-as is important for grouping triples (see Section |4.2). There are several aspects for when

we can consider two word maps the same.

To be included in the same-as relation, the word maps w, and w2 need to fulfill at least one of

the following rules:

® w 1 and w2 need to map to the same coreference cluster. We need to find the corresponding
word maps of each of the cluster’s mentions. We can do this in a core.logic query by

constraining a word maps index to be inside of the mention’s index span:

(let ||start end] (:index-span mention), sentence (:sentence mention) |
(run® |q|
(fresh |index tag|
(word-map q)

(featurec q {:index index, :tag tag, :sentence sentence} )

oo F WN

(in index (interval start (dec end) )))))

We further limit the query result to only include word maps that represent pronouns,

nouns, or determiners.

We run the query for every cluster mention and select every 2 combination of the found
word maps and record the facts]

Same€-aS W] W2 Same-aS W2 W 1

same-as W1 W1 same-as wa W2

We repeat this process for every coreference cluster.

e The query

(run* [wy we]
(noun? wy)

(noun? we)

Ee WwW oe

(depends w, "nn" we))

succeeds for w, and wy.

nn is the noun compound modifier dependency relation that asserts that one noun modifies

another noun [5].

20While facts might be recorded twice, we can safely ignore this.


3. Approach 29

By including compound nouns in same-as, we ensure that every word of a compound noun
is assigned to the same word group later (see Section |4.2).

® w, and wz need to be linked by a wh-word. Word maps that are linked by a wh-word can

be found with the following query:

(run* [wy we|
(fresh |w|
(wh-word® wy)

(depends w, "nsubj" w)

o FW NHN

(depends w (Ivar) we)))

CoreNLP’s coreference system does not include wh-words in its mentions. Some triples
found by the triple builders in Chapter [4] have a wh-word as their subject and we need to
make sure that they can be grouped together with the other groups and do not create a

group by themselves.

3.5. Clide annotations

Clide annotations are used to provide rich information about specific parts of a text. They are
currently static and non-interactivq?!| There is e.g. no way to jump to a specific word in the
document from an annotation. While this limits their usefulness, it does not prevent them from

being helpful.
They follow the same model as the operations sent by Clide (see Section|3.2.2) and are represented

as a list of annotation operations, called an annotation stream. In Clide they are simply called
annotations, but we use the term annotation stream to distinguish them from the annotation

lists they contain.
3.5.1. Annotation streams

An annotation stream is a list of annotation operations. There are two types of operations:

e Plain(n)

e Annotate(n, annotations)
where n is the annotation’s length and annotations is a list of tuples (type, content) with type
being the annotation type and content a string containing the actual annotation content.
We again translate the Scala syntax into Clojure data and replace

Plain(n) with [:plain n]
Annotate(n, annotations) with [:annotate n annotations|

To apply an annotation stream we need to maintain a cursor position starting at 0. The an-

notation is applied by applying each action sequentially and mutating the cursor position after-

wards.

21 This means that you cannot interact with the annotation itself, because they are view-only. You can however
request a new annotation.


30 3.5. Clide annotations

e [:plain n] skips n characters from the current cursor position c;, and adds n to it:
C41 = GQ +N.

e [:annotate n annotations] moves the cursor n characters ahead and annotates the text span
from [c;,¢i41) where cj41 = cq +n. Clide then interprets the annotation list annotations
and displays them.

where
i the index of the operation in the list
co «(O
c; the cursor position before applying the operation
ci+1 the cursor position after applying the operation
There is a direct correspondence between annotation and edit operations (see Section [3.2). Ig-

noring annotations, we can treat :plain and :annotate as :retain operations [20].

An annotation stream should span the whole text, that is by summing up the n-s of each

operation, we would get the text length.

Clide defines several annotation types. clide-nlp uses the following subset of them:
Class sets the CSS class to use for the annotation.

Tooltip sets the tooltip used when hovering over the annotation.

WarningMessage display a warning inline.

Output for displaying generated information, that is not displayed inline by default.

Clide allows HTML inside of its annotations, which means that we can display richer annotations

than only simple plain text annotations.

Example. Given the text "The ,catvishungry."

[[:plain 4], [:annotate 3 [[:Class "error"]]], [:plain 11]|

of length 18 and the annotation stream

and assuming [:Class "error"] is meant to color the annotated text red, applying the annotation
stream to the text results in

"The catyis hungry."

3.5.2. Annotation levels

While Clide annotations can annotate arbitrary ranges of a text, it is useful to distinguish
between different annotation levels in clide-nlp:

Text Annotates the whole text

Chunk Annotates a chunk (as defined in Section [3.2)

Word Annotates a single word

Sentence Annotates a whole sentence

Every annotation in clide-nlp, with the exception of a text level annotation, is relative to a chunk.

By doing so, we keep the annotation creation as simple as possible.


3. Approach 31

As discussed in Section a chunk has an associated span that indicates the chunk’s text
position inside of the global text. A chunk’s internal span begins at 0. CoreNLP never sees the
whole text at once, but instead only sees the texts of every chunk separately, so all spans returned
by CoreNLP also begin at oP] It follows that the NLP knowledge base is chunk local, too. As
the annotations created by clide-nip all use CoreNLP annotations or the NLP knowledge base,
we ideally should use chunk local offsets when creating annotation streams. We later project

their chunk local offsets to offsets that Clide can interpret correctly.

3.5.3. Annotations provided by clide-nlp

In this section we describe each annotation that clide-nlp provides by showing an example of
how they appear in Clide. The annotations make use of one more of the chunk annotations
as described in Section There might be some overlap in their names, but they should be
treated as separate entities. The names are presented to the user by Clide, who can enable them
individually (see the names to the left with the “eyes” in Figure[1.1).

chunk-separators Level: Text

Felix is a cat.

Waldo is fa good dog.

Tweety is a bird.

Highlights the chunk separators. Chunks are described in Section This makes the chunkers

decisions visible.

semantic-graph Level: Sentence

Felix is a cat. Waldo is a dog.

a-DT-1:3

Highlights a sentence and displays the sentence’s semantic graph. This annotation is highly

useful when creating a new triple builder.

22 After some correction (see Section[3.3)


32

3.5. Clide annotations

coref-cluster

Felix [0:1-2]
a cat [0:3-5]

Waldo [1:1-2]
a dog [1:3-5]

Tweety is a bird.

Felix is a cat.| Waldo is a dog.

Level: Chunk

Shows the coref clusters that CoreNLP found for the selected chunk’s text.

same-as

Tweety is a bird.

Felix is a calt. Waldo is a dog.

Level: Word

A direct interface to the knowledge base that uses the same-as relation to highlight the related

words of the selected word.

triples

Felix is| a cat. Waldo is a dog.

Felix-NNP-0:1 is-VBZ-0:2 cat-NN-0:4
Waldo-NNP-1:1 is-VBZ-1:2 dog-NN-1:4

Tweety is a bird.

Level: Chunk

Shows the raw triples extracted from running the triple builders on the selected chunk’s text.

grouped-triples

Level: Chunk

Tweety is a bird.

| [Felix-NNP-0:1 a-DT-0:3 cat-NN-0:4]

Felix is a cat|. Waldo is a dog.

is-VBZ-0:2 [Felix-NNP-0:1 a-DT-0:3 cat-NN-0:4]
[Waldo-NNP-1:1 a-DT-1:3 dog-NN-1:4] is-VBZ-1:2 [Waldo-NNP-1:1 a-DT-1:3 dog-NN-1:4]

Shows the triples’ groups.


3. Approach 33

Level: Chunk

reified-triples

Felix is a cat. Waldo is a gobd dog.

felix-cat-0 :be felix-cat-0
waldo-dog-0 :be waldo-dog-0
waldo-dog-9 :be good-0

Tweety is a bird.

Shows a table with all reified triples extracted from the selected chunk’s text.

Level: Word

reified-name

Felix is a cat. Waldo is a good dog.

Tweety is a bird.

This annotation is identical to the same-as annotation, but additionally adds a tooltip to the

highlighted words, showing the word group they belong to.




39

4. Triples

In the previous chapter we built an NLP knowledge base. This chapter introduces triple
builders that runs simple core.logic queries on it and extracts triples. Triples have the form

(subject, predicate, object). They represent a unit of useful information.

Where possible a triple’s subject and object each have one corresponding word map in a semantic
graph. Using the knowledge base introduced in the previous chapter, we group the triple’s subject
and object with other related subjects or objects of other triples, yielding an ontology.

4.1. Triple builders

Triple builders extract triples. Triples have the form (subject, predicate, object). They represent

a unit of useful information that is directly extracted from the semantic graph.

A subject usually does something (predicate) with an object. Every subject and object is di-
rectly linked to a word map. For predicates however this is not always possible, because there
are predicates which are implied by the semantic graph (see the triple builders nsubj-amod or
possessive for an example of this). These predicates are called derived and written with a colon

prefix (e.g. :be) to distinguish them from word map predicates.

While the triple builders only extracts information from semantic graphs, they could be extended
to include information from ontologies like WordNet [16], VerbOcean [3] or DBpedia [I] to further

constrain the triples that are found.

A triple builder is implemented as a core.logic goal >] It either succeeds with a triple or it does
not. All triple builders are tied together in a logical disjunction (cond®) and are all tried in turn.
Most of the triple builder’s names are directly derived from the semantic graph relation’s names

they use.

We show each triple builder with
e the actual core.logic query,
e an example input sentence,

e the corresponding semantic graph for the input sentence, with highlights for the relevant

nodes and edges to make it easier to follow along,

e a table of the triples that it found when run on the input sentence, displaying the lemmas

of its subject, predicate or object,

e and a discussion of the triple builder.

23Note that we deviate from the core.logic convention of marking a goal with a postfix ° here.


36 4.1. Triple builders

Note that a triple builder may succeed multiple times and thus may find more than one triple.

nsubj-amod

Input text The hungry cat eats.
Query

fresh [subj adj]
noun® subj

depends adj "amod" subj

= triple [subj :be adjj

Triples found
cat | :be | hungry

The meaning of a subject can be modified with an adjectival modifier (amod) [5].
This triple builder captures the fact that cat refers not just to cat but to a hungry cat. Because
there is no node in the graph that can take the role of a predicate, we introduce a derived

predicate :be instead.

nsubj-pred-dobj
Input text It eats the mouse.

Query

eats VBZ

fresh [subject activity object
depends subject "nsubj" activity
depends object "dobj" activity

cond®

[(= triple [subject activity object] )|
[(fresh {[subject2|
depends subject2 ["conj" "and"| subject

= triple |subject2 activity object}) )|

Triples found

it | eat | mouse

This triple builder captures facts from one of the simplest kind of sentences. A subject directly

connected to an object with a predicate.


4. Triples 37

nsubj-VB
Input text The cat eats.

Query

fresh [subj vb]
noun® subj
tag° vb ["VBZ" "VBD" "VBP"|
depends subj "nsubj" vb
= triple {subj :be vb]

Triples found

cat | :be | eat

Some sentences have intransitive verbq™4] and no object. However, they might still contain useful
information.

Here we capture the fact that the cat eats. To do this, the verb becomes our triple object and we
use a derived predicate :be. This mirrors the behavior used in e.g. the triple builder nsubj-amod
for adjectives.

We limit ourselves to sentence with verbs that are in the past tense (tag VBD) or singular
present (tags VBP and VBZ) to not always trigger this triple builder for all sentences with an

nsubj relation between a noun and a verb.

nsubj-adj-cop
Input text The cat is often full.

Query

fresh [subject adj cop|
depends subject "nsubj" adj
depends cop "cop" adj

= triple [subject cop adj|

Triples found
cat | be | full

This triple builder captures adjectives of subjects, e.g. that the cat is full.
We can qualify the object full with an additional triple. See the next triple builder nsubj-advmod.

4verbs with no object


38 4.1. Triple builders

nsubj-advmod
Input text The cat is often full.

Query

fresh {subject predicate advmod cop]

advmod depends subject "nsubj" predicate

det = triple [subject predicate advmod] )|

depends advmod "advmod" predicate
cond®

[(verb° predicate

[(= triple [predicate :be advmod])|

Triples found

full | :be | often

In combinations with nsubj-adj-cop finds additional descriptions of an adjective, but also
additional properties of subjects.
Following e.g. the triple builders nsubj-amod or nsubj-VB, :be is used as our predicate again.

The object from the triple found in the example of nsubj-adj-cop full is qualified here with often.

nsubj-pred-acomp
Input text It looks hungry.

Query

looks vBz

acomp depends subject "nsubj" activity

fresh {subject activity acomp|

depends acomp "acomp" activity

= triple [subject activity acomp|

Triples found
it | look | hungry

Verbs and adjectives have an acomp (adjectival complement) relation, if an adjective can be
treated as the verb’s object [5}.
The triple extraction is straightforward. The adjective becomes the triple’s object. The verb’s

subject the triple’s subject and the verb itself the predicate.


4. Triples 39

nsubj-pred-xcomp

managed VBD

xcomp

Input text He managed to enter the house.

Query

fresh [subject activity xcomp object relation|
depends subject "nsubj" activity

depends xcomp "xcomp" activity

depends object relation xcomp
member?® relation {"advmod" "dobj"|
cond®

[(= triple [subject activity xcomp] |

det

[(= triple [subject xcomp object])|

Triples found
he

he

enter is an open clausal complement (xcomp) of managed. enter does not have its own subject
but refers to the subject of managed (He) [5}.
There are two useful triples that can be extracted from the graph. One is the fact that He

manage | enter

enter house

managed to do something (enter) and one is a fact about what He entered (the house).

nsubjpass-pred-agent

auxpass

Input text He is swayed by a warning.

Query

agent

det

fresh [subject predicate object;
depends subject "nsubjpass" predicate
depends object "agent" predicate

= triple jobject predicate subject]

Triples found
warning | sway | he

An agent is “introduced by the preposition by” [5]. This also implies a passive subject (he),
which we will use for our triple’s object. The agent (warning) is used as the triple’s subject,

because it does something with the passive subject.


40 4.1. Triple builders

agent-ccomp-dobj
Input text It is known by X that you do Y

known VBN

Query

auxpass nsubjpass_ | (fresh |jagent object predicate ccomp|

depends agent "agent" predicate
depends ccomp "ccomp" predicate
depends object "dobj" ccomp
= triple jagent :about object]

mark

Triples found

This triple builder extracts the fact that X talks about Y. Because there is no direct graph node

we could use for the predicate here, we introduce another derived predicate :about.

Any other information from this sentence, will be captured by other triple builders.

possessive
Input text John’s house is red.

Query

fresh [subject object]
depends subject "poss" object
} .
noun® subject
noun® object

= triple {subject :have object

Triples found

John | shave | house

We want to determine what kind of possessions a subject has. The semantic graph has the
relation poss (possession modifier) for this. Because we are missing a direct predicate in the

graph, we introduce a derived predicate :have.


4. Triples 41

nsubjpass-ccomp
Input text X and Y are connected as are B and

C
Query

fresh {subjl predicate subj2 reln1 reln2|

connected VBN

auxpass

depends subjl reln1 predicate
depends subj2 reln2 predicate

member? reln1 |"nsubjpass" "ccomp"|

member? reln2 |"nsubjpass" "ccomp"|

depends subjl ["conj" "and"| subj2
cond®
Jeon and [(= triple |subj1 predicate subj2] )|

[(= triple |subj2 predicate subj1|)|

Triples found

c | connect | b
b | connect

y | connect | x
x | connect | y

The query searches for nouns that are connected via some predicate and have a clausal
complement (ccomp) or passive nominal subject (nsubjpass) relation with it.

Because the subject /object-order of the nouns in the resulting triple shouldn’t matter, the query
is allowed to succeed for all possible combinations of them, with the additional constraint that
the nouns have to be connected via some conjunction. This prevents extracting wrong triples,

like e.g. “b connect x”,

Counterexample. This triple builder sometimes finds information that is obviously wrong. If
we vary the sentence a little bit by changing “connected” to “proven”, we get essentially the same
semantic graph and triples with wrong information.

Running the triple builder on the sentence ,,X and Y are proven as are B and C” would return

the triples

y | prove | x
x | prove | y
c | prove | b
b | prove | c

Clearly this is wrong, “proven” is an intransitive verb here and X and Y did not “prove”
each other, but were proven by some (in this case unknown) agent.

There is something missing here. Integrating a verb ontology might help to determine if a verb
is transitive or intransitive.

In the case of intransitive verbs a more appropriate result (matching the triples found by the

triple builder nsubj-VB) would be:
x | :be | prove
y | :be | prove
c | :be | prove
b

:be | prove


42

4.1. Triple builders

prep-noun

have VBP

They PRP distance NN

Input text They have a distance of 2 cm.

Query

fresh [obj subj activity prep|
depends obj |"prep" prep| subj
noun® obj
noun® subj

project [prep]

= triple [subj (keyword prep) obj|

Triples found

distance | ‘of | cm

This triple builder captures preposition between two nouns (or pronouns). Because CoreNLP

collapses prepositions, we introduce derived predicates for each preposition. In this case because

of the edge between the subject and object (prep of) the predicate will be :of.

noun-prep-noun

prep_in

prep_as

Input text X is in the same state as Y

Query

fresh [obj subj prep activity]
depends subj "nsubj" activity
depends obj |"prep" prep) activity
noun® obj
noun® subj
verb° activity
cond®
| project [prep|
= triple [subj (keyword prep) obj]) )|
[(= triple [subj activity obj]

Triples found
be

tin

x state

xX state

The complement to prep-noun that captures preposition that are indirectly connected to a noun.

Like in prep-noun we again use a derived predicate for capturing the preposition. Because the

nouns are not connected directly, we let the query succeed twice. Once for capturing the prepo-

sition as our predicate (:in) and once for capturing the actual predicate from the graph (is).


4. Triples 43

noun-num
Input text He has 5 apples.

has VBZ Query

dobj

fresh [unit num|

nsubj

depends num "num" unit
noun® unit
tag° num ["CD"|

= triple junit :be num|

Triples found
apple | :be | 5

This triple builder captures numeric modifiers (num) [5] of nouns, e.g. how many of apples there
are (5).

Because we are missing a direct predicate in the graph, we will use the derived predicate :be.

advmod-npadvmod-num
Input text A is 10 cm wide.

Query

fresh [advmod unit num|
cond®

nsubj npadverod ‘(depends advmod "advmod" | Ivar) )|

[(word-map advmod

A DT featurec advmod {:tag "JJ"})|

depends unit "npadvmod" advmod

depends num "num" unit

= triple [advmod :be unit|

Triples found

wide | ‘be | cm
The complement to noun-num to capture the unit of a measurement.

Table [4.1] shows all triples that are captured by running them on an example text that is used
in Chapter [5] to draw a graph from the text.

Looking at the table it is clear that all necessary information for this is available, however we
currently do not have any way of discerning if an instance of e.g. “distance” is the same as

another instance of “distance” or what “it” refers to.


44 4.2. Reifying triples

4.2. Reifying triples

Currently the triples’ subjects or objects refer to one word map only. For example, looking at
Table [4.1] we see several subjects with a “Test” or “it” lemma. There is no way that we can know

if the instances refer to the same entity or to distinct entities.

By using the same-as relation we build in Section we can group the triples’ subjects and
objects with all other words in the knowledge base that can be treated as refering to the same

entity, reifying the triples.

If we apply same-as to every subject and object of our triples our table might look like Table [4-2]
where the subjects and objects are replaced by the word groups that the original word belonged

to.

Example. Let us look at the coreference clusters found by CoreNLP for our input text. This

Node Noname |2:1-3]
node Noname [3:13-15]

gives us an approximation of what the same-as relation looks like:

node End |0:5-7|

If we look at the subject word map w of the triple

Test go End
And we search for every v for which (same-as w v) holds, we get the word group?”
Edge (0,1), Test (0,2), it (1,1), Edge (4,1)

Edge Test [4:1-3]
Edge Test [0:1-3]

node End [3:4-6}

Because working with a list of word maps is cumbersome and also hard to refer to, we give
each word group a unique name. A word group’s name is made up of the nouns (this excludes
Wh-words or pronouns) of each word in the group. Because some names may not be unique,
we add a number to it. We increment the number every time there is a duplicate name for a
group.

A predicate can be derived or refer to a concrete word map. We simply reify the predicates by
making them all derived. For non-derived predicates we use it’s lemma and derived predicates

are copied verbatim. This essentially also groups the predicates together.

The result of applying these steps to Table [4.2] can be seen in Table

Example. There are three word groups with the same name: cm-0, cm-1, cm-2

Because they all refer to separate entities, they all have a unique number.

25The numbers correspond to the word maps sentence and token index (sentence, index).


4. Triples 45

Example. In Table [4.2] the predicate connect occurs several times as (potentially distinct) word
maps. In Table [4.3] we reduced them all to a single :connect.

To allow clients to access the reified triple, we update the knowledge base from Section [3.4] with

a new relation:

(triple t)
triple is a unary relation and we simply add every triple we found to it. Clients can then access

any information from the triple by unifying with t. A reified triple is a map that has the following

schema:

{:subject {:symbol word group name
:group vector of word maps}
‘predicate predicate

‘object same layout as :subject}


46 4.2. Reifying triples

Table 4.1.: Result of running all triple builders on the input text:
Edge Test goes to node End and starts at node Start. It is 15 cm
long. Node Noname and node Start have a distance of 10 cm. Node
Start and node End are connected as are node Start and node Noname.
Edge Test is 4 cm long.
Each row shows a captured triple with its subject, predicate and object and the
triple builder that created it.

Subject Predicate Object Triple builder

Start have distance :nsubj-pred-dobj
Noname have distance :nsubj-pred-dobj
Start have distance :nsubj-pred-dobj
distance :of cm :prep-noun

long ‘be cm :advmod-npadvmod-num
cm ‘be 4 :noun-num

Test go End :noun-prep-noun
Test :to End :noun-prep-noun
long :be cm :advmod-npadvmod-num
cm :be 10 :noun-num

Test start Start :noun-prep-noun
Test cat Start :noun-prep-noun
cm :be 15 :noun-num

Test be long :nsubj-advmod

it be long :nsubj-advmod
Noname connect Start :nsubjpass-ccomp
Start connect Noname _ :nsubjpass-ccomp
End connect = Start :nsubjpass-ccomp
Start connect End :nsubjpass-ccomp
Test :be be :nsubj-VB
Noname :be have :nsubj-VB

it :be be :nsubj-VB

Test ‘be start :nsubj-VB

Start ‘be have :nsubj-VB

Test :be go :nsubj-VB


4. Triples

A7

Table 4.2.: Grouped triples based on Table [4.1]
Predicate Object word group

Subject word group

node (0,10), Start (0,11), node (2,4), Start
(2,5), Node (3,1), Start (3,2), node (3,10),
Start (3,11)

Node (2,1), Noname (2,2), node (3,13),
Noname (3,14)

node (0,10), Start (0,11), node (2,4), Start
(2,5), Node (3,1), Start (3,2), node (3,10),
Start (3,11)

distance (2,8)

long (4,6)

cm (4,5)

Edge (0,1), Test (0,2), it (1,1), Edge (4,1),
Test (4,2)

Edge (0,1), Test (0,2), it (1,1), Edge (4,1),
Test (4,2)

long (1,5)

em (2,11)

Edge (0,1), Test (0,2), it (1,1), Edge (4,1),
Test (4,2)

Edge (0,1), Test (0,2), it (1,1), Edge (4,1),
Test (4,2)

cm (1,4)

Edge (0,1), Test (0,2), it (1,1), Edge (4,1),
Test (4,2)

Edge (0,1), Test (0,2), it (1,1), Edge (4,1),
Test (4,2)

Node (2,1), Noname (2,2), node (3,13),
Noname (3,14)

node (0,10), Start (0,11), node (2,4), Start
(2,5), Node (3,1), Start (3,2), node (3,10),
Start (3,11)

node (0,5), end (0,6), node (3,4), end (3,5)

node (0,10), Start (0,11), node (2,4), Start
(2,5), Node (3,1), Start (3,2), node (3,10),
Start (3,11)

Edge (0,1), Test (0,2), it (1,1), Edge (4,1),
Test (4,2)

Node (2,1), Noname (2,2), node (3,13),
Noname (3,14)

Edge (0,1), Test (0,2), it (1,1), Edge (4,1),
Test (4,2)

Edge (0,1), Test (0,2), it (1,1), Edge (4,1),
Test (4,2)

node (0,10), Start (0,11), node (2,4), Start
(2,5), Node (3,1), Start (3,2), node (3,10),
Start (3,11)

Edge (0,1), Test (0,2), it (1,1), Edge (4,1),
Test (4,2)

have

have

have
:of
be
be
go
:to
:be
be

start

at

ibe

be

be

connect

connect

connect

connect

be

ibe

be

tbe

:be

:be

distance (2,8)

distance (2,8)

distance (2,8)

cm (2,11)

cm (4,5)

4 (4,4)

node (0,5), end (0,6), node (3,4), end (3,5)

node (0,5), end (0,6), node (3,4), end (3,5)

cm (1,4)

10 (2,10)

node (0,10), Start (0,11), node (2,4), Start
(2,5), Node (3,1), Start (3,2), node (3,10),
Start (3,11)

node (0,10), Start (0,11), node (2,4), Start
(2,5), Node (3,1), Start (3,2), node (3,10),
Start (3,11)

15 (1,3)

long (4,6)

long (1,5)

node (0,10), Start (0,11), node (2,4), Start
(2,5), Node (3,1), Start (3,2), node (3,10),
Start (3,11)

Node (2,1), Noname (2,2), node (3,13),
Noname (3,14)

node (0,10), Start (0,11), node (2,4), Start
(2,5), Node (3,1), Start (3,2), node (3,10),
Start (3,11)

node (0,5), end (0,6), node (3,4), end (3,5)
be (4,3)

have (2,6)

be (1,2)

start (0,8)

have (2,6)

go (0,3)


4.2. Reifying triples

Table 4.3.: Reified triples based on Table [4.2]

Subject Predicate Object
node-start-0 shave distance-0
node-noname-0 shave distance-0
distance-0 :of cm-2

long-O :be cm-1

cm-1 :be num-4-0
edge-test-0 ‘go end-node-0
edge-test-0 ‘to end-node-0
long-1 ‘be cm-0

cm-2 :be num-10-0
edge-test-0 ‘start node-start-0
edge-test-0 cat node-start-0
cm-0 ‘be num-15-0
edge-test-0 ‘be long-O
edge-test-0 ‘be long-1
node-noname-0  :connect —_—node-start-0
node-start-0 :connect node-noname-0
end-node-0 :connect —_-node-start-0
node-start-0 :connect —end-node-0
edge-test-0 :be be-1
node-noname-0 :be have-0
edge-test-0 :be be-0
edge-test-0 :be start-0
node-start-0 :be have-0
edge-test-0 ‘be go-0


oF wn

4. Triples 49

4.3. Exporting an OWL ontology

We create an OWL class for every subject and object word group of a triple. OWL 2 introduces
a feature called punning [9] where we create an individual for each of our classes and then use

object properties on these individuals to describe relationships between the classes.

Because a triple’s predicate describes a relationship between its subject and object, we use an
object property with a name based on the predicate and add an axiom to the ontology that links

the subject’s individual with the object’s individual via this object property.

A subject or object word group contains word maps that have additional information about that
group, such as all of the actual words (tokens) that make up the group. We add this information

as datatype properties to the subject’s or object’s individual.

Figure [4.1] shows a subset of an ontology that is based on Table The “has individual” loops
are an artifact of our use of punning. Even though node-start-0, node-noname-0 and num-10-0
are only shown as individuals, they are still represented as classes (and as subclasses of Thing)

in the full ontology.

has subclass has individual _ has individual

node-noname-O

node-start-0O

have

Figure 4.1.: A view on the ontology that is extracted from Table

Example. We can query the ontology using SparQL. E.g. to return all subject word groups with

their constituent tokens that are linked to the word group distance-0, we can run the following

query:

PREFIX : <http://clide.informatik.uni-bremen.de/clide-nlp#>
SELECT ?subject ?token WHERE {

?subject :have :distance-0.

?subject :hasToken ?token

}

Query result:
subject ?token

node-noname-0 “Noname”
node-noname-0 “Node”
node-noname-0 “node”
node-start-0 “Start”

node-start-0 “node”





51

5. Use case: Graph creation from a natural language

specification

This chapter introduces an example application that can create graphs from a text. The appli-
cation is directly integrated into clide-nlp and uses the reified triples introduced in Section

as its input.

The application and its input can be seen in the reconciler’s dependency graph Figure [3.2] and

is named :draw there.

The output is a graph with the nodes and edges as described in the text and a list of warnings

about ambiguous or incomplete information extracted from the triples.
The application should detect
e named nodes,
e edges that are directly specified with a name,
e edges that are indirectly specified as a connection between two nodes, and
e edge lengths.
Emit warnings when there are
e simple contradictions, like different lengths for the same edge,
e unfinished edge or node specifications,
e sentences that specify the same node or edge twice, and
e non-integer edge lengths.

To achieve these goals, we must specify what kind of sentences we would like to understand. We

can specify edges with the following sentences:

Type Sentence example

Unnamed edges | Node A and Node B are connected.

Named edges Edge B starts at Node A and goes to Node B.
Edge distance Edge B is 5 cm long.

Edge distance Node A and Node B have a distance of 5 cm.

Nodes are specified implicitly by mentioned e.g. “Node A” somewhere in the text.
Distances have a unit and magnitude. We only support “cm” as a unit.

Because we use triples as the basis of our application, we can structure the sentences differently,


52 5.1. Triple walks

while keeping the triple set the same.

Example. Extracting triples from the sentences

Node A and Node B are connected. Node A and Node B have a distance of 5 cm.
and the sentence

Node A and Node B are connected with a distance of 5 cm.

will result in the same set of triples.

5.1. Triple walks

We define some helper goals that let us define a walk that follows a chain of triples, and allows

us to essentially pattern match on that chain.

(subject°—> ¢ & clauses)

A subject walk succeeds if t = (So, Py, Oo) can satisfy each of the clauses. t is the triple we start
with.

So Po Oo So Po Oo
S PhO Oy So Pro On
=>
Sn Pn On So Pn On

(a) (b)

Figure 5.1.: Illustration of how a subject walk beginning with triple t, threads t’s subject through
the whole triple chain.

A clause can be a tuple with a predicate and object or a 3-tuple in which case the last element
is a partial match of a word map in the So’s word group.
We thread the subject of t through each of the clauses. This is illustrated in Figure [5.1]


o FW dN Fr

5. Use case: Graph creation from a natural language specification 53

Example. We define the following subject walk to find = an_ edge:
So :start O; where a word map in Sp must match {:lemma "Edge" }

So at O71
So :gO Oz
So ‘to Oz

We use QO; and QO in multiple clauses to make sure that the clauses only match the same object
group.
Looking at Table we can find a triple for which the walk succeeds: t =
(edge-test-0, :start, node-start-0)

edge-test-0 start node-start-0

edge-test-O :at node-start-0

edge-test-O :go  end-node-0

edge-test-O :to — end-node-0

We can run that walk with subject°— inside a core.logic query:

(subject°— t

start O; {:lemma "Edge"}|

[:at O71|

go O2)

/:to O2))
If the subject°— goal succeeds, O; will be bound to node-start-node-0 and Oz to end-node-0.
We can then extract more information out of them, if necessary and perform some additional
validation.

(object°> t & clauses)

The counterpart to subject°— that matches on the triples’ objects first (see Figure |5.2).

So Po Oo So Po Oo

Figure 5.2.: Illustration of how an object walk beginning with triple t, threads the object of each
consecutive triple through the triple chain.



er WwW dw Fe

54 5.1. Triple walks

Example. We define an object walk to get the distance between the nodes of our edge. We
assume that the previous subject walk succeeded with t = (So, Po, Oo).

Oo :have Os where a word map in O3 must match {:lemma "distance" }
O3 :of O4
O, ibe Os5 where a word map in Os must match {:tag "CD"}

The walk succeeds, if we start with the triple t = (edge-test-0, :start, node-start-0) and follow the

triples:
node-start-0 :have distance-0
distance-0 :of cm-2
cm-2 :be num-10-0

We can run that walk with object°— inside a core.logic query:

(object°—> t
[have O3 {:lemma "distance" }|
[:of O4|
be Os {:tag "CD"}))

If the object°— goal succeeds and O3, O4, and Os are logic variables, they will be bound to
distance-0, cm-2, and num-10-0 respectively.

We can then extract more information out of them, if necessary.



5. Use case: Graph creation from a natural language specification 55

5.2. Implementation

We implement several collection stages that search the triples for relevant information. The

general process follows these steps:

KH

Collect node

2. Collect edges

3. Check found edges for inconsistencies
4. Check for singleton nodes

Each stage might emit warnings about inconsistencies, which we need to present to the user

later.

The node and edge collecting stages make use of subject and object walks to extract the infor-

mation that we need to create a graph.

Example. If we combine the object walk with the subject walk in our previous examples, we

get an edge with the distance between its nodes:
e The group So = edge-test-0 contains the edge label ( Test)
e The group Os = num-10-0 is the edge’s length
e The group O4 = cm-2 contains the edge length’s unit

An edge’s or node’s label is extracted by using the word that is immediately next to it in the
original text.

Extracting the edge’s length and unit is easy, because Os and Oy, are word groups with only a
single word map, so we can simply use that word map’s lemma. We then check if the length is

an integer and the unit is one of the supported units (cm).

The output of our example application is presented to the users as additional annotations:

draw Level: Chunk

Edge Test goes to node End and starts at node Start.

It is 2 cm long.

Node Noname and node Start have a distance of 1 cm.

Node Start and node End ate connected as are node Start and
node Noname. Edge Test is cm long.

o-o<cs

Shows the graph that was extracted from the chunk’s text. The input text contains some

ambiguities, which means the graph is not looking like we want it to look. The double edge

between nodes “Start” and “End” looks especially suspicious.


56 5.2. Implementation

draw-warnings and draw-warning-highlights Level: Chunk

Edge Test goes to node End and starts at node Start.

It is 2 cm long.

Node Noname and node Start have a distance of 1 cm.

Node Start and node End are connected as are node Start and
node Noname. Edge Test is 1 cm long.

Edge edge-test-2 is specified multiple times

Suggestions
e Check the sentences below

Affected words
Sentence 0

Edge Test goes to node End and starts at node Start.
@ node [5]
e End [6]
@ node [10]
@ Start [11]

Sentence 2

Node Noname and node Start have a distance of 1 cm.
@ node [4]
e Start [5]

Sentence 3

Node Start and node End are connected as are node Start and node Noname.
®@ Node [1]

Start [2]

node [4]

End [5]

node [10]

Start [11]

Edge end-node-9->node-start-@ has no length

Suggestions
e Add a sentence like Edge B is 5 cm long. OF Node A and Node B have a distance of 2 cm.

The information collecting stages emit warnings about potential problem areas in our input text.
We display some information about which sentences and words might be problematic and some

suggestions about how to resolve the warnings.
Here we can see that the edge “Test” is specified twice which explains the double edge we saw

earlier.


6.

57

Conclusion

We have shown how we can extract information from a text in a straightforward way, while only

using the simple tools provided by CoreNLP, and what kind of problems result in integrating

such a system into a distributed development environment like Clide.

To achieve our initial goals, we have taken the following approach:

1.

We provide an underlying NLP knowledge base (see Section for an input text based

on CoreNLP’s dependency parser and its coreference resolution system.

. The reconciler (see Section |3.2) makes sure that text changes sent by Clide are integrated

into the knowledge base, and keeps the ontology and annotations up to date and in sync
with the input text while making sure to only update them when really necessary. Because
coreference resolution is a slow process, and we need to rerun it after each text change, we

split the input text into chunks and only operate on one chunk at a time.

. Triple builders (see Chapter are simple queries on the knowledge base that extract

meaningful units of information from the text’s semantic graphs in the form of triples

(subject, predicate, object).

. The triples extracted from the queries are augmented by grouping their subjects and ob-

jects according to the coreference chain they belong to, yielding an ontology with unique
classes (word groups). We provide an example for how to export an OWL ontology (see
Section |4.3), so that the ontology can be used by other tools.

. We expose the underlying structure of sentences and texts to the user by providing anno-

tations that visualize that structure in Clide (see Section |3.5).

. In Chapter [5] we have shown how the ontology can be used to create graphs from a simple

natural language specification and how using triples enables sentences in the input text

with slightly different phrasing to still yield the same ontology and graph.

There are some (solvable) caveats to our approach:

e Some triples we extract make no sense. This is a symptom of missing information and of

the triple builders’ simplistic nature. E.g. some triple builders like nsubjpass-ccomp are

limited, because there is currently no way to determine a verb’s transitivity.

e At the moment we ignore all tenses and merge potentially different states of word groups

in different time frames (as indicated e.g. by a triple’s predicate’s tense) into one ontology.
Using a verb ontology in combination with the predicates’ part-of-speech tags, we could

split the ontology into separate ontologies, one for each time frame. We could then e.g.


58

track the changes of a word group’s attributes over time.

e Currently the ontology we create has no concept hierarchy. We could integrate WordNet
to group word groups that have the same concept behind them under one umbrella via e.g.

is-a relationships in the ontology.

e At the moment the ontologies we extract are limited to one chunk of a text only. It should
be possible to develop some heuristics that would allow us to merge the ontologies of two

or more chunks together into one ontology.

e clide-nip is limited by Clide’s current behavior to keep annotations static and to limit the
assistants direct influence to the server-side only. A client side integration could enable
some interactive aspects, like e.g. defining a new triple builder on the fly and using Clojure’s

dynamic aspects to make it available to the system immediately?)

The tools we created while building the assistant are general enough to be used outside of
Clide and could be integrated into other editing environments. Our NLP knowledge base with
information from CoreNLP’s semantic graphs, its coreference resolution system, and the ontology

we extracted from them, provides easy access to information about a text.

Exposing Clojure’s and clide-nlp’s dynamic natures in Clide’s interface and combining it with
Clide’s collaborative aspects can enable an environment and framework where we can quickly
and collaboratively develop simple systems that have some albeit limited and domain specific

text understanding.

26This is possible already, but not exposed to the user in the UI.


A. Part of Speech Tags

59

The part of speech tags used by CoreNLP are based on the tags used by the Penn Treebank [15].
There are however some differences. Table [A-1] shows an updated version of the part of speech
tag table in p. 317| based on experience with CoreNLP. As such this table is most likely

incomplete, but enough to follow the examples in this report.

Table A.1.: An incomplete list of part of speech tags used by CoreNLP based on p. 317|

CC
cD
DT
EX
FW
IN
JJ
JJR
JJS
LS
MD
NN
NNS
NNP
NNPS
PDT
POS
PRP
PPS
RB
RBR
RBS

Coordinating conjunction

Cardinal number
Determiner
Existential there
Foreign word

Preposition/subordinating conjunction

Adjective

Adjective, comparative
Adjective, superlative
List item marker
Modal

Noun, singular or mass
Noun, plural

Proper noun, singular
Proper noun, plural
Predeterminer
Possessive ending
Possessive pronoun
Possessive pronoun
Adverb

Adverb, comparative
Adverb, superlative

ie
UH
VB
VBD
VBG
VBN
VBP
VBZ
WDT
WP
WPS
WRB
RP

$

-LRB-
-RRB-

to

interjection

Verb, base form

Verb, past tense

Verb, gerund/present participle
Verb, past participle

Verb, non-3rd ps. sing. present
Verb, 3rd ps. sing. present
wh-determiner

wh-pronoun

Possessive wh-pronoun
wh-adverb

Participle

Currency sign

Sentence-final punctuation ! ? .
Comma

Colon, semi-colon

Left bracket ( [ { character
Right bracket ) ] } character
Left (double or single) quote
Right (double or single) quote





61

B. Installation notes

The CD that accompanies this report contains three ZIP files:

Filename Contents

report. pdf A digital copy of this report

clide-nlp-src.zip The source code for clide-nip

clide-src.zip The source code to a version of Clide that works correctly with clide-nlp
clide-nlp.zip Contains an executable JAR of clide-nlp and startup scripts

clide-nlp requires Java 7 and Clide works best with a WebKit-based browser like e.g. Chrome.
You need approx. 3 GiB of RAM to successfully run clide-nlp. To execute it:

e Extract clide-nlp.zip and run run.sh on Linux/FreeBSD or run. bat on Windows.
e Wait a minute or two.

e A launcher window will pop up that informs you about the startup process.

e After the system is ready, clide-nlp should inform you that it is ready at http: //localhost:
(14000)

e Open the URL and log in with user clide-nlp and password clide-nlp.
e Open the clide-nlp/Example project and look at 00-README.txt for further help.

e And most importantly, try editing one of the files!




List of Figures

1.1

12

1.3

3.1
3.2

4.1

5.1

5.2

The clide-nlp annotation semantic-graph showing the semantic graph for the cur-

rent sentence (highlighted in blue). ......

The clide-nlp annotation reified-triples showing

the triples that are found for the

given text and the annotation same-as highlighting all words that are detected as

belonging together in red. The highlighted words are part of the group Edge-Test-it-0.

Showing all annotation from the example application draw, draw-warnings and

draw-warning-highlights that draws the graph sp

Architecture overview .............

Chunk annotation dependency graph... . .

ecified in the text. .........

A view on the ontology that is extracted from Table|4.3) ..............

Illustration of how a subject walk beginning with triple t, threads t’s subject

through the whole triple chain. ........

Illustration of how an object walk beginning with triple t, threads the object of

each consecutive triple through the triple chain

63

is]




65

Bibliography

[1]

[2|

[3

—_—

[4]

[5]

[6

=

[7|

[8

—_—

[9|

[10]

[11]

[12]

AUER, S., BIZER, C., KOBILAROV, G., LEHMANN, J., CYGANIAK, R., AND IVES, Z.
DBpedia: A Nucleus for a Web of Open Data. In The Semantic Web. Springer, 2007,
pp. 722-735.

Byrp, W. E. Relational programming in miniKanren: Techniques, applications, and im-

plementations. PhD thesis, Indiana University, 2010.

CHKLOVSKI, T., AND PANTEL, P. VerbOcean: Mining the Web for Fine-Grained Semantic
Verb Relations. In EMNLIP (2004), vol. 2004, pp. 33-40.

DE MARNEFFE, M.-C., MACCARTNEY, B., MANNING, C. D., ET AL. Generating typed

dependency parses from phrase structure parses. In Proceedings of LREC (2006), vol. 6,
pp. 449-454.

DE MARNEFFE, M.-C., AND MANNING, C. D. Stanford typed dependencies manual.
Manual, Stanford NLP Group, Stanford University, September 2008. Revised in December
2013 for the Stanford Parser v. 3.3.

EMERICK, C., CARPER, B., AND GRAND, C. Clojure Programming. O’Reilly Media, Inc.,
2012.

Focus, M., AND Houser, C. The Joy of Clojure: Thinking the Clojure Way. Manning
Publications Co., 2011.

FRIEDMAN, D. P., ByrRD, W. E., AND KISELYOv, O. The Reasoned Schemer. MIT Press,
2005.

GOLBREICH, C., WALLACE, E. K., AND PATEL-SCHNEIDER, P. F. OWL 2 Web Ontology
Language: New Features and Rationale. W3C Recommendation (2012).

HITZLER, P. Semantic Web: Grundlagen. eXamen.press. Springer-Verlag, Berlin, Heidel-
berg, 2008.

LEE, H., CHANG, A., PEIRSMAN, Y., CHAMBERS, N., SURDEANU, M., AND JURAFSKY,

D. Deterministic coreference resolution based on entity-centric, precision-ranked rules.

LEE, H., PEIRSMAN, Y., CHANG, A., CHAMBERS, N., SURDEANU, M., AND JURAFSKY,
D. Stanford’s multi-pass sieve coreference resolution system at the CoNLL-2011 shared task.
In Proceedings of the Fifteenth Conference on Computational Natural Language Learning:

Shared Task (2011), Association for Computational Linguistics, pp. 28-34.


66

Bibliography

[13]

[14]

[15]

[16]

[17]

[18]

[19]

[20]

[21]

[22|

Lorp, P. The Semantic Web takes Wing: Programming Ontologies with Tawny-OWL.
arXiv preprint arXiv:1303.0213 (2013).

LOUTH, C., AND RING, M. A web interface for Isabelle: The Next Generation. In Intelligent
Computer Mathematics. Springer, 2013, pp. 326-329.

Marcus, M. P., MARCINKIEWICZ, M. A., AND SANTORINI, B. Building a large annotated
corpus of English: The Penn Treebank. Computational linguistics 19, 2 (1993), 313-330.

MILLER, G. A. WordNet: A Lexical Database for English. Communications of the ACM
38, 11 (1995), 39-41.

RAGHUNATHAN, K., LEE, H., RANGARAJAN, S., CHAMBERS, N., SURDEANU, M., JU-
RAFSKY, D., AND MANNING, C. A multi-pass sieve for coreference resolution. In Proceed-
ings of the 2010 Conference on Empirical Methods in Natural Language Processing (2010),
Association for Computational Linguistics, pp. 492-501.

RECASENS, M., DE MARNEFFE, M.-C., AND Potts, C. The life and death of discourse
entities: Identifying singleton mentions. In Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computational Linguistics: Human Language Tech-
nologies (2013), pp. 627-633.

Rinc, M. Eine webbasierte Entwicklungsumgebung fiir den interaktiven Theorembeweiser

Isabelle. Diplomarbeit, Universitat Bremen, 2013.

RING, M., AND LUTH, C. Collaborative Interactive Theorem Proving with Clide. In
Proceedings of ITP 2014 (2014), Springer.

VARJU, Z., LITTAUER, R., AND ERNIS, P. Using Clojure in Linguistic Computing. In
Proceedings of the 5th European Lisp Symposium (2012).

WYNNE, M., AND HELLESOY, A. The Cucumber Book: Behaviour-driven Development for
Testers and Developers. Pragmatic Bookshelf, 2012.
